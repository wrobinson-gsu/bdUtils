"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication_Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","License","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Foreword","R. B. Bunt","University of Saskatchewan","IEEE Transactions on Software Engineering","","1987","SE-13","3","362","362","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233167","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702222","","Queueing analysis;Fault tolerant systems;FDDI;Token networks;Protocols","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Operations and implementation of complex objects","W. Kim; H. -. Chou; J. Banerjee","Microelectron. & Comput. Technol. Corp., Austin, TX, USA; Microelectron. & Comput. Technol. Corp., Austin, TX, USA; Microelectron. & Comput. Technol. Corp., Austin, TX, USA","IEEE Transactions on Software Engineering","","1988","14","7","985","996","A model of a complex object is presented and a set of meaningful operations, both basic and advanced, on a single complex object and on a configuration of complex objects is defined. A set of requirements is presented for storage subsystems that support complex objects. Implementation of complex objects and operations on a single complex object are described, and a detailed performance analysis is provided which establishes the merit of complex objects. Finally, storage techniques are proposed for supporting advanced operations on a configuration of complex objects.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.42739","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=42739","","Computer aided manufacturing;CADCAM;Artificial intelligence;Performance analysis;Spatial databases;Multimedia databases;Multimedia systems;Database systems;Microelectronics;Information systems","data structures;query languages;relational databases;storage management","relational databases;data structures;query languages;storage management;complex objects;storage subsystems;performance analysis","","23","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Empirical Software Engineering","D. R. Jeffery; L. G. Votta","CAESAR; NA","IEEE Transactions on Software Engineering","","1999","25","4","435","437","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1999.799935","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=799935","","Software engineering;Biological system modeling;Humans;Biology;Biological information theory;Moon;Process design;Laboratories;In vitro;In vivo","","","","3","","","","","","","","IEEE","IEEE Journals & Magazines"
"Incremental design of a power transformer station controller using a controller synthesis methodology","H. Marchand; M. Samaan","IRISA/INRIA, Rennes, France; NA","IEEE Transactions on Software Engineering","","2000","26","8","729","741","The authors describe the incremental specification of a power transformer station controller using a controller synthesis methodology. They specify the main requirements as simple properties, named control objectives, that the controlled plant has to satisfy. Then, using algebraic techniques, the controller is automatically derived from this set of control objectives. In our case, the plant is specified at a high level, using the data-flow synchronous SIGNAL language, and then by its logical abstraction, called polynomial dynamical system. The control objectives are specified as invariance, reachability, ...properties, as well as partial order relations to be checked by the plant. The control objectives equations are synthesized using algebraic transformations.","0098-5589;1939-3520;2326-3881","","10.1109/32.879811","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=879811","","Power transformers;Automatic control;Signal synthesis;Polynomials;Optimal control;Equations;Control system synthesis;Data structures;Boolean functions;Circuit faults","power transformers;power system control;parallel languages;control system synthesis","incremental design;power transformer station controller;controller synthesis methodology;incremental specification;simple properties;named control objectives;controlled plant;algebraic techniques;control objectives;high level specification;data-flow synchronous SIGNAL language;logical abstraction;polynomial dynamical system;invariance;reachability;partial order relations;control objectives equations;algebraic transformations","","20","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Absolute bounds on set intersection and union sizes from distribution information","N. C. Rowe","Dept. of Comput. Sci., US Naval Postgraduate Sch., Monterey, CA, USA","IEEE Transactions on Software Engineering","","1988","14","7","1033","1048","A catalog of quick closed-form bounds on set intersection and union sizes is presented; they can be expressed as rules, and managed by a rule-based system architecture. These methods use a variety of statistics precomputed on the data, and exploit homomorphisms (onto mappings) of the data items onto distributions that can be more easily analyzed. The methods can be used anytime, but tend to work best when there are strong or complex correlations in the data. This circumstance is poorly handled by the standard independence-assumption and distributional-assumption estimates.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.42743","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=42743","","Information retrieval;Distributed computing;Frequency estimation;Algorithm design and analysis;Transaction databases;Knowledge based systems;Computer architecture;Statistical analysis;Statistical distributions;Algebra","Boolean algebra;database theory;file organisation;set theory;statistical analysis","Boolean algebra;file organisation;database access;set theory;statistical analysis;set intersection;union sizes;distribution information;closed-form bounds;rule-based system architecture","","6","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Empirical data modeling in software engineering using radial basis functions","Miyoung Shin; A. L. Goel","Electron. & Telecommun. Res. Inst., Taejon, South Korea; NA","IEEE Transactions on Software Engineering","","2000","26","6","567","576","Many empirical studies in software engineering involve relationships between various process and product characteristics derived via linear regression analysis. We propose an alternative modeling approach using radial basis functions (RBFs) which provide a flexible way to generalize linear regression function. Further, RBF models possess strong mathematical properties of universal and best approximation. We present an objective modeling methodology for determining model parameters using our recent SG algorithm, followed by a model selection procedure based on generalization ability. Finally, we describe a detailed RBF modeling study for software effort estimation using a well-known NASA dataset.","0098-5589;1939-3520;2326-3881","","10.1109/32.852743","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=852743","","Software engineering;Linear regression;Data analysis;Mathematical model;NASA;Programming;Signal processing algorithms;Predictive models;Inspection;Computer aided software engineering","software development management;data models;radial basis function networks;statistical analysis","empirical data modeling;software engineering;radial basis functions;product characteristics;linear regression analysis;alternative modeling approach;linear regression function;RBF models;mathematical properties;best approximation;objective modeling methodology;model parameters;SG algorithm;model selection procedure;generalization ability;RBF modeling study;software effort estimation;NASA dataset","","66","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Correcton to ""SOFL"": A formal engineering methodology for industrial applicatoins","S. Liu; A. J. Offutt; C. Ho-Stuart","NA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","5","390","390","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1998.685261","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=685261","","Biographies;Software engineering;Computer science;Software safety;Typesetting;Educational institutions;Fellows;Programming;Software testing;Computer Society","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"A quantitative model of the security intrusion process based on attacker behavior","E. Jonsson; T. Olovsson","Dept. of Comput. Eng., Chalmers Univ. of Technol., Goteborg, Sweden; NA","IEEE Transactions on Software Engineering","","1997","23","4","235","245","The paper is based on a conceptual framework in which security can be split into two generic types of characteristics, behavioral and preventive. Here, preventive security denotes the system's ability to protect itself from external attacks. One way to describe the preventive security of a system is in terms of its interaction with the alleged attacker, i.e., by describing the intrusion process. To our knowledge, very little is done to model this process in quantitative terms. Therefore, based on empirical data collected from intrusion experiments, we have worked out a hypothesis on typical attacker behavior. The hypothesis suggests that the attacking process can be split into three phases: the learning phase, the standard attack phase, and the innovative attack phase. The probability for successful attacks during the learning and innovative phases is expected to be small, although for different reasons. During the standard attack phase it is expected to be considerably higher. The collected data indicates that the breaches during the standard attack phase are statistically equivalent and that the times between breaches are exponentially distributed. This would actually imply that traditional methods for reliability modeling could be applicable.","0098-5589;1939-3520;2326-3881","","10.1109/32.588541","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=588541","","Data security;Protection;Probability;Particle measurements;Control system synthesis;Testing","computer crime;social aspects of automation;authorisation;message authentication","quantitative model;security intrusion process;attacker behavior;conceptual framework;preventive security;external attacks;alleged attacker;quantitative terms;empirical data;intrusion experiments;attacking process;learning phase;standard attack phase;innovative attack phase;reliability modeling;computer security;operational security","","140","","19","","","","","","IEEE","IEEE Journals & Magazines"
"A Static Analysis of the NAG Library","M. A. Hennell; J. A. Prudom","Department of Computational Science, University of Liverpool; NA","IEEE Transactions on Software Engineering","","1980","SE-6","4","329","333","This paper reports results obtained from a static analysis of the NAG Mark 4 Fortran numerical algorithms library.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230484","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702740","Basic block;compiler;efficiency;Fortrn;LCSAJ optimization","Software libraries;Algorithm design and analysis;Optimizing compilers;Logic testing;ANSI standards;Error correction;Frequency;Automatic control;Application software;Software testing","","Basic block;compiler;efficiency;Fortrn;LCSAJ optimization","","","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Analyzing error-prone system structure","R. W. Selby; V. R. Basili","Dept. of Inf. & Comput. Sci., California Univ., Irvine, CA, USA; NA","IEEE Transactions on Software Engineering","","1991","17","2","141","152","Using measures of data interaction called data bindings, the authors quantify ratios of coupling and strength in software systems and use the ratios to identify error-prone system structures. A 148000 source line system from a prediction environment was selected for empirical analysis. Software error data were collected from high-level system design through system testing and from field operation of the system. The authors use a set of five tools to calculate the data bindings automatically and use a clustering technique to determine a hierarchical description of each of the system's 77 subsystems. A nonparametric analysis of variance model is used to characterize subsystems and individual routines that had either many or few errors or high or low error correction effort. The empirical results support the effectiveness of the data bindings clustering approach for localizing error-prone system structure.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.67595","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=67595","","Error analysis;Software measurement;Software systems;Data analysis;Computer errors;Software testing;System testing;Error correction;Inspection;Computer science","error analysis;program diagnostics;software metrics","error-prone system structure;data interaction;data bindings;software systems;prediction environment;empirical analysis;clustering technique;nonparametric analysis of variance model","","80","","23","","","","","","IEEE","IEEE Journals & Magazines"
"A transformation approach to derive efficient parallel implementations","T. Rauber; G. Runger","Inst. fur Inf., Univ. Halle-Wittenberg, Germany; NA","IEEE Transactions on Software Engineering","","2000","26","4","315","339","The construction of efficient parallel programs usually requires expert knowledge in the application area and a deep insight into the architecture of a specific parallel machine. Often, the resulting performance is not portable, i.e., a program that is efficient on one machine is not necessarily efficient on another machine with a different architecture. Transformation systems provide a more flexible solution. They start with a specification of the application problem and allow the generation of efficient programs for different parallel machines. The programmer has to give an exact specification of the algorithm expressing the inherent degree of parallelism and is released from the low-level details of the architecture. We propose such a transformation system with an emphasis on the exploitation of the data parallelism combined with a hierarchically organized structure of task parallelism. Starting with a specification of the maximum degree of task and data parallelism, the transformations generate a specification of a parallel program for a specific parallel machine. The transformations are based on a cost model and are applied in a predefined order, fixing the most important design decisions like the scheduling of independent multitask activations, data distributions, pipelining of tasks, and assignment of processors to task activations. We demonstrate the usefulness of the approach with examples from scientific computing.","0098-5589;1939-3520;2326-3881","","10.1109/32.844492","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=844492","","Parallel processing;Parallel machines;Programming profession;Microprocessors;Scientific computing;Message passing;Computer architecture;Costs;Processor scheduling;Pipeline processing","bibliographies;parallel programming;formal specification;parallel machines;message passing","transformation approach;parallel implementations;parallel program design;expert knowledge;application area;parallel machine;transformation systems;parallel machines;exact specification;data parallelism;hierarchically organized structure;task parallelism;cost model;predefined order;design decisions;independent multitask activations;data distributions;task pipelining;processor assignment;task activations;scientific computing","","18","","58","","","","","","IEEE","IEEE Journals & Magazines"
"A group-select operation for relational algebra and implications for database machine design","J. Bradley","Dept. of Comput. Sci., Calgary Univ., Alta., Canada","IEEE Transactions on Software Engineering","","1988","14","1","126","129","A group-select operation has been defined for relational algebra. This operation is found to be useful for efficiently reducing expressions of nonprocedural relational languages that permit natural quantifiers. Conceptually, the operation first partitions a relation into blocks of tuples that have the same value for an attribute or attribute concatenation. It then extracts each block for which a specified number of tuples meet a specified condition. The quantity of tuples for the operation is specified by means of a natural quantifier. Performance of the group-select operation will be poor with conventional file processing, making the operation more suitable for use with a database machine with an associative memory.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4630","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4630","","Algebra;Database machines;Relational databases;Remuneration;Calculus;EMP radiation effects;Associative memory;ANSI standards;Standards development;Natural languages","relational databases","relational algebra;database machine design;group-select operation;nonprocedural relational languages;natural quantifiers;tuples;associative memory","","2","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Mechanically verifying concurrent programs with the Boyer-Moore prover","D. M. Goldschlag","Comp. Logic, Inc., Austin, TX, USA","IEEE Transactions on Software Engineering","","1990","16","9","1005","1023","A proof system suitable for the mechanical verification of concurrent programs is described. This proof system is based on Unity, and may be used to specify and verify both safety and liveness properties. However, it is defined with respect to an operational semantics of the transition system model of concurrency. Proof rules are simply theorems of this operational semantics. This methodology makes a clear distinction between the theorems in the proof system and the logical inference rules and syntax which define the underlying logic. Since this proof system essentially encodes Unity in another sound logic, and this encoding has been mechanically verified, this encoding proves the soundness of this formalization of Unity. This proof system has been mechanically verified by the Boyer-Moore prover. This proof system has been used to mechanically verify the correctness of a distributed algorithm that computes the minimum node value in a tree.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58787","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58787","","Logic;Concurrent computing;Encoding;Distributed algorithms;Distributed computing;Computer architecture;Safety;Formal specifications;Computer languages;Runtime","encoding;inference mechanisms;parallel programming;program verification;theorem proving","mechanically verifying concurrent programs;Boyer-Moore prover;proof system;Unity;safety;liveness;operational semantics;transition system model;concurrency;inference rules;encoding;distributed algorithm","","20","","33","","","","","","IEEE","IEEE Journals & Magazines"
"An optimal algorithm for scheduling soft aperiodic tasks in dynamic-priority preemptive systems","I. Ripoll; A. Crespo; A. Garcia-Fornes","Dept. de Ingenieria de Sistemas, Comput. y Autom., Univ. Politecnica de Valencia, Spain; NA; NA","IEEE Transactions on Software Engineering","","1997","23","6","388","400","The paper addresses the problem of jointly scheduling tasks with both hard and soft real time constraints. We present a new analysis applicable to systems scheduled using a priority preemptive dispatcher, with priorities assigned dynamically according to the EDF policy. Further, we present a new efficient online algorithm (the acceptor algorithm) for servicing aperiodic work load. The acceptor transforms a soft aperiodic task into a hard one by assigning a deadline. Once transformed, aperiodic tasks are handled in exactly the same way as periodic tasks with hard deadlines. The proposed algorithm is shown to be optimal in terms of providing the shortest aperiodic response time among fixed and dynamic priority schedulers. It always guarantees the proper execution of periodic hard tasks. The approach is composed of two parts: an offline analysis and a run time scheduler. The offline algorithm runs in pseudopolynomial time O(mn), where n is the number of hard periodic tasks and m is the hyperperiod/min deadline.","0098-5589;1939-3520;2326-3881","","10.1109/32.601081","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=601081","","Scheduling algorithm;Dynamic scheduling;Processor scheduling;Real time systems;Testing;Delay;Timing;Computer Society;Runtime","scheduling;real-time systems;minimisation;computational complexity;distributed algorithms","optimal algorithm;soft aperiodic task scheduling;dynamic priority preemptive systems;soft real time constraints;priority preemptive dispatcher;EDF policy;online algorithm;acceptor algorithm;aperiodic work load servicing;hard deadlines;aperiodic response time;dynamic priority schedulers;periodic hard tasks;offline analysis;run time scheduler;pseudopolynomial time;earliest deadline first","","25","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Using Larch to specify Avalon/C++ objects","J. M. Wing","Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA","IEEE Transactions on Software Engineering","","1990","16","9","1076","1088","A formal specification of three base Avalon/C++ classes - recoverable, atomic, and subatomic - is given. Programmers derive from class recoverable to define persistent objects, and from either class atomic or class subatomic to define atomic objects. The specifications, written in Larch, provide the means for showing that classes derived from the base classes implement objects that are persistent or atomic and thus exemplify the applicability of an existing specification method to specifying nonfunctional properties. Writing these formal specifications for Avalon/C++'s built-in classes has helped to clarify places in the programming language where features interact, to make unstated assumptions explicit, and to characterize complex properties of objects.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58791","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58791","","Formal specifications;Security;Hardware;Software safety;Writing;Programming profession;Computer languages;Object oriented programming;Specification languages;Sorting","formal specification","Larch;Avalon/C++ objects;formal specification;recoverable;atomic;subatomic;nonfunctional properties;complex properties","","3","","29","","","","","","IEEE","IEEE Journals & Magazines"
"A Bayesian estimation method for the failure rate of a possibly correct program","G. Becker; L. Camarinopoulos","Inst. fuer Prozess & Anlagentechnik. Tech. Univ. of Berlin, West Germany; Inst. fuer Prozess & Anlagentechnik. Tech. Univ. of Berlin, West Germany","IEEE Transactions on Software Engineering","","1990","16","11","1307","1310","An extension of software reliability modeling is introduced to account for the possibility of programs which, after some debugging, contain no more errors. This is achieved by a repetitive application of the Bayes law, each time taking the posterior of the last step as a prior for the next one. A class of conjugate priors considerably facilitates this modeling. The resulting model includes an estimator for the probability that a program still contains errors, which is an upper bound for the failure probability.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.60318","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=60318","","Bayesian methods;Software reliability;Error correction;Debugging;Application software;Upper bound;Error probability;Artificial intelligence;Statistics","Bayes methods;probability;software reliability","prior step;Bayesian estimation method;failure rate;possibly correct program;software reliability modeling;Bayes law;posterior;last step;conjugate priors;estimator;upper bound;failure probability","","15","","5","","","","","","IEEE","IEEE Journals & Magazines"
"Algorithms to Distribute a Database for Parallel Searching","B. Srinivasan; R. Sankar","Computer Centre, Indian Institute of Technology; NA","IEEE Transactions on Software Engineering","","1981","SE-7","1","112","112","Algorithm of Ghosh [1] for distribution of segments over computer network for parallel searchability of multiple segments required by queries have been modified to reduce average running time.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234513","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702807","Computer network;multiple segment queries;parallel search;redundancy","Computer networks;Biographies;Distributed databases;Tin;Testing","","Computer network;multiple segment queries;parallel search;redundancy","","4","","1","","","","","","IEEE","IEEE Journals & Magazines"
"The call-return tree and its application to program performance analysis","S. Kundu","Department of Computer Science, Louisiana State University, Baton Rouge, LA 70803","IEEE Transactions on Software Engineering","","1986","SE-12","11","1096","1098","The notion of a call-return tree is defined to describe the dynamic calling relationship of the procedure and functions in a program execution. It is shown how the call-return tree can be used to compute the live times and the execution times of the various calls made during the execution. The call-return tree can also be used to compute other behavioral metrics such as the depth and height of a call and the number of direct and indirect calls generated from any point. The technique applies uniformly for both nonrecursive and recursive calls. The algorithms take linear time in the length of the source code and the number of calls made during an execution.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313000","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313000","Algorithm;live and execution times;performance;software probe","Vegetation;Software;Silicon;Software algorithms;Probes;Monitoring","program testing;trees (mathematics)","call-return tree;program performance analysis;dynamic calling relationship;program execution;behavioral metrics","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Software Metrics: Guest Editor's Introduction","B. Curtis","NA","IEEE Transactions on Software Engineering","","1983","SE-9","6","637","638","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.235270","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703109","","Software metrics;Software measurement;Measurement techniques;Statistical analysis;Testing;Measurement errors;Failure analysis;Laboratories;Software performance;Performance analysis","","","","3","","","","","","","","IEEE","IEEE Journals & Magazines"
"Software reuse by specialization of generic procedures through views","G. S. Novak","Dept. of Comput. Sci., Texas Univ., Austin, TX, USA","IEEE Transactions on Software Engineering","","1997","23","7","401","417","A generic procedure can be specialized, by compilation through views, to operate directly on concrete data. A view is a computational mapping that describes how a concrete type implements an abstract type. Clusters of related views are needed for specialization of generic procedures that involve several types or several views of a single type. A user interface that reasons about relationships between concrete types and abstract types allows view clusters to be created easily. These techniques allow rapid specialization of generic procedures for applications.","0098-5589;1939-3520;2326-3881","","10.1109/32.605759","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=605759","","Concrete;Software algorithms;Clustering algorithms;Programming profession;Object oriented programming;User interfaces;Application software;Costs;Production;Libraries","software reusability;abstract data types;partial evaluation (compilers);program compilers;user interfaces","software reuse;generic procedure specialization;views;computational mapping;concrete type;abstract data type;user interface;view clusters;partial evaluation;direct manipulation editor","","20","","77","","","","","","IEEE","IEEE Journals & Magazines"
"Design recovery for distributed systems","L. J. Holtzblatt; R. L. Piazza; H. B. Reubenstein; S. N. Roberts; D. R. Harris","Reasoning Inc., Mountain View, CA, USA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1997","23","7","461","472","Two factors limit the utility of reverse engineering technology for many distributed software systems. First, with the exception of tools that support Ada and its explicit tasking constructs, reverse engineering tools fail to capture information concerning the flow of information between tasks. Second, relatively few reverse engineering tools are available for programming languages in which many older legacy applications were written (e.g., Jovial, CMS-2, and various assembly languages). We describe approaches that were developed for overcoming these limitations. In particular, we have implemented an approach for automatically extracting task flow information from a command and control system written in CMS-2. Our approach takes advantage of a small amount of externally provided design knowledge in order to recover design information relevant to the distributed nature of the target system.","0098-5589;1939-3520;2326-3881","","10.1109/32.605763","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=605763","","Software maintenance;Reverse engineering;Software systems;Data mining;Navigation;Productivity;Displays;Software tools;Computer languages;Application software","distributed processing;reverse engineering;software tools;Ada;command and control systems","design recovery;distributed systems;reverse engineering;tools;Ada;tasking constructs;information flow;programming languages;legacy applications;Jovial;CMS-2;assembly languages;command and control system;program understanding","","20","","32","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on ""Formal specification of user interfaces: a comparison and evaluation of four axiomatic approaches"" by U.H. Chi","H. Alexander","STC Technol. Ltd., Newcastle-under-Lyme, UK","IEEE Transactions on Software Engineering","","1988","14","4","438","439","A recent paper (see ibid., vol.11, no.8, p.671-88, Aug. 1985) compared several axiomatic methods of formal specification, one of which was Z. As a result of a comparison made with Z and a similar, but executable, specification language called Me too, it was pointed out that one of the Z specifications given was not correct. In this response, the erroneous function is described and some conclusions are drawn about the process of formal specification.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4665","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4665","","Formal specifications;User interfaces;Displays;Prototypes;Mathematical model","software engineering;specification languages;user interfaces","software engineering;user interfaces;formal specification;specification language;Me too","","","","1","","","","","","IEEE","IEEE Journals & Magazines"
"Diagnosing rediscovered software problems using symptoms","I. Lee; R. K. Iyer","Dept. of Electr. Eng., Hanyang Univ., Seoul, South Korea; NA","IEEE Transactions on Software Engineering","","2000","26","2","113","127","This paper presents an approach to automatically diagnosing rediscovered software failures using symptoms, in environments in which many users run the same procedural software system. The approach is based on the observation that the great majority of field software failures are rediscoveries of previously reported problems and that failures caused by the same defect often share common symptoms. Based on actual data, the paper develops a small software failure fingerprint, which consists of the procedure call trace, problem detection location, and the identification of the executing software. The paper demonstrates that over 60 percent of rediscoveries can be automatically diagnosed based on fingerprints; less than 10 percent of defects are misdiagnosed. The paper also discusses a pilot that implements the approach. Using the approach not only saves service resources by eliminating repeated data collection for and diagnosis of reoccurring problems, but it can also improve service response time for rediscoveries.","0098-5589;1939-3520;2326-3881","","10.1109/32.841113","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=841113","","Software systems;Fingerprint recognition;Databases;Computer Society;Delay;Software measurement;Operating systems;Computer crashes;Software testing;Costs","program diagnostics","symptoms;automatic rediscovered software failure diagnosis;procedural software system;software failure fingerprint;procedure call trace;problem detection location;executing software identification;service response time","","11","","20","","","","","","IEEE","IEEE Journals & Magazines"
"A formal security model for microprocessor hardware","V. Lotz; V. Kessler; G. H. Walter","Corp. Technol., Siemens AG, Munich, Germany; NA; NA","IEEE Transactions on Software Engineering","","2000","26","8","702","712","The paper introduces a formal security model for a microprocessor hardware system. The model has been developed as part of the evaluation process of the processor product according to ITSEC assurance level E4. Novel aspects of the model are the need for defining integrity and confidentiality objectives on the hardware level without the operating system or application specification and security policy being given, and the utilization of an abstract function and data space. The security model consists of a system model given as a state transition automaton on infinite structures and the formalization of security objectives by means of properties of automaton behaviors. Validity of the security properties is proved. The paper compares the model with published ones and summarizes the lessons learned throughout the modeling process.","0098-5589;1939-3520;2326-3881","","10.1109/32.879809","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=879809","","Microprocessors;Hardware;Operating systems;Data security;Application software;Learning automata;Quality assurance;Formal specifications;Context modeling;Access control","microcomputers;security of data;data integrity;automata theory;theorem proving;formal verification;quality management","microprocessor hardware;formal security model;evaluation process;processor product;ITSEC assurance level;E4;integrity;confidentiality objectives;hardware level;operating system;application specification;security policy;abstract function;data space;system model;state transition automaton;infinite structures;security objectives;automaton behaviors;security properties;modeling process;validity proving","","2","","","","","","","","IEEE","IEEE Journals & Magazines"
"Using patterns to design rules in workflows","F. Casati; S. Castano; M. Fugini; I. Mirbel; B. Pernici","Dipt. di Elettronica e Inf., Politecnico di Milano, Italy; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","2000","26","8","760","785","In order to design workflows in changing and dynamic environments, a flexible, correct, and rapid realization of models of the activity flow is required. In particular, techniques are needed to design workflows capable of adapting themselves effectively when exceptional situations occur during process execution. The authors present an approach to flexible workflow design based on rules and patterns developed in the framework of the WIDE project. Rules allow a high degree of flexibility during workflow design by modeling exceptional aspects of the workflow separately from the main activity flow. Patterns model frequently occurring exceptional situations in a generalized way by providing the designer with skeletons of rules and suggestions about their instantiation, together with indications on relationships with other rules, with the activity flow, and with related information. Pattern based design relies on a pattern catalog containing patterns to be reused and on a formal basis for specializing and instantiating available patterns.","0098-5589;1939-3520;2326-3881","","10.1109/32.879813","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=879813","","Computer Society;Proposals;Skeleton;Process control;Control systems;Business communication","bibliographies;workflow management software;object-oriented programming;software reusability;knowledge based systems","rule design;dynamic environments;activity flow;exceptional situations;process execution;flexible workflow design;WIDE project;exceptional aspects;main activity flow;frequently occurring exceptional situations;rule instantiation;pattern based design;pattern catalog;pattern reuse;formal basis","","34","","57","","","","","","IEEE","IEEE Journals & Magazines"
"Formally verified on-line diagnosis","C. J. Walter; P. Lincoln; N. Suri","WW Technol. Group, Ellicott City, MD, USA; NA; NA","IEEE Transactions on Software Engineering","","1997","23","11","684","721","A reconfigurable fault tolerant system achieves the attributes of dependability of operations through fault detection, fault isolation and reconfiguration, typically referred to as the FDIR paradigm. Fault diagnosis is a key component of this approach, requiring an accurate determination of the health and state of the system. An imprecise state assessment can lead to catastrophic failure due to an optimistic diagnosis, or conversely, result in underutilization of resources because of a pessimistic diagnosis. Differing from classical testing and other off-line diagnostic approaches, we develop procedures for maximal utilization of the system state information to provide for continual, on-line diagnosis and reconfiguration capabilities as an integral part of the system operations. Our diagnosis approach, unlike existing techniques, does not require administered testing to gather syndrome information but is based on monitoring the system message traffic among redundant system functions. We present comprehensive on-line diagnosis algorithms capable of handling a continuum of faults of varying severity at the node and link level. Not only are the proposed algorithms on-line in nature, but are themselves tolerant to faults in the diagnostic process. Formal analysis is presented for all proposed algorithms. These proofs offer both insight into the algorithm operations and facilitate a rigorous formal verification of the developed algorithms.","0098-5589;1939-3520;2326-3881","","10.1109/32.637385","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=637385","","Fault diagnosis;Fault tolerant systems;Costs;System testing;Fault detection;Monitoring;Algorithm design and analysis;Formal verification;Resource management","online operation;reconfigurable architectures;software fault tolerance;program diagnostics;program verification;program testing","online diagnosis;formal verification;reconfigurable fault tolerant system;operation dependability;fault detection;fault isolation;FDIR paradigm;fault diagnosis;optimistic diagnosis;pessimistic diagnosis;testing;system state information;system message traffic monitoring;redundant system functions","","33","","40","","","","","","IEEE","IEEE Journals & Magazines"
"Using a Protean language to enhance expressiveness in specification","B. Bloom; A. Cheng; A. Dsouza","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; NA; NA","IEEE Transactions on Software Engineering","","1997","23","4","224","234","A Protean specification language (B. Bloom, 1995) based on structured operational semantics (SOS) allows the user to invent appropriate operations to improve abstraction and readability. This is in contrast to traditional specification languages, where the set of operations is fixed. An efficient algorithm, described by A. Dsouza and B. Bloom (1995), uses binary decision diagrams (BDDs) to verify properties of finite specifications written in a Protean language and provides the basis for a model checker we have developed. The paper provides a synthesis of our work on Protean languages and relates the work to other specification techniques. We show how abstraction and refinement in the Protean framework can improve the effectiveness of model checking. We rewrite and verify properties of an existing Z specification by defining suitable operations. We also show how a Protean language can be used to model restricted I/O automata, action refinement, and 1-safe and k-bounded Petri nets.","0098-5589;1939-3520;2326-3881","","10.1109/32.588539","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=588539","","Specification languages;Algebra;Data structures;Boolean functions;Petri nets;Automata;Process design;Protocols;ISO standards","specification languages;formal specification;rewriting systems;program verification;process algebra","Protean language;expressiveness enhancement;Protean specification language;structured operational semantics;abstraction;readability;specification languages;efficient algorithm;binary decision diagrams;finite specifications;model checker;specification techniques;model checking;Z specification;restricted I/O automata;action refinement;k-bounded Petri nets","","3","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Extracting reusable functions by flow graph based program slicing","F. Lanubile; G. Visaggio","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; NA","IEEE Transactions on Software Engineering","","1997","23","4","246","259","An alternative approach to developing reusable components from scratch is to recover them from existing systems. We apply program slicing, a program decomposition method, to the problem of extracting reusable functions from ill structured programs. As with conventional slicing first described by M. Weiser (1984), a slice is obtained by iteratively solving data flow equations based on a program flow graph. We extend the definition of program slice to a transform slice, one that includes statements which contribute directly or indirectly to transform a set of input variables into a set of output variables. Unlike conventional program slicing, these statements do not include either the statements necessary to get input data or the statements which test the binding conditions of the function. Transform slicing presupposes the knowledge that a function is performed in the code and its partial specification, only in terms of input and output data. Using domain knowledge we discuss how to formulate expectations of the functions implemented in the code. In addition to the input/output parameters of the function, the slicing criterion depends on an initial statement, which is difficult to obtain for large programs. Using the notions of decomposition slice and concept validation we show how to produce a set of candidate functions, which are independent of line numbers but must be evaluated with respect to the expected behavior. Although human interaction is required, the limited size of candidate functions makes this task easier than looking for the last function instruction in the original source code.","0098-5589;1939-3520;2326-3881","","10.1109/32.588543","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=588543","","Software reusability;Data mining;Software quality;Programming profession;Computer Society;Flow graphs;Transforms;Software systems;Equations;Input variables","program diagnostics;flow graphs;software reusability;reverse engineering","reusable function extraction;flow graph based program slicing;reusable components;program slicing;program decomposition method;ill structured programs;data flow equations;program flow graph;transform slice;output variables;transform slicing;domain knowledge;input/output parameters;slicing criterion;decomposition slice;concept validation;human interaction;candidate functions","","72","","44","","","","","","IEEE","IEEE Journals & Magazines"
"A unified high-level Petri net formalism for time-critical systems","C. Ghezzi; D. Mandrioli; S. Morasca; M. Pezze","Dipartimento di Elettronica, Politecnico di Milano, Italy; Dipartimento di Elettronica, Politecnico di Milano, Italy; Dipartimento di Elettronica, Politecnico di Milano, Italy; NA","IEEE Transactions on Software Engineering","","1991","17","2","160","172","The authors introduce a high-level Petri net formalism-environment/relationship (ER) nets-which can be used to specify control, function, and timing issues. In particular, they discuss how time can be modeled via ER nets by providing a suitable axiomatization. They use ER nets to define a time notation that is shown to generalize most time Petri-net-based formalisms which appeared in the literature. They discuss how ER nets can be used in a specification support environment for a time-critical system and, in particular, the kind of analysis supported.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.67597","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=67597","","Time factors;Real time systems;Petri nets;Erbium;Timing;Formal specifications;Mice;Power system modeling;Software prototyping;Prototypes","formal specification;Petri nets;software tools","environment relationship nets;high-level Petri net;time-critical systems;timing;ER nets;time notation;specification support environment","","208","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Automated tuning of parallel I/O systems: an approach to portable I/O performance for scientific applications","Ying Chen; M. Winslett","IBM Almaden Res. Center, San Jose, CA, USA; NA","IEEE Transactions on Software Engineering","","2000","26","4","362","383","Parallel I/O systems typically consist of individual processors, communication networks, and a large number of disks. Managing and utilizing these resources to meet performance, portability, and usability goals of high performance scientific applications has become a significant challenge. For scientists, the problem is exacerbated by the need to retune the I/O portion of their code for each supercomputer platform where they obtain access. We believe that a parallel I/O system that automatically selects efficient I/O plans for user applications is a solution to this problem. The authors present such an approach for scientific applications performing collective I/O requests on multidimensional arrays. Under our approach, an optimization engine in a parallel I/O system selects high quality I/O plans without human intervention, based on a description of the application I/O requests and the system configuration. To validate our hypothesis, we have built an optimizer that uses rule based and randomized search based algorithms to tune parameter settings in Panda, a parallel I/O library for multidimensional arrays. Our performance results obtained from an IBM SP using an out-of-core matrix multiplication application show that the Panda optimizer is able to select high quality I/O plans and deliver high performance under a variety of system configurations with a small total optimization overhead.","0098-5589;1939-3520;2326-3881","","10.1109/32.844494","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=844494","","Application software;Humans;Computer Society;Communication networks;Multidimensional systems;Analytical models;Cost function;Database systems;Resource management;Usability","bibliographies;parallel programming;software portability;natural sciences computing;program diagnostics;input-output programs;matrix multiplication;software libraries","automated tuning;parallel I/O systems;portable I/O performance;scientific applications;usability goals;supercomputer platform;parallel I/O system;user applications;collective I/O requests;multidimensional arrays;optimization engine;high quality I/O plans;human intervention;system configuration;randomized search based algorithms;parameter tuning;parameter settings;Panda;parallel I/O library;IBM SP;out-of-core matrix multiplication application;system configurations;total optimization overhead","","1","","57","","","","","","IEEE","IEEE Journals & Magazines"
"An empirical study of software reuse with special attention to Ada","Nam-Yong Lee; C. R. Litecky","Inf. Syst. Directorate, Korea Inst. for Defense Inf. Syst., Seoul, South Korea; NA","IEEE Transactions on Software Engineering","","1997","23","9","537","549","Over the past several decades, numerous software technologies have been developed for overcoming the software crisis. Among these technologies, reuse has been recognized as one of the most important software technologies. Recently, it has gained substantial attention as a possible solution to the software crisis in Ada and other software communities. The purpose of this empirical study is to examine how organizations actually exploit reuse technologies and evaluates how reuse factors affect the rate of reuse in an organization. This study is an attempt to enhance the measurement of the rate of reuse and the effectiveness of reuse by establishing conceptual foundations in the literature for reuse and conducting an empirical investigation of organizations using Ada technology. This study differentiated software reuse into six criteria: domain, human, tool, organization, software metrics, and environment. The results of this study show that the rate of reuse significantly depends upon reuse capability, software development effort, object-oriented design capability, repository development effort, Ada technology capability, and domain capability.","0098-5589;1939-3520;2326-3881","","10.1109/32.629492","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=629492","","Programming;Software metrics;Software tools;Humans;Software engineering;Regression analysis;Government;Computer industry;Software standards;Standards development","Ada;object-oriented languages;object-oriented programming;software reusability;software metrics;software tools","software reuse;Ada;software crisis;organizations;measurement;literature;domain capability;human factors;software tool;software metrics;software environment;software development effort;object-oriented design;repository development;factor analysis;multiple regression analysis","","26","","91","","","","","","IEEE","IEEE Journals & Magazines"
"Debugging Larch shared language specifications","S. J. Garland; J. V. Guttag; J. J. Horning","Lab. for Comput. Sci., MIT, Cambridge, MA, USA; Lab. for Comput. Sci., MIT, Cambridge, MA, USA; NA","IEEE Transactions on Software Engineering","","1990","16","9","1044","1057","The checkability designed into the LSL (Larch shared language) is described, and two tools that help perform the checking are discussed. LP (the Larch power) is the principal debugging tool. Its design and development have been motivated primarily by work on LSL, but it also has other uses (e.g. reasoning about circuits and concurrent algorithms). Because of these other uses, and because they also tend to use LP to analyze Larch interface specifications, the authors have tried not to make LP too LSL-specific. Instead, they have chosen to build a second tool, LSLC (the LSL checker), to serve as a front-end to LP. LSLC checks the syntax and static semantics of LSL specifications and generates LP proof obligations from their claims. These proof obligations fall into three categories: consistency (that a specification does not contradict itself), theory containment (that a specification has intended consequences), and relative completeness (that a set of operators is adequately defined). An extended example illustrating how LP is used to debug LSL specifications is presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58789","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58789","","Debugging;Formal specifications;Specification languages;Logic testing;Costs;Buildings;Modular construction;Crops;Laboratories;Algorithm design and analysis","formal specification;inference mechanisms;parallel programming;program debugging","Larch shared language specifications;debugging;checkability;Larch power;design;development;concurrent algorithms;static semantics;consistency;theory containment","","24","","19","","","","","","IEEE","IEEE Journals & Magazines"
"A highly available local leader election service","C. Fetzer; F. Cristian","AT&T, Florham-Park, NJ, USA; NA","IEEE Transactions on Software Engineering","","1999","25","5","603","618","We define the highly available local leader election problem (G. LeLann, 1977), a generalization of the leader election problem for partitionable systems. We propose a protocol that solves the problem efficiently and give some performance measurements of our implementation. The local leader election service has been proven useful in the design and implementation of several fail-aware services for partitionable systems.","0098-5589;1939-3520;2326-3881","","10.1109/32.815321","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=815321","","Nominations and elections;Protocols;Broadcasting;Measurement;Bridges;Local area networks;Availability;Clocks;Synchronization","distributed processing;protocols;fault tolerant computing","highly available local leader election service;partitionable systems;protocol;performance measurements;fail-aware services;timed asynchronous systems","","28","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Software testing based on SDL specifications with save","G. Luo; A. Das; G. v. Bochmann","Dept. d'Inf. et de Recherche Oper., Montreal Univ., Que., Canada; NA; NA","IEEE Transactions on Software Engineering","","1994","20","1","72","87","The signal save construct is one of the features distinguishing SDL from traditional high-level specification and programming languages. However, this feature increases the difficulties of testing SDL-specified software. We present a testing approach consisting of the following three phases: SDL specifications are first abstracted into finite state machines with save constructs, called SDL-machines; the resulting SDL-machines are then transformed into equivalent finite state machines without save constructs if this is possible; and, finally, test cases are selected from the resulting finite state machines. Since there are many existing methods for the first and third phases, we mainly concentrate upon the second phase and come up with a method of transforming SDL-machines into equivalent finite state machines, which preserve the same input/output relationship as in the original SDL-machines. The transformation method is useful not only for testing but also for verifying SDL-specified software.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.263756","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=263756","","Software testing;Automata;Protocols;Computer languages;Formal specifications;Communication standards;Software standards;Application software;Communication industry;Computer science","program testing;finite state machines;formal specification;specification languages;program verification","SDL specifications;software testing;signal save construct;high-level specification;programming languages;finite state machines;SDL-machines;SDL-machine transformation;input/output relationship;software verification","","21","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Nontraversible Paths in a Program","M. Chellappa","Flight Control Systems Division, Aeronautical Development Establishment","IEEE Transactions on Software Engineering","","1987","SE-13","6","751","756","A finite-state machine representation of a program graph is shown to have the property of exposing nontraversible paths in a program. A minimal covering set of paths for such a program may fail to yield realizable test cases, as the nontraversible paths have inconsistent path predicates.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233480","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702280","Directed graph;finite state machine;path analysis;path predicates;test case selection;test cover","Testing;Flowcharts;Computer errors;Performance evaluation;Imaging phantoms;Control systems","","Directed graph;finite state machine;path analysis;path predicates;test case selection;test cover","","","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Eager Reclamation","Ching-Chy Wang; M. L. Soffa","IBM T. J. Watson Research Center; NA","IEEE Transactions on Software Engineering","","1985","SE-11","4","437","439","Reclamation policies are presented which permit the reuse of storage for procedure instances before the procedures terminate. These eager reclamation policies are applicable under certain conditions and can reduce the total amount of memory needed for the execution of a program. The policies essentially differ in the amount of run-time checks needed and the reclamation opportunities. This eager reclamation strategy would be particularly useful when instances are implemented using register banks or in a microprocessor environment.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232232","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702025","Implementation;optimization;procedure reclamation;reclamation;storage management","Runtime;Iterative algorithms;Programming profession;Computer science;Registers;Microprocessors;Iterative methods;Automatic control;Optimizing compilers;Program processors","","Implementation;optimization;procedure reclamation;reclamation;storage management","","","","10","","","","","","IEEE","IEEE Journals & Magazines"
"A practical method for specification and analysis of exception handling-a Java/JVM case study","E. Borger; W. Schulte","Dipartimento di Inf., Pisa Univ., Italy; NA","IEEE Transactions on Software Engineering","","2000","26","9","872","887","We provide a rigorous framework for language and platform independent design and analysis of exception handling mechanisms in modern programming languages and their implementations. To illustrate the practicality of the method we develop it for the exception handling mechanism of Java and show that its implementation on the Java Virtual Machine (JVM) Is correct. For this purpose we define precise abstract models for exception handling in Java and in the JVM and define a compilation scheme of Java to JVM code which allows us to prove that, in corresponding runs, Java and the JVM throw the same exceptions and with equivalent effect. Thus, the compilation scheme can, with reasonable confidence, be used as a standard reference for Java exception handling compilation.","0098-5589;1939-3520;2326-3881","","10.1109/32.877847","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=877847","","Java;Computer aided software engineering;Object oriented modeling;Virtual machining;Programming profession;Computer languages;Runtime;Program processors;Concurrent computing;Mathematical model","exception handling;Java;program compilers;formal specification","exception handling specification;exception handling analysis;programming languages;Java;Java Virtual Machine;precise abstract models;compilation scheme","","4","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Query-by-Pictorial-Example","Ning-San Chang; King-Sun Fu","Hewlett Packard Company; NA","IEEE Transactions on Software Engineering","","1980","SE-6","6","519","524","Query-by-Pictorial-Example is a relational query language introduced for manipulating queries regarding pictorial relations as well as conventional relations. In addition to the manipulating capabilities of the conventional query languages, queries can also be expressed in terms of pictorial examples through a display tenninal. Example queries are used to illustrate the language facilities.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230801","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702777","Graphics;image processing;pictorial example;pictorial relations;query language","Satellites;Image processing;Remote sensing;Image storage;Database languages;Image databases;Information retrieval;Relational databases;Image recognition;Packaging","","Graphics;image processing;pictorial example;pictorial relations;query language","","133","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Predicting (individual) software productivity","W. S. Humphrey; N. D. Singpurwalla","Software Eng. Inst., Carnegie Mellon Univ., Pittsburgh, PA, USA; Software Eng. Inst., Carnegie Mellon Univ., Pittsburgh, PA, USA","IEEE Transactions on Software Engineering","","1991","17","2","196","207","A method for projecting software productivity with reasonable accuracy which uses the statistical techniques of time series analysis is described. The measure of productivity is the development time required per line of code. In making productivity projections, the key issue is the need to achieve a balance between forecasting stability and responsiveness to changing conditions. An integrated moving average process of order one, using exponential smoothing of all the previous observations, is judged appropriate for software productivity analysis, particularly where there are limited data available or where conditions are sufficiently varied to make much of the available data inapplicable. Empirical evidence suggests that most commonly encountered time series can be reasonably well described by such methods. The methods for computing the weights used for exponential smoothing are described, as are the means for determining prediction intervals, or measures of forecast uncertainty. This data analytic approach uses historical data alone, unlike structural methods where learning curves as well as prior data are used to define the predictive process.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.67600","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=67600","","Productivity;Time series analysis;Time measurement;Smoothing methods;Software engineering;Programming profession;Meeting planning;Stability;Delay;Measurement uncertainty","DP management;software engineering;statistical analysis","management;software productivity;statistical techniques;time series analysis;development time;moving average process;limited data;exponential smoothing;forecast uncertainty;historical data","","19","","5","","","","","","IEEE","IEEE Journals & Magazines"
"Timed Communicating Object Z","B. Mahony; Jin Song Dong","Div. of Inf. Technol., Defence Sci. & Technol. Organ., Salisbury, SA, Australia; NA","IEEE Transactions on Software Engineering","","2000","26","2","150","177","This paper describes a timed, multithreaded object modeling notation for specifying real-time, concurrent, and reactive systems. The notation Timed Communicating Object Z (TCOZ) builds on Object Z's strengths in modeling complex data and algorithms, and on Timed CSP's strengths in modeling process control and real-time interactions. TCOZ Is novel in that it includes timing primitives, properly separates process control and data/algorithm issues and supports the modeling of true multithreaded concurrency. TCOZ is particularly well-suited for specifying complex systems whose components have their own thread of control. The expressiveness of the notation is demonstrated by a case study in specifying a multilift system that operates in real-time.","0098-5589;1939-3520;2326-3881","","10.1109/32.841115","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=841115","","Object oriented modeling;Process control;Real time systems;Concurrent computing;Timing;Formal specifications;Control systems;Algorithm design and analysis;Carbon capture and storage","formal specification;real-time systems;object-oriented languages;object-oriented methods","timed multithreaded object modeling notation;real-time systems;concurrent systems;reactive systems;specification;Timed Communicating Object Z;Timed CSP;real-time interactions;process control;complex data;algorithms;timing primitives;multithreaded concurrency;multilift system","","74","","52","","","","","","IEEE","IEEE Journals & Magazines"
"Simulation of Procedure Variables Using Ada Tasks","D. A. Lamb; P. N. Hilfinger","Department of Computer Science, Carnegie-Mellon University; NA","IEEE Transactions on Software Engineering","","1983","SE-9","1","13","15","We give a technique for partially simulating procedure variables using Ada tasks. The simulation involves using interface tasks, a technique which may be useful for other problems.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236165","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703007","Ada;procedure variables;programming languages;programming techniques;tasking","Computer languages;Computer science;US Department of Defense;Computerized monitoring;Aerospace electronics;Laboratories;Organizing","","Ada;procedure variables;programming languages;programming techniques;tasking","","2","","4","","","","","","IEEE","IEEE Journals & Magazines"
"Use of Software Engineering Practices at a Small MIS Shop","T. C. Snow","United Technologies Microelectronics Center, Colorado Springs, CO 80907.","IEEE Transactions on Software Engineering","","1984","SE-10","4","408","413","This paper describes the software engineering practices used by the MIS Department at United Technologies Microelectronics Center (UTMC). It describes the life cycle of a software change and the controls established to implement the change. Several software tools used by UTMC to develop and control software development and integration are described as well as methods used to integrate vendor software packages with in-house developed software. A computerized system for tracking and controlling users' modification requests has been developed. Software requirements for a small MIS shop are examined and compared to the requirements for large software development projects.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010253","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010253","","Software engineering;Programming;Software packages;Microelectronics;Software tools;Control systems;Computer aided manufacturing;Reliability engineering;Packaging;Software maintenance","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Estimating software project effort using analogies","M. Shepperd; C. Schofield","Dept. of Comput., Bournemouth Univ., Poole, UK; NA","IEEE Transactions on Software Engineering","","1997","23","11","736","743","Accurate project effort prediction is an important goal for the software engineering community. To date most work has focused upon building algorithmic models of effort, for example COCOMO. These can be calibrated to local environments. We describe an alternative approach to estimation based upon the use of analogies. The underlying principle is to characterize projects in terms of features (for example, the number of interfaces, the development method or the size of the functional requirements document). Completed projects are stored and then the problem becomes one of finding the most similar projects to the one for which a prediction is required. Similarity is defined as Euclidean distance in n-dimensional space where n is the number of project features. Each dimension is standardized so all dimensions have equal weight. The known effort values of the nearest neighbors to the new project are then used as the basis for the prediction. The process is automated using a PC-based tool known as ANGEL. The method is validated on nine different industrial datasets (a total of 275 projects) and in all cases analogy outperforms algorithmic models based upon stepwise regression. From this work we argue that estimation by analogy is a viable technique that, at the very least, can be used by project managers to complement current estimation techniques.","0098-5589;1939-3520;2326-3881","","10.1109/32.637387","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=637387","","Project management;Costs;Software engineering;Euclidean distance;Nearest neighbor searches;Programming;Software development management;Centralized control;Accuracy;Particle measurements","software development management;project management;software cost estimation;software tools;software metrics","software project effort estimation;project effort prediction;software engineering;algorithmic models;COCOMO;estimation by analogy;software development method;functional requirements document;Euclidean distance;nearest neighbors;personal computer-based tool;ANGEL;industrial datasets;stepwise regression;project management","","438","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Corrigendum to ""Proofs of Networks of Processes""","M. Ossefort","Departmenf of Computer Sciences, University of Texas","IEEE Transactions on Software Engineering","","1982","SE-8","2","160","160","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235094","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702923","","Partitioning algorithms;Error correction","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"The imposition of protocols over open distributed systems","N. H. Minsky","Dept. of Comput. Sci., Rutgers Univ., New Brunswick, NJ, USA","IEEE Transactions on Software Engineering","","1991","17","2","183","195","In order to facilitate enforcement of protocols, an architecture for distributed systems is introduced under which all interactions between objects are governed by an explicit and strictly enforced set of rules, called the law of the system. This law is global in the sense that all the objects of the system are made to obey it, but the maintenance of the law and its enforcement are performed locally, at each object (or node). The term law is used to emphasized that it not only provides the specification of protocols, but actually governs the system by enforcing them. In other words, under this architecture a protocol can be established simply by writing it into the law of a system, without having to worry about the programs that drive the various objects that might populate that system. The law, then, is the enforced specification of protocols. It is shown that various familiar protocols can be established under this architecture. A technique for online distributed updating of the global law of a system is presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.67599","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=67599","","Protocols;Computer architecture;Writing;Distributed computing;Clocks;Computer science","distributed processing;protocols","protocols;open distributed systems;enforced specification;online distributed updating;global law","","39","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Specification of realtime systems using ASTRAL","A. Coen-Porisini; C. Ghezzi; R. A. Kemmerer","Dipartimento di Elettronica, Politecnico di Milano, Italy; NA; NA","IEEE Transactions on Software Engineering","","1997","23","9","572","598","ASTRAL is a formal specification language for real-time systems. It is intended to support formal software development and, therefore, has been formally defined. The structuring mechanisms in ASTRAL allow one to build modularized specifications of complex systems with layering. A real-time system is modeled by a collection of state machine specifications and a single global specification. This paper discusses the rationale of ASTRAL's design. ASTRAL's specification style is illustrated by discussing a telephony example. Composability of one or more ASTRAL system specifications is also discussed by the introduction of a composition section, which provides the needed information to combine two or more ASTRAL system specifications.","0098-5589;1939-3520;2326-3881","","10.1109/32.629494","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=629494","","Formal specifications;Programming;Application software;Aerospace electronics;Testing;Specification languages;Telephony;Logic;Timing;Aircraft","formal specification;specification languages;real-time systems;telephony;telecommunication computing;program verification;temporal logic;finite state machines","real-time systems specification;ASTRAL;formal specification language;formal software development;structuring mechanisms;modularized specifications;complex systems;state machine specifications;global specification;telephony;program verification;temporal logic","","31","","59","","","","","","IEEE","IEEE Journals & Magazines"
"Comments, with reply, on ""On the projection method for protocol verification"" by T.-Y. Cheung","Y. Hirakawa","NTT Electr. Commun. Lab., Tokyo, Japan","IEEE Transactions on Software Engineering","","1990","16","3","370","371","A counterexample to a theorem given in a paper by T.-Y. Cheung (see ibid., vol.12, no.11, p.1088-9, 1986) is given. In a reply, the author of the original paper argues that the counterexample is not correct.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.48933","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=48933","","Protocols;Safety;Sufficient conditions;Communication systems","program verification;protocols","projection method;protocol verification;theorem","","","","4","","","","","","IEEE","IEEE Journals & Magazines"
"An extensible system for source code analysis","G. Canfora; A. Cimitile; U. De Carlini; A. De Lucia","Fac. of Eng., Sannio Univ., Piazza Roma, Italy; NA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","9","721","740","Constructing code analyzers may be costly and error prone if inadequate technologies and tools are used. If they are written in a conventional programming language, for instance, several thousand lines of code may be required even for relatively simple analyses. One way of facilitating the development of code analyzers is to define a very high-level domain-oriented language and implement an application generator that creates the analyzers from the specification of the analyses they are intended to perform. This paper presents a system for developing code analyzers that uses a database to store both a no-loss fine-grained intermediate representation and the results of the analyses. The system uses an algebraic representation, called F(p), as the user-visible intermediate representation. Analyzers are specified in a declarative language, called F(p)-l, which enables an analysis to be specified in the form of a traversal of an algebraic expression, with access to, and storage of, the database information the algebraic expression indices. A foreign language interface allows the analyzers to be embedded in C programs. This is useful for implementing the user interface of an analyzer, for example, or to facilitate interoperation of the generated analyzers with pre-existing tools. The paper evaluates the strengths and limitations of the proposed system, and compares it to other related approaches.","0098-5589;1939-3520;2326-3881","","10.1109/32.713328","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=713328","","Performance analysis;Information analysis;Reverse engineering;Databases;Data mining;Computer languages;Software maintenance;Software systems;Programming profession;Testing","reverse engineering;software maintenance;application generators;formal specification;specification languages;user interfaces","extensible system;source code analysis;code analyzers;programming language;domain-oriented language;application generator;specification;database;algebraic representation;declarative language;algebraic expression;foreign language interface;C programs;user interface;reverse engineering;software maintenance","","16","","55","","","","","","IEEE","IEEE Journals & Magazines"
"On Weyuker's axioms for software complexity measures","J. C. Cherniavsky; C. H. Smith","Nat. Sci. Found., Washington, DC, USA; NA","IEEE Transactions on Software Engineering","","1991","17","6","636","638","Properties for software complexity measures are discussed. It is shown that a collection of nine properties suggested by E.J. Weyuker is inadequate for determining the quality of a software complexity measure. (see ibid., vol.14, p.1357-65, 1988). A complexity measure which satisfies all nine of the properties, but which has absolutely no practical utility in measuring the complexity of a program is presented. It is concluded that satisfying all of the nine properties is a necessary, but not sufficient, condition for a good complexity measure.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.87287","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=87287","","Software measurement;Software quality;Software maintenance;Fluid flow measurement;Computer languages;Programming;Metrology;Arithmetic;Software testing;Cost function","computational complexity;software metrics","software complexity measures","","31","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Experimenting with quantitative evaluation tools for monitoring operational security","R. Ortalo; Y. Deswarte; M. Kaaniche","Lab. d'Autom. et d'Anal. des Syst., CNRS, Toulouse, France; NA; NA","IEEE Transactions on Software Engineering","","1999","25","5","633","650","This paper presents the results of an experiment in security evaluation. The system is modeled as a privilege graph that exhibits its security vulnerabilities. Quantitative measures that estimate the effort an attacker might expend to exploit these vulnerabilities to defeat the system security objectives are proposed. A set of tools has been developed to compute such measures and has been used in an experiment to monitor a large real system for nearly two years. The experimental results are presented and the validity of the measures is discussed. Finally, the practical usefulness of such tools for operational security monitoring is shown and a comparison with other existing approaches is given.","0098-5589;1939-3520;2326-3881","","10.1109/32.815323","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=815323","","Information security;Power system security;Computerized monitoring;Computer security;Computer Society;Data security;Computer networks;Collaborative software;Collaborative work;Power system interconnection","security of data;graph theory","quantitative evaluation tools;operational security monitoring;experiment;privilege graph","","189","","15","","","","","","IEEE","IEEE Journals & Magazines"
"A Method for Representing Data Items of Unlimited Length in a Computer Memory","R. L. Baber","NA","IEEE Transactions on Software Engineering","","1981","SE-7","6","590","593","In this paper, a recursive data structure is defined which permits a data item of-unlimited length to be represented in a computer memory. The encoded data are a linear string of symbols which contains a specification of the length of the data item and the data item itself. In a single forward scan of the encoded data string, the length of the data item can be determined and the data item located and/or extracted.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.226470","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702891","Coding unbounded numbers;infinite address space;recursive data structure;storing data in a computer memory;unbounded address space;unbounded linear list;unlimited length data format;unlimited length data item;unlimited length data string;variable length data","Data structures;Data mining;Information processing;Application software;System software;Decoding","","Coding unbounded numbers;infinite address space;recursive data structure;storing data in a computer memory;unbounded address space;unbounded linear list;unlimited length data format;unlimited length data item;unlimited length data string;variable length data","","1","","7","","","","","","IEEE","IEEE Journals & Magazines"
"Risk Assessment of Computer Controlled Systems","M. O. Fryer","Engineering Design Division of EG&amp;G Idaho, Inc.","IEEE Transactions on Software Engineering","","1985","SE-11","1","125","129","Software is increasingly being used to control and monitor systems for which safety and reliability are critical. When comparing software designs for such systems, an evaluation of how each design can contribute to the risk of system failure is desirable. Unfortunately, the science of risk assessment of combined hardware and software systems is in its infancy. Risk assessment of combined hardware/software systems is often based on oversimplified assumptions about software behavior.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231849","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701904","Fault trees;probability of system failure;relative failure probabilities;risk assessment;software reliability","Risk management;Control systems;Hardware;Fault trees;Application software;Safety;Software design;Software systems;Computerized monitoring;Condition monitoring","","Fault trees;probability of system failure;relative failure probabilities;risk assessment;software reliability","","1","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on ""Detection of Mutual Inconsistency in Distributed Systems""","K. V. S. Ramarao","Department of Computer Science, University of Pittsburgh","IEEE Transactions on Software Engineering","","1987","SE-13","6","759","760","In the above paper,<sup>1</sup>authors have given a technique for the detection of mutual inconsistency among the copies of a file, in presence of network partitioning. This technique involves maintaining a ""version vector"" with each file in a partition. Here, we show that it is impossible to maintain the version vectors when arbitrary reconfigurations can occur after a network partitioning.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233482","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702282","Database consistency;fault-tolerance;network partitioning;optimistic protocols","Protocols;Computer science;Fault tolerance;Merging;Broadcasting","","Database consistency;fault-tolerance;network partitioning;optimistic protocols","","","","3","","","","","","IEEE","IEEE Journals & Magazines"
"A decision-analytic stopping rule for validation of commercial software systems","T. Chavez","Rapt Technol. Corp., San Francisco, CA, USA","IEEE Transactions on Software Engineering","","2000","26","9","907","918","The decision of when to release a software product commercially is not a question of when the software has attained some objectively justifiable degree of correctness. It is, rather, a question of whether the software achieves a reasonable balance among engineering objectives, market demand, customer requirements, and marketing directives of the software organization. We present a rigorous framework for addressing this important decision. Conjugate distributions from statistical decision theory provide an attractive means of modeling the cost and rate of bugs given information acquired during software testing, as well as prior information provided by software engineers about the fidelity of the software before testing begins. In contrast to other methods, the stopping analysis yields a computationally simple rule for deciding when to release a commercial software product based on information revealed to engineers during software testing-complicated numerical procedures are not needed. Our method has the added benefits that it is sequential: it measures explicitly the costs of customer dissatisfaction associated with bugs as well as the costs of declining market position while the testing process continues; and it incorporates a practical framework for cost-criticality assessment that makes sense to professional software developers.","0098-5589;1939-3520;2326-3881","","10.1109/32.877849","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=877849","","Software systems;Software testing;Programming;Computer bugs;Costs;Business;Decision theory;Software tools;Design engineering;Engineering management","program testing;software development management;program debugging;formal verification","decision-analytic stopping rule;commercial software system validation;engineering objectives;market demand;customer requirements;marketing directives;software organization;statistical decision theory;conjugate distributions;software testing;bugs;customer dissatisfaction;declining market position;cost-criticality assessment;professional software developers","","12","","20","","","","","","IEEE","IEEE Journals & Magazines"
"The Tinkertoy graphical programming environment","M. Edel","Illinois Univ., Urbana, IL, USA","IEEE Transactions on Software Engineering","","1988","14","8","1110","1115","The Tinkertoy graphical interface to Lisp is described, in which programs are 'built' rather than written, out of icons and flexible interconnections. It represents a computer/user interface that can easily exceed the interaction speed of the best text-based language editors and command languages. It also provides a consistent framework for interaction across both editing and command execution. Moreover, because programs are represented graphically, structures that do not naturally conform to the text medium can be clearly described, the new kinds of information can be incorporated into programs and program elements.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.7621","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=7621","","Programming environments;Computer graphics;Command languages;Power engineering and energy;Computer interfaces;User interfaces;Computer languages;Hardware;Mice","computer graphics;LISP;programming environments;text editing;user interfaces","graphical programming environment;Tinkertoy graphical interface;Lisp;icons;user interface","","12","","7","","","","","","IEEE","IEEE Journals & Magazines"
"Control of a Heterogeneous Two-Server Exponential Queueing System","R. L. Larsen; A. K. Agrawala","National Aeronautics and Space Administration; NA","IEEE Transactions on Software Engineering","","1983","SE-9","4","522","526","A dynamic control policy known as ""threshold queueing"" is defined for scheduling customers from a Poisson source on a set of two exponential servers with dissimilar service rates. The slower server is invoked in response to instantaneous system loading as measured by the length of the queue of waiting customers. In a threshold queueing policy, a specific queue length is identified as a ""threshold,"" beyond which the slower server is invoked. The slower server remains busy until it completes service on a customer and the queue length is less than its invocation threshold. Markov chain analysis is employed to analyze the performance of the threshold queueing policy and to develop optimality criteria. It is shown that probabilistic control is sub-optimal to minimize the mean number of customers in the system. An approximation to the optimum policy is analyzed which is computationally simple and suffices for most operational applications.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.234960","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703085","Analytic models;Markov decision processes;multiserver queues;optimal control;performance evaluation;queueing theory;resource management;threshold queueing","Control systems;Queueing analysis;Network servers;Optimal control;Processor scheduling;Performance analysis;Communication systems;Computer networks;Costs;Dynamic scheduling","","Analytic models;Markov decision processes;multiserver queues;optimal control;performance evaluation;queueing theory;resource management;threshold queueing","","4","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Multiprocessor online scheduling of hard-real-time tasks","M. L. Dertouzos; A. K. Mok","Lab. for Comput. Sci., MIT, Cambridge, MA, USA; NA","IEEE Transactions on Software Engineering","","1989","15","12","1497","1506","The problems of hard-real-time task scheduling in a multiprocessor environment are discussed in terms of a scheduling game representation of the problem. It is shown that optimal scheduling without a priori knowledge is impossible in the multiprocessor case even if there is no restriction on preemption owing to precedence or mutual exclusion constraints. Sufficient conditions that permit a set of tasks to be optimally scheduled at run time are derived.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58762","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58762","","Optimal scheduling;Processor scheduling;Sufficient conditions;Runtime;Computer science;Microprocessors;Multiprocessing systems;Time factors;Robot control","multiprocessing systems;multiprogramming;real-time systems;scheduling","hard-real-time task scheduling;multiprocessor environment;scheduling game representation;optimal scheduling;a priori knowledge;mutual exclusion constraints","","250","","12","","","","","","IEEE","IEEE Journals & Magazines"
"On conditions for defining a closed cover to verify progress for communicating finite state machines","A. Chung; D. P. Sidhu","Dept. of Comput. Sci., Maryland Univ., Baltimore, MD, USA; Dept. of Comput. Sci., Maryland Univ., Baltimore, MD, USA","IEEE Transactions on Software Engineering","","1989","15","11","1491","1494","The closed-cover technique for verifying progress for two communicating finite-state machines exchanging messages over two lossless, FIFO channels is considered. The authors point out that the definition of a closed cover in M.G. Gouda (ibid., vol.SE-10, no.6, p.846-55, Nov. 1984) may be too restrictive, while that in M.G. Gouda and C.K. Chang (ACM Trans. Prog. Lang., vol.8, no.1, p.154-82, Jan. 1986) is not correct. They then show how a condition of the closed-cover definition can be modified to relax restriction to various degrees. They also discuss the similarities and relationship between the structural partition technique and the closed-cover technique.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.41341","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=41341","","Automata;Protocols;Computer science;EMP radiation effects","finite automata;protocols","progress verification;closed cover;communicating finite state machines;lossless;FIFO channels;structural partition technique","","1","","4","","","","","","IEEE","IEEE Journals & Magazines"
"Author's reply<sup>2</sup>","R. L. Baber","NA","IEEE Transactions on Software Engineering","","1982","SE-8","6","621","621","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.236024","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702997","","Memory management;Environmental economics;Encoding;Delay;History;Arithmetic;Organizing;Microcomputers;Registers","","","","1","","","","","","","","IEEE","IEEE Journals & Magazines"
"An empirical approach to studying software evolution","C. F. Kemerer; S. Slaughter","Pittsburgh Univ., PA, USA; NA","IEEE Transactions on Software Engineering","","1999","25","4","493","509","With the approach of the new millennium, a primary focus in software engineering involves issues relating to upgrading, migrating, and evolving existing software systems. In this environment, the role of careful empirical studies as the basis for improving software maintenance processes, methods, and tools is highlighted. One of the most important processes that merits empirical evaluation is software evolution. Software evolution refers to the dynamic behaviour of software systems as they are maintained and enhanced over their lifetimes. Software evolution is particularly important as systems in organizations become longer-lived. However, evolution is challenging to study due to the longitudinal nature of the phenomenon in addition to the usual difficulties in collecting empirical data. We describe a set of methods and techniques that we have developed and adapted to empirically study software evolution. Our longitudinal empirical study involves collecting, coding, and analyzing more than 25000 change events to 23 commercial software systems over a 20-year period. Using data from two of the systems, we illustrate the efficacy of flexible phase mapping and gamma sequence analytic methods, originally developed in social psychology to examine group problem solving processes. We have adapted these techniques in the context of our study to identify and understand the phases through which a software system travels as it evolves over time. We contrast this approach with time series analysis. Our work demonstrates the advantages of applying methods and techniques from other domains to software engineering and illustrates how, despite difficulties, software evolution can be empirically studied.","0098-5589;1939-3520;2326-3881","","10.1109/32.799945","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=799945","","Software maintenance;Software systems;Time series analysis;Software engineering;Dynamic programming;Psychology;Problem-solving;Costs;Software performance;Error correction","software prototyping;software maintenance","empirical approach;software evolution;software engineering;empirical studies;software maintenance processes;dynamic behaviour;longitudinal nature;empirical data;change events;commercial software systems;flexible phase mapping;gamma sequence analytic methods","","147","","44","","","","","","IEEE","IEEE Journals & Magazines"
"A validation of the component-based method for software size estimation","J. J. Dolado","Fac. de Inf., Pais Vasco Univ., San Sebastian, Spain","IEEE Transactions on Software Engineering","","2000","26","10","1006","1021","Estimation of software size is a crucial activity among the tasks of software management. Work planning and subsequent estimations of the effort required are made based on the estimate of the size of the software product. Software size can be measured in several ways: lines of code (LOC) is a common measure and is usually one of the independent variables in equations for estimating several methods for estimating the final LOC count of a software system in the early stages. We report the results of the validation of the component-based method (initially proposed by Verner and Tate, 1988) for software sizing. This was done through the analysis of 46 projects involving more than 100,000 LOC of a fourth-generation language. We present several conclusions concerning the predictive capabilities of the method. We observed that the component-based method behaves reasonably, although not as well as expected for ""global"" methods such as Mark II function points for software size prediction. The main factor observed that affects the performance is the type of component.","0098-5589;1939-3520;2326-3881","","10.1109/32.879821","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=879821","","Lab-on-a-chip;Size measurement;Software measurement;Equations;Software systems;Project management;Life estimation;Linear regression;Neural networks;Genetic programming","software reusability;software development management;high level languages;software metrics","software component-based method;software size estimation;software management;work planning;lines of code;fourth-generation language;Mark II function points;software size prediction;neural networks;genetic programming","","73","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Partition testing vs. random testing: the influence of uncertainty","W. J. Gutjahr","Dept. of Stat. Oper. Res. & Comput. Sci., Wien Univ., Austria","IEEE Transactions on Software Engineering","","1999","25","5","661","674","This paper compares partition testing and random testing on the assumption that program failure rates are not known with certainty before testing and are, therefore, modeled by random variables. It is shown that under uncertainty, partition testing compares more favorably to random testing than suggested by prior investigations concerning the deterministic case: the restriction to failure rates that are known with certainty systematically favors random testing. In particular, we generalize a result by Weyuker and Jeng (1991) stating equal fault detection probabilities for partition testing and random testing in the case where the failure rates in the subdomains defined by the partition are equal. It turns out that for independent random failure rates with equal expectation, the case above is a boundary case (the worst case for partition testing), and the fault detection probability of partition testing can be up to k times higher than that of random testing, where k is the number of subdomains. Also in a related model for dependent failure rates, partition testing turns out to be consistently better than random testing. The dominance can also be verified for the expected (weighted) number of detected faults as an alternative comparison criterion.","0098-5589;1939-3520;2326-3881","","10.1109/32.815325","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=815325","","Uncertainty;Fault detection;Software testing;Acoustic testing;System testing;Random variables;Genetic mutations;Partitioning algorithms;Pain","program testing;program debugging","partition testing;random testing;program failure rates;random variables;fault detection;decisions under uncertainty;program testing","","68","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Some Critical Comments on the Paper ""An Optimal Approach to Fault Tolerant Software Systems Design"" by Gannon and Shapiro","P. A. Lee; J. L. Lloyd; S. K. Shrivastava","Computing Laboratory, The University; NA; NA","IEEE Transactions on Software Engineering","","1981","SE-7","6","608","610","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.226475","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702893","","Fault tolerant systems;Software systems;Software design;Hardware;Fault detection;Fault tolerance;Computer errors;Mathematics;Electronic switching systems;Redundancy","","","","","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on number of faults per line of code","F. Stetter","Lehrstuhl fur Praktische Informatik 1, Universitat Mannheim, A5, 6800 Mannheim 1, West Germany","IEEE Transactions on Software Engineering","","1986","SE-12","12","1145","1145","In a recent paper (see ibid., vol.SE-8, p.437-9, July 1982) an approximate formula for the number of faults per line of code was developed. It is shown that there is an approximation which is easier to develop, more accurate, and simpler to use.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313010","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313010","Program error estimates;program predictions;software reliability;software science","Approximation methods;Software;Indexes;Software reliability","programming theory;software reliability","program error estimates;software reliability;program predictions;faults per line of code","","2","","","","","","","","IEEE","IEEE Journals & Magazines"
"Order and Difficulty of Debugging","M. Trachtenberg","RCA","IEEE Transactions on Software Engineering","","1983","SE-9","6","746","747","The earlier findings of Shooman and Bolsky, that the difficulty of detecting or correcting a software bug is independent of its order of detection, is challenged by new data which shows definite tendencies for early bugs to need less time to be detected and more to be corrected than later bugs.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.235582","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703119","Correlation;debugging;error correction times;error detection times;Musa;Shooman and Bolsky","Computer bugs;Real time systems;Control systems;Error correction;Computer errors;Software testing;Software debugging;System testing;Logic design;Phase detection","","Correlation;debugging;error correction times;error detection times;Musa;Shooman and Bolsky","","1","","3","","","","","","IEEE","IEEE Journals & Magazines"
"Some consideration on real-time behavior of concurrent programs","A. Fuggetta; C. Ghezzi; D. Mandrioli","CEFRIEL, Milan, Italy; NA; NA","IEEE Transactions on Software Engineering","","1989","15","3","356","359","Some basic semantic issues of a language for a reliable and provably correct real-time programs are discussed. The language is based on E.W. Dijkstra's guarded commands and on a proposal by V.H. Haase (1981). Haase's proposal is assessed, its semantic consistencies are shown, and corrections are proposed that give a sound basis for a real-time language based on guarded commands.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21763","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21763","","Proposals;Real time systems;Formal specifications;Production","formal languages;high level languages;parallel programming;program verification;programming theory;real-time systems","real-time behavior;concurrent programs;semantic issues;real-time programs;guarded commands;real-time language","","","","3","","","","","","IEEE","IEEE Journals & Magazines"
"Thorough investigation into ""An improved algorithm based on subset closures for synthesizing a relational database scheme""","Lin Lin Wang","Dept. of Comput. Sci., Chongqing Inst. of Posts & Telecommun., Sichuan, China","IEEE Transactions on Software Engineering","","1996","22","4","271","274","The paper describes a technical improvement of a synthesis algorithm for relational database scheme design, which was proposed by Yang et al. (1988). The improvement is based on the observation that the original algorithm may lose attributes in a decomposition in special cases, due to an insufficient handling of representatives of equivalence classes formed over a given set of functional dependencies. The paper then proposes a correction of the original algorithm in which this problem disappears.","0098-5589;1939-3520;2326-3881","","10.1109/32.491651","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=491651","","Relational databases;Artificial intelligence;Algorithm design and analysis","relational databases;database theory;software engineering;equivalence classes;algorithm theory","relational database scheme synthesis;synthesis algorithm;decomposition;attribute loss;equivalence classes;functional dependencies;algorithm correction","","","","7","","","","","","IEEE","IEEE Journals & Magazines"
"A binary Markov process model for random testing","Sanping Chen; S. Mills","Stat. Consulting Centre, Carleton Univ., Ottawa, Ont., Canada; NA","IEEE Transactions on Software Engineering","","1996","22","3","218","223","A binary Markov process model is proposed for the random testing of software. This model is suggested for replacing the standard binomial distribution model, which is based on the easily-violated assumption of test runs being statistically independent of each other. In addition to a general result on the probability of having any specific number of software failures during testing, practical implications of the new model are also discussed. In particular, we demonstrate that, in general, the effect of a possible correlation between test runs cannot be ignored in estimating software reliability.","0098-5589;1939-3520;2326-3881","","10.1109/32.489081","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=489081","","Software testing;Markov processes;Statistics;Application software;Milling machines;Graphics","program testing;software reliability;binomial distribution;Markov processes","binary Markov process model;random software testing;binomial distribution model;statistically independent test runs;software failure probability;correlation;software reliability estimation;dependent test runs;statistical testing;ultra-reliability application","","18","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on ""Defining software by continuous smooth functions"" by R.A. De Millo and R.J. Lipton","N. Y. Foo","Basser Dept. of Comput. Sci., Sydney Univ., NSW, Australia","IEEE Transactions on Software Engineering","","1993","19","3","307","309","The commenter agrees with R.A. De Millo and R.S. Lipton's assertion in the above-titled work (see ibid., vol.17, no.4, p.383-4, 1991) that continuous, smooth functions of comparable complexity can be used to represent Boolean functions computed by programs. The commenter reconciles this assertion with a referee's objection that the discontinuity of software resides in the large changes of behavior that results from small changes of code, which was countered by the authors by arguing that this notion of discontinuity is vague. It is suggested that this vagueness can be remedied if discontinuity is replaced by a more natural measure that nevertheless captures a similar intuition.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.221140","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=221140","","Q measurement;Mathematics;Length measurement;Software measurement;Reasoning about programs;Mathematical model;Boolean functions;Proposals;Australia Council;Knowledge based systems","Boolean functions;computational complexity;software metrics","smooth functions;comparable complexity;Boolean functions;programs;natural measure","","1","","6","","","","","","IEEE","IEEE Journals & Magazines"
"A linear algorithm for generating random numbers with a given distribution","M. D. Vose","Dept. of Comput. Sci., Tennessee Univ., Knoxville, TN, USA","IEEE Transactions on Software Engineering","","1991","17","9","972","975","Let xi be a random variable over a finite set with an arbitrary probability distribution. Improvements to a fast method of generating sample values for xi in constant time are suggested. The proposed modification reduces the time required for initialization to O(n). For a simple genetic algorithm, this improvement changes an O(g n 1n n) algorithm into an O(g n) algorithm (where g is the number of generations, and n is the population size).<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.92917","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=92917","","Random number generation;Random variables;Probability distribution;Genetic algorithms;Roundoff errors;Computational modeling;Computer science","genetic algorithms;probability;random number generation","linear algorithm;random numbers;random variable;finite set;arbitrary probability distribution;simple genetic algorithm","","41","","4","","","","","","IEEE","IEEE Journals & Magazines"
"Recognizing immediacy in an N-tree hierarchy and its application to protection groups","R. S. Sandhu","Dept. of Inf. Syst. & Syst. Eng., George Mason Univ., Fairfax, VA, USA","IEEE Transactions on Software Engineering","","1989","15","12","1518","1525","The benefits of providing access control with groups of users as the unit of granularity are enhanced if the groups are organized in a hierarchy (partial order) by the subgroup relation <or=, where g<or=h signifies that every member of group g is thereby also a member of group h. It is often useful to distinguish the case when g is an immediate subgroup of h, that is when g<h and there is no group k such that g<k<h. The class of partial orders called n-trees was recently defined by using rooted trees and inverted rooted trees as basic partial orders and combining these recursively by refinement. Any n-tree hierarchy can be expressed as the intersection of two linear orderings, so it is possible to assign a pair of integers l(x) and r(x) to each group x such that g<or=h if and only if l(g)<or=l(h) and r(g)<or=r(h). The author shows how to extend this representation of n-trees by assigning four additional integers to each group so that it is also easily determined whether or not g is an immediate subgroup of h.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58764","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58764","","Protection;Access control;Authorization;Security;Tires;Information systems","data structures;multi-access systems;security of data;set theory;trees (mathematics)","immediacy;N-tree hierarchy;protection groups;access control;granularity;partial order;subgroup relation;inverted rooted trees;recursively;refinement;linear orderings;integers","","","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Comments from a Letter Written on July 19, 1978","B. Shneiderman","NA","IEEE Transactions on Software Engineering","","1981","SE-7","4","370","371","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234538","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702856","","Psychology;Interactive systems;Documentation;Computer errors;Ergonomics;Programming;Read only memory;Protocols;Human factors;Art","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on ""Optimization Algorithms for Distributed Queries","G. D. Lakhanai; J. S. Wang","Department of Electrical Engineering and Computer Science, Texas Tech University, Lubbock, TX 79409.; Department of Electrical Engineering and Computer Science, Texas Tech University, Lubbock, TX 79409.","IEEE Transactions on Software Engineering","","1984","SE-10","4","464","465","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010261","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010261","","Delay;Processor scheduling;Scheduling algorithm;Computer science;Cost function;Databases","","","","2","","1","","","","","","IEEE","IEEE Journals & Magazines"
"The impact on software development costs of using HOL's","J. E. Gaffney","Department of Computer Science, Polytechnic Institute of New York, Brooklyn, NY 11201; Federal Systems Division, IBM, Gaithersburg, MD 20817","IEEE Transactions on Software Engineering","","1986","SE-12","3","496","499","The author quantifies the relative reduction in software development costs provided by the use of a higher order coding language (HOL). Paradoxically, as T. C. Jones (1978) has pointed out, when productivity is measured as source lines of code per labor month, there is `an apparent productivity lowering for the whole development cycle with high level (coding) languages, even though development costs have actually been reduced.' The problem here is the unit of measure for the amount of the software function produced per labor month. It is believed that the amount of machine code produced (after taking compiler inefficiency into account) may provide a better quantification of function than the lines of source coding language used.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312890","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312890","Higher order coding language;software development costs","Software;Productivity;Encoding;Assembly;Software engineering;Testing;Programming","software engineering","HOL;software development costs;higher order coding language;productivity;source lines of code per labor month;development cycle;machine code;compiler inefficiency","","2","","","","","","","","IEEE","IEEE Journals & Magazines"
"Handling of irregularities in human centered systems: a unified framework for data and processes","T. Murata; A. Borgida","Dept. of Comput. Sci., Rutgers Univ., Piscataway, NJ, USA; NA","IEEE Transactions on Software Engineering","","2000","26","10","959","977","Practical process-support and workflow systems should be built to describe the simple, normal flow of events and then deal easily with irregularities, including tolerating deviations. Similarly, these systems should describe the normal format and constraints concerning the large amounts of data that are usually stored, but then deal with abnormalities and possibly accommodate exceptional values. We offer a framework for treating both kinds of irregularities uniformly by using the notion of exception handling (with human agents as potential online exception handlers) and applying it to processes that have been reified as objects in classes with steps as attributes. As a result, only a small number of new constructs, which can be applied orthogonally, need to be introduced. Special runtime checks are used to deal with the consequences of permitting deviations from the norm to persist as violations of constraints. A logical semantics of process coordination and deviations is presented as a specification for implementations.","0098-5589;1939-3520;2326-3881","","10.1109/32.879819","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=879819","","Humans;Runtime;Safety;Engines;Information management;Information retrieval;Databases;Control systems;Error correction;Data models","exception handling;workflow management software;software engineering;human factors","human centered systems;process-support systems;workflow systems;exception handling;runtime checks;logical semantics;process coordination","","6","","50","","","","","","IEEE","IEEE Journals & Magazines"
"A controlled experiment to assess the benefits of estimating with analogy and regression models","I. Myrtveit; E. Stensrud","Norwegian Sch. of Manage., Sandvika, Norway; NA","IEEE Transactions on Software Engineering","","1999","25","4","510","525","To have general validity, empirical results must converge. To be credible, an experimental science must understand the limitations and be able to explain the disagreements of empirical results. We describe an experiment to replicate previous studies which claim that estimation by analogy outperforms regression models. In the experiment, 68 experienced practitioners each estimated a project from a dataset of 48 industrial COTS projects. We applied two treatments, an analogy tool and a regression model, and we used the estimating performance when aided by the historical data as the control. We found that our results do not converge with previous results. The reason is that previous studies have used other datasets and partially different data analysis methods, and last but not least, the tools have been validated in isolation from the tool users. This implies that the results are sensitive to the experimental design: the characteristics of the dataset, the norms for removing outliers and other data points from the original dataset, the test metrics, significance levels, and the use of human subjects and their level of expertise. Thus, neither our results nor previous results are robust enough to claim any general validity.","0098-5589;1939-3520;2326-3881","","10.1109/32.799947","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=799947","","Enterprise resource planning;Testing;Humans;Costs;Convergence;Physics;Data analysis;Design for experiments;Robustness;Software performance","software cost estimation;project management;statistical analysis","controlled experiment;regression models;experienced practitioners;empirical results;experimental science;estimation by analogy;industrial COTS projects;analogy tool;regression model;estimating performance;historical data;partially different data analysis methods;tool users;experimental design;outliers;data points;dataset;test metrics;significance levels;human subjects;software cost estimation;commercial off-the-shelf software projects;multivariate regression analysis;human performance;enterprise resource planning","","89","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Toward constraint-object-oriented development","T. Bolognesi","Istituto di Elaborazione dell'Inf., CNR, Pisa, Italy","IEEE Transactions on Software Engineering","","2000","26","7","594","616","In this paper, we propose to conservatively extend object-oriented decomposition by letting it affect also operations (methods). Different objects may support different parts of the same operation. The responsibility of defining an operation, in terms of enabling conditions and effects on the state, is distributed over several interacting objects, which act as constraints and express different, partial views about the system behavior. Constraint-oriented reasoning has already been explored and applied in the context of formal specification languages for concurrent and reactive systems, and is sufficiently different from object-oriented reasoning to be considered as a paradigm in itself, with its own specific advantages. Nevertheless, the paper shows that the two approaches are sufficiently compatible to be profitably integrated. We introduce a constraint-oriented style for an object-oriented programming language (JAVA).","0098-5589;1939-3520;2326-3881","","10.1109/32.859530","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=859530","","Formal specifications;Java;Programming profession;Object oriented programming;Design methodology;Computer languages;Software engineering;Engineering management;Isolation technology;Data encapsulation","formal specification;object-oriented programming;constraint handling;Java","object-oriented decomposition;constraint-object-oriented development;constraints;partial views;interacting objects;object-oriented reasoning;constraint-oriented reasoning;constraint-oriented specification;LOTOS;multi-object operation;JAVA programming","","4","","36","","","","","","IEEE","IEEE Journals & Magazines"
"The Analogy Between Electrical Networks and Flowcharts","A. C. Davies","Department of Electrical and Electronic Engineering, The City University","IEEE Transactions on Software Engineering","","1980","SE-6","4","391","394","A recently proposed analogy between discrete systems and flowcharts is discussed. It is pointed out that the analog of Kirchhoff's voltage law does not apply to flowcharts, and that the analogy is likely to be of limited value as an aid to program analysis.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234496","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702748","Electrical networks;flowcharts;program analysis;program execution time","Flowcharts;Resistors;Kirchhoff's Law;Testing;Voltage;Probability","","Electrical networks;flowcharts;program analysis;program execution time","","","","5","","","","","","IEEE","IEEE Journals & Magazines"
"Bounding completion times of jobs with arbitrary release times, variable execution times and resource sharing","J. Sun; M. K. Gardner; J. W. S. Liu","Geoworks Inc., Berkeley, CA, USA; NA; NA","IEEE Transactions on Software Engineering","","1997","23","10","603","615","The workload of many real time systems can be characterized as a set of preemptable jobs with linear precedence constraints. Typically their execution times are only known to lie within a range of values. In addition, jobs share resources and access to the resources must be synchronized to ensure the integrity of the system. The paper is concerned with the schedulability of such jobs when scheduled on a priority driven basis. It describes three algorithms for computing upper bounds on the completion times of jobs that have arbitrary release times and priorities. The first two are simple but do not yield sufficiently tight bounds, while the last one yields the tightest bounds but has the greatest complexity.","0098-5589;1939-3520;2326-3881","","10.1109/32.637144","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=637144","","Iterative algorithms;Processor scheduling;Upper bound;Scheduling algorithm;Resource management;Real time systems;Algorithm design and analysis;Timing;Sun;Data analysis","real-time systems;resource allocation;scheduling;computational complexity;data integrity","bounding completion times;arbitrary release times;variable execution times;resource sharing;real time systems;preemptable jobs;linear precedence constraints;system integrity;schedulability;priority driven basis;complexity","","12","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Effects of field service on software reliability","C. T. Baker","IBM Corp., Poughkeepsie, NY, USA","IEEE Transactions on Software Engineering","","1988","14","2","254","258","The reliability of a program, when many copies are run in a multisite environment with the support of a software service organization, depends on the inherent reliability of the program and certain characteristics of the service organization. Here, a small number of parameters that determine the relevant characteristics of the service organization are identified, and their effects on the reliability of the program as it is experienced at an average site are analyzed. This is done with two software reliability models, a first (defect) discovery model and a total (defect) discovery model.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4642","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4642","","Software reliability;Software maintenance;Stability","programming theory;software reliability","field service;software reliability;multisite environment;software service organization","","7","","3","","","","","","IEEE","IEEE Journals & Magazines"
"Performance and stability analysis of multilevel data structures with deferred reorganization","I. -. Chen; S. A. Banawan","Dept. of Comput. Sci., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA; NA","IEEE Transactions on Software Engineering","","1999","25","5","690","700","We develop a methodology for analyzing the performance and stability of a server that maintains a multilevel data structure to service a set of access operations for (key, value) records. A subset of the operations executed by the server (e.g., insert and delete) require the multilevel data structure be reorganized so that the sewer can execute all subsequent requests efficiently. We study how often the server should carry out data reorganization (i.e., maintenance) to maximize its performance. If the server is frequently idle then there is no need to impose the reorganization overhead on the operation requests. The reorganization overhead may be completely eliminated by utilizing server-idling periods. If the server is frequently busy, then the reorganization overhead can be minimized by performing a complete reorganization only after the server has served a sufficient number of insert/delete operations so that the amortized cost per operation is small. Therefore, the issue of how often one should perform data reorganization to minimize the average service time depends not only on the multilevel data structure maintained by the server but also on the type and intensity of the system workload. The proposed methodology is exemplified with a two-level sorted file with deferred maintenance. The performance and stability results are compared with those of a single-level binary tree data structure with on-the-fly maintenance. It is shown that deferred maintenance of the two-level sorted file outperforms on-the-fly maintenance of the single-level binary tree in both open and closed systems. Furthermore, deferred maintenance can sustain higher workload intensities without risking system stability.","0098-5589;1939-3520;2326-3881","","10.1109/32.815327","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=815327","","Stability analysis;Data structures;Network servers;Performance analysis;Binary trees;File servers;Costs;Computer networks;Switches;Tree data structures","software performance evaluation;tree data structures;client-server systems;software maintenance","performance evaluation;stability analysis;multilevel data structures;deferred data reorganization;client server systems;access operations;server-idling periods;system workload;two-level sorted file;binary tree data structure;on-the-fly maintenance","","2","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Total variance approach to software reliability estimation","T. Adams","110 Waterloo Station Dr., Cary, NC, USA","IEEE Transactions on Software Engineering","","1996","22","9","687","688","This paper presents a mathematical model for a new approach to calculating the confidence intervals for software reliability projections. Unlike those calculated by current methods, these confidence intervals account for any uncertainty concerning the operational profile of the system.","0098-5589;1939-3520;2326-3881","","10.1109/32.541438","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=541438","","Software reliability;Uncertainty;System testing;Mathematical model;Bayesian methods;Prediction methods;Certification;Probability density function;Computer Society;Algorithms","software reliability;statistical analysis;Bayes methods","total variance approach;software reliability estimation;mathematical model;confidence intervals;software reliability projections;operational profile uncertainty;random testing;Bayesian methods","","14","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Introduction to the Special Section on Software Maintenance","N. F. Schneidewind","NA","IEEE Transactions on Software Engineering","","1987","SE-13","3","301","301","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233159","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702214","","Special issues and sections;Software maintenance;Software engineering;Software systems;Software performance;Employment;Large-scale systems;Computer science;Integrated circuit modeling;Software standards","","","","1","","","","","","","","IEEE","IEEE Journals & Magazines"
"Correction to 'Certifying the reliability of software' (Jan. 1986 3-11)","P. A. Curritt; M. Dyer; H. D. Mills","IBM Corp., Bethesda, MD, USA; IBM Corp., Bethesda, MD, USA; IBM Corp., Bethesda, MD, USA","IEEE Transactions on Software Engineering","","1989","15","3","362","","The authors correct several typographical errors, and misinterpretations in their abovementioned paper (see ibid., vol.SE-12, no.1, p.3-11, Jan. 1986).<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21765","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21765","","Switches;History;Sampling methods;Error correction;Certification;Electric breakdown;Databases;Software packages;Packaging;Software design","software reliability","software reliability","","55","","1","","","","","","IEEE","IEEE Journals & Magazines"
"Composition validation and subjectivity in GenVoca generators","D. Batory; B. J. Geraci","Dept. of Comput. Sci., Texas Univ., Austin, TX, USA; NA","IEEE Transactions on Software Engineering","","1997","23","2","67","82","GenVoca generators synthesize software systems by composing components from reuse libraries. GenVoca components are designed to export and import standardized interfaces, and thus be plug-compatible, interchangeable, and interoperable with other components. We examine two different but important issues in software system synthesis. First, not all syntactically correct compositions of components are semantically correct. We present simple, efficient, and domain-independent algorithms for validating compositions of GenVoca components. Second, components that export and import immutable interfaces are too restrictive for software system synthesis. We show that the interfaces and bodies of GenVoca components are subjective, i.e., they mutate and enlarge upon instantiation. This mutability enables software systems with customized interfaces to be composed from components with ""standardized"" interfaces.","0098-5589;1939-3520;2326-3881","","10.1109/32.585497","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=585497","","Software systems;Software libraries;Application software;Programming;Buildings;Software tools;Logic;Debugging;Algorithm design and analysis;Encoding","software tools;computer aided software engineering;application generators;software reusability;software libraries;program verification","composition validation;subjectivity;GenVoca generators;software system synthesis;reuse libraries;standardized interfaces;syntactically correct compositions;semantic correctness;domain-independent algorithms;mutability;customized interfaces;software generators;design rule checking;high-level specifications;code synthesis","","60","","58","","","","","","IEEE","IEEE Journals & Magazines"
"Correction to 'Protocol conversion'","S. S. Lam","Dept. of Comput. Sci., Texas Univ., Austin, TX, USA","IEEE Transactions on Software Engineering","","1988","14","9","1376","","In previously giving a summary of the theory of protocol projection (ibid., vol.14, no.3, p.353-62, Mar. 1988), an incorrect statement was made. A given statement is claimed to be false, and is corrected accordingly.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6181","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6181","","Protocols;Sufficient conditions;Logic;Testing;Cities and towns","protocols","protocol projection","","6","","4","","","","","","IEEE","IEEE Journals & Magazines"
"An Experiment on Human Engineering of Interactive Software","H. F. Ledgard; J. A. Whiteside; W. Seymour; A. Singer","Department of Computer and Information Science, University of Massachusetts; NA; NA; NA","IEEE Transactions on Software Engineering","","1980","SE-6","6","602","604","Improved human engineering can add significantly to the acceptance and use of computer technology. We report here an experiment in which users with varying degrees of interactive computing experience used two versions of an interactive text editor: one with an English-like command syntax, the other with a more notational syntax. User performance differences strongly favored the English-like editor at all levels of experience.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230804","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702787","Command languages;human engineering;interactive language;psychology of computer use","Ergonomics;Psychology;Information science;Instruments;Command languages;Natural languages;System testing;Interactive systems;Educational institutions;Computer peripherals","","Command languages;human engineering;interactive language;psychology of computer use","","1","","1","","","","","","IEEE","IEEE Journals & Magazines"
"The Interpretation of Meta Grammars Describing Syntax-Directed Interpreters Using an Attribute Grammar Interpreter","J. Kontos; G. K. Papakonstantinou","Department of Computers, NRC "Democritos," Aghia Paraskevi Attikis; NA","IEEE Transactions on Software Engineering","","1982","SE-8","4","435","436","A syntax-directed interpreter of attribute grammars is applied to interpret meta grammars describing translators. A specific example is used which concerns the formal description of the same syntax-directed interpreter of attribute grammars for illustration of our approach.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235578","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702966","Attribute grammar interpreter;attribute grammars;formal description;meta grammars","Microcomputers;Acceleration;Logic design;Logic programming;Computer languages;Computer errors","","Attribute grammar interpreter;attribute grammars;formal description;meta grammars","","","","3","","","","","","IEEE","IEEE Journals & Magazines"
"Formal requirements analysis of an avionics control system","B. Dutertre; V. Stavridou","Dept. of Comput. Sci., Queen Mary & Westfield Coll., London, UK; NA","IEEE Transactions on Software Engineering","","1997","23","5","267","278","The authors report on a formal requirements analysis experiment involving an avionics control system. They describe a method for specifying and verifying real-time systems with PVS. The experiment involves the formalization of the functional and safety requirements of the avionics system as well as its multilevel verification. First level verification demonstrates the consistency of the specifications whilst the second level shows that certain system safety properties are satisfied by the specification. They critically analyze methodological issues of large scale verification and propose some practical ways of structuring verification activities for optimizing the benefits.","0098-5589;1939-3520;2326-3881","","10.1109/32.588520","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=588520","","Aerospace electronics;Control systems;Software safety;Aircraft;Aerospace control;Real time systems;Large-scale systems;Optimization methods;Formal verification;Collaborative work","formal specification;formal verification;safety-critical software;real-time systems;military avionics;military aircraft;military computing;aircraft control","avionics control system;formal requirements analysis;real-time system specification;real-time system verification;PVS;formalized functional requirements;formalized safety requirements;multilevel verification;system safety properties;large scale verification;verification activity structuring;fighter aircraft","","29","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Program Graphs and Execution Behavior","R. R. Oldehoeft","Department of Computer Science, Colorado State University","IEEE Transactions on Software Engineering","","1983","SE-9","1","103","108","This paper describes a technique for predicting the execution behavior of a source program or a software design specification. As a by-product of syntactic analysis, a program graph is constructed which can subsequently be treated as the graph of a finite automaton. The expression for execution behavior is the regular expression of the graph. Several simplification techniques for these expressions are discussed and exemplified. In particular, the substitution of known values for program segments followed by constant folding cannot be done indiscriminately; the allowable situations are characterized. Applications include the prediction of execution time for a program or a software design, other forms of language analysis, and program restructuring.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236300","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703017","Constant folding;control flow analysis;performance prediction;program graphs;regular expressions","Costs;Software design;Automata;Application software;Performance analysis;Flow graphs;Data analysis;Computer science;Equations;Labeling","","Constant folding;control flow analysis;performance prediction;program graphs;regular expressions","","6","","4","","","","","","IEEE","IEEE Journals & Magazines"
"Heap-filter merge join: a new algorithm for joining medium-size inputs","G. Graefe","Dept. of Comput. Sci., Colorado Univ., Boulder, CO, USA","IEEE Transactions on Software Engineering","","1991","17","9","979","982","A novel algorithm for relational equijoin is presented. The algorithm is a modification of merge join, but promises superior performance for medium-size inputs. In many cases it even compares favorably with both merge join and hybrid hash join, which is shown using analytic cost functions.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.92919","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=92919","","Sorting;Relational databases;Merging;Cost function;Performance analysis;Database systems;Computer science;Writing;Probes","database theory;relational databases","heap filter merge join;medium-size inputs;novel algorithm;relational equijoin;merge join;medium-size inputs;hybrid hash join;analytic cost functions","","","","11","","","","","","IEEE","IEEE Journals & Magazines"
"An incremental version of iterative data flow analysis","L. L. Pollock; M. L. Soffa","Dept. of Comput. Sci., Rice Univ., Houston, TX, USA; NA","IEEE Transactions on Software Engineering","","1989","15","12","1537","1549","A technique is presented for incrementally updating solutions to both union and intersection data-flow problems in response to program edits and transformations. For generality, the technique is based on the iterative approach to computing data-flow information. The authors show that for both union and intersection problems, some changes can be incrementally incorporated immediately into the data-flow sets while others are handled by a two-phase approach. The first phase updates the data-flow sets to overestimate the effect of the program change, enabling the second phase to incrementally update the affected data-flow sets to reflect the actual program change. An important problem that is addressed is the computation of the data-flow changes that need to be propagated throughout a program, based on different local code changes. The technique is compared to other approaches to incremental data-flow analysis.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58766","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58766","","Data analysis;Data flow computing;Information analysis;Application software;Iterative methods;Computer science;Optimizing compilers;Software testing;Optimization methods;Programming environments","iterative methods;parallel programming;set theory;systems analysis","union data flow problems;incremental version;iterative data flow analysis;intersection data-flow problems;program edits;iterative approach;data-flow information;data-flow sets;two-phase approach;data-flow sets;local code changes","","33","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Sufficient condition for a communication deadlock and distributed deadlock detection","B. E. Wojcik; Z. M. Wojcik","Beechcraft Co., Wichita, KS, USA; NA","IEEE Transactions on Software Engineering","","1989","15","12","1587","1595","The necessary and sufficient condition for deadlock in a distributed system and an algorithm for detection of a distributed deadlock based on the sufficient condition are formulated. The protocol formulated, checks all wait-for contiguous requests in one iteration. A cycle is detected when a query message reaches the initiator. A wait-for cycle is only the necessary condition for the distributed deadlock. A no-deadlock message is expected by the query initiator to infer a deadlock-free situation if at least one wait-for cycle is present. A no-deadlock message is issued by a dependent (query intercessor) that is not waiting-for. No no-deadlock message implies a deadlock, and processes listed in the received query messages are the processes involved in a distributed deadlock. Properties of the protocol are discussed. The authors show that a replication of a requested higher-priority (or older) process can prevent a distributed deadlock (in a continuous deadlock treatment). A replication is shown to recover (in a periodical deadlock handling) a sequence of processes from an indefinite wait-die scheme.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58770","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58770","","System recovery;Sufficient conditions;Protocols;Network servers;Resource management;Imaging phantoms;Mathematics;Computer science;Statistics;Hardware","distributed processing;system recovery","communication deadlock;distributed deadlock detection;sufficient condition;protocol;wait-for contiguous requests;query message;wait-for cycle;no-deadlock message;query initiator;deadlock-free situation;query intercessor;replication;periodical deadlock handling;indefinite wait-die scheme","","6","","12","","","","","","IEEE","IEEE Journals & Magazines"
"A modeling framework to implement preemption policies in non-Markovian SPNs","A. Bobbio; A. Puliafito; M. Tekel","Fac. di Sci., Univ. del Piemonte, Alessandrai, Italy; NA; NA","IEEE Transactions on Software Engineering","","2000","26","1","36","54","Petri nets represent a useful tool for performance, dependability, and performability analysis of complex systems. Their modeling power can be increased even more if nonexponentially distributed events are considered. However, the inclusion of nonexponential distributions destroys the memoryless property and requires to specify how the marking process is conditioned upon its past history. We consider, in particular, the class of stochastic Petri nets whose marking process can be mapped into a Markov regenerative process. An adequate mathematical framework is developed to deal with the considered class of Markov Regenerative Stochastic Petri Nets (MRSPN). A unified approach for the solution of MRSPNs where different preemption policies can be defined in the same model is presented. The solution is provided both in steady-state and in transient condition. An example concludes the paper.","0098-5589;1939-3520;2326-3881","","10.1109/32.825765","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=825765","","Power system modeling;Stochastic processes;Petri nets;Steady-state;Transient analysis;Computer Society;Performance analysis;History;Specification languages;Stochastic systems","Petri nets;Markov processes;software performance evaluation;specification languages;formal specification","modeling framework;preemption policies;performance analysis;dependability analysis;nonexponentially distributed events;mathematical framework;Markov Regenerative Stochastic Petri Nets;steady-state condition;transient condition;specification language","","34","","35","","","","","","IEEE","IEEE Journals & Magazines"
"Implementing atomic actions in Ada 95","A. Wellings; A. Burns","Dept. of Comput. Sci., York Univ., UK; NA","IEEE Transactions on Software Engineering","","1997","23","2","107","123","Atomic actions are an important dynamic structuring technique that aid the construction of fault-tolerant concurrent systems. Although they were developed some years ago, none of the well-known commercially-available programming languages directly support their use. This paper summarizes software fault tolerance techniques for concurrent systems, evaluates the Ada 95 programming language from the perspective of its support for software fault tolerance, and shows how Ada 95 can be used to implement software fault tolerance techniques. In particular, it shows how packages, protected objects, requeue, exceptions, asynchronous transfer of control, tagged types, and controlled types can be used as building blocks from which to construct atomic actions with forward and backward error recovery, which are resilient to deserter tasks and task abortion.","0098-5589;1939-3520;2326-3881","","10.1109/32.585500","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=585500","","Fault tolerant systems;Computer languages;Fault tolerance;Redundancy;Fault detection;Computer Society;Packaging;Protection;Error correction;Abortion","Ada;software fault tolerance;system recovery;exception handling;concurrency control;parallel programming","atomic actions;Ada 95;dynamic structuring technique;fault-tolerant concurrent systems;software fault tolerance techniques;packages;protected objects;requeue;exceptions;asynchronous transfer of control;tagged types;controlled types;error recovery;task abortion;deserter tasks;exception handling;recovery blocks","","9","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Modeling the effects of combining diverse software fault detection techniques","B. Littlewood; P. T. Popov; L. Strigini; N. Shryane","Centre for Software Reliability, City Univ., London, UK; NA; NA; NA","IEEE Transactions on Software Engineering","","2000","26","12","1157","1167","Considers what happens when several different fault-finding techniques are used together. The effectiveness of such multi-technique approaches depends upon a quite subtle interplay between their individual efficacies. The modeling tool we use to study this problem is closely related to earlier work on software design diversity which showed that it would be unreasonable even to expect software versions that were developed truly independently to fail independently of one another. The key idea was a ""difficulty function"" over the input space. Later work extended these ideas to introduce a notion of ""forced"" diversity. In this paper, we show that many of these results for design diversity have counterparts in diverse fault detection in a single software version. We define measures of fault-finding effectiveness and diversity, and show how these might be used to give guidance for the optimal application of different fault-finding procedures to a particular program. The effects on reliability of repeated applications of a particular fault-finding procedure are not statistically independent; such an incorrect assumption of independence will always give results that are too optimistic. For diverse fault-finding procedures, it is possible for effectiveness to be even greater than it would be under an assumption of statistical independence. Diversity of fault-finding procedures is a good thing and should be applied as widely as possible. The model is illustrated using some data from an experimental investigation into diverse fault-finding on a railway signalling application.","0098-5589;1939-3520;2326-3881","","10.1109/32.888629","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=888629","","Diversity reception;Fault detection;Software design;Application software;Redundancy;Hardware;Aerospace control;Battery powered vehicles;Software engineering;Particle measurements","system recovery;program diagnostics;software reliability;signalling;railways","software fault detection techniques;multi-technique approach;modeling tool;software design diversity;independently developed software versions;system failure;difficulty function;forced diversity;fault-finding effectiveness;repeated application reliability;diverse fault-finding procedures;statistical independence;railway signalling application;fault removal;software testing;software reliability growth","","22","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Distributed agreement in the presence of processor and communication faults","K. J. Perry; S. Toueg","IBM Thomas J. Watson Research Center, Yorktown Heights, NY 10598; Department of Computer Science, Cornell University, Ithaca, NY 14853","IEEE Transactions on Software Engineering","","1986","SE-12","3","477","482","A model of distributed computation is proposed in which processes may fail by not sending or receiving the message specified by a protocol. The solution to the Byzantine generals problem for this model is presented. The algorithm exhibits early stopping under conditions of less than maximum failure and is as efficient as the algorithm developed for the more restrictive crash-fault model in terms of time, message, and bit complexity. The authors show extant models to underestimate resiliency when faults in the communication medium are considered; the model outlined here is more accurate in this regard.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312888","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312888","Byzantine agreement;distributed computing;early stopping;fault tolerance;protocols","Protocols;Computer crashes;Complexity theory;Computational modeling;Relays;Fault tolerance;Fault tolerant systems","distributed processing;fault tolerant computing;protocols","software engineering;processor faults;communication faults;distributed computation;protocol;Byzantine generals problem;early stopping;crash-fault model;bit complexity;resiliency","","18","","","","","","","","IEEE","IEEE Journals & Magazines"
"Selected papers from the second IFIP Int'l conference on formal methods for open object based distributed systems, 1997","H. Bowman; J. Derrick; E. Brinksma","The University of Kent at Canterbury; NA; NA","IEEE Transactions on Software Engineering","","2000","26","7","577","578","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.2000.859528","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=859528","","","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on ""Allocating programs containing branches and loops within a multiple processor system"" by D. Towsley","F. Kaudel","Dept of Syst. & Comput. Eng., Carleton Univ., Ottawa, Ont., Canada","IEEE Transactions on Software Engineering","","1990","16","4","471","","The assignment algorithms proposed by D. Towsley (see ibid., vol.12, no.10, p.1018-24 (1986)) may not minimize the total communication and execution costs as stated. An example where the proposed restricted assignment algorithm fails to find an optimal assignment is given, and modifications that allow the algorithm to properly consider execution costs are proposed. Additional changes needed to model communication costs correctly in many assignment problems are discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.54298","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=54298","","Cost function;Distributed processing;Processor scheduling;Scheduling algorithm","operating systems (computers);scheduling","programs allocation;branches;loops;multiple processor system;assignment algorithms","","1","","1","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on ""Temporal logic-based deadlock analysis for Ada"" by G.M. Karam and R.J.A. Burh","M. Young; D. L. Levine; R. N. Taylor","Dept. of Comput. Science, Purdue Univ., West Lafayette, IN, USA; NA; NA","IEEE Transactions on Software Engineering","","1993","19","2","198","199","The commenters discuss several flaws they found in the above-titled paper by G.M. Koran and R.J.A. Burh (see ibid., vol.17, no.10, p.109-1125, (1991)). The commenters argue that the characterization of operational and axiomatic proof method is modified and inaccurate; the classification of modeling techniques for concurrent systems confuses the distinction between state-based and event-based models with the essential distinction between explicit enumeration of behaviors and symbolic manipulation of properties; the statements about the limitations of linear-time temporal logic in relation to nondeterminism are inaccurate; and the characterization of the computational complexity of the analysis technique is overly optimistic.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.214836","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=214836","","System recovery;Logic;Computational complexity;Computer science;Interleaved codes;Testing;Heart;Software engineering;Safety;Reachability analysis","Ada;computational complexity;concurrency control;symbol manipulation;temporal logic","temporal logic-based deadlock analysis;state-based models;Ada;axiomatic proof method;event-based models;symbolic manipulation;nondeterminism;computational complexity","","","","14","","","","","","IEEE","IEEE Journals & Magazines"
"A multiframe model for real-time tasks","A. K. Mok; D. Chen","Dept. of Comput. Sci., Texas Univ., Austin, TX, USA; NA","IEEE Transactions on Software Engineering","","1997","23","10","635","645","The well known periodic task model of C.L. Liu and J.W. Layland (1973) assumes a worst case execution time bound for every task and may be too pessimistic if the worst case execution time of a task is much longer than the average. We give a multiframe real time task model which allows the execution time of a task to vary from one instance to another by specifying the execution time of a task in terms of a sequence of numbers. We investigate the schedulability problem for this model for the preemptive fixed priority scheduling policy. We show that a significant improvement in the utilization bound can be established in our model.","0098-5589;1939-3520;2326-3881","","10.1109/32.637146","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=637146","","Processor scheduling;Scheduling algorithm;Vehicles;Computational modeling;Adaptive scheduling;Timing","real-time systems;scheduling;multiprogramming;computational complexity","execution time;real time tasks;periodic task model;worst case execution time bound;multiframe real time task model;schedulability problem;preemptive fixed priority scheduling policy;utilization bound","","95","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Optimal Release Time of Computer Software","H. S. Koch; P. Kubat","Graduate School of Management, University of Rochester; NA","IEEE Transactions on Software Engineering","","1983","SE-9","3","323","327","A decision procedure to determine when computer software should be released is described. This procedure is based upon the cost-benefit for the entire company that has developed the software. This differs from the common practice of only minimizing the repair costs for the data processing division. Decision rules are given to determnine at what time the system should be released based upon the results of testing the software. Necessary and sufficient conditions are identified which determine when the system should be released (immediately, before the deadline, at the deadline, or after the deadline). No assumptions are made about the relationship between any of the model's parameters. The model can be used whether the software was developed by a first or second party. The case where future costs are discounted is also considered.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236868","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703060","Cost-benefit analysis;optimal release time;project management;software reliability","Software testing;System testing;Cost function;Programming;Data processing;Predictive models;Sufficient conditions;Project management;Software reliability;Computer industry","","Cost-benefit analysis;optimal release time;project management;software reliability","","71","","6","","","","","","IEEE","IEEE Journals & Magazines"
"An experimental investigation of software metrics and their relationship to software development effort","R. K. Lind; K. Vairavan","Gen. Electr. Med. Syst., Milwaukee, WI, USA; NA","IEEE Transactions on Software Engineering","","1989","15","5","649","653","The results are reported of an experimental study of software metrics for a fairly large software system used in a real-time application. A number of issues are examined, including the mutual relationship between various software metrics and, more importantly, the relationship between metrics and the development effort. Some interesting connections are reported between metrics and the software development effort.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24715","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24715","","Software metrics;Programming;Bandwidth;Application software;Software maintenance;Software systems;Real time systems;Software quality;Computer industry","software engineering","software metrics;software development;software system;real-time application;mutual relationship","","55","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Algorithms for scheduling real-time tasks with input error and end-to-end deadlines","Wu-Chun Feng; J. W. -. Liu","Dept. of Comput. Sci., Illinois Univ., Urbana, IL, USA; NA","IEEE Transactions on Software Engineering","","1997","23","2","93","106","This paper describes algorithms for scheduling preemptive, imprecise, composite tasks in real-time. Each composite task consists of a chain of component tasks, and each component task is made up of a mandatory part and an optional part. Whenever a component task uses imprecise input, the processing times of its mandatory and optional parts may become larger. The composite tasks are scheduled by a two-level scheduler. At the high level, the composite tasks are scheduled preemptively on one processor, according to an existing algorithm for scheduling simple imprecise tasks. The low-level scheduler then distributes the time budgeted for each composite task across its component tasks so as to minimize the output error of the composite task.","0098-5589;1939-3520;2326-3881","","10.1109/32.585499","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=585499","","Scheduling algorithm;Timing;Processor scheduling;Error correction;Computer applications;Distributed computing;Real time systems;Robustness;Degradation;Video compression","real-time systems;programming theory;scheduling","real-time task scheduling algorithms;input error;end-to-end deadlines;composite task;component tasks;two-level scheduler;imprecise tasks;transient overload;imprecise-computation technique","","34","","22","","","","","","IEEE","IEEE Journals & Magazines"
"A simple mechanism for type security across compilation units","M. L. Scott; R. A. Finkel","Dept. of Comput. Sci., Rochester Univ., NY, USA; NA","IEEE Transactions on Software Engineering","","1988","14","8","1238","1239","A simple technique is described that detects structural-type clashes across compilation units with an arbitrarily high degree of confidence. The type of each external object is described in canonical form. A hash function compresses the description into a short code. If the code is embedded in a symbol-table name, then consistency can be checked by an ordinary linker. For distributed programs, run-time checking of message types can be performed with very little overhead.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.7631","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=7631","","Runtime;Scholarships;Computer science;File servers","data structures;program compilers","compilers;data structures;type security;compilation units;structural-type clashes;hash function;symbol-table name;ordinary linker;distributed programs;run-time checking;message types","","3","","9","","","","","","IEEE","IEEE Journals & Magazines"
"EVA: a flexible programming method for evolving systems","S. Matsuura; H. Kuruma; S. Honiden","Lab. for New Software Archit., Inf. Technol. Promotion Agency, Tokyo, Japan; NA; NA","IEEE Transactions on Software Engineering","","1997","23","5","296","313","The authors' goal is to establish a flexible programming support for evolving systems that will enable one to modify programs using less labor, while maintaining good quality during service life. EVA (evolution mechanism for flexible agent) was developed to allow a flexible programming support system to be constructed based on their programming method for evolving systems. They consider that programming methods for evolving systems need to satisfy the following essential conditions. First, they need to make it easy to specify changes in a system in terms of new requirements. Second, they need to have a procedure for transmitting the new requirements to a program. Third, they need to be able to guarantee that the resultant program will meet the new requirements. Finally, because of the repetitive nature of much evolving systems work, they need to provide for the reuse of similar modifications during programming. In order to overcome limitations in program modification techniques which have only considered programming products, programming processes have been introduced into the method. To achieve their goal, they have formulated programming products and programming processes using such formal techniques as functional programming, type theory, modules, parameterized programming and natural deduction, and have constructed a mechanism of reusing these formal programming processes. The paper explains a case study which shows how to develop an evolving system using EVA and it discusses how one can use EVA's mechanism effectively.","0098-5589;1939-3520;2326-3881","","10.1109/32.588522","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=588522","","Functional programming;Genetic programming;Programming profession;High level languages;Automatic programming;Application software;Laboratories;Software architecture","software reusability;formal specification;programming environments;software maintenance;functional programming;type theory","flexible programming method;evolving systems;EVA;program modification;quality;evolution mechanism for flexible agent;change specification;new requirements;modification reuse;formal techniques;functional programming;type theory;modules;parameterized programming;natural deduction;formal programming processes","","5","","27","","","","","","IEEE","IEEE Journals & Magazines"
"On the projection method for protocol verification","T. Cheung","Distributed Computing Research Group, Department of Computer Science, University of Ottawa, Ottawa, Ont., Canada K1N 9B4","IEEE Transactions on Software Engineering","","1986","SE-12","11","1088","1089","S.S. Lam and A.U. Shankar (1982) have proposed a projection method for protocol verification. They claim that the method guarantees the faithfulness of the safety and liveness properties of a protocol system. Although not clearly defined, `faithfulness' appears to mean that `the image protocol system is live (respectively, safe) if and only if the original protocol system is live (respectively, safe). It is shown that the `only if' part is not true for certain liveness properties, and a remedy is suggested.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312998","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312998","Projection method;protocol verification;safety and liveness properties","Protocols;Real-time systems;Timing;Software reliability;Fault tolerance;Fault tolerant systems","protocols","projection method;protocol verification;image protocol system","","1","","","","","","","","IEEE","IEEE Journals & Magazines"
"Correction to ""Specification and Verification of Communication Protocols in AFFIRM Using State Transition Models""","C. A. Sunshine; D. H. Thompson; R. W. Erickson; S. L. Gerhart; D. Schwabe","Information Sciences Institute, University of Southern California; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1983","SE-9","1","113","113","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236302","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703019","","Protocols;Computer science","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"An architecture for high performance engineering information systems","N. Roussopoulos; L. Mark; T. Sellis; C. Faloutsos","Maryland Univ., College Park, MD, USA; Maryland Univ., College Park, MD, USA; Maryland Univ., College Park, MD, USA; Maryland Univ., College Park, MD, USA","IEEE Transactions on Software Engineering","","1991","17","1","22","33","Commercially available database systems do not meet the information and processing needs of design and manufacturing environments. A new generation of systems-engineering information systems-must be built to meet these needs. The architectural and computational aspects of such systems are addressed, and solutions are proposed. The authors argue that a mainframe-workstation architecture is needed to provide distributed functionality while ensuring high availability and low communication overhead, that explicit control of metaknowledge is needed to support extendibility and evolution, that large rule bases are needed to make the knowledge of the systems active, and that incremental computation models are needed to achieve the required performance of such engineering information systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.67576","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=67576","","Computer architecture;Database systems;Process design;Manufacturing processes;Availability;Communication system control;Distributed computing;High performance computing;Computational modeling;Knowledge engineering","database management systems;manufacturing data processing","design environments;engineering information systems;database systems;manufacturing environments;mainframe-workstation architecture;distributed functionality;metaknowledge;extendibility;evolution;rule bases;knowledge;incremental computation models;performance","","4","","51","","","","","","IEEE","IEEE Journals & Magazines"
"Cost-effective analysis of in-place software processes","J. E. Cook; L. G. Votta; A. L. Wolf","Dept. of Comput. Sci., New Mexico State Univ., Las Cruces, NM, USA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","8","650","663","Process studies and improvement efforts typically call for new instrumentation on the process in order to collect the data they have deemed necessary. This can be intrusive and expensive, and resistance to the extra workload often foils the study before it begins. The result is neither interesting new knowledge nor an improved process. In many organizations, however, extensive historical process and product data already exist. Can these existing data be used to empirically explore what process factors might be affecting the outcome of the process? If they can, organizations would have a cost-effective method for quantitatively, if not causally, understanding their process and its relationship to the product. We present a case study that analyzes an in-place industrial process and takes advantage of existing data sources. In doing this, we also illustrate and propose a methodology for such exploratory empirical studies. The case study makes use of several readily-available repositories of process data in the industrial organization. Our results show that readily available data can be used to correlate both simple aggregate metrics and complex process metrics with defects in the product. Through the case study, we give evidence supporting the claim that exploratory empirical studies can provide significant results and benefits while being cost-effective in their demands on the organization.","0098-5589;1939-3520;2326-3881","","10.1109/32.707700","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=707700","","Instruments;Computer Society;Software engineering;Industrial relations;Aggregates;Software measurement;Software quality;Computer industry;History;Electrical equipment industry","software engineering","cost-effective analysis;in-place software processes;process improvement;historical data;retrospective case study;industrial process;existing data sources;exploratory empirical studies;process data repositories;aggregate metrics;complex process metrics;software product defects;organizational demands;process measurement;process model validation","","7","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Query optimization for nontraditional database applications","T. K. Sellis; L. Shapiro","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; NA","IEEE Transactions on Software Engineering","","1991","17","1","77","86","Database query languages and their use for programming nontraditional applications, such as engineering and artificial intelligence applications, are discussed. In such environments, database programs are used to code applications that work over large data sets residing in databases. Optimizing such programs then becomes a necessity. An examination is made of various optimization techniques, and transformations are suggested for improving the performance of database programs. These transformations result in new equivalent database programs with better space and time performance. Several of these techniques apply to classical query languages, although extended query languages which include an iteration operator are specifically discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.67580","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=67580","","Query processing;Database languages;Relational databases;Data engineering;Artificial intelligence;Computer science;Deductive databases;Indexes;Database systems;Data processing","database management systems;query languages","query optimization;database query languages;space performance;nontraditional database applications;programming;engineering;artificial intelligence;environments;large data sets;equivalent database programs;time performance;extended query languages;iteration operator","","1","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Primitives for distributed computing in a heterogeneous local area network environment","G. Bernard; A. Duda; Y. Haddad; G. Harrus","ISEM, Univ. Paris-Sud, Orsay, France; NA; NA; NA","IEEE Transactions on Software Engineering","","1989","15","12","1567","1578","Epsilon is a testbed for monitoring distributed applications involving heterogeneous computers, including microcomputers, interconnected by a local area network. Such a hardware configuration is usual but raises difficulties for the programmer. First, the interprocess communication mechanisms provided by the operating systems are rather cumbersome to use. Second, they are different from one system to another. Third, the programmer of distributed applications should not worry about system and/or network aspects that are not relevant for the application level. The authors present the solution chosen in Epsilon. A set of high-level communication primitives has been designed and implemented to provide the programmer with an interface independent of the operating system and of the underlying interprocess communications facilities. A program participating in a distributed application can be executed on any host without any change in the source code except for host names.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58768","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58768","","Distributed computing;Programming profession;Application software;Operating systems;Testing;Computerized monitoring;Computer applications;Computer networks;Microcomputers;LAN interconnection","computer communications software;local area networks;software engineering","distributed computing;heterogeneous local area network environment;distributed applications;heterogeneous computers;microcomputers;hardware configuration;interprocess communication mechanisms;operating systems;network aspects;Epsilon;high-level communication primitives;source code;host names","","7","","52","","","","","","IEEE","IEEE Journals & Magazines"
"Performance measurement for parallel and distributed programs: a structured and automatic approach","C. -. Yang; B. P. Miller","Dept. of Comput. Sci., North Texas Univ., Denton, TX, USA; NA","IEEE Transactions on Software Engineering","","1989","15","12","1615","1629","Novel approaches are presented for designing performance measurement systems for parallel and distributed programs. The first approach involves unifying performance information into a single, regular structure that reflects the structure of programs under measurement. The authors define a hierarchical model for the execution of parallel and distributed programs as a framework for the performance measurement. A complete different levels of detail in the hierarchy. The second approach is based on the development of automatic guidance techniques that can direct users to the location of performance problems in the program. Guidance information from such techniques supplies facts about problems in the program and provides possible answers for the further improvement of program efficiency. A performance measurement system, called IPS, has been developed as a prototype of the authors' model and design. Some of the test results from IPS are also discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58772","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58772","","Operating systems;Prototypes;Testing;Distributed computing;Concurrent computing;Delay;Peer to peer computing;Computer science;Current measurement;Computer languages","multiprocessing programs;performance evaluation;program testing;software reliability","parallel programs;automatic approach;performance measurement systems;distributed programs;performance information;hierarchical model;automatic guidance techniques;performance problems;program efficiency;IPS","","28","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Using coverage information to predict the cost-effectiveness of regression testing strategies","D. S. Rosenblum; E. J. Weyuker","Dept. of Inf. & Comput. Sci., California Univ., Irvine, CA, USA; NA","IEEE Transactions on Software Engineering","","1997","23","3","146","156","Selective regression testing strategies attempt to choose an appropriate subset of test cases from among a previously run test suite for a software system, based on information about the changes made to the system to create new versions. Although there has been a significant amount of research in recent years on the design of such strategies, there has been very little investigation of their cost-effectiveness. The paper presents some computationally efficient predictors of the cost-effectiveness of the two main classes of selective regression testing approaches. These predictors are computed from data about the coverage relationship between the system under test and its test suite. The paper then describes case studies in which these predictors were used to predict the cost-effectiveness of applying two different regression testing strategies to two software systems. In one case study, the TESTTUBE method selected an average of 88.1 percent of the available test cases in each version, while the predictor predicted that 87.3 percent of the test cases would be selected on average.","0098-5589;1939-3520;2326-3881","","10.1109/32.585502","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=585502","","System testing;Software testing;Costs;Software systems;Computer Society;Information analysis;Personnel","statistical analysis;software cost estimation;program testing;system monitoring","coverage information;cost effectivenes prediction;selective regression testing strategies;test cases;test suite;software system;system changes;computationally efficient predictors;coverage relationship;TESTTUBE method","","43","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on ""A distributed scheme for detecting communication deadlocks"" by N. Natarajan","Liu Lingzhong","Dept. of Electron., Inner Mongolia Univ., Huhehot, China","IEEE Transactions on Software Engineering","","1989","15","7","926","","A distributed scheme for detecting communication deadlocks and a correctness proof of the algorithm were given by N. Natarajan (see ibid., vol.SE-12, p.531-7 (1986)). It is shown in this correspondence that the proof is not strict.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.29492","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=29492","","System recovery;Microcomputers;Software design","distributed processing","communication deadlocks detection;distributed scheme;correctness proof","","","","2","","","","","","IEEE","IEEE Journals & Magazines"
"An Aspect of Aesthetics in Human-Computer Communications: Pretty Windows","J. Gait","Computer Research Laboratory, Tektronix, Inc.","IEEE Transactions on Software Engineering","","1985","SE-11","8","714","717","Aesthetics in user interfaces addresses font definitions, typesetting conventions, color combinations, graphics design considerations, high resolution for viewscreens, and the shapes of windows. Computer viewscreens are evolving into pictorial media, communicating information with visual immediacy. The more interesting interfaces make use of multiple windows, menus, icons, and other visual effects to waken and sustain user interest and effectiveness. A pretty window is a viewscreen window with the dimensions of a golden rectangle, a rectangle whose width and height form the golden ratio of Euclid. Psychologists believe golden rectangles are aesthetically more pleasing than arbitrary rectangles, and subjects tend to select them in preference to other rectangles in tests.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232520","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702080","Aesthetics;human factors;man-machine communications;psychological preferences;viewscreen windows","Computer interfaces;Application software;User interfaces;Typesetting;Computer graphics;Shape;Psychology;Software safety;Workstations;Communication system control","","Aesthetics;human factors;man-machine communications;psychological preferences;viewscreen windows","","10","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Supertotal function definition in mathematics and software engineering","R. Boute","INTEC, Ghent Univ., Belgium","IEEE Transactions on Software Engineering","","2000","26","7","662","672","In engineering (including computing), mathematics and logic, expressions can arise that contain function applications where the argument is outside the function's domain. Such a situation need not represent a conceptual error, for instance, in conditional expressions, but it is traditionally considered a type error. Various solutions can be found in the literature based on the notion of partial function and/or a distinguished value undefined. However, these have rather pervasive effects, complicating function definition, sacrificing convenient algebraic laws of logical operators and/or Leibniz's rule, one of the most valuable assets in formal reasoning (especially in the calculational style). Other solutions have in common the realization that well-structured mathematical arguments are always guarded by conditions and that the value of A/spl rArr/B is not affected by domain violations in B in case-A. These solutions preserve Leibniz's rule and the standard meaning of the logical operators. In this second category, we propose the simplest possible solution, called supertotal function definition, and consisting of assigning the value false (or 0, depending on the preferred formalism) to any function application where the argument is outside the domain. This approach assumes the notion of function with which a domain is associated as a part of its specification. Ramifications regarding formal reasoning, use in software engineering (such as Parnas's predicate calculus) and in mathematical formulation in general are discussed. The proposed solution justifies formal reasoning as usual, but with increased freedom in expressions regarding types of function arguments. Hence, it can be adopted in existing formalisms with very minor changes to the latter, As a bonus, this discussion includes a very simple new view on conditional expressions, yielding unusually powerful and convenient calculational properties. Finally, differences and advantages w.r.t. other approaches are pointed out.","0098-5589;1939-3520;2326-3881","","10.1109/32.859534","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=859534","","Mathematics;Software engineering;Application software;Calculus;Logic;Software standards","formal specification","function definition;software engineering;mathematics;formal methods;software specification;predicate calculus;calculational reasoning;functional mathematics;guarded formulas;conditional expressions;undefinedness;type correctness;subtyping","","1","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Mathematical notation in formal specification: too difficult for the masses?","K. Finney","Sch. of Comput. & Math. Sci., Greenwich Univ., London, UK","IEEE Transactions on Software Engineering","","1996","22","2","158","159","The phrase ""not much mathematics required"" can imply a variety of skill levels. When this phrase is applied to computer scientists, software engineers, and clients in the area of formal specification, the word ""much"" can be widely misinterpreted with disastrous consequences. A small experiment in reading specifications revealed that students already trained in discrete mathematics and the specification notation performed very poorly; much worse than could reasonably be expected if formal methods proponents are to be believed.","0098-5589;1939-3520;2326-3881","","10.1109/32.485225","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=485225","","Formal specifications;Mathematics;Programming profession;Mathematical programming;Education;Software engineering;Computer science;Natural languages;Set theory;Logic","formal specification;computer science education;teaching","mathematical notation;formal specification;skill levels;computer scientists;software engineers;students;discrete mathematics;specification notation;formal methods","","33","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Using CSP to detect errors in the TMN protocol","G. Lowe; B. Roscoe","Dept. of Math. & Comput. Sci., Leicester Univ., UK; NA","IEEE Transactions on Software Engineering","","1997","23","10","659","669","We use FDR (Failures Divergence Refinement), a model checker for CSP, to detect errors in the TMN protocol (M. Tatebayashi et al., 1990). We model the protocol and a very general intruder as CSP processes, and use the model checker to test whether the intruder can successfully attack the protocol. We consider three variants on the protocol, and discover a total of 10 different attacks leading to breaches of security.","0098-5589;1939-3520;2326-3881","","10.1109/32.637148","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=637148","","Cryptography;Cryptographic protocols;State-space methods;Testing;Communication system security;Mobile communication;Algebra;Authentication;Redundancy","protocols;formal verification;program verification;cryptography;communicating sequential processes","security breaches;TMN protocol;error detection;FDR;Failures Divergence Refinement;model checker;general intruder;CSP processes;communicating sequential processes","","67","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Efficient expressions for completely and partly unsuccessful batched search of tree-structured files","S. D. Lang; Y. Manolopoulos","Dept. of Comput. Sci., Central Florida Univ., Orlando, FL, USA; NA","IEEE Transactions on Software Engineering","","1990","16","12","1433","1435","Closed-form, nonrecurrent expressions for the cost of completely and partly unsuccessful batched searching are developed for complete j-ary tree files. These expressions are applied to both the replacement and nonreplacement models of the search queries. The expressions provide more efficient formulas than previously reported for calculating the cost of batched searching. The expressions can also be used to estimate the number of block accesses for hierarchical file structures.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.62451","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=62451","","Costs;Database systems;Tiles;Buffer storage;Query processing;Relational databases;Closed-form solution;Computer science;Probability","batch processing (computers);data structures;database management systems;information retrieval systems;search problems;trees (mathematics)","nonrecurrent expressions;partly unsuccessful batched searching;complete j-ary tree files;nonreplacement models;search queries;block accesses;hierarchical file structures","","1","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Factors that impact implementing a system development methodology","T. L. Roberts; M. L. Gibson; K. T. Fields; R. K. Rainer","Dept. of Manage., Central Florida Univ., Orlando, FL, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","8","640","649","Presents the findings of empirical research from 61 companies, mostly from the USA, to identify the factors that may impact implementation of a system development methodology (SDM). The study uses a survey instrument to identify the SDM implementation factors. The survey focused on the perspective of the primary constituents: functional managers, information systems managers, system personnel and external consultants. The study uses an exploratory factor analysis that identifies five factors important to implementing an SDM: organizational SDM transition, functional management involvement/support, SDM transition, the use of models and external support. The research findings have important implications for further research and the practice of system development. For researchers, it points to important measures in the implementation and use of SDMs that may be further verified and extended in subsequent research. For practitioners, it provides a general guide to the important aspects to consider in the implementation and use of an SDM.","0098-5589;1939-3520;2326-3881","","10.1109/32.707699","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=707699","","Computer aided software engineering;Information management;Management information systems;Project management;Software development management;Programming;Information systems;Error correction;Instruments;Personnel","software engineering;statistical analysis","system development methodology implementation factors;USA;survey instrument;functional managers;information systems managers;system personnel;external consultants;exploratory factor analysis;organizational transition;functional management involvement;functional management support;models;external support;project management;system life-cycle","","14","","42","","","","","","IEEE","IEEE Journals & Magazines"
"A simplification of a conversation design scheme using Petri nets","J. Wu; E. B. Fernandez","Dept. of Electr. & Comput. Eng., Florida Atlantic Univ., Boca Raton, FL, USA; Dept. of Electr. & Comput. Eng., Florida Atlantic Univ., Boca Raton, FL, USA","IEEE Transactions on Software Engineering","","1989","15","5","658","660","In the conversation design procedure, the definition of the state of the system is one of the most important aspects. The question is how to identify transitions in Occam programs in order to express them as Petri nets. In the paper, a simplified transition identification method is proposed. Using the robot arm control program of A.M. Tyrrell and D.J. Holding it is shown that the correspondent Petri net graph is simpler than theirs, but the communication state change table is the same. It is also shown that these two methods are equivalent.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24717","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24717","","Petri nets;Fault tolerance;Robot control;Reactive power;Buildings;Software testing","fault tolerant computing;Petri nets;software engineering;software reliability","system state;fault tolerant software;conversation design;Petri nets;transitions;Occam programs;simplified transition identification method;robot arm control program;Tyrrell;Holding;Petri net graph;communication state change table","","2","","5","","","","","","IEEE","IEEE Journals & Magazines"
"An Experimental Study of Software Metrics for Real-Time Software","H. A. Jensen; K. Vairavan","Johnson Controls, Inc.; NA","IEEE Transactions on Software Engineering","","1985","SE-11","2","231","234","The rising costs of software development and maintenance have naturally aroused intere5t in tools and measures to quantify and analyze software complexity. Many software metrics have been studied widely because of the potential usefulness in predicting the complexity and quality of software. Most of the work reported in this area has been related to nonreal-time software. In this paper we report and discuss the results of an experimental investigation of some important metrics and their relationship for a class of 202 Pascal programs used in a real-time distributed processing environment. While some of our observations confirm independent studies, we have noted significant differences. For instance the correlations between McCabe's control complexity measure and Halstead's metrics are low in comparison to a previous study. Studies of the type reported here are important for understanding the relationship between software metrics.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232199","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701992","Program length;real-time software;software complexity;software metrics","Software metrics;Software maintenance;Software tools;Costs;Software quality;Error correction;Operating systems;Programming;Software measurement;Distributed processing","","Program length;real-time software;software complexity;software metrics","","19","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on Program Slicing","H. K. N. Leung; H. K. Reghbati","Department of Computer Science, University of Alberta; NA","IEEE Transactions on Software Engineering","","1987","SE-13","12","1370","1371","This correspondence points out some of the problems with Weiser's algorithm [5] for computing program slices. Corrections are made to Weiser's algorithm. It is shown how Weiser's algorithm can be amended to handle loops. Advantages of the Bergeretti and Carre's approach [1] are discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233147","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702186","Data flow analysis;debugging;information flow;slicing","","","Data flow analysis;debugging;information flow;slicing","","8","","5","","","","","","IEEE","IEEE Journals & Magazines"
"Debugging concurrent Ada programs by deterministic execution","K. -. Tai; R. H. Carver; E. E. Obaid","Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA; NA; NA","IEEE Transactions on Software Engineering","","1991","17","1","45","63","A language-based approach to deterministic execution debugging of concurrent Ada programs is presented. The approach is to define synchronization (SYN)-sequences of a concurrent Ada program in terms of Ada language constructs and to replay such SYN-sequences without the need for system-dependent debugging tools. It is shown how to define a SYN-sequence of a concurrent Ada program in order to provide sufficient information for deterministic execution. It is also shown how to transform a concurrent Ada program P so that the SYN-sequences of previous executions of P can be replayed. This transformation adds an Ada task to P that controls program execution by synchronizing with the original tasks in P. A brief description is given of the implementation of tools supporting deterministic execution debugging of concurrent Ada programs.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.67578","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=67578","","Computer science;Testing;Software debugging;Software engineering;Mathematics","Ada;parallel programming;program debugging","synchronisation sequences;concurrent Ada programs;deterministic execution debugging;Ada language constructs;SYN-sequences;sufficient information;previous executions;transformation;program execution;tools","","91","","32","","","","","","IEEE","IEEE Journals & Magazines"
"A multilayer client-server queueing network model with synchronous and asynchronous messages","Sridhar Ramesh; H. G. Perros","Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA; NA","IEEE Transactions on Software Engineering","","2000","26","11","1086","1100","We analyze a multilayered queueing network that models a client-server system where clients and servers communicate via synchronous and asynchronous messages. The servers are organized in groups such that they form a multilayered hierarchical structure. The queueing network is approximately analyzed using a decomposition algorithm. Numerical tests show that the approximation algorithm has a good accuracy.","0098-5589;1939-3520;2326-3881","","10.1109/32.881719","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=881719","","Nonhomogeneous media;Queueing analysis;Client-server systems;Network servers;Software performance;Computer architecture;Software systems;Algorithm design and analysis;Testing;Approximation algorithms","client-server systems;message passing;queueing theory;software performance evaluation;multi-threading","multilayer client-server queueing network model;synchronous messages;asynchronous messages;multilayered queueing network;client-server system;multilayered hierarchical structure;decomposition algorithm;approximation algorithm","","18","","15","","","","","","IEEE","IEEE Journals & Magazines"
"The mean resequencing delay for M/H/sub K// infinity systems","S. Chowdhury","Dept. of Comput. Sci., Arizona Univ., Tucson, AZ, USA","IEEE Transactions on Software Engineering","","1989","15","12","1633","1638","The relationship between the mean resequencing delay and variations in packet transmission times is studied. Assuming a Poisson stream of packets, a K-stage hyperexponential transmission time distribution and an infinite number of equal capacity links connecting the source and destination nodes, the authors derive an expression for the mean resequencing delay. This result provides an upper bound on the mean resequencing delay for nodes connected by finitely many links. They observe that for the two-stage and three-stage hyperexponential distribution, the mean resequencing delay varies almost perfectly linearly with the squared coefficient of variation. An asymptotic bound analysis can explain this behavior.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58774","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58774","","H infinity control;Circuits;Computer networks;Joining processes;Delay effects;Queueing analysis;Upper bound;Computer architecture;Computer science;Virtual colonoscopy","computer networks;electronic messaging;packet switching;queueing theory","mean resequencing delay;packet transmission times;Poisson stream;K-stage hyperexponential transmission time distribution;equal capacity links;destination nodes;upper bound;asymptotic bound analysis","","8","","7","","","","","","IEEE","IEEE Journals & Magazines"
"IASTED conference on reliability and quality control","B. Dhillon","Department of Mechanical Engineering, University of Ottawa, Ottawa, Ont. K1N 6N5, Canada","IEEE Transactions on Software Engineering","","1986","SE-12","9","996","996","THE International Association of Science and Technology for Development (IASTED) Conference on Reliability and Quality Control is to be held at the Palais des Congres in Paris, France.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313055","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313055","","Quality control;Analytical models;Predictive models;Software;Power system reliability;Software reliability","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"CSPL: an Ada95-like, Unix-based process environment","Jen-Yen Jason Chen","Dept. of Comput. Sci. & Inf. Eng., Nat. Chiao Tung Univ., Hsinchu, Taiwan","IEEE Transactions on Software Engineering","","1997","23","3","171","184","The paper presents a new process-centered environment called ""concurrent software process language"" (CSPL). CSPL takes a unique and innovative approach to integrate the object-oriented Ada95-like syntax (for its modeling power) with Unix shell semantics (for its enactment capability) in a software process language. The paper depicts the following new CSPL features: (1) object orientation, (2) multirole and multiuser, and (3) unified object modeling. Language constructs specially designed for software process such as work assignment statement, communication-related statements, role unit, tool unit, relation unit and so on, are, respectively, described. The related work of this diversified field is also surveyed in some depth. The CSPL environment prototype has been built. A CSPL process program for the IEEE Software Process Modeling Example Problem has been developed and enacted to demonstrate the capabilities of this environment.","0098-5589;1939-3520;2326-3881","","10.1109/32.585504","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=585504","","Object oriented modeling;Computer languages;Software design;Process design;Software prototyping;Prototypes;Software engineering;Software maintenance;Software tools;Computer industry","Unix;object-oriented languages;programming environments;parallel languages;computational linguistics;operating systems (computers)","Ada95-like Unix-based process environment;CSPL;concurrent software process language;object-oriented Ada95-like syntax;Unix shell semantics;modeling;enactment;object orientation;multirole feature;multiuser feature;unified object modeling;language constructs;work assignment statement;communication-related statements;role unit;tool unit;relation unit;CSPL environment prototype;CSPL process program;IEEE Software Process Modeling Example Problem","","20","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Requirements elicitation and validation with real world scenes","P. Haumer; K. Pohl; K. Weidenhaupt","Tech. Hochschule Aachen, Germany; NA; NA","IEEE Transactions on Software Engineering","","1998","24","12","1036","1054","A requirements specification defines the requirements for the future system at a conceptual level (i.e., class or type level). In contrast, a scenario represents a concrete example of current or future system usage. In early RE phases, scenarios are used to support the definition of high level requirements (goals) to be achieved by the new system. In many cases, those goals can to a large degree be elicited by observing, documenting and analyzing scenarios about current system usage. To support the elicitation and validation of the goals achieved by the existing system and to illustrate problems of the old system, we propose to capture current system usage using rich media (e.g., video, speech, pictures, etc.) and to interrelate those observations with the goal definitions. Thus, we aim at making the abstraction process which leads to the definition of the conceptual models more transparent and traceable. We relate the parts of the observations which have caused the definition of a goal or against which a goal was validated with the corresponding goal. These interrelations provide the basis for: 1) explaining and illustrating a goal model to, e.g., untrained stakeholders and/or new team members; 2) detecting, analyzing, and resolving a different interpretation of the observations; 3) comparing different observations using computed goal annotations; and 4) refining or detailing a goal model during later process phases. Using the PRIME implementation framework, we have implemented the PRIME-CREWS environment, which supports the interrelation of conceptual models and captured system usage observations. We report on our experiences with PRIME-CREWS gained in an experimental case study.","0098-5589;1939-3520;2326-3881","","10.1109/32.738338","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=738338","","Layout;Object oriented modeling;Context modeling;History;Erbium;Unified modeling language;Business process re-engineering;System testing;Knowledge engineering;Concrete","formal specification;program verification;systems analysis;program diagnostics","requirements elicitation;requirements validation;real world scenes;requirements specification;future system;conceptual level;type level;future system usage;early RE phases;high level requirements;new system;current system usage;old system;goal definitions;abstraction process;conceptual models;untrained stakeholders;new team members;computed goal annotations;goal model;PRIME implementation framework;PRIME-CREWS environment;captured system usage observations;experimental case study","","66","","48","","","","","","IEEE","IEEE Journals & Magazines"
"Guest Editorial: Programming Environments","D. R. Barstow; H. E. Shrobe","Schlumberger-Doll Research; NA","IEEE Transactions on Software Engineering","","1981","SE-7","5","449","450","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230852","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702870","","Programming environments;Software systems;Artificial intelligence;Software tools;Computer languages;Operating systems;Software engineering;Application software;Large-scale systems;Production","","","","","","4","","","","","","IEEE","IEEE Journals & Magazines"
"New NP-Complete Problems in Performance Evaluation of Concurrent Systems Using Petri Nets","J. Magott","Institute of Engineering Cybernetics, Technical University of Wroclaw","IEEE Transactions on Software Engineering","","1987","SE-13","5","578","581","Timed Petri nets are useful in performance evaluation of concurrent systems. The maximum computation rate is achieved for minimal cycle time of timed Petri net. It is known that minimal cycle time problem for P-invariant Petri nets is NP-complete. In this paper we prove that the minimal cycle time problem, for non-P-invariant Petri nets and for a small subclass of P-invariant Petri nets called free-choice nets having live and safe marking, is NP-complete.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233462","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702257","Computational complexity;free-choice net;minimal cycle time;non-P-invariant Petri net;performance evaluation;timed Petri net","Petri nets;Time factors;Random variables;Time measurement;Data analysis;Data flow computing;Cybernetics;Fires","","Computational complexity;free-choice net;minimal cycle time;non-P-invariant Petri net;performance evaluation;timed Petri net","","9","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Integration and analysis of use cases using modular Petri nets in requirements engineering","Woo Jin Lee; Sung Deok Cha; Yong Rae Kwon","Dept. of Comput. Sci., Korea Adv. Inst. of Sci. & Technol., Taejon, South Korea; NA; NA","IEEE Transactions on Software Engineering","","1998","24","12","1115","1130","It is well known that requirements engineering plays a critical role in software quality. The use case approach is a requirements elicitation technique commonly used in industrial applications. Software requirements are stated as a collection of use cases, each of which is written in the user's perspective and describes a specific flow of events in the system. The use case approach offers several practical advantages in that use case requirements are relatively easy to describe, understand, and trace. Unfortunately, there are a couple of major drawbacks. Since use cases are often stated in natural languages, they lack formal syntax and semantics. Furthermore, it is difficult to analyze their global system behavior for completeness and consistency, partly because use cases describe only partial behaviors and because interactions among them are rarely represented explicitly. We propose the Constraints-based Modular Petri Nets (CMPNs) approach as an effective way to formalize the informal aspects of use cases. CMPNs, an extension of Place/Transition nets, allow the formal and incremental specification of requirements. The major contributions of the paper, in addition to the formal definitions of CMPNs, are the development of: 1) a systematic procedure to convert use cases stated in natural language to a CMPN model; and 2) a set of guidelines to find inconsistency and incompleteness in CMPNs. We demonstrate an application of our approach using use cases developed for telecommunications services.","0098-5589;1939-3520;2326-3881","","10.1109/32.738342","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=738342","","Computer aided software engineering;Petri nets;Natural languages;Computer Society;Software quality;Application software;Guidelines;Telecommunication services;Software systems","formal specification;systems analysis;software quality;Petri nets;telecommunication computing","requirements elicitation technique;modular Petri nets;requirements engineering;software quality;use case approach;software requirements;use case requirements;natural languages;global system behavior;completeness;consistency;partial behaviors;Constraints-based Modular Petri Nets;CMPNs;informal aspects;Place/Transition nets;incremental specification;formal definitions;systematic procedure;telecommunications services;formal syntax;formal specification","","38","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Minimizing aperiodic response times in a firm real-time environment","G. C. Buttazzo; M. Caccamo","Scuola Superiore S. Anna, Pisa, Italy; NA","IEEE Transactions on Software Engineering","","1999","25","1","22","32","In certain real-time applications, ranging from multimedia to telecommunication systems, timing constraints can be more flexible than scheduling theory usually permits. In this paper, we deal with the problem of scheduling hybrid sets of tasks, consisting of firm periodic tasks (i.e. tasks with deadlines which can occasionally skip one instance) and soft aperiodic requests, which have to be served as soon as possible to achieve good responsiveness. We propose and analyze an algorithm, based on a variant of earliest-deadline-first scheduling, which exploits skips to minimize the response time of aperiodic requests. One of the most interesting features of our algorithm is that it can easily be tuned to balance performance vs. complexity, for adapting it to different application requirements. Extensive simulation experiments show the effectiveness of the proposed approach with respect to existing methods. Schedulability bounds are also derived to perform off-line analysis.","0098-5589;1939-3520;2326-3881","","10.1109/32.748916","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=748916","","Time factors;Scheduling algorithm;Real time systems;Timing;Communication system control;Multimedia systems;Delay;Algorithm design and analysis;Processor scheduling;Quality of service","scheduling;real-time systems;quality of service;timing;minimisation;communication complexity;software performance evaluation","aperiodic response time minimization;hard real-time environment;multimedia;telecommunication systems;flexible timing constraints;hybrid task set scheduling;periodic tasks;task deadlines;soft aperiodic requests;responsiveness;earliest-deadline-first scheduling;skips;performance-complexity balance;application requirements;simulation;schedulability bounds;off-line analysis;service quality","","15","","19","","","","","","IEEE","IEEE Journals & Magazines"
"A unified framework for coupling measurement in object-oriented systems","L. C. Briand; J. W. Daly; J. K. Wust","Fraunhofer Inst. for Exp. Software Eng., Kaiserslautern, Germany; NA; NA","IEEE Transactions on Software Engineering","","1999","25","1","91","121","The increasing importance being placed on software measurement has led to an increased amount of research developing new software measures. Given the importance of object-oriented development techniques, one specific area where this has occurred is coupling measurement in object-oriented systems. However, despite a very interesting and rich body of work, there is little understanding of the motivation and empirical hypotheses behind many of these new measures. It is often difficult to determine how such measures relate to one another and for which application they can be used. As a consequence, it is very difficult for practitioners and researchers to obtain a clear picture of the state of the art in order to select or define measures for object-oriented systems. This situation is addressed and clarified through several different activities. First, a standardized terminology and formalism for expressing measures is provided which ensures that all measures using it are expressed in a fully consistent and operational manner. Second, to provide a structured synthesis, a review of the existing frameworks and measures for coupling measurement in object-oriented systems takes place. Third, a unified framework, based on the issues discovered in the review, is provided and all existing measures are then classified according to this framework. This paper contributes to an increased understanding of the state-of-the-art.","0098-5589;1939-3520;2326-3881","","10.1109/32.748920","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=748920","","Software measurement;Terminology;Software quality;Measurement standards;Area measurement;Decision making;Object oriented modeling;Force measurement;Programming","software metrics;object-oriented programming;software quality","software measurement;object-oriented systems;object-oriented development techniques;coupling measurement;standardized terminology;standardized formalism;structured synthesis;unified framework","","353","","37","","","","","","IEEE","IEEE Journals & Magazines"
"An automatic class generation mechanism by using method integration","K. Maruyama; K. I. Shima","Media Technol. Dev. Center, NTT Commun. Corp., Tokyo, Japan; NA","IEEE Transactions on Software Engineering","","2000","26","5","425","440","The paper presents a mechanism for automatically generating new classes from classes existing in a library by using their modification histories. To generate classes that are likely to meet a programmer's requirements and that are consistent with the existing classes, we propose three actors: a Specifier, a Finder, and an integrator. The Specifier records the history of modifications between methods with the same interface of a parent class and its heir. If the required method is not defined in the existing class which a programmer is referring to, the Finder retrieves classes similar to the referenced class and the Integrator applies the past modifications of similar classes to the referenced class. Classes are determined to be similar, based on their positions in a class hierarchy tree. Both the Specifier and Integrator are achieved by using a method integration algorithm based on object oriented bounded program slicing and class dependence graph matching. This mechanism enables programmers to reuse classes with little or no modification, and thus, easily create object oriented programs.","0098-5589;1939-3520;2326-3881","","10.1109/32.846300","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=846300","","Programming profession;History;Mobile communication;Computer Society;Tree graphs;Costs;Object oriented programming;Software libraries;Laboratories","object-oriented programming;software libraries;program slicing;automatic programming;graph theory","automatic class generation mechanism;method integration;library classes;modification histories;Specifier;Finder;integrator;parent class;past modifications;referenced class;class hierarchy tree;method integration algorithm;object oriented bounded program slicing;class dependence graph matching;class reuse;object oriented programs","","1","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Comments, with reply, on ""On criteria for module interfaces"" by D. Hoffman","L. L. Constantine","Acton, MA, USA","IEEE Transactions on Software Engineering","","1990","16","12","1440","","The commenter acknowledges that the practical criteria provided in the above-titled paper (see ibid., vol.16, no.5, p.537-42, 1990), offer substantive guidelines for designing module interfaces. He points out that the results obtained can be further improved and certain remaining conflicts resolved through consideration of established principles of structured design and software engineering. He illustrates his point with an example involving the specification of a stack interface that requires two or three separate references to replace one. He presents two designs and argues that the first is better. The author refutes the commenter's arguments and argues that the second design is better.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.62453","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=62453","","Inspection;Computer science","data structures;structured programming;user interfaces","module interfaces;practical criteria;structured design;software engineering;stack interface","","","","5","","","","","","IEEE","IEEE Journals & Magazines"
"Performance analysis of stochastic timed Petri nets using linear programming approach","Zhen Liu","Inst. Nat. de Recherche en Inf. et Autom., Sophia-Antipolis, France","IEEE Transactions on Software Engineering","","1998","24","11","1014","1030","Stochastic timed Petri nets are a useful tool in the performance analysis of concurrent systems such as parallel computers, communication networks and flexible manufacturing systems. In general, performance measures of stochastic timed Petri nets are difficult to obtain for practical problems due to their sizes. In this paper, we provide a method to efficiently compute upper and lower bounds for the throughputs and mean token numbers for a large class of stochastic timed Petri nets. Our approach is based on uniformization technique and linear programming.","0098-5589;1939-3520;2326-3881","","10.1109/32.730548","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=730548","","Performance analysis;Stochastic processes;Petri nets;Stochastic systems;Computer aided manufacturing;Computer networks;Concurrent computing;Communication networks;Flexible manufacturing systems;Size measurement","Petri nets;stochastic systems;linear programming;performance evaluation;telecommunication networks;flexible manufacturing systems;concurrency theory","performance analysis;stochastic timed Petri nets;linear programming;concurrent systems;parallel computers;communication networks;flexible manufacturing systems;performance measures;upper bounds;lower bounds;throughput;mean token number;uniformization technique;performance bounds","","15","","54","","","","","","IEEE","IEEE Journals & Magazines"
"A methodology for feature interaction detection in the AIN 0.1 framework","F. J. Lin; Hong Liu; A. Ghosh","Appl. Res., Bellcore, Morristown, NJ, USA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","10","797","817","We propose an integrated methodology for specifying AIN (advanced intelligent networks) and switch based features and analyzing their interactions in the AIN 0.1 framework. The specification of each individual feature is tied to the AIN call model and requires only a minimum amount of information in terms of control and data for interaction analysis. Once a feature is specified, its specification is then validated for consistency with respect to control and data. Interaction analysis is conducted for a set of features based on the sharing of call variables between the SSP and the SCP. With this approach, one can detect the following interactions involving AIN features: (1) side effects, where a call variable modified by one feature is used by another feature and (2) disabling, where one feature disconnects a call, preventing another feature from execution. We also develop a theory that is based on the computation of sequences of messages exchanged between the SSP and the SCP and their call variable usage. This theory is shown to dramatically reduce the number of cases considered during the analysis. A brief overview of a tool that makes use of this methodology to aid in the task of feature interaction detection is also given.","0098-5589;1939-3520;2326-3881","","10.1109/32.729681","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=729681","","Computer vision;Logic;Telecommunication switching;Information analysis;Data analysis;Switches;Telecommunication services;Telephony;Software engineering;Packaging","intelligent networks;telecommunication computing;knowledge based systems;telecommunication switching;software engineering","feature interaction detection;AIN framework;integrated methodology;advanced intelligent networks;switch based features;AIN call model;interaction analysis;specification;call variables;SSP;SCP;AIN features;side effects;disabling;message sequences;feature specification;telecommunication services","","2","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Foreword","H. K. T. Wong","NA","IEEE Transactions on Software Engineering","","1985","SE-11","10","1038","1039","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231850","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701918","","Data compression;Database languages;Costs;Statistical analysis;Computational modeling;Artificial intelligence;Multidimensional systems;Sampling methods;User interfaces;Data security","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Allocating programs containing branches and loops within a multiple processor system","D. Towsley","Department of Computer and Information Science, University of Massachusetts, Amherst, MA 01003","IEEE Transactions on Software Engineering","","1986","SE-12","10","1018","1024","The problem of assigning the modules of distributed program to the processors of a distributed system is addressed. The goal of such an assignment is to minimize the total execution and communication costs. A computational model of a distributed program containing probabilistic branches and loops is described by a directed graph whose edges represent precedence relations between modules. Efficient algorithms based on short-path methods are presented to determine the optimum assignment on a distributed system containing <i>N</i> heterogeneous processors.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313018","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313018","Computer networks;distributed processing;multiprocessor system scheduling;shortest path algorithms","Computational modeling;Resource management;Algorithm design and analysis;Computational efficiency;Computational complexity;Context","directed graphs;modules;multiprocessing systems","programs allocation;branches;loops;multiple processor system;modules;distributed program;computational model;probabilistic branches;directed graph;short-path methods;optimum assignment","","25","","","","","","","","IEEE","IEEE Journals & Magazines"
"Achieving high availability in distributed databases","H. Garcia-Molina; B. Kogan","Dept. of Comput. Sci., Princeton Univ., NJ, USA; Dept. of Comput. Sci., Princeton Univ., NJ, USA","IEEE Transactions on Software Engineering","","1988","14","7","886","896","An approach is presented for managing distributed database systems in the face of communication failures and network partitions. The approach is based on the idea of dividing the database into fragments and assigning each fragment a controlling entity called an agent. The goals achieved by this approach include high data availability and the ability to operate without promptly and correctly detecting partitions. A correctness criterion for transaction execution, called fragmentwise serializability, is introduced. It is less strict than the conventional serializability, but provides a valuable alternative for some applications.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.42732","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=42732","","Availability;Distributed databases;Database systems;Concurrency control;Protocols;Intelligent networks;Face detection;Transaction databases;Communication system control;Fault tolerant systems","database theory;distributed databases;fault tolerant computing;program verification;software reliability","fault tolerant computing;distributed databases;communication failures;network partitions;controlling entity;agent;data availability;correctness criterion;transaction execution;fragmentwise serializability","","12","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Display Condensation of Program Text","J. Archer; R. Conway","Rational Machines, Inc.; NA","IEEE Transactions on Software Engineering","","1982","SE-8","5","526","529","In interactive systems that must display the text of programs, the size of the program is usually much larger than the capacity of the screen. While the obvious strategy is to simply choose k contiguous lines for display in a k-line window, in some cases it is useful to be able to represent m lines in a k-line window, where m &gt; k, by ""condensing"" portions of the text. This paper is concerned with alternative strategies for controlling such condensation.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235876","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702980","Editing;interactive programming;prettyprinting;programming environments;programming methodology","Large screen displays;Interactive systems;Computer displays;Programming environments;Cathode ray tubes;Computer science","","Editing;interactive programming;prettyprinting;programming environments;programming methodology","","","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Toward the Next Generation of Data Modeling Tools","C. R. Carlson; A. K. Arora","Department of Computer Science, Illinois Institute of Technology, IIT Center; NA","IEEE Transactions on Software Engineering","","1985","SE-11","9","966","970","This paper describes the Update Protocol Model (UPM), a formal language for the expression of database update semantics. UPM has been used primarily to capture and communicate in a precise and uniform notation the plethora of database semantics described by a variety of ""fourth generation"" models, many of which are imprecise when it comes to update semantics. Several computing trendsknowledge-based expert systems, distributed database management systems, and new applications based on higher order semantic modelspoint to the need for modeling techniques beyond that which current data models such as the relational and entity-relationship models provide.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232831","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702116","Database;data modeling;relational model;update protocol model;update semantics","Protocols;Relational databases;Data models;Distributed databases;Formal languages;Distributed computing;Expert systems;Database systems;Information management","","Database;data modeling;relational model;update protocol model;update semantics","","3","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Guest Editorial: COMPSAC '81 Special Section","J. D. Musa","NA","IEEE Transactions on Software Engineering","","1983","SE-9","2","118","119","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236455","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703027","","Software engineering;Printers;Indexes;Transaction databases;Network operating systems;Application software;Programming profession;Approximation algorithms;Computer networks;Computer applications","","","","","","1","","","","","","IEEE","IEEE Journals & Magazines"
"Structured solution of asynchronously communicating stochastic modules","J. Campos; S. Donatelli; M. Silva","Dept. de Inf. & Ingenieria de Sistemas, Zaragoza Univ., Spain; NA; NA","IEEE Transactions on Software Engineering","","1999","25","2","147","165","Asynchronously communicating stochastic modules (SAM) are Petri nets that can be seen as a set of modules that communicate through buffers, so they are not (yet another) Petri net subclass, but they complement a net with a structured view. This paper considers the problem of exploiting the compositionality of the view to generate the state space and to find the steady-state probabilities of a stochastic extension of SAM in a net-driven, efficient way. Essentially we give an expression of an auxiliary matrix, G, which is a supermatrix of the infinitesimal generator of a SAM. G is a tensor algebra expression of matrices of the size of the components for which it is possible to numerically solve the characteristic steady-state solution equation /spl pi//spl middot/G=0, without the need to explicitly compute G. Therefore, we obtain a method that computes the steady-state solution of a SAM without ever explicitly computing and storing its infinitesimal generator, and therefore without computing and storing the reachability graph of the system. Some examples of application of the technique are presented and compared to previous approaches.","0098-5589;1939-3520;2326-3881","","10.1109/32.761442","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=761442","","Stochastic processes;State-space methods;Tensile stress;Algebra;Steady-state;Petri nets;Equations;Explosions;Computer Society;Matrices","Petri nets;software performance evaluation;matrix algebra","asynchronously communicating stochastic modules;Petri nets;buffer communication;structured solution;structured view;compositionality;state space;steady-state probabilities;auxiliary matrix;supermatrix;infinitesimal generator;tensor algebra expression;numerical solution","","20","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Correction to 'A modified priority based probe algorithm for distributed deadlock detection and resolution' (A.N. Choudhary et al.)","A. N. Choudhary; W. H. Kohler; J. A. Stankovic; D. Towsley","Comput. Syst. Group, Illinois Univ., Urbana, IL, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1989","15","12","1644","","A line inadvertently omitted from a section of the pseudocode in the above paper (see ibid., vol.15, no.1, p.10-17, 1989) is provided. The correct reading of the section is given in full.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58776","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58776","","Probes;System recovery;Information science","distributed processing;error correction;system recovery","modified priority based probe algorithm;distributed deadlock detection;pseudocode","","2","","1","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on ""Towards a framework for software measurement validation""","S. Morasca; L. C. Briand; V. R. Basili; E. J. Weyuker; M. V. Zelkowitz; B. Kitchenham; S. Lawrence Pfleeger; N. Fenton","Dipartimento di Elettronica, Politecnico di Milano, Italy; NA; NA; NA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1997","23","3","187","189","A view of software measurement that disagrees with the model presented by Kitchenham, Pfleeger, and Fenton (1995), is given. Whereas Kitchenham et al. argue that properties used to define measures should not constrain the scale type of measures, the authors contend that that is an inappropriate restriction. In addition, a misinterpretation of Weyuker's (1988) properties is noted.","0098-5589;1939-3520;2326-3881","","10.1109/32.585506","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=585506","","Software measurement;Particle measurements;Computer Society;Temperature measurement;Size measurement;Measurement units;Impedance;Physics","software metrics;program testing;program verification","software measurement validation","","17","","5","","","","","","IEEE","IEEE Journals & Magazines"
"Foreword Software Reliability","A. L. Goel; F. B. Bastani","NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","12","1409","1410","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232175","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701961","","Software reliability;Software measurement;Software testing;Error correction;Condition monitoring;Software systems;Fault tolerance;Probability;History;Programming","","","","4","","","","","","","","IEEE","IEEE Journals & Magazines"
"Software Engineering with Reusable Designs and Code","R. G. Lanergan; C. A. Grasso","Missile Systems Division, Raytheon Company, Bedford, MA 01730.; Missile Systems Division, Raytheon Company, Bedford, MA 01730.","IEEE Transactions on Software Engineering","","1984","SE-10","5","498","501","For over six years Raytheon's Missile Systems Division, Information Processing Systems Organization has used a successful approach in developing and maintaining business software. The approach centers on the fact that 60 percent of all business application designs and code are redundant and can be standardized and reused. This approach has resulted in significant gains in productivity and reliability and improved end-user relations, while providing better utilization of data processing personnel, primarily in the maintenance phase of the software life cycle.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010273","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010273","","Software engineering;Companies;Application software;Software maintenance;Algorithms;Computer aided manufacturing;Logic testing;Aging;Missiles;Manufacturing processes","","","","49","","6","","","","","","IEEE","IEEE Journals & Magazines"
"Corrigendum for 'Constraint-based automatic test data generation' by R.A. DeMillo and A.J. Offutt","M. R. Girgis","Dept. of Comput. Sci., Bahrain Univ., Isa Town, Bahrain","IEEE Transactions on Software Engineering","","1993","19","6","640","","In reference to the above-titled paper by R.A. DeMillo and A.J. Offutt (see ibid., vol.17, no.9, p.900-10, Sept. 1991), the commenter rates that he and M.R. Woodward (1985) implemented a system for FORTRAN-77 programs that integrates weak mutation and data flow analysis. He reports here that experiments have been carried out by them (1986), using the system to compare the error exposing ability of weak mutation, data flow, and control flow testing strategies.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.232028","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=232028","","Automatic testing;Genetic mutations;System testing;Data analysis;Error correction;Instruments;History;Arithmetic;Monitoring;Control systems","program debugging;program testing","constraint-based test data generation;FORTRAN-77;weak mutation;data flow analysis;control flow testing","","1","","3","","","","","","IEEE","IEEE Journals & Magazines"
"A Data Structure and an Algorithm for the Nearest Point Problem","I. Kalantari; G. McDonald","Department of Mathematics, Western Illinois University; NA","IEEE Transactions on Software Engineering","","1983","SE-9","5","631","634","In this paper we present a tree structure for storing points from a normed space whose norm is effectively computable. We then give an algorithm for finding the nearest point from the tree to a given query point. Our algorithm searches the tree and uses the triangle inequality to eliminate searching of the entirety of some branches of the tree whenever a certain predicate is satisfied. Our data structure uses 0(n) for storage. Empirical data which we have gathered suggest that the expected complexity for preprocessing and the search time are, respectively, 0(nlogn) and 0(logn).","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.235263","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703102","Algorithm;computational time;data structure;nearest point problem;preprocessing;storage binary search;trees;triangle inequality","Data structures;Tree data structures;Mathematics;Organizing;Data analysis;Information retrieval;Image retrieval;Pattern recognition;Statistical analysis","","Algorithm;computational time;data structure;nearest point problem;preprocessing;storage binary search;trees;triangle inequality","","66","","13","","","","","","IEEE","IEEE Journals & Magazines"
"How to improve the calibration of cost models","N. B. Ebrahimi","Div. of Stat., Northern Illinois Univ., DeKalb, IL, USA","IEEE Transactions on Software Engineering","","1999","25","1","136","140","One of software engineering's long-standing problems is to estimate the cost of a software project. Using the volume or size of a program to estimate the cost is a common practice in many software development organizations. However, in many situations one is unable to observe the value of this variable at the beginning of the project; one has to estimate it. In this paper we introduce a fairly general model which permits a surrogate or a proxy variable to be observed instead of the actual size. Under this model we obtain estimation of software cost at the given value of a surrogate variable. A confidence interval is also provided under this model.","0098-5589;1939-3520;2326-3881","","10.1109/32.748922","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=748922","","Calibration;Costs;Measurement errors;Size measurement;Software measurement;Parameter estimation;Volume measurement;Mathematical model;Regression analysis;Gaussian distribution","calibration;software cost estimation;project management;software development management","cost model calibration;software engineering;software project cost estimation;surrogate variable;proxy variable;confidence interval","","6","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Correspondence: Response to Botting's Comments","R. H. Bourdeau; B. H. C. Cheng","Department of Computer Science, Michigan State University, East Lansing, MI 48824; NA","IEEE Transactions on Software Engineering","","1996","22","12","911","911","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1996.553640","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=553640","","Error correction;Object oriented programming;Writing","","","","1","","1","","","","","","IEEE","IEEE Journals & Magazines"
"An efficient state space generation for the analysis of real-time systems","I. Kang; I. Lee; Young-Si Kim","Sch. of Comput., Soongsil Univ., Seoul, South Korea; NA; NA","IEEE Transactions on Software Engineering","","2000","26","5","453","477","State explosion is a well-known problem that impedes analysis and testing based on state-space exploration. This problem is particularly serious in real time systems because unbounded time values cause the state space to be infinite even for simple systems. The author presents an algorithm that produces a compact representation of the reachable state space of a real time system. The algorithm yields a small state space, but still retains enough information for analysis. To avoid the state explosion which can be caused by simply adding time values to states, our algorithm uses history equivalence and transition bisimulation to collapse states into equivalent classes. Through history equivalence, states are merged into an equivalence class with the same untimed executions up to the states. Using transition bisimulation, the states that have the same future behaviors are further collapsed. The resultant state space is finite and can be used to analyze real time properties. To show the effectiveness of our algorithm, we have implemented the algorithm and have analyzed several example applications.","0098-5589;1939-3520;2326-3881","","10.1109/32.846302","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=846302","","State-space methods;Real time systems;Automata;Safety;Explosions;Reachability analysis;Logic testing;System testing;Algorithm design and analysis;History","state-space methods;real-time systems;systems analysis;formal specification;bisimulation equivalence;equivalence classes;reachability analysis","state space generation;real time systems analysis;state explosion;state-space exploration;unbounded time values;compact representation;reachable state space;time values;history equivalence;transition bisimulation;equivalent classes;untimed executions;future behaviors;real time properties","","11","","30","","","","","","IEEE","IEEE Journals & Magazines"
"A New Verification Rule and Its Applications","J. C. Huang","Department of Computer Science, University of Houston","IEEE Transactions on Software Engineering","","1980","SE-6","5","480","484","This paper describes a verification rule for loop programs, and shows how it can be used in conjunction with the invariant-relation theorem to facilitate verification of programs.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230788","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702764","Consistency;decomposition;invariant-relation theorem;loop program;predicate transformation;program verification;subgoal induction;verification rule","Computer science","","Consistency;decomposition;invariant-relation theorem;loop program;predicate transformation;program verification;subgoal induction;verification rule","","1","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Macro Implementation of a Structured Assembly Language","J. L. Reuss","Medicomp, Inc.","IEEE Transactions on Software Engineering","","1982","SE-8","3","284","287","The feasibility of using macros to compile a linear assembly language is well established. A cross assembler has been implemented, via macros, for an assembly language, SCRAM, which embodies high-level language features such as user-controlled symbol scope and nested DO and IF/THEN/ELSE control structutes. Difficulties arose in implementation primarily from the inconvenience of managing assembly-time data","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235256","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702943","Cross assembler;macro assembler;macros;microprocessing;structured programming","Computer graphics;Computer displays;Testing;Image restoration;Current control;Assembly systems;System software;Parallel programming;Microprocessors","","Cross assembler;macro assembler;macros;microprocessing;structured programming","","1","","5","","","","","","IEEE","IEEE Journals & Magazines"
"Managing Feature Interactions Telecommunications Software Systems - Guest Editorial","Yow-Jian Lin; M. Jazayeri","University of California; NA","IEEE Transactions on Software Engineering","","1998","24","10","777","778","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1998.729679","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=729679","","Software systems;Testing;Computer vision;Interference;Packaging;Intelligent networks;Internet telephony;Environmental management;Software engineering;Software architecture","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on ""Protocols for Deadlock Detection in Distributed Database Systems""","J. R. Jagannathan; R. Vasudevan","Department of Computer Science, University of Waterloo; NA","IEEE Transactions on Software Engineering","","1983","SE-9","3","371","371","The two-phase deadlock detection protocol in the above paperl detects false deadlocks. This is contrary to what the authors claim. The false detection o. f deadlocks is shown using a counterexample.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.237019","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703066","","Protocols;System recovery;Database systems;Broadcasting;Resource management;Phase detection;Computer science","","","","2","","3","","","","","","IEEE","IEEE Journals & Magazines"
"Distributed feature composition: a virtual architecture for telecommunications services","M. Jackson; P. Zave","Res. Labs., AT&T, Florham Park, NJ, USA; NA","IEEE Transactions on Software Engineering","","1998","24","10","831","847","Distributed Feature Composition (DFC) is a new technology for feature specification and composition, based on a virtual architecture offering benefits analogous to those of a pipe-and-filter architecture. In the DFC architecture, customer calls are processed by dynamically assembled configurations of filter-like components: each component implements an applicable feature, and communicates with its neighbors by featureless internal calls that are connected by the underlying architectural substrate.","0098-5589;1939-3520;2326-3881","","10.1109/32.729683","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=729683","","Telecommunication services;Digital-to-frequency converters;Computer architecture;Switches;Assembly;Computer Society;Routing;Communication switching;Productivity","telecommunication computing;telecommunication services;user interfaces;interactive systems","distributed feature composition;virtual architecture;telecommunications services;feature specification;pipe-and-filter architecture;DFC architecture;customer calls;dynamically assembled configurations;filter-like components;featureless internal calls;architectural substrate","","98","","26","","","","","","IEEE","IEEE Journals & Magazines"
"A Note on Concurrent Programming Control","C. M. Davidson","Philips Telecommunicatie en Data Systemen Nederland","IEEE Transactions on Software Engineering","","1987","SE-13","7","865","866","An extension to Dijkstra's solution [1], of the problem of limiting access by multiple processors to a single resource, is described. The solution has similar delay characteristics to Ferguson's solution [3] while using less complex data structures. Some claims in [3] are examined.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233498","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702298","Cooperating sequential processes;cooperative mutual exclusion;critical sections;semaphores","Delay;Data structures;System recovery;Timing;Decision making;Telecommunications","","Cooperating sequential processes;cooperative mutual exclusion;critical sections;semaphores","","1","","4","","","","","","IEEE","IEEE Journals & Magazines"
"Foreword Advances in Distributed Computing Systems","S. F. Lundstrom; E. E. Swartzlander","NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","10","1092","1096","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231856","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701924","","Distributed computing;Database systems;Broadcasting;Communication networks;Routing;Computer networks;Application software;Delay;Distributed databases;Intelligent networks","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Efficient algorithms for selection of recovery points in tree task models","S. K. Mishra; V. V. Raghavan; N. -. Tzeng","Center for Adv. Comput. Studies, Southwestern Louisiana Univ., Lafayette, LA, USA; Center for Adv. Comput. Studies, Southwestern Louisiana Univ., Lafayette, LA, USA; Center for Adv. Comput. Studies, Southwestern Louisiana Univ., Lafayette, LA, USA","IEEE Transactions on Software Engineering","","1991","17","7","731","734","Efficient solutions to the problem of optimally selecting recovery points are developed. The solutions are intended for models of computation in which task precedence has a tree structure and a task may fail due to the presence of faults. An algorithm to minimize the expected computation time of the task system under a uniprocessor environment has been developed for the binary tree model. The algorithm has time complexity of O(N/sub 2/), where N is the number of tasks, while previously reported procedures have exponential time requirements. The results are generalized for an arbitrary tree model.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.83909","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=83909","","Binary trees;Computational modeling;Tree data structures;Dynamic programming;Software systems;Tree graphs;Databases;Software algorithms;Fault tolerant systems;Availability","computational complexity;optimisation;trees (mathematics)","tree task models;recovery points;task precedence;tree structure;uniprocessor environment;binary tree model;time complexity;exponential time requirements;arbitrary tree model","","1","","7","","","","","","IEEE","IEEE Journals & Magazines"
"Quicksort revisited","C. M. Davidson","Philips Telecommun. en Data Syst. Nederland BV, Apeldoorn, Netherlands","IEEE Transactions on Software Engineering","","1988","14","10","1480","1481","H.D. Mills and R.C. Linger (1986) propose adding the datatype set to existing programming languages. During some investigations using sets, it became apparent that Quicksort can be written without using stacks (or recursion). Using sets can lead to efficient multiprocessor usage, because if the elements of a set can be processed in any order, they can frequently be processed simultaneously. An example of the possibilities is an intelligent disk control unit based on External Quicksort, using four processors and four read/write heads., The control unit can sort a large disk file in about 1/3 of the time taken by the one-processor version.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6193","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6193","","Computer languages;Milling machines;Intelligent control;Sorting;Telecommunications","data structures;sorting","data structures;datatype set;Quicksort;multiprocessor usage;disk control unit;External Quicksort","","1","","5","","","","","","IEEE","IEEE Journals & Magazines"
"A queueing network model for a distributed database testbed system","B. -. Jenq; W. H. Kohler; D. Towsley","Massachusetts Univ., Amherst, MA, USA; Massachusetts Univ., Amherst, MA, USA; Massachusetts Univ., Amherst, MA, USA","IEEE Transactions on Software Engineering","","1988","14","7","908","921","A queuing network model for analyzing the performance of a distributed database testbed system with a transaction workload is developed. The model includes the effects of the concurrency control protocol (two-phase locking with distributed deadlock detection), the transaction recovery protocol (write-ahead logging of before-images), and the commit protocol (centralized two-phase commit) used in the testbed system. The queuing model differs from previous analytical models in three major aspects. First, it is a model for a distributed transaction processing system. Second, it is more general and integrated than previous analytical models. Finally, it reflects a functioning distributed database testbed system and is validated against performance measurements.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.42734","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=42734","","Distributed databases;System testing;Transaction databases;Protocols;Queueing analysis;Analytical models;Performance analysis;Concurrency control;System recovery;Measurement","distributed databases;program testing;protocols;queueing theory;system recovery","queueing network model;distributed database testbed system;transaction workload;concurrency control protocol;two-phase locking;distributed deadlock detection;transaction recovery protocol;write-ahead logging;commit protocol;centralized two-phase commit","","14","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Reply to: ""Property-based software engineering measurement""","H. Zuse","Fachbereich Inf., Tech. Univ. Berlin, Germany","IEEE Transactions on Software Engineering","","1997","23","8","533","","L.C. Briand, S. Morasca and V.R. Basili (ibid., vol. 22, no. 1, pp. 68-85, Jan. 1996) introduced a measurement-theoretic approach to software measurement and criticized (among others) the work of the author, but they misinterpreted his work. The author does not require additive software (complexity) measures as Briand, Morasca and Basili state. The author uses the concept of the extensive structure in order to show the empirical properties behind software measures. Briand, Morasca and Basili use the concept of meaningfulness in order to describe scales and that certain scale levels are not excluded by the Weyuker properties. However, they do not consider that scales and scale types are different things.","0098-5589;1939-3520;2326-3881","","10.1109/32.624309","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=624309","","Software engineering;Software measurement;Additives;Size measurement;Software metrics;Lab-on-a-chip","software metrics","property-based software engineering measurement;measurement-theoretic approach;additive software complexity measures;extensive structure;empirical properties;software measures;meaningfulness;scale levels;Weyuker properties;scale types;software metrics","","9","","4","","","","","","IEEE","IEEE Journals & Magazines"
"Transient analysis of superposed GSPNs","P. Kemper","Inf. IV, Dortmund Univ., Germany","IEEE Transactions on Software Engineering","","1999","25","2","182","193","The paper considers transient analysis using randomization for superposed generalized stochastic Petri nets (GSPNs). Since state space explosion implies that space is the bottleneck for numerical analysis, superposed GSPNs profit from the structured representation known for its associated Markov chain. This moves the bottleneck for analysis from space for generator matrices to space for iteration vectors. Hence a variation of randomization is presented which allows to reduce space requirements for iteration vectors. An additional and welcome side effect is that during an initial phase, this algorithm avoids useless multiplications involving states with zero probability. Furthermore, it accommodates to adaptive randomization in a natural way. Although the algorithm has been developed for superposed GSPNs, it applies to continuous time Markov chains in a more general setting.","0098-5589;1939-3520;2326-3881","","10.1109/32.761444","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=761444","","Transient analysis;State-space methods;Petri nets;Explosions;Stochastic processes;Numerical analysis;Functional analysis;Algebra;Stochastic systems;Performance analysis","Petri nets;Markov processes;randomised algorithms;matrix algebra;iterative methods;state-space methods","transient analysis;randomization;superposed generalized stochastic Petri nets;state space explosion;numerical analysis bottleneck;structured representation;associated Markov chain;generator matrices;iteration vectors;space requirements;algorithm;adaptive randomization;continuous time Markov chains","","14","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Computation of dynamic program slices for unstructured programs","B. Korel","Dept. of Comput. Sci., Illinois Inst. of Technol., Chicago, IL, USA","IEEE Transactions on Software Engineering","","1997","23","1","17","34","A dynamic program slice is an executable part of the program whose behaviour is identical, for the same program input, to that of the original program with respect to a variable(s) of interest at some execution position. The existing algorithms of dynamic slice computation use data and control dependencies to compute dynamic slices. These algorithms are limited to structured programs because they may compute incorrect dynamic slices for unstructured programs, due to the limitations of control dependencies that are used to compute dynamic slices. In this paper, we present a novel approach to dynamic slice computation for unstructured programs. The approach employs the notion of a removable block in finding dynamic program slices. Dynamic slices are derived by identifying not only those parts of program execution that contribute to the computation of the value of a variable of interest, but also those parts of program execution that do not contribute to the computation of the variable value. Data dependencies are used to identify contributing computations, whereas removable blocks are used to identify noncontributing computations. We have proved that the presented dynamic slicing algorithms correctly compute dynamic slices. In addition, these algorithms may compute more accurate dynamic slices compared to existing algorithms that use control dependencies. The presented algorithms have been implemented in a tool that supports dynamic slicing for Pascal programs.","0098-5589;1939-3520;2326-3881","","10.1109/32.581327","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=581327","","Heuristic algorithms;Software testing;Software maintenance;Software debugging;Algorithm design and analysis","program debugging;program control structures;program diagnostics","dynamic program slice computation;unstructured programs;executable part;execution position;data dependencies;control dependencies;removable block;variable value computation;contributing computations;noncontributing computations;Pascal programs;execution trace;debugging","","42","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on ""Property-based software engineering measurement: refining the additivity properties""","G. Poels; G. Dedene; L. C. Briand; S. Morasca; V. R. Basili","Dept. of Appl. Econ. Sci., Katholieke Univ., Leuven, Belgium; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1997","23","3","190","197","The measure property set of Briand, Morasca, and Basili (1996) establishes the foundation of a real software measurement theory. Unfortunately, a number of inconsistencies related to additivity properties might hinder its acceptance and further elaboration. The authors show how to remove the ambiguity in the property definitions.","0098-5589;1939-3520;2326-3881","","10.1109/32.585508","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=585508","","Software engineering;Software measurement;Area measurement;Time measurement;Software systems;Feedback;Psychology;Additives;Flow graphs","software metrics;program testing","property-based software engineering measurement;additivity properties;measure property set;real software measurement theory;property definitions","","8","","15","","","","","","IEEE","IEEE Journals & Magazines"
"The specification and verified decomposition of system requirements using CSP","A. P. Moore","US Naval Res. Lab., Washington, DC, USA","IEEE Transactions on Software Engineering","","1990","16","9","932","948","A formal method for decomposing the critical requirements of a system into requirements of its component processes and a minimal, possibly empty, set of synchronization requirements is described. The trace model of Hoare's communicating sequential processes (CSP) is the basis for the formal method. The method is applied to an abstract voice transmitter and describes the role that the EHDM verification system plays in the transmitter's decomposition is described. In combination with other verification techniques, it is expected that this method will promote the development of more trustworthy systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58782","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58782","","Formal specifications;Algebra;Computer security;Buildings;Transmitters;Formal verification;Safety;Information security;Process design;Space technology","formal specification;synchronisation;theorem proving","specification;verified decomposition;system requirements;CSP;formal method;synchronization requirements;trace model","","5","","50","","","","","","IEEE","IEEE Journals & Magazines"
"False Deadlock Detection in Distributed Systems","G. T. Wuu; A. J. Bernstein","Department of Computer Science, State University of New York; NA","IEEE Transactions on Software Engineering","","1985","SE-11","8","820","821","Detecting a nonexistent deadlock in distributed systems has been referred to as false deadlock detection. This correspondence shows that false deadlock wi1l never occur in a system of two-phase locking transactions. We also describe an algorithm to avoid false deadlock detection when transactions are not two-phase locking.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232530","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702090","Distributed system;false deadlock;transaction-wait-for graph;two-phase locking","System recovery;TV;Detection algorithms;Detectors;Distributed computing;Resource management;Delay;Protocols;Computer networks;Military computing","","Distributed system;false deadlock;transaction-wait-for graph;two-phase locking","","3","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Planning models for software reliability and cost","M. E. Helander; Ming Zhao; N. Ohlsson","Dept. of Mech. Eng., Linkoping Univ., Sweden; NA; NA","IEEE Transactions on Software Engineering","","1998","24","6","420","434","This paper presents modeling frameworks for distributing development effort among software components to facilitate cost-effective progress toward a system reliability goal. Emphasis on components means that the frameworks can be used, for example, in cleanroom processes and to set certification criteria. The approach, based on reliability allocation, uses the operational profile to quantify the usage environment and a utilization matrix to link usage with system structure. Two approaches for reliability and cost planning are introduced: Reliability-Constrained Cost-Minimization (RCCM) and Budget-Constrained Reliability-Maximization (BCRM). Efficient solutions are presented corresponding to three general functions for measuring cost-to-attain failure intensity. One of the functions is shown to be a generalization of the basic COCOMO form. Planning within budget, adaptation for other cost functions and validation issues are also discussed. Analysis capabilities are illustrated using a software system consisting of 26 developed modules and one procured module. The example also illustrates how to specify a reliability certification level, and minimum purchase price, for the procured module.","0098-5589;1939-3520;2326-3881","","10.1109/32.689400","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=689400","","Software reliability;Software systems;Certification;Linear programming;Software testing;Cost function;Lagrangian functions;Time measurement;Milling machines;Software measurement","software reliability;software cost estimation;software development management","software reliability;planning models;cost-effective progress;system reliability goal;cleanroom processes;certification criteria;reliability allocation;operational profile;usage environment;utilization matrix;reliability-constrained cost-minimization;budget-constrained reliability-maximization;cost-to-attain failure intensity;basic COCOMO form;cost functions;validation issues;reliability certification level;minimum purchase price;Lagrangian multipliers;linear programming;nonlinear programming","","37","","24","","","","","","IEEE","IEEE Journals & Magazines"
"An Interpreter of Attribute Grammars and Its Application to Waveform Analysis","G. K. Papakonstantinou","Computer Center, Greek Atomic Energy Commission","IEEE Transactions on Software Engineering","","1981","SE-7","3","279","283","A simple portable interpreter for testing the specifications of problems is presented in this paper. These specificiations are supposed to be expressed in the formalism of attribute grammars. The parsing and the semantics evaluation are carried out simultaneously, so that the parsing can be directed by the semantics. This increases the power of the grammars and context sensitive characteristics of a language can be described.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230838","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702841","Attribute grammar evaluator;attribute grammars;context sensitive characteristics;formal specifications;semantics;waveform analysis","Counting circuits;Formal specifications;Specification languages;Text processing;Automatic programming;System testing;Computer languages","","Attribute grammar evaluator;attribute grammars;context sensitive characteristics;formal specifications;semantics;waveform analysis","","14","","4","","","","","","IEEE","IEEE Journals & Magazines"
"Efficient interprocedural array data-flow analysis for automatic program parallelization","Junjie Gu; Zhiyuan Li","Sun Microsyst. Inc., Palo Alto, CA, USA; NA","IEEE Transactions on Software Engineering","","2000","26","3","244","261","Since sequential languages such as Fortran and C are more machine-independent than current parallel languages, it is highly desirable to develop powerful parallelization tools which can generate parallel codes, automatically or semi-automatically, targeting different parallel architectures. Array data-flow analysis is known to be crucial to the success of automatic parallelization. Such an analysis should be performed interprocedurally and symbolically and it often needs to handle the predicates represented by IF conditions. Unfortunately, such a powerful program analysis can be extremely time-consuming if it is not carefully designed. How to enhance the efficiency of this analysis to a practical level remains an issue largely untouched to date. This paper presents techniques for efficient interprocedural array data-flow analysis and documents experimental results of its implementation in a research parallelizing compiler. Our techniques are based on guarded array regions and the resulting tool runs faster, by one or two orders of magnitude, than other similarly powerful tools.","0098-5589;1939-3520;2326-3881","","10.1109/32.842950","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=842950","","Data analysis;Parallel languages;Parallel architectures;Performance analysis;Privatization;Computer Society;Power generation;Concurrent computing;Text analysis;Computer applications","arrays;data structures;data flow analysis;parallelising compilers;automatic programming;parallel programming;software performance evaluation","interprocedural array data-flow analysis;automatic program parallelization;parallel code generation;parallel architectures;symbolic analysis;predicates;IF conditions;efficiency enhancement;parallelizing compiler;guarded array regions","","5","","45","","","","","","IEEE","IEEE Journals & Magazines"
"Regeneration of replicated objects: a technique and its Eden implementation","C. Pu; J. D. Noe; A. Proudfoot","Dept. of Comput. Sci., Washington Univ., Seattle, WA, USA; Dept. of Comput. Sci., Washington Univ., Seattle, WA, USA; Dept. of Comput. Sci., Washington Univ., Seattle, WA, USA","IEEE Transactions on Software Engineering","","1988","14","7","936","945","A replicated directory system based on a method called regeneration is designed and implemented. The directory system allows selection of arbitrary object to be replicated, choice of the number of replicas for each object, and placement of the copies on machines with independent failure modes. Copies can become inaccessible due to node crashes, but as long as a single copy survives, the replication level is restored by automatically replacing lost copies on other active machines. The focus is on a regeneration algorithm for replica replacement and its application to a replicated directory structure in the Eden local area network. A simple probabilistic approach is used to compare the availability provided by the algorithm to three other replication techniques.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.42736","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=42736","","Computer crashes;Voting;Availability;Computer science;Algorithm design and analysis;Data analysis;Local area networks;Degradation;Analytical models;Testing","distributed databases;fault tolerant computing;local area networks;system recovery","availability analysis;data replication;distributed databases;replicated objects;Eden;replicated directory system;regeneration;independent failure modes;replica replacement;local area network","","38","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Special Issue - Mobility and Network-Aware Computing","","","IEEE Transactions on Software Engineering","","1998","24","5","0_1","0_1","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1998.685254","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=685254","","","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Cautious transaction schedulers for database concurrency control","T. Ibaraki; T. Kameda; N. Katoh","Dept. of Inf. & Comput. Sci., Toyohashi Univ. of Technol., Japan; NA; NA","IEEE Transactions on Software Engineering","","1988","14","7","997","1009","Cautious schedulers, which never resort to rollbacks for the purpose of concurrency control, are investigated. In particular, cautious schedulers for classes WW consisting of schedules serializable under the write-write constraints, and WRW, a superclass of W, are considered. The cautious WW-scheduler has a number of nice properties, one of which is the existence of a polynomial-time scheduling algorithm. Since cautious WRW-scheduling is, in general, NP-complete, some restrictions are introduced which allow polynomial-time scheduling. All of these cautious schedulers are based on the assumption that transaction predeclare their read and write sets on arrival. Anomalies which occur when transaction modify their read sets or write sets during execution are discussed and countermeasures are proposed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.42740","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=42740","","Transaction databases;Concurrency control;Software testing;Delay;Scheduling algorithm;Polynomials;Database systems;Strontium;Algorithm design and analysis;Councils","computational complexity;database theory;distributed databases;scheduling","computational complexity;distributed databases;transaction schedulers;database concurrency control;cautious schedulers;WW;write-write constraints;WRW;WW-scheduler;polynomial-time scheduling algorithm;NP-complete;read sets;write sets","","10","","19","","","","","","IEEE","IEEE Journals & Magazines"
"A theory-based representation for object-oriented domain models","S. A. DeLoach; T. C. Hartrum","Dept. of Electr. & Comput. Eng., US Air Force Inst. of Technol., Wright-Patterson AFB, OH, USA; NA","IEEE Transactions on Software Engineering","","2000","26","6","500","517","Formal software specification has long been touted as a way to increase the quality and reliability of software; however, it remains an intricate, manually intensive activity. An alternative to using formal specifications directly is to translate graphically based, semiformal specifications into formal specifications. However, before this translation can take place, a formal definition of basic object oriented concepts must be found. The paper presents an algebraic model of object orientation that defines how object oriented concepts can be represented algebraically using an object oriented algebraic specification language O-SLANG. O-SLANG combines basic algebraic specification constructs with category theory operations to capture internal object class structure, as well as relationships between classes.","0098-5589;1939-3520;2326-3881","","10.1109/32.852740","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=852740","","Object oriented modeling;Formal specifications;Software quality;Software systems;Computer Society;Specification languages;Software engineering;Formal languages;Application software;Natural languages","object-oriented programming;object-oriented languages;algebraic specification;category theory","theory based representation;object oriented domain models;formal software specification;graphically based semiformal specification translation;formal definition;basic object oriented concepts;algebraic model;object orientation;object oriented concepts;object oriented algebraic specification language;O-SLANG;basic algebraic specification constructs;category theory operations;internal object class structure","","14","","25","","","","","","IEEE","IEEE Journals & Magazines"
"An industrial strength theorem prover for a logic based on Common Lisp","M. Kaufmann; J. S. Moore","Motorola Inc., Austin, TX, USA; NA","IEEE Transactions on Software Engineering","","1997","23","4","203","213","ACL2 is a reimplemented extended version of R.S. Boyer and J.S. Moore's (1979; 1988) Nqthm and M. Kaufmann's (1988) Pc-Nqthm, intended for large scale verification projects. The paper deals primarily with how we scaled up Nqthm's logic to an industrial strength"" programming language-namely, a large applicative subset of Common Lisp-while preserving the use of total functions within the logic. This makes it possible to run formal models efficiently while keeping the logic simple. We enumerate many other important features of ACL2 and we briefly summarize two industrial applications: a model of the Motorola CAP digital signal processing chip and the proof of the correctness of the kernel of the floating point division algorithm on the AMD5/sub K/86 microprocessor by Advanced Micro Devices, Inc.","0098-5589;1939-3520;2326-3881","","10.1109/32.588534","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=588534","","Logic programming;Logic devices;Digital signal processing chips;Mathematics;Large-scale systems;Functional programming;Kernel;Signal processing algorithms;Microprocessors;Automatic logic units","theorem proving;LISP;program verification;digital signal processing chips;floating point arithmetic","industrial strength theorem prover;Common Lisp;ACL2;reimplemented extended version;Nqthm;Pc-Nqthm;large scale verification projects;industrial strength programming language;large applicative subset;formal models;Motorola CAP digital signal processing chip;proof of correctness;floating point division algorithm;AMD5/sub K/86 microprocessor;Advanced Micro Devices;formal logic","","63","","42","","","","","","IEEE","IEEE Journals & Magazines"
"Modeling and online scheduling of flexible manufacturing systems using stochastic Petri nets","I. Hatono; K. Yamagata; H. Tamura","Dept. of Precision Eng., Osaka Univ., Japan; Dept. of Precision Eng., Osaka Univ., Japan; Dept. of Precision Eng., Osaka Univ., Japan","IEEE Transactions on Software Engineering","","1991","17","2","126","132","The authors discuss the modeling of flexible manufacturing systems (FMSs) under uncertainty and evaluate a rule base for online scheduling. To represent uncertain events in an FMS, such as failure of machine tools, repair time, and processing time, they develop continuous-time and discrete-time stochastic Petri nets with hierarchical structures for constructing the FMS model. For obtaining an efficient schedule for the FMS with an online real-time basis, they construct a rule base and evaluate its performance using the FMS simulation system proposed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.67588","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=67588","","Job shop scheduling;Flexible manufacturing systems;Stochastic systems;Petri nets;Stochastic processes;Processor scheduling;Machine tools;Computational modeling;Manufacturing systems;Uncertainty","digital simulation;flexible manufacturing systems;knowledge based systems;Petri nets;scheduling","flexible manufacturing systems;stochastic Petri nets;uncertainty;rule base;online scheduling;machine tools;repair time;processing time;continuous-time;discrete-time stochastic Petri nets;hierarchical structures","","41","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Discrete-event simulation of fluid stochastic Petri nets","G. Ciardo; D. M. Nicol; K. S. Trivedi","Dept. of Comput. Sci., Coll. of William & Mary, Williamsburg, VA, USA; NA; NA","IEEE Transactions on Software Engineering","","1999","25","2","207","217","The purpose of this paper is to describe a method for the simulation of the recently introduced fluid stochastic Petri nets. Since such nets result in rather complex system of partial differential equations, numerical solution becomes a formidable task. Because of a mixed (discrete and continuous) state space, simulative solution also poses some interesting challenges, which are addressed in the paper.","0098-5589;1939-3520;2326-3881","","10.1109/32.761446","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=761446","","Discrete event simulation;Stochastic processes;Petri nets;State-space methods;Stochastic systems;Performance analysis;Power system modeling;Partial differential equations;Continuous time systems;Fluid flow","discrete event simulation;Petri nets;partial differential equations;discrete event systems","discrete-event simulation;fluid stochastic Petri nets;partial differential equations;numerical solution;mixed state space;simulative solution","","45","","25","","","","","","IEEE","IEEE Journals & Magazines"
"A note on regeneration with virtual copies","R. J. Hilderman; H. J. Hamilton","Dept. of Comput. Sci., Regina Univ., Sask., Canada; NA","IEEE Transactions on Software Engineering","","1997","23","1","56","59","Regeneration with virtual copies (RVC) is a voting-based consistency control algorithm for replicated data objects in a distributed computing system. Proposed by Adam and Tewari (ibid., vol. 19, no. 6, pp. 594-602, 1993), it utilizes selective regeneration and recovery mechanisms for maintaining the availability and consistency of copies. This paper describes some problems with the original paper and proposes solutions.","0098-5589;1939-3520;2326-3881","","10.1109/32.581329","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=581329","","Maintenance;Distributed computing;Availability;Partitioning algorithms;Performance analysis;Control systems;Voting;Algorithm design and analysis","virtual storage;system recovery;replicated databases;concurrency control;distributed databases","selective regeneration mechanisms;virtual copies;voting-based consistency control algorithm;replicated data objects;distributed computing system;selective recovery mechanisms;copy availability;copy consistency;dynamic voting;mutual consistency;network partitioning;reliability;RVC algorithm","","2","","3","","","","","","IEEE","IEEE Journals & Magazines"
"Embedded processes in stochastic Petri nets","W. Henderson; P. G. Taylor","Dept. of Appl. Math., Adelaide Univ., SA, Australia; NA","IEEE Transactions on Software Engineering","","1991","17","2","108","116","Embedded discrete time processes are used to study a class of SPNs (stochastic Petri nets) which have a closed-form equilibrium distribution. These SPNs have probabilistic output bags, colored tokens, and alternating periods of arbitrarily distributing enabling and firing times (periods of time between transitions becoming enabled and absorption of tokens and between transitions absorbing tokens and depositing them in output places, respectively). In addition, an aggregation procedure is proposed which, in certain nets, not only reduces a complex SPN to a much simpler skeleton SPN but also obtains results for the skeleton SPN with are exact marginal distributions for the original SPN.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.67592","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=67592","","Stochastic processes;Petri nets;Routing;Skeleton;Equations;Mathematics;Intelligent networks;Absorption;Random variables;Computer networks","performance evaluation;Petri nets;stochastic processes","embedded discrete time processes;stochastic Petri nets;closed-form equilibrium distribution;probabilistic output bags;colored tokens;arbitrarily distributing enabling;firing times;aggregation procedure","","37","","27","","","","","","IEEE","IEEE Journals & Magazines"
"A formal model of program dependences and its implications for software testing, debugging, and maintenance","A. Podgurski; L. A. Clarke","Dept. of Comput. Eng. & Sci., Case Western Reserve Univ., Cleveland, OH, USA; NA","IEEE Transactions on Software Engineering","","1990","16","9","965","979","A formal, general model of program dependences is presented and used to evaluate several dependence-based software testing, debugging, and maintenance techniques. Two generalizations of control and data flow dependence, called weak and strong syntactic dependence, are introduced and related to a concept called semantic dependence. Semantic dependence models the ability of a program statement to affect the execution behavior of other statements. It is shown that weak syntactic dependence is a necessary but not sufficient condition for semantic dependence and that strong syntactic dependence is necessary but not sufficient condition for a restricted form of semantic dependence that is finitely demonstrated. These results are used to support some proposed uses of program dependences, to controvert others, and to suggest new uses.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58784","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58784","","Software testing;Sufficient conditions;Fault detection;Software debugging;Software maintenance;Programming;Laboratories;Information science;Data analysis;Computer security","formal specification;program debugging;program testing","formal model;program dependences;software testing;debugging;maintenance;data flow dependence;syntactic dependence;semantic dependence","","182","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Empirical studies of a safe regression test selection technique","G. Rothermel; M. J. Harrold","Dept. of Comput. Sci., Oregon State Univ., Corvallis, OR, USA; NA","IEEE Transactions on Software Engineering","","1998","24","6","401","419","Regression testing is an expensive testing procedure utilized to validate modified software. Regression test selection techniques attempt to reduce the cost of regression testing by selecting a subset of a program's existing test suite. Safe regression test selection techniques select subsets that, under certain well-defined conditions, exclude no tests (from the original test suite) that if executed would reveal faults in the modified software. Many regression test selection techniques, including several safe techniques, have been proposed, but few have been subjected to empirical validation. This paper reports empirical studies on a particular safe regression test selection technique, in which the technique is compared to the alternative regression testing strategy of running all tests. The results indicate that safe regression test selection can be cost-effective, but that its costs and benefits vary widely based on a number of factors. In particular, test suite design can significantly affect the effectiveness of test selection, and coverage-based test suites may provide test selection results superior to those provided by test suites that are not coverage-based.","0098-5589;1939-3520;2326-3881","","10.1109/32.689399","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=689399","","Software testing;Costs;Software safety;Algorithm design and analysis;Fault detection;Performance evaluation","program testing;software maintenance;statistical analysis","safe regression test selection technique;empirical validation;test suite design;software maintenance;selective retest","","118","","41","","","","","","IEEE","IEEE Journals & Magazines"
"Correction to ""A Concurrency Measure""","M. G. Khayat; W. S. Breger; M. Freiling; T. G. Lewis","Department of Computer Science and Engineering, University of Petroleum &amp; Minerals; NA; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","8","822","822","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232532","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702092","","Concurrent computing;Computer science;Petroleum;Minerals;Laboratories","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"A Method for Improving String Pattern Matching Machines","J. Aoe; Y. Yamamoto; R. Shimada","Department of Information Science and Systems Engineering, Faculty of Engineering, Tokushima University, Minami-josanjima-cho, Tokushima-shi 770, Japan.; Department of Information Science and Systems Engineering, Faculty of Engineering, Tokushima University, Minami-josanjima-cho, Tokushima-shi 770, Japan.; Department of Information Science and Systems Engineering, Faculty of Engineering, Tokushima University, Minami-josanjima-cho, Tokushima-shi 770, Japan.","IEEE Transactions on Software Engineering","","1984","SE-10","1","116","120","This correspondence describes an efficient string pattern matching machine to locate all occurrences of any of a finite number of keywords and phrases in an arbitrary text string. Some conditions are defined on the states of the machine in order to improve the speed and size of the machine by Aho and Corasick [1]. The pattern matching algorithm is partitioned into various cases by combining these conditions. Finally, the correspondence illustrates the proposed approach by applying it to the analysis of the machines for a simple search.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010205","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010205","Data structure;finite state machine;keywords;matching algorithm;storage requirements;string pattern matching machine","Pattern matching;Partitioning algorithms;Keyboards;Automata;Data structures;Pattern analysis;Speech analysis;Algorithm design and analysis;Pattern recognition;Speech recognition","","","","25","","7","","","","","","IEEE","IEEE Journals & Magazines"
"Guest Editor's Introduction","R. E. Fairley","NA","IEEE Transactions on Software Engineering","","1987","SE-13","11","1141","1142","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232861","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702159","","Software engineering;Educational programs;Computer science education;Computer industry;Software quality;Educational products;Software design;Engineering education;Industrial economics;Educational technology","","","","","","10","","","","","","IEEE","IEEE Journals & Magazines"
"""On-the-fly"" solution techniques for stochastic Petri nets and extensions","D. D. Deavours; W. H. Sanders","Center for Reliable & High Performance Comput., Illinois Univ., Urbana, IL, USA; NA","IEEE Transactions on Software Engineering","","1998","24","10","889","902","High level modeling representations, such as stochastic Petri nets, frequently generate very large state spaces and corresponding state transition rate matrices. We propose a new steady state solution approach that avoids explicit storing of the matrix in memory. This method does not impose any structural restrictions on the model, uses Gauss Seidel and variants as the numerical solver, and uses less memory than current state of the art solvers. An implementation of these ideas shows that one can realistically solve very large, general models in relatively little memory.","0098-5589;1939-3520;2326-3881","","10.1109/32.729691","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=729691","","Stochastic processes;Petri nets;State-space methods;Jacobian matrices;Gaussian processes;Computer Society;Steady-state;Scalability;Explosions;Impedance","Petri nets;stochastic systems;iterative methods;mathematics computing;matrix algebra;modelling","on-the-fly solution techniques;stochastic Petri nets;high level modeling representations;very large state spaces;state transition rate matrices;steady state solution approach;structural restrictions;Gauss Seidel;numerical solver;very large general models","","15","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Formal verification of concurrent programs using the Larch prover","B. Chetali","GIE DYADE, Rocquencourt, France","IEEE Transactions on Software Engineering","","1998","24","1","46","62","The paper describes the use of the Larch prover to verify concurrent programs. The chosen specification environment is UNITY, whose proposed model can be fruitfully applied to a wide variety of problems and modified or extended for special purposes. Moreover, UNITY provides a high level of abstraction to express solutions to parallel programming problems. We investigate how the UNITY methodology can be mechanized within a general purpose first order logic theorem prover like LP, and how we can use the theorem proving methodology to prove safety and liveness properties. Then we describe the formalization and the verification of a communication protocol over faulty channels, using the Larch prover LP. We present the full computer checked proof, and we show that a theorem prover can be used to detect flaws in a system specification.","0098-5589;1939-3520;2326-3881","","10.1109/32.663997","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=663997","","Formal verification;Protocols;Software development management;Engineering management;Concurrent computing;Parallel programming;Logic programming;Safety;Mechanical factors;Fault detection","parallel programming;program verification;formal specification;theorem proving;protocols","formal verification;concurrent programs;Larch prover;specification environment;abstraction;parallel programming problems;UNITY methodology;general purpose first order logic theorem prover;LP;theorem proving methodology;liveness properties;communication protocol;faulty channels;computer checked proof;system specification","","5","","35","","","","","","IEEE","IEEE Journals & Magazines"
"Toward formally-based design of message passing programs","S. Gorlatch","Passau Univ., Germany","IEEE Transactions on Software Engineering","","2000","26","3","276","288","Presents a systematic approach to the development of message passing programs. Our programming model is SPMD, with communications restricted to collective operations: scan, reduction, gather, etc. The design process in such an architecture-independent language is based on correctness-preserving transformation rules that are provable in a formal functional framework. We develop a set of design rules for composition and decomposition. For example, scan followed by reduction is replaced by a single reduction, and global reduction is decomposed into two faster operations. The impact of the design rules on the target performance is estimated analytically and tested in machine experiments. As a case study, we design two provably correct, efficient programs using the Message Passing Interface (MPI) for the famous maximum segment sum problem, starting from an intuitive, but inefficient, algorithm specification.","0098-5589;1939-3520;2326-3881","","10.1109/32.842952","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=842952","","Message passing;Algorithm design and analysis;Process design;Skeleton;Design methodology;Performance analysis;Testing;Parallel programming;Programming profession;Parallel architectures","message passing;distributed programming;application program interfaces;formal specification;software performance evaluation","formally-based design;message passing programs;SPMD programming model;collective operations;scanning operation;reduction operation;gathering operation;architecture-independent language;correctness-preserving transformation rules;formal functional framework;design rules;composition;decomposition;performance;efficient programs;Message Passing Interface;MPI;maximum segment sum problem;algorithm specification;program transformations;systematic program design;homomorphisms;skeletons","","12","","33","","","","","","IEEE","IEEE Journals & Magazines"
"Special issues for fm '99: the first world congress on formal methods in the development of computing systems","J. M. Wing; J. Woodcock","Carnegie Mellon University; NA","IEEE Transactions on Software Engineering","","2000","26","8","673","674","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.2000.879806","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=879806","","","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Providing quality responses with natural language interfaces: the null value problem","M. Kao; N. Cercone; W. -. Luk","Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada; Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada; Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada","IEEE Transactions on Software Engineering","","1988","14","7","959","984","An underlying relational database model and the database query language SQL are assumed, and methods are presented for responding with appropriate answers to null value responses. This is done by using a knowledge base based on RM/T, an extended relational model. The advantages of this approach are described. To demonstrate the utility of the knowledge base model, a simple knowledge base is constructed. The algorithms that provide additional information when a null answer is returned are detailed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.42738","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=42738","","Natural languages;Information retrieval;Relational databases;Database languages;Database systems;Null value;History;Quality management;Graphics","knowledge engineering;natural languages;query languages;relational databases;user interfaces","user interfaces;knowledge engineering;quality responses;natural language interfaces;relational database model;query language;SQL;null value responses;knowledge base;RM/T;extended relational model","","14","","68","","","","","","IEEE","IEEE Journals & Magazines"
"Defining software by continuous, smooth functions","R. A. DeMillo; R. J. Lipton","Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA; NA","IEEE Transactions on Software Engineering","","1991","17","4","383","384","A simple proof is given, showing that for every operational description of a software system expressed as a discrete state transition function on a virtual machine, there is a continuous smooth function on the reals that agrees with the state transition function on all legal states and has exactly the same complexity. It is suggested that an implication of this result is that there is no reason, in principle, that the methods of classical analysis cannot be used in software engineering.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.90437","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=90437","","Software systems;Virtual machining;Software engineering;Mathematics;Logic;Law;Legal factors;Control systems;Mathematical analysis;State-space methods","computational complexity;software engineering","software system;discrete state transition function;virtual machine;continuous smooth function;legal states;complexity;classical analysis;software engineering","","5","","6","","","","","","IEEE","IEEE Journals & Magazines"
"KLAIM: a kernel language for agents interaction and mobility","R. De Nicola; G. L. Ferrari; R. Pugliese","Dept. of Syst. & Inf., Florence Univ., Italy; NA; NA","IEEE Transactions on Software Engineering","","1998","24","5","315","330","We investigate the issue of designing a kernel programming language for mobile computing and describe KLAIM, a language that supports a programming paradigm where processes, like data, can be moved from one computing environment to another. The language consists of a core Linda with multiple tuple spaces and of a set of operators for building processes. KLAIM naturally supports programming with explicit localities. Localities are first-class data (they can be manipulated like any other data), but the language provides coordination mechanisms to control the interaction protocols among located processes. The formal operational semantics is useful for discussing the design of the language and provides guidelines for implementations. KLAIM is equipped with a type system that statically checks access right violations of mobile agents. Types are used to describe the intentions (read, write, execute, etc.) of processes in relation to the various localities. The type system is used to determine the operations that processes want to perform at each locality, and to check whether they comply with the declared intentions and whether they have the necessary rights to perform the intended operations at the specific localities. Via a series of examples, we show that many mobile code programming paradigms can be naturally implemented in our kernel language. We also present a prototype implementation of KLAIM in Java.","0098-5589;1939-3520;2326-3881","","10.1109/32.685256","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=685256","","Kernel;Computer languages;Mobile computing;Buildings;Access protocols;Guidelines;Permission;Mobile agents;Prototypes;Java","parallel languages;parallel programming;type theory;object-oriented languages;process algebra;software portability;software agents","KLAIM;kernel programming language;agent interaction;agent mobility;mobile computing;Linda;multiple tuple spaces;operators;explicit localities;first-class data;coordination mechanisms;interaction protocols;formal operational semantics;type system;access right violations;mobile code programming;Java;process algebra","","228","","41","","","","","","IEEE","IEEE Journals & Magazines"
"A weakest precondition semantics for refinement of object-oriented programs","A. Cavalcanti; D. A. Naumann","Centro de Inf., Univ. Fed. de Pernambuco, Recife, Brazil; NA","IEEE Transactions on Software Engineering","","2000","26","8","713","728","We define a predicate-transformer semantics for an object oriented language that includes specification constructs from refinement calculi. The language includes recursive classes, visibility control, dynamic binding, and recursive methods. Using the semantics, we formulate notions of refinement. Such results are a first step toward a refinement calculus.","0098-5589;1939-3520;2326-3881","","10.1109/32.879810","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=879810","","Java;Calculus;Object oriented modeling;Object oriented programming;Computer Society;Formal specifications;Terminology;Logic programming;Testing;Software algorithms","object-oriented programming;object-oriented languages;programming language semantics;formal specification;refinement calculus;type theory","weakest precondition semantics;object oriented program refinement;predicate-transformer semantics;object oriented language;specification constructs;refinement calculi;recursive classes;visibility control;dynamic binding;recursive methods","","24","","34","","","","","","IEEE","IEEE Journals & Magazines"
"A system for specification and rapid prototyping of application command languages","J. Stelovsky; H. Sugaya","Swiss Federal Inst. of Technol., Zurich, Switzerland; NA","IEEE Transactions on Software Engineering","","1988","14","7","1023","1032","The XS-2 system that integrates specification, rapid prototyping, and the actual use of application dialogs is described. The XS-2 command language grammar, a nonprocedural description language based on regular expressions, is used to specify commands for any application program. The syntax of the command specification is visible to the user: command names and their activation rules are displayed as a command tree. Since a small set of tools is provided for the development of the command specification and its automatic translation into a prototype application module in Modula-2, no programming work is necessary to design and evaluate the commands. Experience shows that an advanced end user can develop his or her own prototype application without a programmer's assistance.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.42742","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=42742","","Prototypes;Command languages;Application software;User interfaces;Operating systems;Software prototyping;Automatic programming;Microcomputers;Workstations;Productivity","grammars;interactive systems;programming environments;software tools;user interfaces","software tools;programming environments;user interfaces;rapid prototyping;application command languages;XS-2 system;application dialogs;command language grammar;nonprocedural description language;regular expressions;command specification;command tree;automatic translation;Modula-2","","","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Validating the ISO/IEC 15504 measure of software requirements analysis process capability","K. El Emam; A. Birk","Inst. for Inf. Technol., Nat. Res. Council of Canada, Ottawa, Ont., Canada; NA","IEEE Transactions on Software Engineering","","2000","26","6","541","566","ISO/IEC 15504 is an emerging international standard on software process assessment. It defines a number of software engineering processes and a scale for measuring their capability. One of the defined processes is software requirements analysis (SRA). A basic premise of the measurement scale is that higher process capability is associated with better project performance (i.e., predictive validity). The paper describes an empirical study that evaluates the predictive validity of SRA process capability. Assessments using ISO/IEC 15504 were conducted on 56 projects world-wide over a period of two years. Performance measures on each project were also collected using questionnaires, such as the ability to meet budget commitments and staff productivity. The results provide strong evidence of predictive validity for the SRA process capability measure used in ISO/IEC 15504, but only for organizations with more than 50 IT staff. Specifically, a strong relationship was found between the implementation of requirements analysis practices as defined in ISO/IEC 15504 and the productivity of software projects. For smaller organizations, evidence of predictive validity was rather weak. This can be interpreted in a number of different ways: that the measure of capability is not suitable for small organizations or that the SRA process capability has less effect on project performance for small organizations.","0098-5589;1939-3520;2326-3881","","10.1109/32.852742","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=852742","","ISO standards;IEC standards;Software measurement;Software quality;Capability maturity model;Software standards;Software engineering;Productivity;Military standards;Design engineering","ISO standards;IEC standards;software standards;software metrics;formal specification;software process improvement;software development management;program verification;human resource management","ISO/IEC 15504 measure validation;software requirements analysis process capability;international standard;software process assessment;software engineering processes;measurement scale;process capability;project performance;predictive validity;SRA process capability;performance measures;budget commitments;staff productivity;SRA process capability measure;IT staff;requirements analysis practices;software projects;small organizations","","72","","92","","","","","","IEEE","IEEE Journals & Magazines"
"Comparing verification systems: interactive consistency in ACL2","W. D. Young","Comput.. Logic Inc., Austin, TX, USA","IEEE Transactions on Software Engineering","","1997","23","4","214","223","Achieving interactive consistency among processors in the presence of faults is an important problem in fault tolerant computing, first cleanly formulated by L. Lamport, R. Pease, and M. Shostak (1980; 1982) and solved in selected cases with their Oral Messages (OM) algorithm. Several machine supported verifications of this algorithm have been presented, including a particularly elegant formulation and proof by John Rushby using EHDM and PVS (S. Owre et al., 1992, 1995; J. Rushby, 1992). Rushby proposes interactive consistency as a benchmark problem for specification and verification systems. We present a formalization of the OM algorithm in the ACL2 logic and compare our formalization and proof to his. We draw some conclusions concerning the range of desirable features for verification systems. In particular, while higher order functions, strong typing, lambda abstraction, and full quantification have some value they come with a cost; moreover, many uses of such features can be easily translated into simpler logical constructs, which facilitate more automated proof discovery. We offer a cautionary note about comparing systems with respect to a small set of problems in a limited domain.","0098-5589;1939-3520;2326-3881","","10.1109/32.588536","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=588536","","Fault tolerance;Fault tolerant systems;Cost function;Automatic logic units;Specification languages;Algorithm design and analysis","program verification;software fault tolerance;formal logic;formal specification;theorem proving","verification systems;interactive consistency;ACL2;fault tolerant computing;Oral Messages algorithm;machine supported verifications;EHDM;PVS;benchmark problem;specification systems;OM algorithm;ACL2 logic;higher order functions;strong typing;lambda abstraction;full quantification;logical constructs;automated proof discovery","","5","","23","","","","","","IEEE","IEEE Journals & Magazines"
"A framework based approach to the development of network aware applications","J. Bolliger; T. Gross","Dept. of Comput. Sci., Fed.. Inst. of Technol., Zurich, Switzerland; NA","IEEE Transactions on Software Engineering","","1998","24","5","376","390","Modern networks provide a QoS (quality of service) model to go beyond best-effort services, but current QoS models are oriented towards low-level network parameters (e.g., bandwidth, latency, jitter). Application developers, on the other hand, are interested in quality models that are meaningful to the end-user and, therefore, struggle to bridge the gap between network and application QoS models. Examples of application quality models are response time, predictability or a budget (for transmission costs). Applications that can deal with changes in the network environment are called network-aware. A network-aware application attempts to adjust its resource demands in response to network performance variations. This paper presents a framework-based approach to the construction of network-aware programs. At the core of the framework is a feedback loop that controls the adjustment of the application to network properties. The framework provides the skeleton to address two fundamental challenges for the construction of network-aware applications: how to find out about dynamic changes in network service quality; and how to map application-centric quality measures (e.g., predictability) to network-centric quality measures (e.g., QoS models that focus on bandwidth or latency). Our preliminary experience with a prototype network-aware image retrieval system demonstrates the feasibility of our approach. The prototype illustrates that there is more to network-awareness than just taking network resources and protocols into account and raises questions that need to be addressed (from a software engineering point of view) to make a general approach to network-aware applications useful.","0098-5589;1939-3520;2326-3881","","10.1109/32.685260","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=685260","","Quality of service;Delay;Bandwidth;Predictive models;Software prototyping;Jitter;Bridges;Costs;Feedback loop;Skeleton","software engineering;distributed processing;computer networks;visual databases","framework based approach;network aware applications;quality of service;QoS models;low-level network parameters;end-user;application quality models;response time;predictability;budget;resource demands;network performance variations;feedback loop;network service quality;prototype;image retrieval system;protocols;software engineering","","80","","41","","","","","","IEEE","IEEE Journals & Magazines"
"Adaptive time warp simulation of timed Petri nets","A. Ferscha","Inst. fur Angewandte Inf., Wien Univ., Austria","IEEE Transactions on Software Engineering","","1999","25","2","237","257","Time warp (TW), although generally accepted as a potentially effective parallel and distributed simulation mechanism for timed Petri nets, can reveal deficiencies in certain model domains. Particularly, the unlimited optimism underlying TW can lead to excessive aggressiveness in memory consumption due to saving state histories, and waste of CPU cycles due to over-optimistically progressing simulations that eventually have to be ""rolled back"". Furthermore, in TW simulations executing in distributed memory environments, the communication overhead induced by the roll-back mechanism can cause pathological overall simulation performance. In this work, an adaptive optimism control mechanism for TW is developed to overcome these shortcomings. By monitoring and statistically analyzing the arrival processes of synchronization messages, TW simulation progress is probabilistically throttled based on the forecasted time stamp of forthcoming messages. Two classes of arrival process characterizations are studied, reflecting that a natural trade-off exists among the computational and space complexity, and the respective prediction accuracy: While forecasts based on metrics of central tendency are computationally cheap but yield inadequate predictions for correlated arrivals (thus negatively affecting performance), time series based forecast methods give higher prediction accuracy, but at higher computational cost.","0098-5589;1939-3520;2326-3881","","10.1109/32.761448","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=761448","","Time warp simulation;Petri nets;High performance computing;Accuracy;History;Discrete event simulation;Pathology;Programmable control;Adaptive control;Communication system control","time warp simulation;Petri nets;synchronisation;statistical analysis;time series;computational complexity;distributed processing","adaptive time warp simulation;timed Petri nets;distributed simulation mechanism;parallel simulation mechanism;model domains;memory consumption;state history saving;CPU cycles;distributed memory environments;communication overhead;roll back mechanism;pathological overall simulation performance;arrival process monitoring;statistical analysis;synchronization messages;forecasted time stamp;computational complexity;space complexity;prediction accuracy;metrics","","9","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Stability, availability, and response in network file service","J. Gait","Tekronix Inc., Beaverton, OR, USA","IEEE Transactions on Software Engineering","","1991","17","2","133","140","A network file system called Multifile is described. It meets response, availability, and stability requirements as primitive functions. Multifile has a high degree of responsiveness because its component parts compete among themselves to service file requests; it has high availability because it maintains multiple copies of files; and it exhibits stable behavior over wise range of system parameters. The responsiveness of Multifile to read requests improves as the number of pages per request rises, implying that read ahead pages can profitably be cached at client sites. The throughput of Multifile improves as the request size increases and as the number of clients increases. As server load increases, the responsiveness of Multifile to read requests is stable in most configurations. The throughput of writes is unstable as the number of pages in the wire request rises, implying that write back pages should not be cached at client sites. The scale of events in file service is dominated by disk activity, so lost message exceptions do not occur frequently enough to affect file service; however, duplicate message exceptions are a factor in performance.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.67594","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=67594","","Stability;Availability;Intelligent networks;Delay;Workstations;Data engineering;File systems;Throughput;Application software;Automotive engineering","file servers;network operating systems","network file service;Multifile;stable behavior;responsiveness;read ahead pages;request size;disk activity;duplicate message exceptions","","","","31","","","","","","IEEE","IEEE Journals & Magazines"
"A C++ data model supporting reachability analysis and dead code detection","Yih-Fam Chen; E. R. Gansner; E. Koutsofios","AT&T Labs. Res., Florham Park, NJ, USA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","9","682","694","A software repository provides a central information source for understanding and reengineering code in a software project. Complex reverse engineering tools can be built by analyzing information stored in the repository without reparsing the original source code. The most critical design aspect of a repository is its data model, which directly affects how effectively the repository supports various analysis tasks. This paper focuses on the design rationales behind a data model for a C++ software repository that supports reachability analysis and dead code detection at the declaration level. These two tasks are frequently needed in large software projects to help remove excess software baggage, select regression tests and support software reuse studies. The language complexity introduced by class inheritance, friendship, and template instantiation in C++ requires a carefully designed model to catch all necessary dependencies for correct reachability analysis. We examine the major design decisions and their consequences in our model and illustrate how future software repositories can be evaluated for completeness at a selected abstraction level. Examples are given to illustrate how our model also supports variants of reachability analysis: impact analysis, class visibility analysis, and dead code detection. Finally, we discuss the implementation and experience of our analysis tools on a few C++ software projects.","0098-5589;1939-3520;2326-3881","","10.1109/32.713323","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=713323","","Reachability analysis;Relational databases;Reverse engineering;Data models;Information analysis;Software testing;Software maintenance;Software tools;Buildings;Tree graphs","object-oriented languages;object-oriented programming;C language;reachability analysis;software libraries;software reusability;systems re-engineering;reverse engineering;inheritance;data structures","C++;data model;reachability analysis;dead code detection;software repository;program understanding;system reengineering;software project;reverse engineering tools;large software projects;regression tests;software reuse;language complexity;class inheritance;friendship;template instantiation;impact analysis;class visibility analysis","","26","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Mechanizing CSP trace theory in higher order logic","A. J. Camilleri","Hewlett-Packard Lab., Stoke Gifford, UK","IEEE Transactions on Software Engineering","","1990","16","9","993","1004","How a mechanized tool for reasoning about CSP (communicating sequential processes) can be developed by customizing an existing general-purpose theorem prover based on higher-order logic is described. How the trace semantics of CSP operators can be mechanized in higher-order logic is investigated, and how the laws associated with these operators can be proved from their semantic definitions is shown. The resulting system is one in which natural-deduction style proofs can be conducted using the standard CSP laws.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58786","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58786","","Algebra;Logic functions;Concurrent computing;Humans;Formal verification;System recovery;Information systems","formal logic;formal specification;theorem proving","mechanising CSP trace theory;higher order logic;communicating sequential processes;general-purpose theorem prover","","34","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Formal verification of Ada programs","D. Guaspari; C. Marceau; W. Polak","Odyssey Res. Associates Inc., Ithaca, NY, USA; Odyssey Res. Associates Inc., Ithaca, NY, USA; Odyssey Res. Associates Inc., Ithaca, NY, USA","IEEE Transactions on Software Engineering","","1990","16","9","1058","1075","The Penelope verification editor and its formal basis are described. Penelope is a prototype system for the interactive development and verification of programs that are written in a rich subset of sequential Ada. Because it generates verification conditions incrementally, Penelope can be used to develop a program and its correctness proof in concert. If an already-verified program is modified, one can attempt to prove the modified version by replaying and modifying the original sequence of proof steps. Verification conditions are generated by predicate transformers whose logical soundness can be proven by establishing a precise formal connection between predicate transformation and denotational definitions in the style of continuation semantics. Penelope's specification language, Larch/Ada, belongs to the family of Larch interface languages. It scales up properly, in the sense that one can demonstrate the soundness of decomposing an implementation hierarchically and reasoning locally about the implementation of each node in the hierarchy.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58790","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58790","","Formal verification;Specification languages;Formal specifications;Prototypes;Transformers;Programming;Mathematical model;Error correction;Buildings;Manuals","Ada;program verification;software engineering","Ada programs;Penelope verification editor;formal basis;prototype system;interactive development;correctness proof;predicate transformers;logical soundness;interface languages","","34","","35","","","","","","IEEE","IEEE Journals & Magazines"
"Optimum Cell Size for the Storage of Messages","P. Sipala","Istituto di Elettrotecnica e di Elettronica, Universiti di Trieste","IEEE Transactions on Software Engineering","","1981","SE-7","1","132","134","In this paper we discuss a memory allocation problem first introduced by Wolman in [1] (see also [2]). A general solution formula is presented, from which closed form expressions for a few special cases may be easily derived.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230819","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702810","Compact storage of messages;memory management;message buffering;storage allocation","Buffer storage;Memory management;Genetic expression;Joining processes;Probability distribution;Linearity;Random variables;Sufficient conditions;Probability density function","","Compact storage of messages;memory management;message buffering;storage allocation","","","","6","","","","","","IEEE","IEEE Journals & Magazines"
"Storing and retrieving software components: a refinement based system","R. Mili; A. Mili; R. T. Mittermeir","Southwestern Med. Center, Texas Univ., Dallas, TX, USA; NA; NA","IEEE Transactions on Software Engineering","","1997","23","7","445","460","Software libraries are repositories which contain software components; as such, they represent a precious resource for the software engineer. As software libraries grow in size, it becomes increasingly difficult to maintain adequate precision and recall with informal retrieval algorithms. In this paper, we discuss the design and implementation of a storage and retrieval structure for software components that is based on formal specifications and on the refinement ordering between specifications.","0098-5589;1939-3520;2326-3881","","10.1109/32.605762","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=605762","","Software libraries;Formal specifications;Software algorithms;Information science;Application software;Information retrieval;Software maintenance;Humans;Maintenance engineering;Computer languages","software libraries;software reusability;information retrieval;formal specification","software component storage;software component retrieval;refinement based system;software libraries;software repositories;informal retrieval algorithms;recall;precision;formal specifications;refinement ordering;software reuse","","65","","67","","","","","","IEEE","IEEE Journals & Magazines"
"An Extension of Norton's Theorem for Queueing Networks","S. Balsamo; G. Iazeolla","Istituto di Scienze dell'Informazione, University of Pisa; NA","IEEE Transactions on Software Engineering","","1982","SE-8","4","298","305","Given a closed BCMP queueing network, the problem is considered of studying the behavior of any subsystem a without solving for the entire system. This paper proves that this is possible for a consisting of any number of queues, arbitrarily interfacing the rest of the system, thus generalizing the classic CHW theorem, also known as Norton's theorem. A general flow-equivalent solution procedure is given and its computational complexity is compared with that of the product-form and the exact aggregation procedure. The relative merits of these procedures are also expressed in terms of a's cardinality.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235424","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702953","Aggregation;computer/communication networks;decomposition;equivalent network;networks of queues;queueing theory","Queueing analysis;Computational complexity;Computer networks;Communication networks;Network servers;Throughput","","Aggregation;computer/communication networks;decomposition;equivalent network;networks of queues;queueing theory","","5","","6","","","","","","IEEE","IEEE Journals & Magazines"
"Components of software development risk: how to address them? A project manager survey","J. Ropponen; K. Lyytinen","Finnish Evangelical Lutheran Mission, Helsinki, Finland; NA","IEEE Transactions on Software Engineering","","2000","26","2","98","112","Software risk management can be defined as an attempt to formalize risk oriented correlates of development success into a readily applicable set of principles and practices. By using a survey instrument we investigate this claim further. The investigation addresses the following questions: 1) What are the components of software development risk? 2) how does risk management mitigate risk components, and 3) what environmental factors if any influence them? Using principal component analysis we identify six software risk components: 1) scheduling and timing risks, 2) functionality risks, 3) subcontracting risks, 4) requirements management, 5) resource usage and performance risks, and 6) personnel management risks. By using one-way ANOVA with multiple comparisons we examine how risk management (or the lack of it) and environmental factors (such as development methods, manager's experience) influence each risk component. The analysis shows that awareness of the importance of risk management and systematic practices to manage risks have an effect on scheduling risks, requirements management risks, and personnel management risks. Environmental contingencies were observed to affect all risk components. This suggests that software risks can be best managed by combining specific risk management considerations with a detailed understanding of the environmental context and with sound managerial practices, such as relying on experienced and well-educated project managers and launching correctly sized projects.","0098-5589;1939-3520;2326-3881","","10.1109/32.841112","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=841112","","Programming;Risk management;Environmental management;Project management;Environmental factors;Personnel;Analysis of variance;Instruments;Principal component analysis;Software performance","risk management;software development management;principal component analysis","software development risk management;project manager survey;environmental factors;principal component analysis;timing risks;scheduling risks;functionality risks;subcontracting risks;requirements management;resource usage;performance risks;personnel management risks;one-way ANOVA;multiple comparisons;environmental contingencies","","162","","48","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on estimating the number of faults in code and two corrections to published data","M. Lipow","Hughes Aircraft Company, Radar Systems Group, P.O. Box 92426, Los Angeles, CA 90009","IEEE Transactions on Software Engineering","","1986","SE-12","4","584","585","The subject paper<sup>1</sup>concludes that number of faults per line of code is independent of whether Assembly language or a high order language (HOL) is used, contrary to previously published results by the author of this correspondence. However, the subject paper contains some technical errors and uses erroneous data. An explanation of the source of the erroneous data is given. Also, previously published information by the author of this correspondence on average number of operators plus operands per line of Assembly language code is corrected.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312907","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312907","Software error rate;software reliability","Assembly;Software;Software reliability;Compass;Computer bugs;Earth Observing System;Registers","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"The parallel assignment problem redefined","C. May","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA","IEEE Transactions on Software Engineering","","1989","15","6","821","824","The parallel assignment problem is slightly redefined using a subtler cost function that tends to reduce the number of extra assignments required. It is shown that the new problem, like the classical, is NP-hard. The new problem is then solved for the restricted case of assignment from invertible functions of single variables. For this restricted case and optimum solution can be found in linear time for both the classical problem and the new problem. However, the number of extra assignments required for the classical problem is equal to the number of cycles in the dependency graph, while in the new problem it is equal to the number of isolated cycles in the dependency graph which may be less.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24735","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24735","","Cost function;Couplings;Artificial intelligence","computational complexity;parallel algorithms;parallel programming","parallel assignment problem;cost function;NP-hard;invertible functions;single variables;restricted case;optimum solution;linear time;classical problem;dependency graph;isolated cycles","","1","","","","","","","","IEEE","IEEE Journals & Magazines"
"Evolution of object behavior using context relations","L. M. Seiter; J. Palsberg; K. J. Lieberherr","Comput. Eng. Dept., Santa Clara Univ., CA, USA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","1","79","92","A collection of design patterns was described by E. Gamma et al. (1994). Each pattern ensures that a certain system aspect can vary over time, for example the operations that can be applied to an object or the algorithm of a method. The patterns are described by constructs such as the inheritance and reference relations, attempting to emulate more dynamic relationships. As a result, the design patterns demonstrate how awkward it is to program natural concepts of evolution when using a traditional object oriented language. We present a new relation between classes: the context relation. It directly models dynamic evolution, and it is meaningful at both the design and implementation level. At the design level we extend the Unified Modeling Language (UML) to include the context relation as a new form of arrow between classes. At the implementation level we present a small extension of Java. The context relation introduces a new form of dynamic binding that serves as a replacement to delegation. We demonstrate how the context relation can be used to easily model and program numerous design patterns.","0098-5589;1939-3520;2326-3881","","10.1109/32.663999","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=663999","","Unified modeling language;Software engineering;Java;Computer science;Computer Society;Context modeling;Production;Software reusability;Design engineering","object-oriented programming;object-oriented languages;software reusability;inheritance","object behavior evolution;context relations;design patterns;system aspect;inheritance;reference relations;dynamic relationships;natural concepts;evolution;object oriented language;context relation;dynamic evolution;Unified Modeling Language;implementation level;Java extension;dynamic binding;delegation","","23","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Program Structure Charts for Applicative Languages","F. G. Pagan","Department of Computer Science, California State University","IEEE Transactions on Software Engineering","","1987","SE-13","4","490","493","A framework for a system of charts compatible with the use of applicative programming languages is proposed and illustrated. The charts are similar in spirit to the structured flowcharts that have sometimes been used with algorithmic languages. They are based on a method of representing the structure of nested expressions of arbitrary complexity. This method is adaptable to the incorporation of graphical devices for the depiction of local identifier bindings, conditional expressions, recursive function definitions, and the various functional combining forms employed in the FP-style of applicative programming.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233185","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702240","Applicative languages;functional programming;program design and documentation;program structure charts;structured flowcharts","Computer languages;Functional programming;Flowcharts;Documentation;Computer science;History;Diversity reception;Computer displays;Writing","","Applicative languages;functional programming;program design and documentation;program structure charts;structured flowcharts","","","","4","","","","","","IEEE","IEEE Journals & Magazines"
"Formal development and verification of a distributed railway control system","A. E. Haxthausen; J. Peleska","Dept. of Inf. Technol., Tech. Univ., Lyngby, Denmark; NA","IEEE Transactions on Software Engineering","","2000","26","8","687","701","The authors introduce the concept for a distributed railway control system and present the specification and verification of the main algorithm used for safe distributed control. Our design and verification approach is based on the RAISE method, starting with highly abstract algebraic specifications which are transformed into directly implementable distributed control processes by applying a series of refinement and verification steps. Concrete safety requirements are derived from an abstract version that can be easily validated with respect to soundness and completeness. Complexity is further reduced by separating the system model into a domain model and a controller model. The domain model describes the physical system in absence of control and the controller model introduces the safety-related control mechanisms as a separate entity monitoring observables of the physical system to decide whether it is safe for a train to move or for a point to be switched.","0098-5589;1939-3520;2326-3881","","10.1109/32.879808","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=879808","","Rail transportation;Distributed control;Control systems;Communication system control;Switches;Railway safety;Centralized control;Formal specifications;Mobile communication;Concrete","railways;rail traffic;traffic control;algebraic specification;program verification;distributed control;safety-critical software","formal development;distributed railway control system verification;formal specification;safe distributed control;verification approach;RAISE method;highly abstract algebraic specifications;directly implementable distributed control processes;verification steps;safety requirements;abstract version;soundness;completeness;domain model;controller model;safety-related control mechanisms","","52","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Protocols for Deadlock Detection in Distributed Database Systems","G. S. Ho; C. V. Ramamoorthy","Bell Laboratories; NA","IEEE Transactions on Software Engineering","","1982","SE-8","6","554","557","In distributed databases, deadlocks may occur due to conflicts in data file lockings A system is in a deadlock if and only if there is a directed cycle in its demand graph. However, due to the inherent communication delay in a distributed system, it is not easy to construct a consistent demand graph for a distributed system. In this paper, three deadlock detection protocols are discussed. The first protocol uses two communication phases. The second protocol uses a single communication phase. Based on the second protocol, a one-phase hierarchical deadlock detection protocol is developed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235884","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702988","Communication protocol;deadlock;demand graph;distributed database;hierarchical","Protocols;System recovery;Database systems;Distributed databases;Communication system control;Control systems;Delay;Centralized control;Permission;Sufficient conditions","","Communication protocol;deadlock;demand graph;distributed database;hierarchical","","26","","7","","","","","","IEEE","IEEE Journals & Magazines"
"The model multiplicity problem: experimenting with real-time specification methods","M. Peleg; D. Dori","Sch. of Med., Stanford Univ., CA, USA; NA","IEEE Transactions on Software Engineering","","2000","26","8","742","759","The object-process methodology (OPM) specifies both graphically and textually the system's static-structural and behavioral-procedural aspects through a single unifying model. This model singularity is contrasted with the multimodel approach applied by existing object oriented system analysis methods. These methods usually employ at least three distinct models for specifying various system aspects: mainly structure, function, and behavior. Object modeling technique (OMT), the main ancestor of the unified modeling language (UML), extended with timed statecharts, represents a family of such multimodal object oriented methods. Two major open questions related to model multiplicity vs. model singularity have been: 1) whether or not a single model, rather than a combination of several models, enables the synthesis of a better system specification; and 2) which of the two alternative approaches yields a specification that is easier to comprehend. The authors address these questions through a double-blind controlled experiment. To obtain conclusive results, real time systems, which exhibit a more complex dynamic behavior than nonreal time systems were selected as the focus of the experiment. We establish empirically that a single model methodology, OPM, is more effective than a multimodel one, OMT, in terms of synthesis. We pinpoint specific issues in which significant diiferences between the two methodologies were found. The specification comprehension results show that there were significant differences between the two methods in specific issues.","0098-5589;1939-3520;2326-3881","","10.1109/32.879812","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=879812","","Object oriented modeling;Real time systems;Unified modeling language;Control system synthesis;Biomedical engineering;Design methodology;Software engineering;Computer aided software engineering;Manuals;Information systems","formal specification;real-time systems;object-oriented methods;temporal logic","model multiplicity problem;real time specification methods;object-process methodology;OPM;behavioral-procedural aspects;static-structural aspects;unifying model;multimodel approach;object oriented system analysis methods;distinct models;system aspects;object modeling technique;unified modeling language;timed statecharts;multimodal object oriented methods;model multiplicity;model singularity;system specification;double-blind controlled experiment;real time systems;complex dynamic behavior;nonreal time systems;single model methodology;OMT;specification comprehension results","","40","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Reliability of systems with Markov transfer of control","K. Siegrist","Dept. of Math. & Stat., Alabama Univ., Huntsville, AL, USA","IEEE Transactions on Software Engineering","","1988","14","7","1049","1053","Software/hardware systems are considered which can be decomposed into a finite number of modules. It is assumed that control of the system is transferred among the modules according to a Markov process. Each module has an associated reliability which gives the probability that the module will operate correctly when called and will transfer control successfully when finished. The system will eventually either fail or complete its task successfully and enter a terminal state. The reliability of the system is studied in terms of the module reliabilities and the transition probabilities. Improved methods of predicting system reliability, allocating module reliability, and determining module sensitivity are developed. Special branching and sequential systems are studied in detail.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.42744","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=42744","","Control systems;State-space methods;Probability;Mathematical model;Markov processes;Software reliability;Software systems;Mathematics;Statistics","Markov processes;probability;software reliability","software reliability;branching systems;Markov process;probability;module reliabilities;transition probabilities;sequential systems","","38","","4","","","","","","IEEE","IEEE Journals & Magazines"
"Some conservative stopping rules for the operational testing of safety critical software","B. Littlewood; D. Wright","Centre for Software Reliability, City Univ., London, UK; NA","IEEE Transactions on Software Engineering","","1997","23","11","673","683","Operational testing, which aims to generate sequences of test cases with the same statistical properties as those that would be experienced in real operational use, can be used to obtain quantitative measures of the reliability of software. In the case of safety critical software it is common to demand that all known faults are removed. This means that if there is a failure during the operational testing, the offending fault must be identified and removed. Thus an operational test for safety critical software takes the form of a specified number of test cases (or a specified period of working) that must be executed failure-free. This paper addresses the problem of specifying the numbers of test cases (or time periods) required for a test, when the previous test has terminated as a result of a failure. It has been proposed that, after the obligatory fix of the offending fault, the software should be treated as if it were completely novel, and be required to pass exactly the same test as originally specified. The reasoning here claims to be conservative, in as much as no credit is given for any previous failure-free operation prior to the failure that terminated the test. We show that, in fact, this is not a conservative approach in all cases, and propose instead some new Bayesian stopping rules. We show that the degree of conservatism in stopping rules depends upon the precise way in which the reliability requirement is expressed. We define a particular form of conservatism that seems desirable on intuitive grounds, and show that the stopping rules that exhibit this conservatism are also precisely the ones that seem preferable on other grounds.","0098-5589;1939-3520;2326-3881","","10.1109/32.637384","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=637384","","Software testing;Software safety;System testing;Licenses;Bayesian methods;Protection;Regulators;Phase frequency detector;Battery powered vehicles;Software measurement","safety-critical software;program testing;statistical analysis;software fault tolerance;Bayes methods","conservative stopping rules;operational software testing;safety critical software;test case generation;statistical testing;quantitative measures;software reliability;failure-free;Bayesian stopping rules","","62","","6","","","","","","IEEE","IEEE Journals & Magazines"
"An architecture for exporting environment awareness to mobile computing applications","G. Welling; B. R. Badrinath","C&C Res. Labs., NEC-USA Inc., Princeton, NJ, USA; NA","IEEE Transactions on Software Engineering","","1998","24","5","391","400","In mobile computing, factors such as add-on hardware components and heterogeneous networks result in an environment of changing resource constraints. An application in such a constrained environment must adapt to these changes so that available resources are properly utilized. We propose an architecture for exporting awareness of the mobile computing environment to an application. In this architecture, a change in the environment is modeled as an asynchronous event that includes information related to the change. Events are typed and are organized as an extensible class hierarchy so that they can be handled at different levels of abstraction according to the requirement of each application. We also compare two approaches to structure an adaptive application. One addresses the problem of incorporating adaptiveness into legacy applications, while the other considers the design of an application with adaptiveness in mind.","0098-5589;1939-3520;2326-3881","","10.1109/32.685262","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=685262","","Computer architecture;Mobile computing;Computer applications;Application software;Resource management;Availability;Computer networks;Operating systems;Hardware;Protocols","wireless LAN;software engineering;distributed processing;portable computers;resource allocation","mobile computing applications;application environment awareness;mobile computing;add-on hardware components;heterogeneous networks;changing resource constraints;asynchronous event;extensible class hierarchy;abstraction levels;adaptive application;legacy applications;application design;event delivery framework","","16","","25","","","","","","IEEE","IEEE Journals & Magazines"
"A System to Automatically Analyze Assembled Programs","V. Hayward; A. Osorio","L.I.M.S.I.; NA","IEEE Transactions on Software Engineering","","1983","SE-9","2","210","213","An original system to perform an automatic analysis of assembled programs is presented. Executable programs are analyzed from the description of the machine on which they run and are translated into an intermediate language taking into account the particularities of the considered machine. The system was primarily designed as the first step of a project for transferring programs from one machine to another. The final goal of the project is to achieve an even utilization of computer resources for a real-time controlled robot, on the basis of partially dedicated processors. At the present time, the actual implementation provides a tool for studying the theoretical aspect of machine-level program analysis. Nevertheless, other applications can be found in program debugging and assembled program validation.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236599","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703039","Machine description;machine program analysis;program debugging;program transfer;real-time robot control;resources optimization","Assembly systems;Robot control;Debugging;Application software;Robot sensing systems;Performance analysis;Robotic assembly;Robot programming;Power system planning;Decision making","","Machine description;machine program analysis;program debugging;program transfer;real-time robot control;resources optimization","","","","10","","","","","","IEEE","IEEE Journals & Magazines"
"An environment for developing fault-tolerant software","J. M. Purtilo; P. Jalote","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; NA","IEEE Transactions on Software Engineering","","1991","17","2","153","159","An environment that supports execution of programs using both N-version programming and recovery blocks in a uniform manner is described. For N-version programming, the system offers an easy and flexible way of specifying the target machines for the separate versions. The basic unit of fault tolerance supported by this system is at the procedure or function level. Each such program unit can be packaged as its own task, and different fault tolerance techniques can subsequently be employed, even within the same application. The environment also allows versions to be written in different programming languages and executed on different machines. This enhances the independence between the different versions, making the fault tolerance techniques more effective. This environment has been developed for use on Unix-based hosts and currently runs on a network of Sun and DEC workstations.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.67596","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=67596","","Fault tolerance;Computer languages;Testing;Application software;Fault tolerant systems;Voting;Programming profession;Computer science;Packaging machines;Sun","fault tolerant computing;programming environments;software reliability;system recovery","environment;fault-tolerant software;N-version programming;recovery blocks;programming languages;Unix-based hosts;Sun;DEC workstations","","18","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Clustering algorithm for parallelizing software systems in multiprocessors environment","D. Kadamuddi; J. J. P. Tsai","Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA; NA","IEEE Transactions on Software Engineering","","2000","26","4","340","361","A variety of techniques and tools exist to parallelize software systems on different parallel architectures (SIMD, MIMD). With the advances in high-speed networks, there has been a dramatic increase in the number of client/server applications. A variety of client/server applications are deployed today, ranging from simple telnet sessions to complex electronic commerce transactions. Industry standard protocols, like Secure Socket Layer (SSL), Secure Electronic Transaction (SET), etc., are in use for ensuring privacy and integrity of data, as well as for authenticating the sender and the receiver during message passing. Consequently, a majority of applications using parallel processing techniques are becoming synchronization-centric, i.e., for every message transfer, the sender and receiver must synchronize. However, more effective techniques and tools are needed to automate the clustering of such synchronization-centric applications to extract parallelism. The authors present a new clustering algorithm to facilitate the parallelization of software systems in a multiprocessor environment. The new clustering algorithm achieves traditional clustering objectives (reduction in parallel execution time, communication cost, etc.). Additionally, our approach: 1) reduces the performance degradation caused by synchronizations, and 2) avoids deadlocks during clustering. The effectiveness of our approach is depicted with the help of simulation results.","0098-5589;1939-3520;2326-3881","","10.1109/32.844493","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=844493","","Clustering algorithms;Software algorithms;Software systems;Application software;Network servers;Parallel architectures;High-speed networks;Electronic commerce;Electronics industry;Protocols","parallel programming;multiprocessing systems;workstation clusters;client-server systems;message passing;synchronisation;concurrency control","clustering algorithm;software system parallelization;multiprocessor environment;parallel architectures;high-speed networks;client/server applications;telnet sessions;electronic commerce transactions;industry standard protocols;Secure Socket Layer;Secure Electronic Transaction;data privacy;data integrity;message passing;user authentication;parallel processing techniques;message transfer;synchronization-centric applications;traditional clustering objectives;performance degradation;deadlocks","","11","","34","","","","","","IEEE","IEEE Journals & Magazines"
"Integration of sequential scenarios","J. Desharnais; M. Frappier; R. Khedri; A. Mili","Dept. d'Inf., Laval Univ., Que., Canada; NA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","9","695","708","We give a formal relation-based definition of scenarios and we show how different scenarios can be integrated to obtain a more global view of user-system interactions. We restrict ourselves to the sequential case, meaning that we suppose that there is only one user (thus, the scenarios we wish to integrate cannot occur concurrently). Our view of scenarios is state-based, rather than event-based, like most of the other approaches, and can be grafted to the well-established specification language Z. Also, the end product of scenario integration, the specification of the functional aspects of the system, is given as a relation; this specification can be refined using independently developed methods. Our formal description is coupled with a diagram-based, transition-system like, presentation of scenarios, which is better suited to communication between clients and specifiers.","0098-5589;1939-3520;2326-3881","","10.1109/32.713325","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=713325","","Specification languages;Refining;Automata;Humans;Matrix decomposition;Mathematics","formal specification;specification languages;user interfaces;diagrams","sequential scenario integration;formal relation;user-system interactions;state-based approach;specification language;Z;requirements specification;functional aspects;formal description;diagram;relational approach","","15","","44","","","","","","IEEE","IEEE Journals & Magazines"
"Bayesian Extensions to a Basic Model of Software Reliability","W. S. Jewell","Department of Industrial Engineering and Operations Research, University of California","IEEE Transactions on Software Engineering","","1985","SE-11","12","1465","1471","A Bayesian analysis of the software reliability model of Jelinski and Moranda is given, based upon Meinhold and Singpurwalla. Important extensions are provided to the stopping rule and prior distribution of the number of defects, as well as permitting uncertainty in the failure rate. It is easy to calculate the predictive distribution of unfound errors at the end of software testing, and to see the relative effects of uncertainty in the number of errors and in the detection efficiency. The behavior of the predictive mode and mean over time are examined as possible point estimators, but are clearly inferior to calculating the full predictive distribution.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231890","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701969","Bayesian analysis;program testing;software reliability","Bayesian methods;Software reliability;Software testing;Uncertainty;Computer errors;Computer science;Stochastic processes;Computer bugs;Failure analysis;Performance analysis","","Bayesian analysis;program testing;software reliability","","35","","13","","","","","","IEEE","IEEE Journals & Magazines"
"KIDS: a semiautomatic program development system","D. R. Smith","Kestrel Inst., Palo Alto, CA, USA","IEEE Transactions on Software Engineering","","1990","16","9","1024","1043","The Kestrel Interactive Development System (KIDS), which provides automated support for the development of correct and efficient programs from formal specifications, is described. The system has components for performing algorithm design, deductive inference, program simplification, partial evaluation, finite differencing optimizations, data type refinement, compilation, and other development operations. Although their application is interactive, all of the KIDS operations are automatic except the algorithm design tactics, which require some interaction at present. Dozens of programs have been derived using the system, and it is believed that KIDS could be developed to the point where it becomes economical to use for routine programming. To illustrate the use of KIDS, the author traces the derivation of an algorithm for enumerating solutions to the k-queens problem. The initial algorithm that KIDS designed takes about 60 minutes on a SUN-4/110 to find all 92 solutions to the 8-queens problem instance. The final optimized version finds the same solutions in under one second.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58788","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58788","","Inference algorithms;Algorithm design and analysis;Formal specifications;Finite difference methods;Performance evaluation;Design optimization;Data structures;Environmental economics;Automatic programming","inference mechanisms;optimisation;software engineering","KIDS;semiautomatic program development system;Kestrel Interactive Development System;formal specifications;algorithm design;deductive inference;program simplification;partial evaluation;finite differencing optimizations;data type refinement;compilation;k-queens problem;SUN-4/110","","186","","49","","","","","","IEEE","IEEE Journals & Magazines"
"Formal specification of a look manager","K. T. Narayana; S. Dharap","Dept. of Comput. Sci., Pennsylvania State Univ., University Park, PA, USA; Dept. of Comput. Sci., Pennsylvania State Univ., University Park, PA, USA","IEEE Transactions on Software Engineering","","1990","16","9","1089","1103","A formal specification of the look manager of a dialog system is presented. The look manager deals with the presentation of visual aspects of objects and the editing of those visual aspects. A formal model for specifying the look of objects based on the notion of texturing objects is presented. The texturing model is built from the observed real-life use of overlays of slides. The specification takes as a given hypothesis an invariant relation between the logical display of objects and their layout on the physical screen. The look on the screen is characterized as an invariant ideal show relation. The formalization achieves modularity for the look manager. The specifications are written using the Z notation. The experiment is an integral part of a larger effort in the formal design of a dialog system. It shows that the state-based specification methodology Z is very well suited for description of graphical interface software. Further, the formal specification yields insight into the inherent complexity of building graphical interfaces and their associated displays.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58792","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58792","","Formal specifications;Design methodology;Geometry;Shape;Large screen displays;Buildings;User interfaces;Windows;Software design","computer graphics;formal specification;interactive systems;user interfaces","look manager;formal specification;dialog system;formal model;texturing model;modularity;Z notation;graphical interface software","","5","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Capture-Recapture Sampling for Estimating Software Error Content","J. W. Duran; J. J. Wiorkowski","Programs in Mathematical Sciences, University of Texas at Dallas; NA","IEEE Transactions on Software Engineering","","1981","SE-7","1","147","148","Mills capture-recapture sampling method allows the estimation of the number of errors in a program by randomly inserting known errors and then testing the program for both inserted and indigenous errors. This correspondence shows how correct confidence limits and maximum likelihood estimates can be obtained from the test results. Both fixed sample size testing and sequential testing are considered.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230821","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702812","Confidence limits;error count estimates;hypergeometric distribution;program testing;software quality assurance","Sampling methods;Milling machines;Maximum likelihood estimation;Sequential analysis;Computer errors;Computer aided software engineering;Software testing;Software quality;Software measurement;Software reliability","","Confidence limits;error count estimates;hypergeometric distribution;program testing;software quality assurance","","30","","9","","","","","","IEEE","IEEE Journals & Magazines"
"On the properties of extended inclusion dependences","H. Arisawa; T. Miura","Yokohama National University, Tokiwadai, Hodogayaku, Yokohama, Japan; Mitsui Engineering Co. Ltd., Tsukiji, Chuo-ku, Tokyo, Japan","IEEE Transactions on Software Engineering","","1986","SE-12","11","1098","1101","New classes of inclusion dependences are proposed as an extension of `generalization' based on the entity and association concept. Various kinds of extensions are discussed, and four classes (IND, IXG, UXG, and co-EXD) are evaluated from the viewpoint of database design. The complete inference axioms for each class and the polynomial of inference problems are presented.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313001","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313001","AIS diagram;AIS model;coexclusion dependence;database design;entity-association model;exclusion dependence;generalization;inclusion dependence","Databases;Data models;Computational modeling;Adaptation models;Software;Polynomials;Testing","database theory","properties;extended inclusion dependences;IND;IXG;UXG;co-EXD;database design;inference axioms;polynomial","","5","","","","","","","","IEEE","IEEE Journals & Magazines"
"Other comments on 'Optimization algorithms for distributed queries' by P.M.G. Apears","W. Cellary; Z. Krolikowski; T. Morzy","Inst. of Control Eng., Tech. Univ. of Poznan, Poland; Inst. of Control Eng., Tech. Univ. of Poznan, Poland; Inst. of Control Eng., Tech. Univ. of Poznan, Poland","IEEE Transactions on Software Engineering","","1988","14","4","439","441","An erroneous fact concerning the assumption of irreducibility of nonjoining attributes of the distributed query optimization algorithm called GENERAL presented in the above paper (see ibid., vol.SE-9, no.1, p.57-68, Jan. 1983) is pointed out. It is shown that it is possible to generate an efficient semijoin program with better response time than the one produced by the GENERAL algorithm. A counterexample that proves this possibility is provided.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4666","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4666","","Delay;Database systems;Scheduling algorithm;Distributed processing;Heuristic algorithms;Control engineering","computational complexity;database theory;distributed databases;optimisation","distributed databases;computational complexity;distributed queries;irreducibility;nonjoining attributes;query optimization algorithm;GENERAL;semijoin program;response time","","","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Generation of execution sequences for modular time critical systems","P. S. Pietro; A. Morzenti; S. Morasca","Dipt. di Elettronica e Inf., Politecnico di Milano, Italy; NA; NA","IEEE Transactions on Software Engineering","","2000","26","2","128","149","We define methods for generating execution sequences for time-critical systems based on their modularized formal specification. An execution sequence represents a behavior of a time critical system and can be used, before the final system is built, to validate the system specification against the user requirements (specification validation) and, after the final system is built, to verify whether the implementation satisfies the specification (functional testing). Our techniques generate execution sequences in the large, in that we focus on the connections among the abstract interfaces of the modules composing a modular specification. Execution sequences in the large are obtained by composing execution sequences in the small for the individual modules. We abstract from the specification languages used for the individual modules of the system, so our techniques can also be used when the modules composing the system are specified with different formalisms. We consider the cases in which connections give rise to either circular or noncircular dependencies among specification modules. We show that execution sequence generation can be carried out successfully under rather broad conditions and we define procedures for efficient construction of execution sequences. These procedures can be taken as the basis for the implementation of (semi)automated tools that provide substantial support to the activity of specification validation and functional testing for industrially-sized time critical systems.","0098-5589;1939-3520;2326-3881","","10.1109/32.841114","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=841114","","System testing;Software testing;Animation;Formal specifications;Sequential analysis;Computer Society;Time factors;Construction industry;Electrical equipment industry;Software prototyping","formal specification;specification languages;formal verification;program testing;sequences","execution sequence generation;modular time critical systems;modularized formal specification;user requirements;specification validation;abstract interfaces;specification languages;noncircular dependencies;circular dependencies;automated tools;functional testing","","3","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Allocating modules to processors in a distributed system","D. Fernandez-Baca","Dept. of Comput. Sci., Iowa State Univ., Ames, IA, USA","IEEE Transactions on Software Engineering","","1989","15","11","1427","1436","The author studies the complexity of the problem of allocating modules to processes in a distributed system to minimize total communication and execution costs. He shows that unless P=NP, there can be no polynomial-time epsilon -approximate algorithm for the problem, nor can there exist a local search algorithm that requires polynomial time per iteration and yields an optimum assignment. Both results hold even if the communication graph is planar and bipartite. On the positive side, it is shown that if the communication graph is a partial k-tree or an almost-tree with parameter k, the module allocation problem can be solved in polynomial time.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.41334","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=41334","","Polynomials;Tree graphs;Interference;Cost function;Dynamic programming;Processor scheduling;Dynamic scheduling;Hardware;Monitoring","computational complexity;distributed processing;graph theory","distributed system;complexity;execution costs;P=NP;polynomial-time epsilon -approximate algorithm;local search algorithm;polynomial time;iteration;optimum assignment;communication graph;planar;bipartite;partial k-tree;almost-tree;module allocation problem","","239","","28","","","","","","IEEE","IEEE Journals & Magazines"
"CSM: A Distributed Programming Language","Sun Zhongxiu; Li Xining","Department of Computer Science, Nanjing University; NA","IEEE Transactions on Software Engineering","","1987","SE-13","4","497","500","This paper presents an overview of a distributed programming language called Communicating Sequential Modules or CSM, intended to support distributed computing. Developed from Modula-2 and CSP, CSM has been implemented on the ZCZ distributed microcomputer system consisting of several LSI-11 microcomputers. Its implementation is also described.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233187","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702242","Commands;communication;distributed programming;distributed programming languages;modules;networks","Computer languages;Distributed computing;Microcomputers;Concurrent computing;Sun;Proposals;Computer science;Trademarks","","Commands;communication;distributed programming;distributed programming languages;modules;networks","","1","","10","","","","","","IEEE","IEEE Journals & Magazines"
"An empirical investigation of an object-oriented software system","M. Cartwright; M. Shepperd","Dept. of Comput., Bournemouth Univ., UK; NA","IEEE Transactions on Software Engineering","","2000","26","8","786","796","The paper describes an empirical investigation into an industrial object oriented (OO) system comprised of 133000 lines of C++. The system was a subsystem of a telecommunications product and was developed using the Shlaer-Mellor method (S. Shlaer and S.J. Mellor, 1988; 1992). From this study, we found that there was little use of OO constructs such as inheritance, and therefore polymorphism. It was also found that there was a significant difference in the defect densities between those classes that participated in inheritance structures and those that did not, with the former being approximately three times more defect-prone. We were able to construct useful prediction systems for size and number of defects based upon simple counts such as the number of states and events per class. Although these prediction systems are only likely to have local significance, there is a more general principle that software developers can consider building their own local prediction systems. Moreover, we believe this is possible, even in the absence of the suites of metrics that have been advocated by researchers into OO technology. As a consequence, measurement technology may be accessible to a wider group of potential users.","0098-5589;1939-3520;2326-3881","","10.1109/32.879814","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=879814","","Software systems;Computer industry;Testing;Lab-on-a-chip;Buildings;Computer languages;Java;Large-scale systems;Particle measurements;Software measurement","object-oriented programming;C++ language;telecommunication computing;software performance evaluation","empirical investigation;object oriented software system;industrial object oriented system;C++ code;telecommunications product;Shlaer-Mellor method;OO constructs;inheritance;polymorphism;defect densities;inheritance structures;prediction systems;local significance;software developers;local prediction systems;OO technology;measurement technology;potential users","","133","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Visual and textual consistency checking tools for graphical user interfaces","R. Mahajan; B. Shneiderman","BDM Int. Inc., McLean, VA, USA; NA","IEEE Transactions on Software Engineering","","1997","23","11","722","735","Designing user interfaces with consistent visual and textual properties is difficult. To demonstrate the harmful effects of inconsistency, we conducted an experiment with 60 subjects. Inconsistent interface terminology slowed user performance by 10 to 25 percent. Unfortunately, contemporary software tools provide only modest support for consistency control. Therefore, we developed SHERLOCK, a family of consistency analysis tools, which evaluates visual and textual properties of user interfaces. It provides graphical analysis tools such as a dialog box summary table that presents a compact overview of visual properties of all dialog boxes. SHERLOCK provides terminology analysis tools including an interface concordance, an interface spellchecker, and terminology baskets to check for inconsistent use of familiar groups of terms. Button analysis tools include a button concordance and a button layout table to detect variant capitalization, distinct typefaces, distinct colors, variant button sizes, and inconsistent button placements. We describe the design, software architecture, and the use of SHERLOCK. We tested SHERLOCK with four commercial prototypes. The outputs, analysis, and feedback from designers of the applications are presented.","0098-5589;1939-3520;2326-3881","","10.1109/32.637386","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=637386","","Terminology;User interfaces;Software tools;Color;Software design;Software architecture;Testing;Software prototyping;Prototypes;Output feedback","software tools;graphical user interfaces;user interface management systems;software metrics;human factors","textual consistency checking tools;visual consistency checking tools;graphical user interfaces;experiment;inconsistent interface terminology;user performance;software tools;SHERLOCK;graphical analysis tools;dialog box summary table;terminology analysis tools;interface spell checker;button analysis tools;interface color;software architecture;software metrics","","19","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Design of dynamically reconfigurable real-time software using port-based objects","D. B. Stewart; R. A. Volpe; P. K. Khosla","Dept. of Electr. Eng., Maryland Univ., College Park, MD, USA; NA; NA","IEEE Transactions on Software Engineering","","1997","23","12","759","776","The port-based object is a new software abstraction for designing and implementing dynamically reconfigurable real-time software. It forms the basis of a programming model that uses domain-specific elemental units to provide specific, yet flexible, guidelines to control engineers for creating and integrating software components. We use a port-based object abstraction, based on combining the notion of an object with the port-automaton algebraic model of concurrent processes. It is supported by an implementation using domain-specific communication mechanisms and templates that have been incorporated into the Chimera real-time operating system and applied to several robotic applications. This paper describes the port-based object abstraction, provides a detailed analysis of communication and synchronization based on distributed shared memory, and describes a programming paradigm based on a framework process and code templates for quickly implementing applications.","0098-5589;1939-3520;2326-3881","","10.1109/32.637390","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=637390","","Real time systems;Software design;Operating systems;Application software;Robot programming;Control systems;Robot sensing systems;Guidelines;Laboratories;Communication system software","software reusability;software portability;real-time systems;object-oriented methods;operating systems (computers);synchronisation;shared memory systems;distributed memory systems;robot programming","dynamically reconfigurable real-time software;port-based objects;software abstraction;programming model;domain-specific units;control engineers;software components;port-based object abstraction;port-automaton algebraic model;concurrent processes;Chimera;real-time operating system;robotic applications;synchronization;distributed shared memory;code templates;software reuse","","132","","43","","","","","","IEEE","IEEE Journals & Magazines"
"An approach to the reliability optimization of software with redundancy","F. Belli; P. Jedrzejowicz","Dept. of Electr. & Electron. Eng., Paderborn Univ., Germany; NA","IEEE Transactions on Software Engineering","","1991","17","3","310","312","An approach to the optimization of software reliability is proposed. The emphasis is put on the software redundancy to achieve fault tolerance, i.e. the results of the optimization process are used to determine the optimal structure of the software to be developed. Two optimization models are formulated covering, respectively, modified recovery block scheme and multiversion programming approaches. Both cases are illustrated by simple examples. The models show that it is possible to formulate and solve some software related reliability optimization problems. They further show that the concept of redundancy to achieve fault tolerance (basic for the traditional theory of reliability) can be used in the field of software reliability optimization.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.75419","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=75419","","Redundancy;Software reliability;Power system modeling;Reliability theory;Software systems;Predictive models;Software testing;Power system reliability;Application software;Mathematical model","fault tolerant computing;optimisation;redundancy;software reliability","reliability optimization;software;redundancy;software reliability;fault tolerance;modified recovery block scheme;multiversion programming","","32","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Corrigenda: software size estimation of object-oriented systems","B. Henderson-Sellers","Sch. of Inf. Technol., Swinburne Univ. of Technol., Hawthorn, Vic., Australia","IEEE Transactions on Software Engineering","","1997","23","4","260","261","In an interesting paper, L.A. Laranjeira (see ibid., vol.6, no.5, p.510-22, 1990) describes a first attempt to understand cost estimation within an object oriented environment. While the presented approach presents many interesting and useful ideas, it is, unfortunately, marred by several mathematical errors pertaining to statistics, exponential functions, and the nature of discrete vs. continuous data. These are discussed here and more appropriate correct procedures outlined.","0098-5589;1939-3520;2326-3881","","10.1109/32.588544","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=588544","","Equations;Costs;Mercury (metals);Error analysis;Mathematics;Statistics;Object oriented modeling;Mathematical model;State estimation;Convergence","software cost estimation;object-oriented programming;statistics","software size estimation;object oriented systems;cost estimation;object oriented environment;mathematical errors;statistics;exponential functions;continuous data","","4","","3","","","","","","IEEE","IEEE Journals & Magazines"
"Clarification of two phase locking in concurrent transaction processing","P. -. Leu; B. Bhargava","Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA; Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA","IEEE Transactions on Software Engineering","","1988","14","1","122","125","The authors propose a formal definition of the two-phase locking class derived from the semantic description of the two-phase locking protocol, and prove that this definition is equivalent to that given by C.H. Papadimitriou (1979). They present: (1) a precise definition of the two phase locking; (2) a clarification of the occurrence and the order of all events such as lock points, unlock points, read operations, and write operations of conflicting transactions; and (3) by relaxing some conditions in the given definition, the derivation of a new class called restricted-non-two-phase locking (RN2PL), which is a superset of the class two-phase locking (2PL) but a subset of the class D-serializable (DSR) given by Papadimitriou.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4629","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4629","","Transaction databases;Concurrency control;Access protocols","database theory;distributed databases;parallel programming;protocols","two phase locking;concurrent transaction processing;semantic description;locking protocol;lock points;unlock points;read operations;write operations;conflicting transactions;RN2PL;D-serializable","","3","","8","","","","","","IEEE","IEEE Journals & Magazines"
"An empirical comparison of software fault tolerance and fault elimination","T. J. Shimeall; N. G. Leveson","Dept. of Comput. Sci., US Naval Postgraduate Sch., Monterey, CA, USA; NA","IEEE Transactions on Software Engineering","","1991","17","2","173","182","The authors compared two major approaches to the improvement of software-software fault elimination and software fault tolerance-by examination of the fault detection (and tolerance, where applicable) of five techniques: run-time assertions, multiversion voting, functional testing augmented by structural testing, code reading by stepwise abstraction, and static data-flow analysis. The focus was on characterizing the sets of faults detected by the techniques and on characterizing the relationships between these sets of faults. Two categories of questions were investigated: (1) comparison between fault elimination and fault tolerance techniques and (2) comparisons among various testing techniques. The results provide information useful for making decisions about the allocation of project resources, show strengths and weaknesses of the techniques studies, and indicate directions for future research.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.67598","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=67598","","Fault tolerance;Fault detection;Software testing;Software systems;Runtime;Data analysis;Computer science;Fault tolerant systems;Performance evaluation;Software performance","fault tolerant computing;program testing;software reliability","software reliability;software fault tolerance;fault elimination;run-time assertions;multiversion voting;functional testing;structural testing;code reading;stepwise abstraction;static data-flow analysis;project resources","","27","","29","","","","","","IEEE","IEEE Journals & Magazines"
"The Compositional Security Checker: a tool for the verification of information flow security properties","R. Focardi; R. Gorrieri","Dipt. di Matematica Appl. e Inf, Univ. ca Foscari di Venezia, Mestre, Italy; NA","IEEE Transactions on Software Engineering","","1997","23","9","550","571","The Compositional Security Checker (CoSeC for short) is a semantic-based tool for the automatic verification of some compositional information flow properties. The specifications given as inputs to CoSeC are terms of the Security Process Algebra, a language suited for the specification of concurrent systems where actions belong to two different levels of confidentiality. The information flow security properties which can be verified by CoSeC are some of those classified in (Focardi and Gorrieri, 1994). They are derived from some classic notions, e.g., noninterference. The tool is based on the same architecture as the Concurrency Workbench, from which some modules have been imported unchanged. The usefulness of the tool is tested with the significant case-study of an access-monitor, presented in several versions in order to illustrate the relative merits of the various information flow properties that CoSeC can check. Finally, we present an application in the area of network security: we show that the theory (and the tool) can be reasonably applied also for singling out security flaws in a simple, yet paradigmatic, communication protocol.","0098-5589;1939-3520;2326-3881","","10.1109/32.629493","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=629493","","Information security;Access control;Invasive software;Access protocols;Communication system control;Control systems;Computer security;Multilevel systems;Algebra;Concurrent computing","security of data;program verification;algebraic specification;specification languages;process algebra;data privacy;computer networks;protocols;authorisation","Compositional Security Checker;verification tool;information flow security properties;CoSeC;semantic-based tool;specifications;Security Process Algebra;specification language;concurrent systems;data confidentiality;noninterference;Concurrency Workbench;access-monitor;network security;communication protocol","","94","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Subtypes for specifications: predicate subtyping in PVS","J. Rushby; S. Owre; N. Shankar","Comput. Sci. Lab., SRI Int., Menlo Park, CA, USA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","9","709","720","A specification language used in the context of an effective theorem prover can provide novel features that enhance precision and expressiveness. In particular, type checking for the language can exploit the services of the theorem prover. We describe a feature called ""predicate subtyping"" that uses this capability and illustrate its utility as mechanized in PVS.","0098-5589;1939-3520;2326-3881","","10.1109/32.713327","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=713327","","Specification languages;Computer languages;Logic;Java;Security;Set theory","formal specification;type theory;specification languages;theorem proving","formal specifications;predicate subtyping;PVS;specification language;theorem prover;type checking","","42","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Hierarchical simulation approach to accurate fault modeling for system dependability evaluation","Z. Kalbarczyk; R. K. Iyer; G. L. Ries; J. U. Patel; M. S. Lee; Y. Xiao","Center for Reliable & High Performance Comput., Illinois Univ., Urbana, IL, USA; NA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1999","25","5","619","632","This paper presents a hierarchical simulation methodology that enables accurate system evaluation under realistic faults and conditions. In this methodology, effects of low-level (i.e., transistor or circuit level) faults are propagated to higher levels (i.e., system level) using fault dictionaries. The primary fault models are obtained via simulation of the transistor-level effect of a radiation particle penetrating a device. The resulting current bursts constitute the first-level fault dictionary and are used in the circuit-level simulation to determine the impact on circuit latches and flip-flops. The latched outputs constitute the next level fault dictionary in the hierarchy and are applied in conducting fault injection simulation at the chip-level under selected workloads or application programs. Faults injected at the chip-level result in memory corruptions, which are used to form the next level fault dictionary for the system-level simulation of an application running on simulated hardware. When an application terminates, either normally or abnormally, the overall fault impact on the software behavior is quantified and analyzed. The system in this sense can be a single workstation or a network. The simulation method is demonstrated and validated in the case study of Myrinet (a commercial, high-speed network) based network system.","0098-5589;1939-3520;2326-3881","","10.1109/32.815322","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=815322","","Circuit faults;Dictionaries;Circuit simulation;Application software;Analytical models;Power system modeling;Voltage;Space technology;Digital circuits;Latches","circuit simulation;virtual machines;fault tolerant computing;flip-flops","hierarchical simulation;fault modeling;system dependability evaluation;fault dictionaries;transistor-level effect;radiation particle;circuit-level simulation;circuit latches;flip-flops;fault injection simulation;memory corruptions;Myrinet","","25","","17","","","","","","IEEE","IEEE Journals & Magazines"
"IASTED conference on reliability and quality control","B. Dhillon","Department of Mechanical Engineering, University of Ottawa, Ottawa, Ont. K1N 6N5, Canada","IEEE Transactions on Software Engineering","","1986","SE-12","11","1104","1104","THE International Association of Science and Technology for Development (IASTED) Conference on Reliability and Quality Control is to be held at the Palais des Congres in Paris, France.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313003","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313003","","Quality control;Analytical models;Predictive models;Software;Power system reliability;Software reliability","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Interinput and Interoutput Time Distribution in Classical Product-Form Networks","J. Y. Le Boudec","INSA Rennes","IEEE Transactions on Software Engineering","","1987","SE-13","6","756","759","It is shown that, in a general Jackson network of queues, the distribution of interinput and interoutput times are not equal. Equality holds in reversible classical product-form networks with or without blocking. A sufficient condition for reversibility is given.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233481","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702281","Flow-distributions;queueing systems","Intelligent networks;Software testing;Software reliability;Sufficient conditions;Software design;Art;Data analysis;Computer languages;Software measurement","","Flow-distributions;queueing systems","","","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Variations on a Method for Representing Data Items of Unlimited Length","F. Luccio","Dipartimento di Informatica, University of Pisa","IEEE Transactions on Software Engineering","","1985","SE-11","4","439","441","A recent encoding method [11 is revisited here, and two simple variations are proposed to reduce the length of the encoded data strings. The new variations also decrease encoding time, and allow numerical data to be represented in any base.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232233","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702026","Data length specification;decoding numbers;encoding numbers;storing data in memory;unlimited length data;variable length data","Encoding;Decoding;Costs;Information retrieval","","Data length specification;decoding numbers;encoding numbers;storing data in memory;unlimited length data;variable length data","","","","4","","","","","","IEEE","IEEE Journals & Magazines"
"On the design of a single-key-lock mechanism based on Newton's interpolating polynomial","Chi-Sung Laih; Lein Harn; Jau-Yien Lee","Dept. of Electr. Eng., Nat. Cheng Kung Univ., Tainan, Taiwan; Dept. of Electr. Eng., Nat. Cheng Kung Univ., Tainan, Taiwan; Dept. of Electr. Eng., Nat. Cheng Kung Univ., Tainan, Taiwan","IEEE Transactions on Software Engineering","","1989","15","9","1135","1137","A single-key-lock (SKL) mechanism used for implementing the access matrix of a computer protection system is proposed. The key selection is very flexible. The lock values are generated recursively using the Newton interpolating polynomial. A new user/file can be inserted into the system without recomputing all locks/keys. Since the computational load of the key-lock operation depends on the key positions in the access matrix, a user-hierarchy structure can be constructed for the mechanism. Thus, the smallest key value is assigned to a user who accesses the information resources more frequently than others, in order to reduce the average computation time. An example is included to illustrate this idea.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.31371","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=31371","","Polynomials;Protection;Interpolation;Information resources;National security;Councils;Computer science;Cities and towns;Telecommunication computing;Cryptography","interpolation;polynomials;security of data","recursive generation;single-key-lock mechanism;access matrix;computer protection system;key selection;lock values;Newton interpolating polynomial;user/file;computational load;key positions;user-hierarchy structure;information resources","","14","","7","","","","","","IEEE","IEEE Journals & Magazines"
"Cryptographic verification of test coverage claims","P. T. Devanbu; S. G. Stubblebine","Dept. of Comput. Sci., California Univ., Davis, CA, USA; NA","IEEE Transactions on Software Engineering","","2000","26","2","178","192","The market for software components is growing, driven on the ""demand side"" by the need for rapid deployment of highly functional products and, on the ""supply side"", by distributed object standards. As components and component vendors proliferate, there is naturally a growing concern about quality and the effectiveness of testing processes. White-box testing, particularly the use of coverage criteria, Is a widely used method for measuring the ""thoroughness"" of testing efforts. High levels of test coverage are used as indicators of good quality control procedures. Software vendors who can demonstrate high levels of test coverage have a credible claim to high quality. However, verifying such claims involves knowledge of the source code, test cases, build procedures, etc. In applications where reliability and quality are critical, it would be desirable to verify test coverage claims without forcing vendors to give up valuable technical secrets. In this paper, we explore cryptographic techniques that can be used to verify such claims. Our techniques have certain limitations, which we discuss in this paper. However, vendors who have done the hard work of developing high levels of test coverage can use these techniques (for a modest additional cost) to provide credible evidence of high coverage, while simultaneously reducing disclosure of intellectual property.","0098-5589;1939-3520;2326-3881","","10.1109/32.841116","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=841116","","Cryptography;Costs;Application software;Software testing;Software standards;Intellectual property;Particle measurements;Quality control;Software quality;Software safety","program testing;formal verification;quality control;software quality;cryptography;safety-critical software;industrial property","software components;test coverage claims;cryptographic verification;distributed object standards;white-box testing;quality control procedures;software vendors;reliability;intellectual property","","5","","39","","","","","","IEEE","IEEE Journals & Magazines"
"Correction to a rational design process: How and why to fake it","D. L. Parnas; P. C. Clements","Department of Computer Science, University of Victoria, Victoria, B.C. V8W 2Y2, Canada; Computer Science and Systems Branch, Naval Research Laboratory, Washington, DC 20375; Computer Science and Systems Branch, Naval Research Laboratory, Washington, DC 20375","IEEE Transactions on Software Engineering","","1986","SE-12","8","874","874","A careful reader, Max Stern of Teradata Corporation, has brought to our attention two errors in the above paper.<sup>1</sup>On page 253 in the second paragraph under point 4) the text reads, A purely digital or purely hybrid computer is a special case of this general module. It should read, A purely digital or purely analog computer is a special case of this general model.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312991","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312991","","","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on ""Language design for program manipulation""","W. G. Griswold","Dept. of Comput. Sci. & Eng., California Univ., San Diego, La Jolla, CA, USA","IEEE Transactions on Software Engineering","","1994","20","3","218","219","The paper by E.A.T. Merks et al. (see ibid., vol. 18, p. 19-32, 1992) ""Language design for program manipulation"" identifies design principles for a procedural or object-oriented language whose programs will be easier to manipulate. However, it neglects to relate these design principles to existing, broader, design principles, and in some instances omits good examples of languages meeting their criteria. The author relates the new principles to more fundamental design principles, and provides the needed examples of languages meeting their criteria. Together these additions can better help designers of new programming languages that are amenable to manipulation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.268924","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=268924","","Programming profession;Concrete;Computer languages;Software tools;Buildings;Computer science","object-oriented languages;programming;programming theory","language design;program manipulation;design principles;object-oriented language;new programming languages;procedural language;syntax;semantics","","1","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Foreword Technical Conferences: A Window to the Future","N. L. Marselos","NA","IEEE Transactions on Software Engineering","","1985","SE-11","9","830","831","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232541","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702101","","Application software;Manufacturing;Software maintenance;Telecommunication computing;Hardware;Computer applications;Explosives;Computer science;Statistics;Reflection","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Current trends in exception handling","D. E. Perry; A. Romanovsky; A. Tripathi","University of Texas; NA; NA","IEEE Transactions on Software Engineering","","2000","26","10","921","922","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.2000.879816","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=879816","","Computer languages;Fault tolerant systems;Spreadsheet programs;Humans;Process design;Algorithm design and analysis;Computational modeling;Large-scale systems;Maintenance","","","","9","","1","","","","","","IEEE","IEEE Journals & Magazines"
"Assignment and scheduling communicating periodic tasks in distributed real-time systems","Dar-Tzen Peng; K. G. Shin; T. F. Abdelzaher","Dept. of Electr. Eng. & Comput. Sci., Michigan Univ., Ann Arbor, MI, USA; NA; NA","IEEE Transactions on Software Engineering","","1997","23","12","745","758","Presents an optimal solution to the problem of allocating communicating periodic tasks to heterogeneous processing nodes (PNs) in a distributed real-time system. The solution is optimal in the sense of minimizing the maximum normalized task response time, called the system hazard, subject to the precedence constraints resulting from intercommunication among the tasks to be allocated. Minimization of the system hazard ensures that the solution algorithm allocates tasks so as to meet all task deadlines under an optimal schedule, whenever such an allocation exists. The task system is modeled with a task graph (TG), in which computation and communication modules, communication delays and intertask precedence constraints are clearly described. Tasks described by this TG are assigned to PNs by using a branch-and-bound (B&B) search algorithm. The algorithm traverses a search tree whose leaves correspond to potential solutions to the task allocation problem. We use a bounding method that prunes, in polynomial time, nonleaf vertices that cannot lead to an optimal solution, while ensuring that the search path leading to an optimal solution will never be pruned. For each generated leaf vertex, we compute the exact cost using the algorithm developed by Peng and Shin (1993). The lowest-cost leaf vertex (one with the least system hazard) represents an optimal task allocation. Computational experiences and examples are provided to demonstrate the concept, utility and power of the proposed approach.","0098-5589;1939-3520;2326-3881","","10.1109/32.637388","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=637388","","Real time systems;Delay;Hazards;Optimal scheduling;Costs;Processor scheduling;Computer Society;Minimization methods;Scheduling algorithm;Tree graphs","distributed processing;real-time systems;processor scheduling;resource allocation;minimisation;tree searching;delays","communicating periodic tasks;task assignment;task scheduling;distributed real-time systems;heterogeneous processing nodes;maximum normalized task response time minimization;system hazard;branch-and-bound search algorithm;task intercommunication;task deadlines;optimal schedule;task graph;computation modules;communication modules;communication delays;intertask precedence constraints;search tree traversal;bounding method;polynomial time algorithm;nonleaf vertex pruning;exact cost computation;lowest-cost leaf vertex","","73","","55","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on ""A Method for Representing Data Items of Unlimited Length in a Computer Memory""","R. N. Horspool; E. C. R. Hehner","School of Computer Science, McGill University; NA","IEEE Transactions on Software Engineering","","1982","SE-8","6","620","621","In the above paper,<sup>1</sup>Baber describes a scheme for representing data items with unlimited length. We would like to argue that this scheme is not very different from other published schemes and that his scheme is not obviously useful for the proposed application.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.236023","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702996","","Encoding;Hardware;Image storage;Computer science;Computer architecture","","","","1","","6","","","","","","IEEE","IEEE Journals & Magazines"
"Handling obstacles in goal-oriented requirements engineering","A. van Lamsweerde; E. Letier","Dept. d'Ingenierie Inf., Univ. Catholique de Louvain, Belgium; NA","IEEE Transactions on Software Engineering","","2000","26","10","978","1005","Requirements engineering is concerned with the elicitation of high-level goals to be achieved by the envisioned system, the refinement of such goals and their operationalization into specifications of services and constraints and the assignment of responsibilities for the resulting requirements to agents such as humans, devices and software. Requirements engineering processes often result in goals, requirements, and assumptions about agent behavior that are too ideal; some of them are likely not to be satisfied from time to time in the running system due to unexpected agent behavior. The lack of anticipation of exceptional behaviors results in unrealistic, unachievable, and/or incomplete requirements. As a consequence, the software developed from those requirements will not be robust enough and will inevitably result in poor performance or failures, sometimes with critical consequences on the environment. This paper presents formal techniques for reasoning about obstacles to the satisfaction of goals, requirements, and assumptions elaborated in the requirements engineering process. The techniques are based on a temporal logic formalization of goals and domain properties; they are integrated into an existing method for goal-oriented requirements elaboration with the aim of deriving more realistic, complete, and robust requirements specifications. A key principle is to handle exceptions at requirements engineering time and at the goal level, so that more freedom is left for resolving them in a satisfactory way. The various techniques proposed are illustrated and assessed in the context of a real safety-critical system.","0098-5589;1939-3520;2326-3881","","10.1109/32.879820","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=879820","","Humans;Robustness;Software systems;Software performance;Logic;Software engineering;Stress;Face;Dispatching","formal specification;systems analysis;temporal logic;safety-critical software;exception handling","goal-oriented requirements engineering;formal specification;unexpected agent behavior;software performance;software failure;temporal logic;requirements specifications;exception handling;safety-critical system","","272","","88","","","","","","IEEE","IEEE Journals & Magazines"
"A parsing methodology for the implementation of visual systems","G. Costagliola; A. De Lucia; S. Orefice; G. Tortora","Dipt. di Inf. ed Applicazioni, Salerno Univ., Italy; NA; NA; NA","IEEE Transactions on Software Engineering","","1997","23","12","777","799","The Visual Language Compiler-Compiler (VLCC) is a grammar-based graphical system for the automatic generation of visual programming environments. In this paper the theoretical and algorithmic issues of VLCC are discussed in detail. The parsing methodology we present is based on the ""positional grammar"" model. Positional grammars naturally extend context-free grammars by considering new relations in addition to string concatenation. Thanks to this, most of the results from LR parsing can be extended to the positional grammars inheriting the well known LR technique efficiency. In particular, we provide algorithms to implement a YACC-like tool embedded in the VLCC system for automatic compiler generation of visual languages described by positional grammars.","0098-5589;1939-3520;2326-3881","","10.1109/32.637392","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=637392","","Production;Visual system;Programming environments;Program processors;Multidimensional systems;Flowcharts;Performance analysis","visual programming;programming environments;compiler generators;visual languages;grammars;software tools","parsing methodology;visual systems;Visual Language Compiler-Compiler;VLCC;grammar-based graphical system;visual programming environment generation;positional grammar;context-free grammars;string concatenation;LR parsing;YACC-like tool;automatic compiler generation;visual languages;multidimensional grammars;flow graph languages","","44","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Comment on ""A pre-run-time scheduling algorithm for hard real-time systems""","T. F. Abdelzaher; K. G. Shin","Real-Time Comput. Lab., Michigan Univ., Ann Arbor, MI, USA; NA","IEEE Transactions on Software Engineering","","1997","23","9","599","600","In Shepard and Gagne (1991), a branch-and-bound implicit enumeration algorithm is described whose purpose is to generate a feasible schedule, if any, for each processor on a multiprocessing node running hard real-time processes. The optimization criterion is to minimize process lateness defined as the difference between the process completion time and deadline. We show in this correspondence that this algorithm does not always succeed in finding a feasible solution, and describe the reason why the algorithm might fail.","0098-5589;1939-3520;2326-3881","","10.1109/32.629495","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=629495","","Scheduling algorithm;Real time systems;Processor scheduling;Runtime;Application software;Timing;Stochastic processes;Computational modeling;Costs;Software maintenance","processor scheduling;parallel algorithms;real-time systems;tree searching;multiprocessing systems;minimisation","pre-run-time scheduling algorithm;hard real-time systems;branch-and-bound implicit enumeration algorithm;processor scheduling;multiprocessing node;optimization;process lateness minimization;process completion time;deadline","","4","","3","","","","","","IEEE","IEEE Journals & Magazines"
"Verifying authentication protocols in CSP","S. Schneider","Dept. of Comput. Sci., R. Holloway Univ. of London, Egham, UK","IEEE Transactions on Software Engineering","","1998","24","9","741","758","This paper presents a general approach for analysis and verification of authentication properties using the theory of Communicating Sequential Processes (CSP). The paper aims to develop a specific theory appropriate to the analysis of authentication protocols, built on top of the general CSP semantic framework. This approach aims to combine the ability to express such protocols in a natural and precise way with the ability to reason formally about the properties they exhibit. The theory is illustrated by an examination of the Needham-Schroeder (1978) public key protocol. The protocol is first examined with respect to a single run and then more generally with respect to multiple concurrent runs.","0098-5589;1939-3520;2326-3881","","10.1109/32.713329","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=713329","","Authentication;Protocols;Security;ISO standards;IEC standards;Computer Society;Public key;Digital signatures;Logic","message authentication;formal verification;protocols;communicating sequential processes;public key cryptography","authentication protocol verification;CSP;Communicating Sequential Processes;semantic framework;public key protocol;Needham-Schroeder protocol","","78","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Systematic formal verification for fault-tolerant time-triggered algorithms","J. Rushby","Comput. Sci. Lab., SRI Int., Menlo Park, CA, USA","IEEE Transactions on Software Engineering","","1999","25","5","651","660","Many critical real-time applications are implemented as time-triggered systems. We present a systematic way to derive such time-triggered implementations from algorithms specified as functional programs (in which form their correctness and fault-tolerance properties can be formally and mechanically verified with relative ease). The functional program is first transformed into an untimed synchronous system and, then, to its time-triggered implementation. The first step is specific to the algorithm concerned, but the second is generic and we prove its correctness. This proof has been formalized and mechanically checked with the PVS verification system. The approach provides a methodology that can ease the formal specification and assurance of critical fault-tolerant systems.","0098-5589;1939-3520;2326-3881","","10.1109/32.815324","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=815324","","Formal verification;Fault tolerant systems;Synchronization;Upper bound;Control systems;Automobiles;Operating systems;Fault diagnosis;Real time systems;Mechanical factors","program verification;formal specification;software fault tolerance;real-time systems;functional programming","formal verification;fault-tolerant time-triggered algorithms;real-time applications;functional programs;program correctness;untimed synchronous system;PVS verification system;formal specification","","42","","49","","","","","","IEEE","IEEE Journals & Magazines"
"Distributed computing with single read-single write variables","P. M. Lenders","Dept. of Electr. & Comput. Eng., Oregon State Univ., Corvallis, OR, USA","IEEE Transactions on Software Engineering","","1989","15","5","569","574","Single-read-single-write (SRSW) variables are presented for synchronous and asynchronous communication between processes. The operational semantics of the instruction accessing these variables is quite simple: a SRSW variable can be written if it is free, and, once written, it becomes busy. A SRSW variable can be read when busy, and, once read, it becomes free. A process attempting to read a free SRSW variable or write a busy SRSW variable is put in a wait state until the state of the variable changes. The advantages of SRSW variables are multiple. The syntax of a regular sequential language can be used without any change, other than the introduction of a new SRSW data type. Parallel programs tend to be concise and easy to prove correct. The message passing paradigm can be very easily modeled with SRSW variables.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24706","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24706","","Distributed computing;Message passing;Concurrent computing;Asynchronous communication;Command languages;Energy management;Power system management;Condition monitoring;Strontium","distributed processing","distributed computing;synchronous communication;parallel programs;single read-single write variables;asynchronous communication;operational semantics;free;busy;wait state;SRSW variables;syntax;regular sequential language;SRSW data type;message passing","","","","8","","","","","","IEEE","IEEE Journals & Magazines"
"A Model for the Basic Block Protocol of the Cambridge Ring","G. Harrus","ISEM Laboratory, Universite Paris-Sud","IEEE Transactions on Software Engineering","","1985","SE-11","1","130","136","In this paper, we study a model of the Basic Block Protocol of the Cambridge Ring. The model is close to the real behavior so that, with statistically, identical stations and light or moderate load assumptions. we obtain good approximate results of the Ring characteristics. These results are partially validated by a simulation.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231537","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701905","Cambridge Ring;distributed systems;local area network;Markov chain;modeling","Local area networks;Hardware;Monitoring;Wire;Access protocols;Costs;Digital communication;Computer vision;Delay","","Cambridge Ring;distributed systems;local area network;Markov chain;modeling","","","","7","","","","","","IEEE","IEEE Journals & Magazines"
"An embedded modeling language approach to interactive 3D and multimedia animation","C. Elliott","Microsoft Corp., Redmond, WA, USA","IEEE Transactions on Software Engineering","","1999","25","3","291","308","While interactive multimedia animation is a very compelling medium, few people are able to express themselves in it. There are too many low-level details that have to do not with the desired content-e.g., shapes, appearance and behavior-but rather how to get a computer to present the content. For instance, behavior such as motion and growth are generally gradual, continuous phenomena. Moreover, many such behaviors go on simultaneously. Computers, on the other hand, cannot directly accommodate either of these basic properties, because they do their work in discrete steps rather than continuously, and they only do one thing at a time. Graphics programmers have to spend much of their effort bridging the gap between what an animation is and how to present it on a computer. We propose that this situation can be improved by a change of language, and present Fran, synthesized by complementing an existing declarative host language, Haskell, with an embedded domain-specific vocabulary for modeled animation. As demonstrated in a collection of examples, the resulting animation descriptions are not only relatively easy to write, but also highly composable.","0098-5589;1939-3520;2326-3881","","10.1109/32.798320","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=798320","","Animation;Vocabulary;Programming profession;Computer languages;Shape;Computer graphics;Domain specific languages;Functional programming;Automatic programming;Writing","computer animation;multimedia computing;simulation languages","embedded modeling language approach;interactive 3D animation;interactive multimedia animation;motion;growth;Fran;declarative host language;Haskell;embedded domain-specific vocabulary;modeled animation","","19","","35","","","","","","IEEE","IEEE Journals & Magazines"
"Addendum to ""Proof rules for flush channels""","S. Stoller","Dept. of Comput. Sci., Cornell Univ., Ithaca, NY, USA","IEEE Transactions on Software Engineering","","1994","20","8","664","","The logic presented in a previous paper, see ibid., vol. 19, no.4, p.366-78 (1993) for processes that communicate using flush channels is inadequate for reasoning about processes that send multiple identical messages along a channel. A modification to the logic and proof system that remedies this deficiency is described herein.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.310675","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=310675","","Logic;Mathematical model;Reasoning about programs;Computer science;Costs;Tagging","distributed processing;program verification;message passing;formal logic","flush channels;multiple identical messages;channel;proof system;logic system;proof rules;communicating processes;asynchronous communication;distributed systems;program verification","","1","","1","","","","","","IEEE","IEEE Journals & Magazines"
"On ""A framework for source code search using program patterns""","P. Devanbu","Software & Syst. Res. Lab., AT&T Bell Labs., Murray Hill, NJ, USA","IEEE Transactions on Software Engineering","","1995","21","12","1009","1010","The need to query and understand source code is an important practical problem for software engineers in large development projects. A paper by Paul and Prakash (1994) proposes a workable solution to this problem. However, there are several previously reported systems that can also address this problem. The relationship of their work to the body of existing work is the subject of the paper.","0098-5589;1939-3520;2326-3881","","10.1109/32.489076","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=489076","","Data mining;Programming profession;Electronic mail;Switches;Performance analysis;Electrical capacitance tomography;Software maintenance;Maintenance engineering;Software systems;Software tools","software maintenance;compiler generators;software tools","source code search;program patterns;source code querying;software engineers;large development projects","","6","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Extending CSP to Allow Dynamic Resource Management","A. Silberschatz","Department of Computer Science, University of Texas","IEEE Transactions on Software Engineering","","1983","SE-9","4","527","531","In his paper ""Communicating Sequential Processes,"" Hoare suggested the use of the input/output construct and Dijkstra's guarded commands for handling the task of communication and synchronization in distributed systems. Hoare's proposal was intended for programming general parallel systems; as a result, little consideration was given by Hoare to the question of how his mechanisms could be utilized in the construction of reliable dynamic resource management schemes. In this paper, we examine this problem and propose several simple extensions to Hoare's constructs that will make the extended Communicating Sequential Processes concept more suitable for the handling of such management schemes.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.234961","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703086","Communication ports;distributed systems;guarded commands;input/output commands;programming languages;resource management;synchronization","Resource management;Proposals;Dynamic programming;Parallel programming;Computer languages;Intelligent networks;Microcomputers;Writing;Computer science;Software engineering","","Communication ports;distributed systems;guarded commands;input/output commands;programming languages;resource management;synchronization","","","","8","","","","","","IEEE","IEEE Journals & Magazines"
"On the relationship between partition and random testing","T. Y. Chen; Y. T. Yu","Dept. of Comput. Sci., Melbourne Univ., Parkville, Vic., Australia; Dept. of Comput. Sci., Melbourne Univ., Parkville, Vic., Australia","IEEE Transactions on Software Engineering","","1994","20","12","977","980","Weyuker and Jeng (ibid., vol. SE-17, pp. 703-711, July 1991) have investigated the conditions that affect the performance of partition testing and have compared analytically the fault-detecting ability of partition testing and random testing. This paper extends and generalizes some of their results. We give more general ways of characterizing the worst case for partition testing, along with a precise characterization of when this worst case is as good as random testing. We also find that partition testing is guaranteed to perform at least as well as random testing so long as the number of test cases selected is in proportion to the size of the subdomains.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.368132","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=368132","","Software testing;Performance evaluation;Costs;Performance analysis;Computer bugs;Computer science","program testing;random processes;software performance evaluation","partition testing;random testing;fault-detecting ability;worst case;subdomain size;test cases;software testing;performance","","66","","3","","","","","","IEEE","IEEE Journals & Magazines"
"Foreword What is AI? And What Does It Have to Do with Software Engineering?","J. Mostow","NA","IEEE Transactions on Software Engineering","","1985","SE-11","11","1253","1256","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231876","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701944","","Artificial intelligence;Software engineering;Medical expert systems;Diagnostic expert systems;Medical diagnosis;Machine intelligence;Learning systems;Programming environments;Software design;History","","","","10","","7","","","","","","IEEE","IEEE Journals & Magazines"
"Measurements of Ada overhead in OSI-style communications systems","N. R. Howes; A. C. Weaver","Dept. of Comput. Sci., George Mason Univ., Fairfax, VA, USA; NA","IEEE Transactions on Software Engineering","","1989","15","12","1507","1517","A discussion is given on whether the Ada model of concurrency is suitable for implementing the seven-layer OSI reference model. Using the communications model introduced by R.J.A. Buhr (1984), they determine the overhead introduced by Ada when the model is implemented on two single-processor machines, a VAX 11/785 and a Rational 1000. The authors then calculate a lower bound on expected message delay. A novel model using server tasks is proposed and shown to have better performance. The authors investigate performance on an eight-processor Sequent Model 821 and a 14-processor Encore Multimax 320 by implementing the Buhr model, the server task model and a third model which abandons the Ada rendezvous in favor of procedure calls. They determine the Ada overhead per message as a function of the number of processors and calculate lower bounds on expected message delay attributable to Ada overhead for all three communications models.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58763","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58763","","Concurrent computing;Proposals;Delay;Computer science;Mathematical model;Magnetic heads;Communication standards;Standards organizations;LAN interconnection;Open systems","Ada;computer networks;open systems;parallel programming;standards","OSI-style communications systems;Ada model;concurrency;seven-layer OSI reference model;communications model;single-processor machines;VAX 11/785;Rational 1000;expected message delay;novel model;server tasks;eight-processor Sequent Model 821;14-processor Encore Multimax 320;Buhr model;server task model;Ada rendezvous;procedure calls;Ada overhead per message","","8","","7","","","","","","IEEE","IEEE Journals & Magazines"
"Global Comments","T. Robers","NA","IEEE Transactions on Software Engineering","","1981","SE-7","4","370","370","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234537","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702855","","","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Designing process replication and activation: a quantitative approach","M. Litoiu; J. Rolia; G. Serazzi","IBM Canada Ltd., Toronto, Ont., Canada; NA; NA","IEEE Transactions on Software Engineering","","2000","26","12","1168","1178","Distributed application systems are composed of classes of objects with instances that interact to accomplish common goals. Such systems can have many classes of users with many types of requests. Furthermore, the relative load of these classes can shift throughout the day, causing changes to system behavior and bottlenecks. When designing and deploying such systems, it is necessary to determine a process replication and threading policy for the server processes that contain the objects, as well as process activation policies. To avoid bottlenecks, the policy must support all possible workload conditions. Licensing, implementation or resource constraints can limit the number of permitted replicas or threads of a server process. Process activation policies determine whether a server is persistent or should be created and terminated with each call. This paper describes quantitative techniques for choosing process replication or threading levels and process activation policies. Inappropriate policies can lead to unnecessary queuing delays for callers or unnecessarily high consumption of memory resources. The algorithms presented consider all workload conditions, are iterative in nature and are hybrid mathematical programming and analytic performance evaluation methods. An example is given to demonstrate the technique and describe how the results can be applied during software design and deployment.","0098-5589;1939-3520;2326-3881","","10.1109/32.888630","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=888630","","Process design;Licenses;Delay;Iterative algorithms;Iterative methods;Mathematical programming;Performance analysis;Algorithm design and analysis;Software design","multi-threading;distributed programming;queueing theory;mathematical programming;software performance evaluation;distributed object management;systems analysis","process replication design;process activation design;quantitative approach;distributed application systems;object classes;common goals;user classes;user requests;relative load;system behavior;bottlenecks;threading policy;server processes;workload conditions;licensing constraints;implementation constraints;resource constraints;queuing delays;memory resource consumption;iterative algorithms;mathematical programming;analytic performance evaluation methods;software design;software deployment;closed queuing networks;performance analysis;performance modeling;distributed design;nonlinear programming;linear programming","","21","","18","","","","","","IEEE","IEEE Journals & Magazines"
"The use of proof in diversity arguments","B. Littlewood","Centre for Software Reliability, City Univ., London, UK","IEEE Transactions on Software Engineering","","2000","26","10","1022","1023","The limits to the reliability that can be claimed for a design-diverse fault-tolerant system are mainly determined by the dependence that must be expected in the failure behaviours of the different versions: claims for independence between version failure processes are not believable. We examine a different approach, in which a simple secondary system is used as a back-up to a more complex primary. The secondary system is sufficiently simple that claims for its perfection (with respect to design faults) are possible, but there is not complete certainty about such perfection. It is shown that assessment of the reliability of the overall fault-tolerant system in this case may take advantage of claims for independence that are more plausible than those involved in design diversity.","0098-5589;1939-3520;2326-3881","","10.1109/32.879822","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=879822","","Safety;Protection;Phase frequency detector;Air traffic control;Aerospace control;Fault tolerant systems;Fault tolerance;Aircraft;Cultural differences;Battery powered vehicles","software fault tolerance","software reliability;software fault tolerance;version failure processes;design diversity","","8","","7","","","","","","IEEE","IEEE Journals & Magazines"
"A coding scheme to support systematic analysis of software comprehension","A. von Mayrhauser; S. Lang","Dept. of Comput. Sci., Colorado State Univ., Fort Collins, CO, USA; NA","IEEE Transactions on Software Engineering","","1999","25","4","526","540","Protocol analysis is a valuable tool for gaining qualitative data from observations of programmer behaviour during software maintenance. However, there are some major drawbacks with protocol analysis as it is currently practiced. Firstly, protocol analysis requires a daunting amount of effort at each stage of analysis. Secondly, the results from one protocol analysis are often difficult to compare with results from another. The paper describes a coding scheme, AFECS, designed to reduce the effort required to perform protocol analysis and to resolve the problem of noncomparable results. AFECS uses codes that consist of expandable and flexible segments. This allows AFECS to be tailored to the requirements of a variety of research studies, while maintaining a degree of consistency. Explicit segmentation also makes AFECS easy to use. An example shows AFECS' use and ability to adapt to diverse research questions.","0098-5589;1939-3520;2326-3881","","10.1109/32.799950","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=799950","","Software systems;Protocols;Software maintenance;Programming profession;Software tools;Software quality;Performance analysis;Reverse engineering;Guidelines;Documentation","reverse engineering;software maintenance;systems re-engineering;protocols","coding scheme;systematic analysis;software comprehension;protocol analysis;qualitative data;programmer behaviour;software maintenance;AFECS;flexible segments;research studies;explicit segmentation;diverse research questions","","15","","32","","","","","","IEEE","IEEE Journals & Magazines"
"Modula and a Question of Time","J. E. Allchin","Department of Computer Science, Stanford University","IEEE Transactions on Software Engineering","","1980","SE-6","4","390","391","The programming language Modula is reviewed for its ability to support the wide variety of time usages required in a process control system. It is shown that in many instances concurrent languages supporting device control and multiprogramming may need additional facilities for the support of time.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234495","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702747","Concurrent languages;modula;multiprogramming;real-time systems;systems programming;time dependencies","Process control;Delay effects;Clocks;Computer languages;Switching systems;Force control;Computer science;Hardware;Condition monitoring;Communication system control","","Concurrent languages;modula;multiprogramming;real-time systems;systems programming;time dependencies","","2","","7","","","","","","IEEE","IEEE Journals & Magazines"
"Dynamic Rematerialization: Processing Distributed Queries Using Redundant Data","E. Wong","Department of Electrical Engineering and Computer Sciences and the Electronics Research Laboratory, University of California","IEEE Transactions on Software Engineering","","1983","SE-9","3","228","232","In this paper an approach to processing distributed queries that makes explicit use of redundant data is proposed. The basic idea is to focus on the dynamics of materialization, defined as the collection of data and partial results available for processing at any given time, as query processing proceeds. In this framework the role of data redudancy in maximizing parallelism and minimizing data movement is clarified. What results is not only the discovery of new algorithms but an improved framework for their evaluation.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236731","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703049","Distributed databases;distributed query processing;query processing","Query processing;Distributed databases;Parallel processing;Partitioning algorithms;Database systems;Costs;Computer science;Military computing;Dispersion;Database machines","","Distributed databases;distributed query processing;query processing","","1","","8","","","","","","IEEE","IEEE Journals & Magazines"
"A critique of software defect prediction models","N. E. Fenton; M. Neil","Centre for Software Reliability, London, UK; NA","IEEE Transactions on Software Engineering","","1999","25","5","675","689","Many organizations want to predict the number of defects (faults) in software systems, before they are deployed, to gauge the likely delivered quality and maintenance effort. To help in this numerous software metrics and statistical models have been developed, with a correspondingly large literature. We provide a critical review of this literature and the state-of-the-art. Most of the wide range of prediction models use size and complexity metrics to predict defects. Others are based on testing data, the ""quality"" of the development process, or take a multivariate approach. The authors of the models have often made heroic contributions to a subject otherwise bereft of empirical studies. However, there are a number of serious theoretical and practical problems in many studies. The models are weak because of their inability to cope with the, as yet, unknown relationship between defects and failures. There are fundamental statistical and data quality problems that undermine model validity. More significantly many prediction models tend to model only part of the underlying problem and seriously misspecify it. To illustrate these points the Goldilock's Conjecture, that there is an optimum module size, is used to show the considerable problems inherent in current defect prediction approaches. Careful and considered analysis of past and new results shows that the conjecture lacks support and that some models are misleading. We recommend holistic models for software defect prediction, using Bayesian belief networks, as alternative approaches to the single-issue models used at present. We also argue for research into a theory of ""software decomposition"" in order to test hypotheses about defect introduction and help construct a better science of software engineering.","0098-5589;1939-3520;2326-3881","","10.1109/32.815326","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=815326","","Predictive models;Bayesian methods;Software quality;Computer Society;System testing;Process design;Software maintenance;Software systems;Software metrics;Software testing","program testing;software quality;software maintenance;software reliability;software metrics;belief networks","software defect prediction models;software quality;software maintenance;software metrics;statistical models;literature review;multivariate approach;holistic models;Bayesian belief networks;software decomposition;software engineering","","450","","","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on the Critique of Lee, Lloyd, and Shrivastava","T. F. Gannon; S. D. Shapiro","Manufacturing Data Systems, Inc.; NA","IEEE Transactions on Software Engineering","","1981","SE-7","6","610","611","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.226471","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702894","","Fault tolerant systems;Testing;System performance;Hardware;Computer errors;Computer science;Fault tolerance;Electronic switching systems;Software reliability;Digital systems","","","","","","8","","","","","","IEEE","IEEE Journals & Magazines"
"On Programming by Iterations","W. M. Turski","Institute of Informatics, Warsaw University, Warsaw, Poland; Department of Computing, Imperial College of Science and Technology, London, England.","IEEE Transactions on Software Engineering","","1984","SE-10","2","175","178","Iterative computations are considered in this paper as a general problem-solving technique. The loop invariant is derived from problem properties rather than from program properties (as is usual in programming literature). To this end, the notion of equisolution states-a special subset of space-state in which lie the iterated trajectories-is introduced.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010219","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010219","Iterations;loop invariants;problem solving;program derivation","Problem-solving;Computer aided instruction;Computer applications;Calculators;Joining processes;Computer languages;Writing;Councils;Informatics","","","","2","","2","","","","","","IEEE","IEEE Journals & Magazines"
"No special schemes are needed for solving software reliability optimization models","H. Sarper","Dept. of Eng., Southern Colorado Univ., Puebio, CO, USA","IEEE Transactions on Software Engineering","","1995","21","8","701","702","This paper resolves four previous software reliability optimization models published in this journal (Berman and Ashrafi, 1993). It is shown that a recent optimization software, LINGO, makes it unnecessary to develop special branch and bound or dynamic programming schemes to solve nonlinear reliability optimization models with binary decision variables.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.403793","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=403793","","Software reliability;Reliability engineering;Dynamic programming;Mathematical model;Design optimization;Software design;Redundancy;Operations research;Clocks;Software tools","software reliability;dynamic programming;optimisation;tree searching","software reliability optimization models;optimization software;LINGO;branch and bound;dynamic programming;nonlinear reliability optimization models;binary decision variables","","3","","6","","","","","","IEEE","IEEE Journals & Magazines"
"The case for electric design of real-time software","B. Sanden","Dept. of Inf. Syst. & Syst. Eng., George Mason Univ., Fairfax, VA, USA","IEEE Transactions on Software Engineering","","1989","15","3","360","362","G. Booch (see ibid., vol.SE-12, no.2, p.211-21, Feb. 1986) has analyzed a problem involving the software of a set of free-floating buoys. The correspondence points out that Booch's analysis fails to address one important system issue, namely the fact that the software must support two concurrent activities, and shows that an analysis according to the M.A. Jackson method will reveal this difficulty at an early design stage. On the other hand, the Jackson approach does not deal with some configuration issues, which are handled in Booch's analysis. This shows that one method is sometimes not enough to address all important, systemwide aspects of a problem. Rather than arguing about which one design method is best, the author recommends taking an electric view and using any combination of approaches that yields important results in a given situation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21764","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21764","","Computer aided software engineering;Software design;Temperature sensors;Switches;Ocean temperature;Broadcasting;Wind speed;Failure analysis;Radio transmitters;Receivers","real-time systems;software engineering;structured programming","electric design;real-time software;free-floating buoys;Jackson method;configuration issues","","11","","6","","","","","","IEEE","IEEE Journals & Magazines"
"On the Combined Problem of Compaction and Sorting","F. L. Vermeulen","Laboratorium voor Elektronika en Meettechniek, Rijksuniversiteit","IEEE Transactions on Software Engineering","","1982","SE-8","4","432","435","Under certain assumptions, a garbage collection algorithm which compacts the dynamic storage area also involves sorting a set of pointers, whose order usually has only been partially disturbed since the last garbage coliection. Using this structure and combining the sorting and compaction, we can achieve a rather important reduction of the time to perform a garbage collection.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235577","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702965","Automatic space management;compaction;dynamic storage allocation;garbage collection;sorting of partially perturbed lists","Compaction;Sorting;Data structures;Packaging machines;Viterbi algorithm;Decoding","","Automatic space management;compaction;dynamic storage allocation;garbage collection;sorting of partially perturbed lists","","","","3","","","","","","IEEE","IEEE Journals & Magazines"
"Programming with streams in a Pascal-like language","I. Nakata; M. Sassa","Inst. of Inf. Sci. & Electron., Tsukuba Univ., Ibaraki, Japan; Inst. of Inf. Sci. & Electron., Tsukuba Univ., Ibaraki, Japan","IEEE Transactions on Software Engineering","","1991","17","1","1","9","A description is given of features which were added to a conventional programming language that will manipulate streams of values. A stream is a sequence of values of a certain fixed type. The number of elements of a stream may be determined at execution time, and evaluation of each element can be postponed until its value is actually needed. Many programs can be expressed naturally and clearly as networks of processes communicating by means of streams. The network is called a composite function and consists of several component functions. Since component functions are connected solely by streams, they greatly increase the flexibility of combinations and the reusability of programs. Loop statements can be considered as iterative statements over streams. One general problem in these networks is the mechanism of terminating each process of the network. A practical solution for this problem is presented. Comparisons to other programming styles, such as coroutines, Lisp, functional programming, and dataflow languages, are described. Three modes of execution are considered for the implementation of composite functions: parallel mode, coroutine mode, and inline mode. In the inline mode, a composite function is expanded and transformed into a single function, realizing maximum run-time efficiency. Algorithms for this expansion are given.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.67573","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=67573","","Computer languages;Functional programming;Data structures;Joining processes;Runtime;Software engineering;Level control;Algorithms","programming","loop statements;streams;Pascal-like language;fixed type;composite function;component functions;combinations;reusability;iterative statements;programming styles;coroutines;Lisp;functional programming;dataflow languages;parallel mode;coroutine mode;inline mode","","2","","40","","","","","","IEEE","IEEE Journals & Magazines"
"Correction to 'On satisfying timing constraints in hard-real-time systems' by J. Xu and D.L. Parnas","J. Xu; D. L. Parnas","Dept. of Comput. Sci., York Univ., North York, Ont., Canada; NA","IEEE Transactions on Software Engineering","","1993","19","3","310","","Corrected versions are presented for tables I and III that appear in the above-titled paper (see ibid,. vol.19, no.1, p.70-84, 1993).<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.221141","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=221141","","Timing;Scheduling algorithm;Runtime;Processor scheduling;Production systems;Length measurement;Velocity measurement;Software engineering","real-time systems;scheduling","timing constraints;hard-real-time systems","","","","1","","","","","","IEEE","IEEE Journals & Magazines"
"On the complexity of generating optimal test sequences","S. C. Boyd; H. Ural","Dept. of Comput. Sci., Ottawa Univ., Ont., Canada; Dept. of Comput. Sci., Ottawa Univ., Ont., Canada","IEEE Transactions on Software Engineering","","1991","17","9","976","978","The authors investigate whether maximal overlapping of protocol test subsequences can be achieved in polynomial time. They review the concepts related to FSM (finite state machine)-based test sequence generation and then define the optimal test sequence generation (OTSG) problem. It is proved that the OTSG problem is NP-complete. Therefore an efficient solution to the problem should not be expected in the general case.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.92918","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=92918","","Testing;Protocols;Tail;Councils;Computer science;Polynomials","computational complexity;finite automata;program testing;protocols","protocol testing;communications protocols;maximal overlapping;test subsequences;polynomial time;FSM;finite state machine;optimal test sequence generation;OTSG problem;NP-complete","","20","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Performance analysis of periodic and concurrent data structure maintenance strategies for network servers","W. H. Bahaa-El-Din; F. B. Bastani; J. -. Teng","Digital Equipment Corp., Colorado Springs, CO, USA; NA; NA","IEEE Transactions on Software Engineering","","1989","15","12","1526","1536","Three strategies for designing servers and maintaining their data structures are discussed: incremental maintenance, periodic maintenance, and concurrent maintenance. The authors study periodic and concurrent maintenance strategies analytically in order to gain more insight into the behavior of servers using these strategies and determine when and how the maintenance should be performed. For periodic maintenance, it is shown that there is a value of the period which minimizes the average response time, and a formula to compute this value analytically is derived. For concurrent maintenance, a formula for its average response time and the condition under which concurrent maintenance would be preferable to periodic maintenance is derived. The authors have conducted a series of experiments to compare the performance of different maintenance strategies. For the system considered in the experiment, periodic maintenance yields the best average response time, whereas concurrent maintenance gives the least standard deviation and the smallest maximum response time.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58765","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58765","","Performance analysis;Data structures;Network servers;Local area networks;Delay;Databases;Analytical models;Resource management;Information retrieval;Computer science","data structures;network servers;parallel programming;performance evaluation","performance analysis;concurrent data structure maintenance strategies;network servers;incremental maintenance;periodic maintenance;average response time;maximum response time","","3","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Author's reply","A. Singer; H. Ledgard; J. F. Hueras","NA; NA; NA","IEEE Transactions on Software Engineering","","1981","SE-7","4","373","374","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234539","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702857","","Human factors;Books;Helium;Programming profession;Interactive systems;Biomedical engineering;Instruments;Laboratories;Psychology;Computer architecture","","","","","","1","","","","","","IEEE","IEEE Journals & Magazines"
"A Method for Processing Distributed Database Queries","W. Perrizo","Department of Computer Science, North Dakota State University, Fargo, ND 58105.","IEEE Transactions on Software Engineering","","1984","SE-10","4","466","471","The efficient processing of distributed database queries is of great importance in a distributed database management system. The algorithm-S described in this research is very efficient and low in complexity. The algorithm assumes uniformly distributed data within the attributes of a relation and data independence across attributes. Natural data reductions which occur in nonjoining attributes with iow data multiplicity are recognized. The method can give far more efficient solutions than methods which ignore these reductions. The processing strategies generated exhibit low response time as well as low total transmission time regardless of the cost objective employed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010262","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010262","Attribute independence;distributed database system;distributed query processing;equijoin operation;relational data model;semijoin","Distributed databases;Database systems;Query processing;Delay;Data models;Costs;Control systems;Concurrent computing;Distributed computing;Relational databases","","","","6","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Correction to optimal load balancing in a multiple processor system with many job classes","L. M. Ni; K. Hwang","Department of Computer Science, Michigan State University, East Lansing, MI 48824; Computer Research Institute and the Department of Electrical Engineering-Systems, University of Southern California, Los Angeles, CA 90089","IEEE Transactions on Software Engineering","","1986","SE-12","3","500","500","In the above paper, an error was made in the Load Balancing Algorithm. A more clear recursive way to present this algorithm is to modify steps S3 to S5 as follows.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312891","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312891","","Load management;Nickel;Educational institutions;Software algorithms;Computer science;Computers","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"A control-flow analysis for a calculus of concurrent objects","P. di Blasio; K. Fisher; C. Talcott","Arthur Andersen MBA, Rome, Italy; NA; NA","IEEE Transactions on Software Engineering","","2000","26","7","617","634","We present a set-based control flow analysis for an imperative, concurrent object calculus extending the Fisher-Honsell-Mitchell functional object-oriented calculus described in Fisher, Honsell and Mitchell, (1993). The analysis is shown to be sound with respect to a transition-system semantics.","0098-5589;1939-3520;2326-3881","","10.1109/32.859531","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=859531","","Calculus;Performance analysis;Runtime;Object oriented programming;Information analysis;Software safety;Prototypes;Concurrent computing;Programming profession;Data flow computing","object-oriented programming;calculus;concurrency theory;program diagnostics","control-flow analysis;calculus of concurrent objects;concurrent object calculus;concurrency;object-oriented;soundness;prototype-based","","3","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Presentation and Correction of Errors in Operating System Measurements","P. Bourret; P. Cros","ONERA-CERT/DERI; NA","IEEE Transactions on Software Engineering","","1980","SE-6","4","395","398","This cofrespondence presents two ldnds of errors which occur when data supplied by software monitors are gathered. Various ways of assessing their effects are suggested.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234497","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702749","Error in operating system measurement;performance evaluation;software measurements","Error correction;Operating systems;Software measurement;Distortion measurement;Algorithms;Time measurement;Kernel;Clocks;Delay effects;Hardware","","Error in operating system measurement;performance evaluation;software measurements","","1","","6","","","","","","IEEE","IEEE Journals & Magazines"
"Structuring communication software for quality-of-service guarantees","A. Mehra; A. Indiresan; K. G. Shin","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; NA; NA","IEEE Transactions on Software Engineering","","1997","23","10","616","634","We propose architectural mechanisms for structuring host communication software to provide QoS guarantees. We present and evaluate a QoS sensitive communication subsystem architecture for end hosts that provides real time communication support for generic network hardware. This architecture provides services for managing communication resources for guaranteed QoS (real time) connections, such as admission control, traffic enforcement, buffer management, and CPU and link scheduling. The architecture design is based on three key goals: maintenance of QoS guarantees on a per connection basis, overload protection between established connections, and fairness in delivered performance to best effort traffic. Using this architecture we implement real time channels, a paradigm for real time communication services in packet switched networks. The proposed architecture features a process per channel model that associates a channel handler with each established channel. The model employed for handler execution is one of ""cooperative"" preemption, where an executing handler yields the CPU to a waiting higher priority handler at well defined preemption points. The architecture provides several configurable policies for protocol processing and overload protection. We present extensions to the admission control procedure for real time channels to account for cooperative preemption and overlap between protocol processing and link transmission at a sending host. We evaluate the implementation to demonstrate the efficacy with which the architecture maintains QoS guarantees on outgoing traffic while adhering to the stated design goals.","0098-5589;1939-3520;2326-3881","","10.1109/32.637145","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=637145","","Software quality;Quality of service;Computer architecture;Resource management;Admission control;Communication system traffic control;Protection;Protocols;Hardware;Traffic control","computer communications software;real-time systems;software quality;packet switching;telecommunication congestion control;resource allocation","communication software structuring;quality of service guarantees;architectural mechanisms;QoS guarantees;QoS sensitive communication subsystem architecture;real time communication support;generic network hardware;communication resource management;admission control;traffic enforcement;overload protection;real time channels;real time communication services;packet switched networks;channel model;channel handler;handler execution;cooperative preemption;higher priority handler;well defined preemption points;configurable policies","","16","","81","","","","","","IEEE","IEEE Journals & Magazines"
"Guest Editorial: Reliability Issues in Distributed Systems","B. Bhargava","NA","IEEE Transactions on Software Engineering","","1982","SE-8","3","165","167","TO provide continuity of operations in automated systems, we need to develop techniques that can make them reliable. Many systems such as used in space programs, air traffic control, nuclear plant monitors, ballistic missile defense, etc., demand robust operation. In the past, research efforts have focused on the design and implementation of distributed systems used in such applications. We foresee a need of research effort in the investigation of algorithms and system structures that make error/failure detection, reconfiguration, recovery, and restart of a system feasible with the least amount of interruptions.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235103","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702932","","Transaction databases;Computer crashes;Hardware;Computer architecture;Air traffic control;Missiles;Robust control;Application software;Computer errors;Computer networks","","","","1","","3","","","","","","IEEE","IEEE Journals & Magazines"
"Using abstraction and model checking to detect safety violations in requirements specifications","C. Heitmeyer; J. Kirby; B. Labaw; M. Archer; R. Bharadwaj","Centre for High Assurance Comput. Syst., Naval Res. Lab., Washington, DC, USA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","11","927","948","Exposing inconsistencies can uncover many defects in software specifications. One approach to exposing inconsistencies analyzes two redundant specifications, one operational and the other property-based, and reports discrepancies. This paper describes a ""practical"" formal method, based on this approach and the SCR (software cost reduction) tabular notation, that can expose inconsistencies in software requirements specifications. Because users of the method do not need advanced mathematical training or theorem-proving skills, most software developers should be able to apply the method without extraordinary effort. This paper also describes an application of the method which exposed a safety violation in the contractor-produced software requirements specification of a sizable, safety-critical control system. Because the enormous state space of specifications of practical software usually renders direct analysis impractical, a common approach is to apply abstraction to the specification. To reduce the state space of the control system specification, two ""pushbutton"" abstraction methods were applied, one which automatically removes irrelevant variables and a second which replaces the large, possibly infinite, type sets of certain variables with smaller type sets. Analyzing the reduced specification with the model checker Spin uncovered a possible safety violation. Simulation demonstrated that the safety violation was not spurious but an actual defect in the original specification.","0098-5589;1939-3520;2326-3881","","10.1109/32.730543","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=730543","","Software safety;Thyristors;Costs;Control systems;Automatic control;State-space methods;Aerospace electronics;Software tools;Application software;Analytical models","program verification;formal specification;software cost estimation;safety-critical software;computerised control","pushbutton abstraction methods;model checking;safety violation detection;software requirements specifications;inconsistencies;software specification defects;redundant specifications;operational specification;property-based specification;discrepancies;software cost reduction;SCR tabular notation;safety-critical control system;contractor-produced specification;state space reduction;irrelevant variable removal;infinite type sets;reduced specification;Spin model checker;simulation;formal verification;safety analysis;consistency checking","","83","","66","","","","","","IEEE","IEEE Journals & Magazines"
"Analyzing partially-implemented real-time systems","G. S. Avrunin; J. C. Corbett; L. K. Dillon","Dept. of Math. & Stat., Massachusetts Univ., Amherst, MA, USA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","8","602","614","Most analysis methods for real-time systems assume that all the components of the system are at roughly the same stage of development and can be expressed in a single notation, such as a specification or programming language. There are, however, many situations in which developers would benefit from tools that could analyze partially-implemented systems: those for which some components are given only as high-level specifications while others are fully implemented in a programming language. In this paper, we propose a method for analyzing such partially-implemented real-time systems. We consider real-time concurrent systems for which some components are implemented in Ada and some are partially specified using regular expressions and graphical interval logic (GIL), a real-time temporal logic. We show how to construct models of the partially-implemented systems that account for such properties as run-time overhead and scheduling of processes, yet support tractable analysis of nontrivial programs. The approach can be fully automated, and we illustrate it by analyzing a small example.","0098-5589;1939-3520;2326-3881","","10.1109/32.707696","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=707696","","Real time systems;Computer languages;Timing;System testing;Computer Society;Logic programming;Processor scheduling;Concurrent computing;Sequential analysis;Error correction","real-time systems;temporal logic;program diagnostics;processor scheduling;multiprocessing programs;Ada;algebraic specification","partially-implemented real-time systems analysis;high-level specifications;programming language;real-time concurrent systems;Ada-implemented components;partially specified components;regular expressions;graphical interval logic;GIL;real-time temporal logic;run-time overhead;process scheduling;static analysis;hybrid systems","","1","","26","","","","","","IEEE","IEEE Journals & Magazines"
"BDL: a specialized language for per-object reactive control","F. Bertrand; M. Augeraud","Lab. d'Inf. et d'Imagerie Ind., La Rochelle Univ., France; NA","IEEE Transactions on Software Engineering","","1999","25","3","347","362","The problem of describing the concurrent behavior of objects in object oriented languages is addressed. The approach taken is to let methods be the behavior units whose synchronization is controlled separate from their specification. Our proposal is a domain-specific language called BDL for expressing constraints on this control and actually implementing its enforcement. We propose a model where each object includes a so-called ""execution controller"", programmed in BDL. This separates cleanly the concepts of what the methods do, the object processes, from the circumstances in which they are allowed to do it, the control. The object controller ensures that scheduling constraints between the object's methods are met. Aggregate objects can be controlled in terms of their components. This language has a convenient formal base. Thus, using BDL expressions, behavioral properties of objects or groups of interesting objects can be verified. Our approach allows, for example, deadlock detection or verification of safety properties, while maintaining a reasonable code size for the running controller. A compiler from BDL has been implemented, automatically generating controller code in an Esterel program, i.e., in a reactive programming language. From this code, the Esterel compiler, in turn, generates an automaton on which verifications are done. Then this automaton is translated into a C code to be executed. This multistage process typifies the method for successful use of a domain-specific language. This also allows high level concurrent programming.","0098-5589;1939-3520;2326-3881","","10.1109/32.798324","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=798324","","Domain specific languages;Automata;Proposals;Object oriented modeling;Aggregates;System recovery;Safety;Automatic control;Size control;Program processors","parallel languages;object-oriented languages;formal specification;program compilers;automata theory;synchronisation;scheduling","BDL;specialized language;per-object reactive control;concurrent behavior;object oriented languages;behavior units;domain-specific language;execution controller;object processes;object controller;scheduling constraints;aggregate objects;formal base;BDL expressions;behavioral properties;deadlock detection;safety properties;Esterel program;reactive programming language;Esterel compiler;automaton;C code;multistage process;high level concurrent programming","","3","","47","","","","","","IEEE","IEEE Journals & Magazines"
"Representation inheritance: a safe form of ""White box"" code inheritance","S. H. Edwards","Dept. of Comput. Sci., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA","IEEE Transactions on Software Engineering","","1997","23","2","83","92","There are two approaches to using code inheritance for defining new component implementations in terms of existing implementations. Black box code inheritance allows subclasses to reuse superclass implementations as-is, without direct access to their internals. Alternatively, white box code inheritance allows subclasses to have direct access to superclass implementation details, which may be necessary for the efficiency of some subclass operations and to prevent unnecessary duplication of code. Unfortunately, white box code inheritance violates the protection that encapsulation affords superclasses, opening up the possibility of a subclass interfering with the correct operation of its superclass methods. Representation inheritance is proposed as a restricted form of white box code inheritance where subclasses have direct access to superclass implementation details, but are required to respect the representation invariant(s) and abstraction relation(s) of their ancestor(s). This preserves the protection that encapsulation provides, while allowing the freedom of access that component implementers sometimes desire.","0098-5589;1939-3520;2326-3881","","10.1109/32.585498","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=585498","","Protection;Encapsulation;Computer Society;Object oriented modeling;Functional programming;Object oriented programming;Safety;Programming profession;Computer science","inheritance;encapsulation;object-oriented programming;software reusability","representation inheritance;black box code inheritance;superclass implementations;white box code inheritance;encapsulation;software reuse;abstraction relations;abstraction function;behavioral subtypes;model-based specification;object-oriented programming;representation invariance","","4","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Number of Faults per Line of Code","M. Lipow","TRW Electronics and Defense Sector","IEEE Transactions on Software Engineering","","1982","SE-8","4","437","439","In this note, the number of faults or ""bugs"" per line of code is estimated based upon Halstead's software science relationships. This number is shown to be an increasing function of the number of lines of code in a program, a result in agreement with intuition and some current theories of complexity. The form of this function is investigated and an easy-to-use approximation is developed. An application to a moderately large software project is shown in which the predicted number of faults for program modules of various sizes agrees fairly well with the actual numbers of faults discovered.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235579","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702967","Fault prediction;fault rate;program complexity;software science","Computer bugs;Application software;Programming profession;Vocabulary;Arithmetic;Logic arrays;Programmable logic arrays;Upper bound","","Fault prediction;fault rate;program complexity;software science","","71","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on an optimal set of indices for a relational database","B. -. Falkowski","Datex Al, Gesellschaft fuer Angewandte Kunstliche Intelligenz mbH, Munchen, Germany","IEEE Transactions on Software Engineering","","1992","18","2","168","171","M. Y. L. Ip et al., (see ibid., vol.SE-9, p.135-43, 1983) solved the index selection problem for a relational database by reducing it to a classical knapsack problem and then applying an approximation algorithm. It is shown that this reduction process does not work in general by providing a counterexample, and its practical significance is discussed. It turns out that the main idea of Ip et al. need not be discarded. In particular, the approximation algorithm used can be adapted fairly easily to take care of the problems which were raised by the counterexample. In spite of its simplicity, this modification can lead to a reduced number of indices, which is rather attractive from a practical point of view.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.121758","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=121758","","Relational databases;Costs;Approximation algorithms;Artificial intelligence;Indexes;NP-complete problem;Organizing","approximation theory;database theory;optimisation;relational databases","index selection problem;relational database;classical knapsack problem;approximation algorithm;reduction process","","4","","6","","","","","","IEEE","IEEE Journals & Magazines"
"The model checker SPIN","G. J. Holzmann","Comput. Sci. Res. Center, AT&T Bell Labs., Murray Hill, NJ, USA","IEEE Transactions on Software Engineering","","1997","23","5","279","295","SPIN is an efficient verification system for models of distributed software systems. It has been used to detect design errors in applications ranging from high-level descriptions of distributed algorithms to detailed code for controlling telephone exchanges. The paper gives an overview of the design and structure of the verifier, reviews its theoretical foundation, and gives an overview of significant practical applications.","0098-5589;1939-3520;2326-3881","","10.1109/32.588521","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=588521","","Software systems;Application software;Distributed algorithms;Control system synthesis;Algorithm design and analysis;Error correction codes;Telephony;Design methodology;Concurrent computing;Message passing","formal verification;formal specification;distributed processing","SPIN model checker;efficient verification system;distributed software system models;design error detection;high-level distributed algorithm descriptions;detailed code;telephone exchange control;verifier design;verifier structure","","1557","","82","","","","","","IEEE","IEEE Journals & Magazines"
"Steady-State Probabilities for a Queue with a General Service Distribution and State-Dependent Arrivals","R. A. Marie; J. M. Pellaumail","IRISA-INRIA, Campus Universitaire de Beaulieu; NA","IEEE Transactions on Software Engineering","","1983","SE-9","1","109","113","We consider a queueing system with a general service distribution having a possibility of feedback. The customers belong to the same class, and the queueing discipline is first-in, first-out. There is only one server in the station. The facility is rendered Markovian by means of fictitious stages. The input flow depends on the state of the station. It is shown that the equilibrium probabilities can be simply expressed by means of a matrix product. Two particular cases are studied.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236301","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703018","General server;network;performance evaluation;queueing models;steady-state distribution","Steady-state;State feedback;Network servers;Computer science;Tin","","General server;network;performance evaluation;queueing models;steady-state distribution","","","","3","","","","","","IEEE","IEEE Journals & Magazines"
"Reference Model for Smooth Growth of Software Systems(003)5402022","","","IEEE Transactions on Software Engineering","","1996","22","8","","","","0098-5589;1939-3520;2326-3881","","10.1109/32.536959","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=536959","","Software systems;Size measurement;Software measurement;Reflection;Informatics;Electrical resistance measurement;Electric resistance","","","","1","","1","","","","","","IEEE","IEEE Journals & Magazines"
"Environmental Testing Techniques for Software Certification","M. S. Karasik","OASAS Limited","IEEE Transactions on Software Engineering","","1985","SE-11","9","934","938","The problems of developing software requirements and quality assurance techniques have basically dealt with an environment where a single organization acts as the designer, developer, and user of the software product. Since the mid-1970' s, however, there has been a great increase in the use of ""packaged"" software products designed and developed by one organization for use in a variety of other organizations. The great profusion of products has resulted in many products being peddled for generic applications (accounting, manufacturing, etc.) which are of questionable quality and/or ""fit"" to a given organization's environment. This paper describes some techniques that are being used to certify software produced by third parties and how to determine if the ""fit"" is there. Current quality assurance techniques deal with the ""correctness"" of a program as compared to its specifications [2], [4], [7], [8], [12]. The real issue for a purchaser of software is whether the software is ""correct"" for its environment.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232551","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702111","Environmental testing;logical pathway;quality assurance;system testing;test generator;test plans","Software testing;Certification;Software quality;Quality assurance;Software packages;Packaging;Software design;Product design;Application software;Manufacturing","","Environmental testing;logical pathway;quality assurance;system testing;test generator;test plans","","","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Extending statecharts with temporal logic","A. Sowmya; S. Ramesh","Sch. of Comput. Sci. & Eng., New South Wales Univ., Sydney, NSW, Australia; NA","IEEE Transactions on Software Engineering","","1998","24","3","216","231","The task of designing large real-time reactive systems, which interact continuously with their environment and exhibit concurrency properties, is a challenging one. The authors explore the utility of a combination of behavior and function specification languages in specifying such systems and verifying their properties. An existing specification language, statecharts, is used to specify the behavior of real-time reactive systems, while a new logic-based language called FNLOG (based on first-order predicate calculus and temporal logic) is designed to express the system functions over real time. Two types of system properties, intrinsic and structural, are proposed. It is shown that both types of system properties are expressible in FNLOG and may be verified by logical deduction, and also hold for the corresponding behavior specification.","0098-5589;1939-3520;2326-3881","","10.1109/32.667880","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=667880","","Real time systems;Concurrent computing;Specification languages;Formal specifications;Embedded computing;Embedded system;Calculus;Logic design;Robots;Hardware","specification languages;formal specification;real-time systems;logic programming languages","temporal logic;statecharts extension;large real-time reactive system design;concurrency properties;continuous environmental interaction;function specification languages;behavior specification languages;property verification;specification language;logic-based language;FNLOG;first-order predicate calculus;system functions;intrinsic system properties;structural system properties;logical deduction","","16","","64","","","","","","IEEE","IEEE Journals & Magazines"
"A theorem prover for verifying iterative programs over integers","D. Sarkar; S. C. De Sarkar","Dept. of Comput. Sci. & Eng., Indian Inst. of Technol., Kharagpur, India; Dept. of Comput. Sci. & Eng., Indian Inst. of Technol., Kharagpur, India","IEEE Transactions on Software Engineering","","1989","15","12","1550","1566","An implementation of a rule-based theorem prover for verifying iterative programs over integers is presented. The authors emphasize the overall proof construction strategy of the prover which has been able to construct the correctness proofs of all iterative programs taken from the literature. Two performance measures for the prover are proposed, and its proof construction for an array-sorting program is evaluated using these measures.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58767","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58767","","Programmable logic arrays;Computer science;Sorting;Humans","expert systems;iterative methods;program verification;theorem proving","rule-based theorem prover;iterative programs;overall proof construction strategy;correctness proofs;performance measures;array-sorting program","","9","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Investigating reading techniques for object-oriented framework learning","F. Shull; F. Lanubile; V. R. Basili","Fraunhofer Center, Maryland Univ., College Park, MD, USA; NA; NA","IEEE Transactions on Software Engineering","","2000","26","11","1101","1118","The empirical study described in the paper addresses software reading for construction: how application developers obtain an understanding of a software artifact for use in new system development. The study focuses on the processes that developers would engage in when learning and using object oriented frameworks. We analyzed 15 student software development projects using both qualitative and quantitative methods to gain insight into what processes occurred during framework usage. The contribution of the study is not to test predefined hypotheses but to generate well-supported hypotheses for further investigation. The main hypotheses produced are that example based techniques are well suited to use by beginning learners, while hierarchy based techniques are not, because of a larger learning curve. Other more specific hypotheses are proposed and discussed.","0098-5589;1939-3520;2326-3881","","10.1109/32.881720","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=881720","","Application software;Programming;Software engineering;Software libraries;Computer Society;Testing;Technical activities;User interfaces;Buildings;Skeleton","bibliographies;computer science education;teaching;object-oriented programming;reverse engineering","reading techniques;object oriented framework learning;software reading;application developers;software artifact;system development;object oriented frameworks;student software development projects;quantitative methods;framework usage;predefined hypotheses;example based techniques;beginning learners;hierarchy based techniques;learning curve","","33","","52","","","","","","IEEE","IEEE Journals & Magazines"
"Conceptual modeling of coincident failures in multiversion software","B. Littlewood; D. R. Miller","Centre for Software Reliability, City Univ., London, UK; NA","IEEE Transactions on Software Engineering","","1989","15","12","1596","1614","Work by D.E. Eckhardt and L.D. Lee (1985), shows that independently developed program versions fail dependently. The authors show that there is a precise duality between input choice and program choice in this model and consider a generalization in which different versions can be developed using diverse methodologies. The use of diverse methodologies is shown to decrease the probability of the simultaneous failure of several versions. Indeed, it is theoretically possible to obtain versions which exhibit better than independent failure behavior. The authors formalize the notion of methodological diversity by considering the sequence of decision outcomes that constitute a methodology. They show that diversity of decision implies likely diversity of behavior for the different versions developed under such forced diversity. For certain one-out-of-n systems the authors obtain an optimal method for allocating diversity between versions. For two-out-of-three systems there seem to be no simple optimality results which do not depend on constraints which cannot be verified in practice.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58771","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58771","","Fault tolerance;Reliability engineering;Operations research;Battery powered vehicles;Diversity methods;Stochastic processes;Councils;Glands;Software reliability;Cities and towns","decision theory;fault tolerant computing;probability;software reliability","conceptual modeling;coincident failures;multiversion software;independently developed program versions;precise duality;input choice;program choice;diverse methodologies;simultaneous failure;independent failure behavior;methodological diversity;decision outcomes;optimal method;constraints","","128","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Assessing software review meetings: results of a comparative analysis of two experimental studies","A. A. Porter; P. M. Johnson","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; NA","IEEE Transactions on Software Engineering","","1997","23","3","129","145","Software review is a fundamental tool for software quality assurance. Nevertheless, there are significant controversies as to the most efficient and effective review method. One of the most important questions currently being debated is the utility of meetings. Although almost all industrial review methods are centered around the inspection meeting, recent findings call their value into question. In prior research the authors separately and independently conducted controlled experimental studies to explore this issue. The paper presents new research to understand the broader implications of these two studies. To do this, they designed and carried out a process of ""reconciliation"" in which they established a common framework for the comparison of the two experimental studies, reanalyzed the experimental data with respect to this common framework, and compared the results. Through this process they found many striking similarities between the results of the two studies, strengthening their individual conclusions. It also revealed interesting differences between the two experiments, suggesting important avenues for future research.","0098-5589;1939-3520;2326-3881","","10.1109/32.585501","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=585501","","Software reviews;Costs;Inspection;Software quality;Computer Society;Programming;Job shop scheduling;Collaborative work;Aggregates","software quality;software development management;inspection","software review meeting assessment;software quality assurance;inspection meeting;reconciliation","","56","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Correction to 'The case for electric design of real-time software'","B. Sanden","Dept. of Inf. Syst. & Syst. Eng. George Mason Univ., Fairfax, VA, USA","IEEE Transactions on Software Engineering","","1989","15","7","926","","The title of this paper (see ibid., vol.15, p.360-2 (1989)) was printed incorrectly. It should have read: the case for the eclectic design of real-time software.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.29491","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=29491","","Computer aided software engineering;Software design","real-time systems;software engineering","real-time software;eclectic design","","","","1","","","","","","IEEE","IEEE Journals & Magazines"
"Respectful type converters","J. M. Wing; J. Ockerbloom","Dept. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA; NA","IEEE Transactions on Software Engineering","","2000","26","7","579","593","In converting an object of one type to another, we expect some of the original object's behavior to remain the same and some to change. How can we state the relationship between the original object and converted object to characterize what information is preserved and what is lost after the conversion takes place? We answer this question by introducing the new relation, respects, and say that a type converter function C:A/spl rarr/B respects a type T. We formally define respects in terms of the Liskov and Wing behavioral notion of subtyping; types A and B are subtypes of T. We explain in detail the applicability of respectful type converters in the context of the Typed Object Model (TOM) Conversion Service, built at Carnegie Mellon and used on a daily basis throughout the world. We also briefly discuss how our respects relation addresses a similar question in two other contexts: type evolution and interoperability.","0098-5589;1939-3520;2326-3881","","10.1109/32.859529","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=859529","","Information retrieval;Image converters;Displays;HTML;Context-aware services;Object oriented modeling;Context modeling;Internet;Web sites","type theory;object-oriented programming","type converters;respects;type converter function;subtyping;respectful type converters;Typed Object Model;type evolution;interoperability","","6","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Correction to 'Allocating programs containing branches and loops within a multiple processor system'","D. Towsley","Dept. of Comput. & Inf. Sci., Massachusetts Univ., Amherst, MA, USA","IEEE Transactions on Software Engineering","","1990","16","4","472","","A number of typographical errors in the above-mentioned paper (see ibid., vol.12, no.10, p.1018-24 (1986)) are corrected.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.54299","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=54299","","Computer errors;Costs;Equations;Councils;Formal specifications","operating systems (computers);scheduling","branches;loops;multiple processor system;typographical errors","","6","","1","","","","","","IEEE","IEEE Journals & Magazines"
"Predicting fault incidence using software change history","T. L. Graves; A. F. Karr; J. S. Marron; H. Siy","Los Alamos Nat. Lab., NM, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","2000","26","7","653","661","This paper is an attempt to understand the processes by which software ages. We define code to be aged or decayed if its structure makes it unnecessarily difficult to understand or change and we measure the extent of decay by counting the number of faults in code in a period of time. Using change management data from a very large, long-lived software system, we explore the extent to which measurements from the change history are successful in predicting the distribution over modules of these incidences of faults. In general, process measures based on the change history are more useful in predicting fault rates than product metrics of the code: For instance, the number of times code has been changed is a better indication of how many faults it will contain than is its length. We also compare the fault rates of code of various ages, finding that if a module is, on the average, a year older than an otherwise similar module, the older module will have roughly a third fewer faults. Our most successful model measures the fault potential of a module as the sum of contributions from all of the times the module has been changed, with large, recent changes receiving the most weight.","0098-5589;1939-3520;2326-3881","","10.1109/32.859533","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=859533","","History;Predictive models;Software systems;Aging;Time measurement;Software measurement;Length measurement;Software development management;Statistical analysis;Degradation","software maintenance;software metrics;software fault tolerance;management of change","fault incidence;software change history;change management data;change history;fault potential;code decay;metrics;statistical analysis","","319","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Correction to 'A practical view of software measurement and implementation experiences within Motorola'","M. K. Daskalantonakis","Motorola, Arlington Heights, IL, USA","IEEE Transactions on Software Engineering","","1993","19","2","199","200","A corrected reference list for the above-titled paper (see ibid., vol.18, no.11, p.998-1010, (1992)) is presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.214837","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=214837","","Software measurement;Software engineering;Application software;Software metrics;Conferences;Extraterrestrial measurements;Software prototyping;Quality control;Software quality","software metrics","software measurement;implementation;Motorola","","","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Clock trees: logical clocks for programs with nested parallelism","K. Audenaert","Univ. of Gent-ELIS, Belgium","IEEE Transactions on Software Engineering","","1997","23","10","646","658","A vector clock is a valuable tool for maintaining run time concurrency information in parallel programs. A novel method is presented for modifying vector clocks to make them suitable for programs with nested fork join parallelism (having a variable number of tasks). The resulting kind of clock is called a clock tree, due to its tree structure. The clock tree method compares favorably with other timestamping methods for variable parallelism: task identifier reuse and task recycling. The worst case space requirements of clock trees equals the best case for the latter two methods, and the average size of a clock tree is much smaller than the size of a vector with task recycling. Furthermore, the algorithm for maintaining clock trees does not require a shared data structure and thus avoids the serialization bottleneck that task recycling suffers from.","0098-5589;1939-3520;2326-3881","","10.1109/32.637147","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=637147","","Clocks;Recycling;Timing;Fault detection;Tree data structures;Runtime;Concurrent computing;Parallel processing;Labeling;Parallel programming","parallel programming;computational complexity;clocks;trees (mathematics);tree data structures","logical clocks;nested parallelism;vector clock;run time concurrency information;parallel programs;nested fork join parallelism;timestamping methods;tree structure;clock tree method;variable parallelism;task identifier reuse;task recycling;worst case space requirements;serialization bottleneck","","14","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Inconsistency management for multiple-view software development environments","J. Grundy; J. Hosking; W. B. Mugridge","Dept. of Comput. Sci., Waikato Univ., Hamilton, New Zealand; NA; NA","IEEE Transactions on Software Engineering","","1998","24","11","960","981","Developers need tool support to help manage the wide range of inconsistencies that occur during software development. Such tools need to provide developers with ways to define, detect, record, present, interact with, monitor and resolve complex inconsistencies between different views of software artifacts, different developers and different phases of software development. This paper describes our experience with building complex multiple-view software development tools that support diverse inconsistency management facilities. We describe software architectures that we have developed and user interface techniques that are used in our multiple-view development tools, and we discuss the effectiveness of our approaches compared to other architectural and HCI techniques.","0098-5589;1939-3520;2326-3881","","10.1109/32.730545","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=730545","","Programming;Software development management;Software systems;Documentation;Environmental management;Collaborative software;Computer Society;Phase detection;Computerized monitoring;Software tools","programming environments;software tools;software architecture;groupware;configuration management","inconsistency management facilities;multiple-view software development environments;software tool support;software artifacts;software developers;software development phases;software development tools;software architectures;integrated software development environments;user interface techniques;HCI techniques;collaborative software development","","57","","74","","","","","","IEEE","IEEE Journals & Magazines"
"A domain-specific language for regular sets of strings and trees","N. Klarlund; M. I. Schwartzbach","AT&T Labs.-Res., Denmark; NA","IEEE Transactions on Software Engineering","","1999","25","3","378","386","We propose a novel high level programming notation, called FIDO, that we have designed to concisely express regular sets of strings or trees. In particular, it can be viewed as a domain-specific language for the expression of finite state automata on large alphabets (of sometimes astronomical size). FIDO is based on a combination of mathematical logic and programming language concepts. This combination shares no similarities with usual logic programming languages. FIDO compiles into finite state string or tree automata, so there is no concept of run-time. It has already been applied to a variety of problems of considerable complexity and practical interest. We motivate the need for a language like FIDO, and discuss our design and its implementation. Also, we briefly discuss design criteria for domain-specific languages that we have learned from the work with FIDO. We show how recursive data types, unification, implicit coercions, and subtyping can be merged with a variation of predicate logic, called the Monadic Second-order Logic (M2L) on trees. FIDO is translated first into pure M2L via suitable encodings, and finally into finite state automata through the MONA tool.","0098-5589;1939-3520;2326-3881","","10.1109/32.798326","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=798326","","Domain specific languages;Logic programming;Encoding;Application software;Computer languages;Runtime;Learning automata;Software systems;Embedded computing;Tree graphs","high level languages;set theory;trees (mathematics);string matching;finite state machines;data structures;type theory;formal logic","domain-specific language;regular sets;trees;high level programming notation;FIDO;finite state automata;large alphabets;mathematical logic;programming language concepts;logic programming languages;finite state string;tree automata;design criteria;recursive data types;unification;implicit coercions;subtyping;predicate logic;Monadic Second-order Logic;pure M2L;MONA tool","","3","","12","","","","","","IEEE","IEEE Journals & Magazines"
"An extended banker's algorithm for deadlock avoidance","S. -. Lang","Sch. of Comput. Sci., Univ. of Central Florida, Orlando, FL, USA","IEEE Transactions on Software Engineering","","1999","25","3","428","432","We describe a natural extension of the banker's algorithm (D.W. Dijkstra, 1968) for deadlock avoidance in operating systems. Representing the control flow of each process as a rooted tree of nodes corresponding to resource requests and releases, we propose a quadratic-time algorithm which decomposes each flow graph into a nested family of regions, such that all allocated resources are released before the control leaves a region. Also, information on the maximum resource claims for each of the regions can be extracted prior to process execution. By inserting operating system calls when entering a new region for each process at runtime, and applying the original banker's algorithm for deadlock avoidance, this method has the potential to achieve better resource utilization because information on the ""localized approximate maximum claims"" is used for testing system safety.","0098-5589;1939-3520;2326-3881","","10.1109/32.798330","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=798330","","System recovery;Resource management;Operating systems;Safety;System testing;Software algorithms;Tree graphs;Flow graphs;Data mining;Runtime","concurrency control;flow graphs;resource allocation;computational complexity","extended banker algorithm;deadlock avoidance;operating systems;control flow;rooted tree;resource requests;quadratic-time algorithm;flow graph;nested family of regions;allocated resources;maximum resource claims;process execution;operating system calls;resource utilization;localized approximate maximum claims;system safety testing","","11","","7","","","","","","IEEE","IEEE Journals & Magazines"
"Statistical Estimation of Software Reliability","S. M. Ross","Department of Industrial Engineering and OPerations Research, University of California","IEEE Transactions on Software Engineering","","1985","SE-11","5","479","483","When a new computer software package is developed, a testing procedure is often put into effect to eliminate the faults, or bugs, in the package. One common procedure is to try the package on a set of well-known problems to try to see if any errors result. This goes for some fixed time with all detected errors being noted. Then the testing stops and the package is carefully checked to determine the specific bugs that were responsible for the observed errors, and the package is then altered to remove these bugs. A problem of great importance is the estimation of the error rate of this revised software package.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232487","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702038","Estimation;reliability;Poisson process","Software reliability;Packaging;Computer bugs;Software packages;Error analysis;Debugging;Software testing;Computer errors;Estimation error;Industrial engineering","","Estimation;reliability;Poisson process","","23","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Compositional programming abstractions for mobile computing","P. J. McCann; G. -. Roman","Lucent Technol., Naperville, IL, USA; NA","IEEE Transactions on Software Engineering","","1998","24","2","97","110","Recent advances in wireless networking technology and the increasing demand for ubiquitous, mobile connectivity demonstrate the importance of providing reliable systems for managing the reconfiguration and disconnection of components. The design of such systems requires tools and techniques appropriate to the task. Many formal models of computation, including UNITY, are not adequate for expressing reconfiguration and disconnection and are, therefore, inappropriate vehicles for investigating the impact of mobility on the construction of modular and composable systems. Algebraic formalisms such as the /spl pi/-calculus have been proposed for modeling mobility. This paper addresses the question of whether UNITY, a state-based formalism with a foundation in temporal logic, can be extended to address concurrent, mobile systems. In the process, we examine some new abstractions for communication among mobile components that express reconfiguration and disconnection and which can be composed in a modular fashion.","0098-5589;1939-3520;2326-3881","","10.1109/32.666824","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=666824","","Mobile computing;Computer networks;Pervasive computing;Computer Society;Computational modeling;Computer network reliability;Computer network management;Technology management;Vehicles;Modular construction","wireless LAN;process algebra;temporal logic;reconfigurable architectures;programming theory;algebraic specification","compositional programming abstractions;mobile computing;wireless networking technology;mobile connectivity;reliable systems;component reconfiguration;component disconnection;formal models;computation;UNITY;modular systems;composable systems;algebraic formalisms;/spl pi/-calculus;state-based formalism;temporal logic;concurrent mobile systems;mobile component communications;weak consistency;shared variables;synchronization;transient interactions","","35","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Correction to ""Information Flow Certification Using an Intermediate Code Program Representation""","G. H. MacEwen","Department of Computing and Information Science, Queen's University, Kingston, Ont., Canada and Andyne computing Ltd.","IEEE Transactions on Software Engineering","","1982","SE-8","4","446","446","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235729","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702969","","Certification;Algorithm design and analysis;Information science","","","","","","1","","","","","","IEEE","IEEE Journals & Magazines"
"Dynamic verification of C++ generic algorithms","Changqing Wang; D. R. Musser","Dept. of Software Syst., GTE Labs. Inc., Waltham, MA, USA; NA","IEEE Transactions on Software Engineering","","1997","23","5","314","323","Dynamic verification is a new approach to formal verification, applicable to generic algorithms such as those found in the Standard Template Library (STL, part of the Draft ANSI/ISO C++ Standard Library). Using behavioral abstraction and symbolic execution techniques, verifications are carried out at an abstract level such that the results can be used in a variety of instances of the generic algorithms without repeating the proofs. This is achieved by substituting for type parameters of generic algorithms special data types that model generic concepts by accepting symbolic inputs and deducing outputs using inference methods. By itself, this symbolic execution technique supports testing of programs with symbolic values at an abstract level. For formal verification one also needs to generate multiple program execution paths and use assertions (to handle while loops, for example), but the authors show how this can be achieved via directives to a conventional debugger program and an analysis database. The assertions must still be supplied, but they can be packaged separately and evaluated as needed by appropriate transfers of control orchestrated via the debugger. Unlike all previous verification methods, the dynamic verification method thus works without having to transform source code or process it with special interpreters. They include an example of the formal verification of an STL generic algorithm.","0098-5589;1939-3520;2326-3881","","10.1109/32.588523","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=588523","","Formal verification;ISO standards;Debugging;ANSI standards;Libraries;Inference algorithms;Testing;Data analysis;Databases;Packaging","formal verification;program debugging;program interpreters;subroutines;software libraries;data structures;inference mechanisms;program testing","C++ generic algorithms;dynamic verification;formal verification;Standard Template Library;behavioral abstraction;symbolic execution techniques;data types;model generic concepts;symbolic inputs;output deduction;inference methods;program testing;multiple program execution paths;debugger program;analysis database;control transfer;STL generic algorithm","","7","","32","","","","","","IEEE","IEEE Journals & Magazines"
"System Testing Aided by Structured Analysis: A Practical Experience","T. J. Mc Cabe; G. G. Schulmeyer","McCabe &amp; Associates, Inc.; NA","IEEE Transactions on Software Engineering","","1985","SE-11","9","917","921","This paper deals with the use of Structured Analysis just prior to system acceptance testing. Specifically, the drawing of data flow diagrams (DFD) was done after integration testing. The DFD's provided a picture of the logical flow through the integrated system for thorough system acceptance testing. System test sets, were derived from the flows in the DFD's. System test repeatability was enhanced by the matrix which flowed from the test sets.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232549","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702109","Data flow diagrams;structured analysis;system testing","System testing;Design for disassembly;Costs;Project management;Packaging;Documentation;Companies;Logic testing;Software testing;Software systems","","Data flow diagrams;structured analysis;system testing","","4","","10","","","","","","IEEE","IEEE Journals & Magazines"
"ADTEST: a test data generation suite for Ada software systems","M. J. Gallagher; V. Lakshmi Narasimhan","Sch. of Inf. Technol., Queensland Univ., Qld., Australia; NA","IEEE Transactions on Software Engineering","","1997","23","8","473","484","Presents the design of the software system ADTEST (ADa TESTing), for generating test data for programs developed in Ada83. The key feature of this system is that the problem of test data generation is treated entirely as a numerical optimization problem and, as a consequence, this method does not suffer from the difficulties commonly found in symbolic execution systems, such as those associated with input variable-dependent loops, array references and module calls. Instead, program instrumentation is used to solve a set of path constraints without explicitly knowing their form. The system supports not only the generation of integer and real data types, but also non-numerical discrete types such as characters and enumerated types. The system has been tested on large Ada programs (60,000 lines of code) and found to reduce the effort required to test programs as well as providing an increase in test coverage.","0098-5589;1939-3520;2326-3881","","10.1109/32.624304","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=624304","","Software testing;System testing;Software systems;Software design;Instruments;Optimization methods;Character generation;Inspection;Software tools;Production","program testing;Ada;software tools;optimisation;abstract data types","ADTEST;software test data generation suite;Ada83 software systems;numerical optimization;symbolic execution systems;program instrumentation;path constraints;integer data type;real data type;nonnumerical discrete types;characters;enumerated types;test coverage","","70","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Experimental evaluation of a real-time scheduler for a multiprocessor system","B. A. Blake; K. Schwan","Dept. of Comput. & Inf. Sci., Cleveland State Univ., OH, USA; NA","IEEE Transactions on Software Engineering","","1991","17","1","34","44","A description is given of the design, implementation, and experimental evaluation of a multiprocessor scheduler used with robotics applications and other real-time programs. The scheduler makes decisions concerning both the assignment of processes and the scheduling of these processes on each processor such that a near-optimal numer of processor deadlines is satisfied. It assumes that process execution times, deadlines, and earliest possible start times are known.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.67577","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=67577","","Real time systems;Multiprocessing systems;Dynamic scheduling;Processor scheduling;Scheduling algorithm;Robots;Operating systems;Application software;Costs;Helium","multiprogramming;real-time systems;scheduling","real-time scheduler;multiprocessor system;multiprocessor scheduler;robotics applications;assignment;processor deadlines;process execution times;earliest possible start times","","19","","62","","","","","","IEEE","IEEE Journals & Magazines"
"Optimization models for reliability of modular software systems","O. Berman; N. Ashrafi","Fac. of Manage., Toronto Univ., Ont., Canada; NA","IEEE Transactions on Software Engineering","","1993","19","11","1119","1123","The authors present optimization models for software systems that are developed using a modular design technique. Four different software structures are considered: one program, no redundancy; one program, with redundancy; multiple programs, no redundancy; and multiple programs, with redundancy. The optimization problems are solved by using the authors' version of established optimization methods. The practical usefulness of this study is to draw the attention of software practitioners to an existing methodology that may be used to make an optimal selection out of an available pool of modules with known reliability and cost. All four models maximize software reliability while ensuring that expenditures remain within available resources. The software manager is allowed to select the appropriate model for a given situation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.256858","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=256858","","Software systems;Redundancy;Software reliability;Cost function;Fault tolerance;Application software;Fault tolerant systems;Dynamic programming;Resource management;Software development management","dynamic programming;fault tolerant computing;redundancy;software reliability","optimization models;modular software systems;modular design technique;redundancy;software practitioners;software reliability;dynamic programming;fault tolerance;integer programming;modularization","","67","","7","","","","","","IEEE","IEEE Journals & Magazines"
"Performance measurement and modeling to evaluate various effects on a shared memory multiprocessor","X. Zhang","Div. of Math. & Comput. Sci., Texas Univ., San Antonio, TX, USA","IEEE Transactions on Software Engineering","","1991","17","1","87","93","Shared-memory multiprocessor performance is strongly affected by factors such as sequential code, barriers, cache coherence, virtual memory paging, and the multiprocessor system itself with resource scheduling and multiprogramming. Several timing models and analysis for these effects are presented. A modified Ware model based on these timing models is given to evaluate comprehensive performance of a shared-memory multiprocessor. Performance measurement has been done on the Encore Multimax, a shared-memory multiprocessor. The evaluation models are the analyses based on a general shared-memory multiprocessor system and architecture and can be applied to other types of shared-memory multiprocessors. Analytical and experimental results give a clear understanding of the various effects and a correct measure of the performance, which are important for the effective use of a shared-memory multiprocessor.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.67581","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=67581","","Measurement;Timing;Performance analysis;Parallel processing;Coherence;Multiprocessing systems;Algorithm design and analysis;Parallel algorithms;Runtime;Parallel architectures","multiprocessing systems;performance evaluation","performance measurement;performance modelling;shared memory multiprocessor;sequential code;barriers;cache coherence;virtual memory paging;resource scheduling;multiprogramming;timing models;modified Ware model;Encore Multimax;architecture","","9","","20","","","","","","IEEE","IEEE Journals & Magazines"
"A method for design and performance modeling of client/server systems","D. A. Menasce; H. Gomaa","Dept. of Comput. Sci., George Mason Univ., Fairfax, VA, USA; NA","IEEE Transactions on Software Engineering","","2000","26","11","1066","1085","Designing complex distributed client/server applications that meet performance requirements may prove extremely difficult in practice if software developers are not willing or do not have the time to help software performance analysts. The paper advocates the need to integrate both design and performance modeling activities so that one can help the other. We present a method developed and used by the authors in the design of a fairly large and complex client/server application. The method is based on a software performance engineering language developed by one of the authors. Use cases were developed and mapped to a performance modeling specification using the language. A compiler for the language generates an analytic performance model for the system. Service demand parameters at servers, storage boxes, and networks are derived by the compiler from the system specification. A detailed model of DBMS query optimizers allows the compiler to estimate the number of I/Os and CPU time for SQL statements. The paper concludes with some results of the application that prompted the development of the method and language.","0098-5589;1939-3520;2326-3881","","10.1109/32.881718","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=881718","","Design methodology;Application software;Software performance;Network servers;Performance analysis;Computer Society;Databases;Unified modeling language;Mission critical systems;Costs","client-server systems;software performance evaluation;formal specification;program compilers;query processing","performance modeling;client/server systems design;distributed client/server applications;performance requirements;software developers;software performance analysts;performance modeling activities;software performance engineering language;use cases;performance modeling specification;compiler;analytic performance model;service demand parameters;storage boxes;system specification;DBMS query optimizers;CPU time;SQL statements","","37","","46","","","","","","IEEE","IEEE Journals & Magazines"
"Predictability of process resource usage: a measurement-based study on UNIX","M. V. Devarakonda; R. K. Iyer","Coord. Sci. Lab., Illinois Univ., Urbana, IL, USA; Coord. Sci. Lab., Illinois Univ., Urbana, IL, USA","IEEE Transactions on Software Engineering","","1989","15","12","1579","1586","A statistical approach is developed for predicting the CPU time, the file I/O, and the memory requirements of a program at the beginning of its life, given the identity of the program. Initially, statistical clustering is used to identify high-density regions of process resource usage. The identified regions form the states for building a state-transition model to characterize the resource usage of each program in its past executions. The prediction scheme uses the knowledge of the program's resource usage in its last execution together with its state-transition model to predict the resource usage in its next execution. The prediction scheme is shown to work using process resource-usage data collected from a VAX 11/780 running 4.3 BSD Unix. The results show that the predicted values correlate strongly with the actual; the coefficient of correlation between the predicted and actual values for CPU time is 0.84. The errors in prediction are mostly small and are heavily skewed toward small values.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58769","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58769","","Predictive models;Time measurement;Accuracy;Load management;Costs;Distributed computing;Aerodynamics;NASA;High performance computing","performance evaluation;program testing;scheduling;statistical analysis;Unix","measurement-based study;statistical approach;CPU time;file I/O;memory requirements;statistical clustering;high-density regions;process resource usage;state-transition model;prediction scheme;VAX 11/780;BSD Unix;correlation","","52","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Validating Halstead's theory for Pascal programs","L. Felician; G. Zalateu","Dipartimento di Ingegneria Elettronica, Elettrotecnica, e Inf., Trieste Univ., Italy; NA","IEEE Transactions on Software Engineering","","1989","15","12","1630","1632","M.H. Halstead's theory (1977) has been validated for different languages, but Pascal programs seem to fit only partially with the theory. D.B. Johnston and A.M. Lister (1981) first recognized the lack of operators due to the structure of this language and proposed a modification of Halstead's formula. The article confirms their results but suggests a correction to their formula, which is particularly necessary for large programs. Experimental results, obtained by examining about 550 Pascal programs, represent the widest test to date of Halstead theory with regard to Pascal programs.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58773","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58773","","Data processing;Testing;Software algorithms","Pascal;programming theory","Pascal programs;operators;large programs;Halstead theory","","4","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Runtime Checking for ISO Standard Pascal","P. R. Eggert","Department of Computer Science, University of California","IEEE Transactions on Software Engineering","","1981","SE-7","4","447","448","Changes to Pascal, embodied in the proposed ISO Pascal standard, affected Fischer and LeBlanc's runtime error checking implementation designed for Wirthian Pascal. Three kinds of runtime errors became obsolete; two were introduced, and one was apparently neglected. A criticism is made of Fischer and LeBlanc's conclusion that runtime errors will always be with us.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230847","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702865","Error checking and reliability;ISO standardization;Pascal;runtime errors","Runtime;ISO standards;Costs;Counting circuits;Debugging;Data structures;Compaction","","Error checking and reliability;ISO standardization;Pascal;runtime errors","","","","8","","","","","","IEEE","IEEE Journals & Magazines"
"On the practical need for abstraction relations to verify abstract data type representations","M. Sitaraman; B. W. Weide; W. F. Ogden","Dept. of Stat. & Comput. Sci., West Virginia Univ., Morgantown, WV, USA; NA; NA","IEEE Transactions on Software Engineering","","1997","23","3","157","170","The typical correspondence between a concrete representation and an abstract conceptual value of an abstract data type (ADT) variable (object) is a many-to-one function. For example, many different pointer aggregates give rise to exactly the same binary tree. The theoretical possibility that this correspondence generally should be relational has long been recognized. By using a nontrivial ADT for handling an optimization problem, the authors show why the need for generalizing from functions to relations arises naturally in practice. Making this generalization is among the steps essential for enhancing the practical applicability of formal reasoning methods to industrial-strength software systems.","0098-5589;1939-3520;2326-3881","","10.1109/32.585503","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=585503","","Concrete;Computer Society;Aggregates;Binary trees;Computer industry;Industrial relations;Software systems;Formal specifications;Greedy algorithms","abstract data types;data structures;formal specification;program verification;optimisation;tree data structures","abstraction relations;abstract data type representation verification;concrete representation;abstract conceptual value;abstract data type variable;pointer aggregates;binary tree;optimization problem;formal reasoning methods;industrial-strength software systems","","6","","26","","","","","","IEEE","IEEE Journals & Magazines"
"A Universal File Server","A. D. Birrell; R. M. Needham","Xerox Palo Alto Research Center; NA","IEEE Transactions on Software Engineering","","1980","SE-6","5","450","453","A file server is a utility provided in a computer connected via a local communications network to a number of other computer. File servers exist to preserve material for the benefit of client machines or systems. It is desirable for a file server to be able to support multiple file directory and access management systems, so that the designer of a client system retains the freedom to design the system that best suits him. For example, he may wish to use the rile server to support a predefimed directory structure or as a swapping disk. The paper explores the dedgn issues associated with such a file server and proposes some solutions.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230493","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702761","Access control;directory;distributed computing;file server;filing system;garbage collector","File servers;Network servers;Time sharing computer systems;Computer networks;Communication networks;Laboratories;Access control;Distributed control;Communication system control;Control systems","","Access control;directory;distributed computing;file server;filing system;garbage collector","","3","","6","","","","","","IEEE","IEEE Journals & Magazines"
"An Extension of ""Representative Instances and -Acyclic Relational Schemes""","S. Jajodia","Computer Science and Systems Branch, Naval Research Laboratory","IEEE Transactions on Software Engineering","","1987","SE-13","9","1047","1048","Let R be a -acyclic relational scheme, and let F be the set of functional dependencies (FD's) embodied in R. Given an existence constrained database r over R, it was shown in [1] that it is possible to connect tuples from different relations in r and construct a universal instance L, possibly containing null values , such that the total projection of L onto R yields exactly the set r. Moreover, conditions were given which guarantee that this L would satisfy the functional dependency with nulls (NFD) counterparts of FD's, in F. The purpose of this note is to generalize the latter result and show that under the same conditions, L actually satisfies NFD counterparts of FD's in the closure F+ of F.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233792","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702327","Functional dependency with nulls;-acyclic relational scheme;representative instance;universal instance","Relational databases;Constraint theory;Terminology;Computer science;Transaction databases","","Functional dependency with nulls;-acyclic relational scheme;representative instance;universal instance","","","","3","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on ""Critical races in Ada programs","C. M. McNamee; R. A. Olsson","Dept. of Electr. Eng. & Comput. Sci., California Univ., Davis, CA, USA; Dept. of Electr. Eng. & Comput. Sci., California Univ., Davis, CA, USA","IEEE Transactions on Software Engineering","","1990","16","12","1439","","Comments are made on the above named work by G.M. Karam, C.M. Stanczyk, and G.W. Bond (see ibid., vol.15, no.11, p.1471-80, 1989), in which the semantics of the Ada rendezvous mechanism are discussed in terms of the critical race problem and a method is proposed for designing critical race-free programs. It is noted that this problem has been well described and numerous solutions have been presented in the literature during the past ten years (1980-90).<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.62452","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=62452","","Bonding;Design methodology;Computer science;Strontium;Computer languages;Discrete event simulation;Processor scheduling;Prototypes;Handicapped aids;Operating systems","Ada;programming","semantics;Ada rendezvous mechanism;critical race problem;critical race-free programs","","","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Secure broadcasting using the secure lock","Guang-Huei Chiou; Wen-Tsuen Chen","Inst. of Comput. Sci., Nat. Tsing-Hua Univ., Hsinchu, Taiwan; Inst. of Comput. Sci., Nat. Tsing-Hua Univ., Hsinchu, Taiwan","IEEE Transactions on Software Engineering","","1989","15","8","929","934","The authors discuss secure broadcasting, effected by means of a secure lock, on broadcast channels, such as satellite, radio, etc. This lock is implemented by using the Chinese Remainder theorem (CRT). The secure lock offers the following advantages: only one copy of the ciphertext is sent; the deciphering operation is efficient; and the number of secret keys held by each user is minimized. Protocols for secure broadcasting using the secure lock, based on the public-key cryptosystem as well as the private-key cryptosystem, are presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.31350","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=31350","","Satellite broadcasting;Radio broadcasting;Public key cryptography;Casting;Cathode ray tubes;Telecommunication traffic;Protocols;Local area networks;Packet radio networks","broadcasting;cryptography;protocols;telecommunication channels","secure broadcasting protocols;secret key minimization;session key;secure broadcasting;secure lock;broadcast channels;satellite;radio;Chinese Remainder theorem;ciphertext;deciphering operation;secret keys;public-key cryptosystem;private-key cryptosystem","","145","","5","","","","","","IEEE","IEEE Journals & Magazines"
"On the Asymptotic Optimality of First-Fit Storage Allocation","E. G. Coffman; T. T. Kadota; L. A. Shepp","AT& T Bell Laboratories; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","2","235","239","Suppose requests to store files arrive at a storage facility in a Poisson stream at rate 1. Each file is allocated storage space on arrival and each remains independently for an exponential time with mean l/p. The lengths of the files are assumed to be independent with common distribution F. Each file is placed in the lowest addressed contiguous sequence of locations large enough to accommodate the fre at its arrival time. This is the so-called first-fit storage discipline. We conjecture that first-fit is asymptotically optimal in the sense that the ratio of expected empty space to expected occupied space tends to zero as p  0, i.e., as the occupied space tends to . This conjecture seems very hard to prove, but it has been proved for constant file lengths [1], i.e., when F degenerates. We are unable to prove the conjecture but give a graphic display of the results of a Monte Carlo simulation which makes it very convincing.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232200","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701993","Analysis of algorithms;data structures;dynamic storage allocation;first-fit allocation","Graphics;Displays;Heuristic algorithms;Data structures;Markov processes;State-space methods;Random variables;Length measurement;Distribution functions;Application software","","Analysis of algorithms;data structures;dynamic storage allocation;first-fit allocation","","1","","5","","","","","","IEEE","IEEE Journals & Magazines"
"PRIM: A Fast Matrix Transpose Method","G. C. Goldbogen","Office of Computer Services, Rensselaer Polytechnic Institute","IEEE Transactions on Software Engineering","","1981","SE-7","2","255","257","An efficient algorithm called PRIM is proposed for transposing an arbitraxy R C matrix which is too large to be stored in its entirety in working memory and which instead is stored by rows on disk. PRIM facilitates the execution of numerical matrix algorithms which operate both by rows and by columns.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234523","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702832","Fast matrix transposition;intermediate matrix;partial row interchange method;two-dimensional transposition;working memory size","Buffer storage;Iterative algorithms","","Fast matrix transposition;intermediate matrix;partial row interchange method;two-dimensional transposition;working memory size","","8","","1","","","","","","IEEE","IEEE Journals & Magazines"
"Alpha: an extension of relational algebra to express a class of recursive queries","R. Agrawal","AT&T Bell Labs., Murray Hill, NJ, USA","IEEE Transactions on Software Engineering","","1988","14","7","879","885","An extension of E.F. Codd's relational algebra (1970) with an alpha ( alpha ) operator is presented that allows a large class of natural and useful recursive queries to be expressed, and yet has the property of being efficiently implementable. Formally, this class is a superset of linear recursive queries. Intuitively, this class comprises queries that examine transitive relationships between various instances of an entity. It is believed that this class covers many natural and interesting recursive queries. Examples of such queries include determining parts requirements for manufacturing a product, finding the critical path in a project management network, finding the shortest path between two cities, verifying connectivity between two points of a circuit, etc.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.42731","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=42731","","Algebra;Relational databases;Database languages;Calculus;Database systems;Deductive databases;Aggregates;Proposals;Manufacturing;Project management","database theory;query languages;recursive functions;relational databases","Codd;alpha operator;deductive databases;relational algebra;recursive queries;transitive relationships;critical path;project management network","","57","","32","","","","","","IEEE","IEEE Journals & Magazines"
"Guest Editorial Special Collection on Program Testing","B. Chandrasekaran","NA","IEEE Transactions on Software Engineering","","1980","SE-6","3","233","235","THIS special collection had its genesis at the IEEE Computer Society Workshop on Software Testing and Test Documentation, held in Fort Lauderdale, Florida, during December 18-20, 1978. This collection is devoted to selected papers on program testing that were presented at the Workshop. It contains six papers whose concerns span a wide range: theoretical issues, practical expenence With particular strategies, extension of a class of techniques to new classes of language constructs, and building integrated test tools. In the next section, we present an overview of the papers in the collection.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234484","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702724","","Software testing;Error correction;Societies;Conferences;Concrete;Buildings;Terminology;Input variables;Shape","","","","","","3","","","","","","IEEE","IEEE Journals & Magazines"
"Software cost reduction methods in practice","J. A. Hager","State College, PA, USA","IEEE Transactions on Software Engineering","","1989","15","12","1638","1644","In 1978, a software cost reduction program was initiated with the goal of applying modern design and documentation principles to the development of large systems. The results of this effort have been documented in several research papers published by D. Parnas et al. (1983). The author extends that approach by updating the methodology based on lessons learned during the application of the concepts to the development of a computer-based training system. An engineering life-cycle which provides more visibility to maintenance concerns is described, and the lessons learned during its implementation are discussed. A summary provides the author's impressions of the methodology and its potential to reduce system maintenance costs.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58775","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58775","","Costs;Software maintenance;Software design;Computer networks;Application software;Documentation;Distributed computing;Equations;Delay;Probability","computer aided instruction;software engineering","software cost reduction program;modern design;documentation principles;computer-based training system;engineering life-cycle;maintenance concerns;system maintenance costs","","5","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Explicit communication revisited: two new attacks on authentication protocols","M. Abadi","Syst. Res. Center, Digital Equipment Corp., Palo Alto, CA, USA","IEEE Transactions on Software Engineering","","1997","23","3","185","186","SSH and AKA are recent, practical protocols for secure connections over an otherwise unprotected network. The paper shows that, despite the use of public-key cryptography, SSH and AKA do not provide authentication as intended. The flaws of SSH and AKA can be viewed as the result of their disregarding a basic principle for the design of sound authentication protocols: the principle that messages should be explicit.","0098-5589;1939-3520;2326-3881","","10.1109/32.585505","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=585505","","Authentication;Cryptographic protocols;Public key cryptography;Public key;Knowledge based systems;Internet;Web server;Terminology;Protection;Displays","computer networks;public key cryptography;message authentication;protocols;software engineering","explicit communication;AKA protocol;SSH protocol;authentication protocols;secure connections;unprotected network;public key cryptography;sound authentication protocol design;explicit messages","","10","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Guiding goal modeling using scenarios","C. Rolland; C. Souveyet; C. B. Achour","Centre de Recherche en Inf., Paris I Univ., France; NA; NA","IEEE Transactions on Software Engineering","","1998","24","12","1055","1071","Even though goal modeling is an effective approach to requirements engineering, it is known to present a number of difficulties in practice. The paper discusses these difficulties and proposes to couple goal modeling and scenario authoring to overcome them. Whereas existing techniques use scenarios to concretize goals, we use them to discover goals. Our proposal is to define enactable rules which form the basis of a software environment called L'Ecritoire to guide the requirements elicitation process through interleaved goal modeling and scenario authoring. The focus of the paper is on the discovery of goals from scenarios. The discovery process is centered around the notion of a requirement chunk (RC) which is a pair <Goal, Scenario>. The paper presents the notion of RC, the rules to support the discovery of RCs and illustrates the application of the approach within L'Ecritoire using the ATM example. It also evaluates the potential practical benefits expected from the use of the approach.","0098-5589;1939-3520;2326-3881","","10.1109/32.738339","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=738339","","Proposals;Air traffic control;Human resource management;Documentation;Joining processes","formal specification;systems analysis;programming environments;authoring systems","goal modeling;enactable rules;requirements engineering;scenario authoring;software environment;L'Ecritoire;requirements elicitation process;interleaved goal modeling;goal discovery;discovery process;requirement chunk;ATM example","","211","","34","","","","","","IEEE","IEEE Journals & Magazines"
"Use case maps as architectural entities for complex systems","R. J. A. Buhr","Dept. of Syst. & Comput. Eng., Carleton Univ., Ottawa, Ont., Canada","IEEE Transactions on Software Engineering","","1998","24","12","1131","1155","The paper presents a novel, scenario based notation called Use Case Maps (UCMs) for describing, in a high level way, how the organizational structure of a complex system and the emergent behavior of the system are intertwined. The notation is not a behavior specification technique in the ordinary sense, but a notation for helping a person to visualize, think about, and explain the big picture. UCMs are presented as ""architectural entities"" that help a person stand back from the details during all phases of system development. The notation has been thoroughly exercised on systems of industrial scale and complexity and the distilled essence of what has been found to work in practice is summarized. Examples are presented that confront difficult complex system issues directly: decentralized control, concurrency, failure, diversity, elusiveness and fluidity of runtime views of software, self modification of system makeup, difficulty of seeing large scale units of emergent behavior cutting across systems as coherent entities (and of seeing how such entities arise from the collective efforts of components), and large scale.","0098-5589;1939-3520;2326-3881","","10.1109/32.738343","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=738343","","Computer aided software engineering;Runtime;Software systems;Large-scale systems;Visualization;Computer languages;Electrical equipment industry;Distributed control;Concurrent computing","program visualisation;formal specification;systems analysis;software architecture","use case maps;architectural entities;complex systems;scenario based notation;UCMs;organizational structure;emergent behavior;behavior specification technique;decentralized control;concurrency;runtime views;software failure;self modification;system makeup;large scale units;software architecture;system behavior;requirements","","118","","31","","","","","","IEEE","IEEE Journals & Magazines"
"An Essay on Software Reuse","T. A. Standish","Programming Environment Project, Department of Computer Science, University of California, Irvine, CA 92717.","IEEE Transactions on Software Engineering","","1984","SE-10","5","494","497","This paper explores software reuse. It discusses briefly some economic incentives for developing effective software reuse technology and notes that different kinds of software reuse, such as direct use without modification and reuse of abstract software modules after refinement, have different technological implications. It sketches some problem areas to be addressed if we are to achieve the goal of devising practical software reuse systems. These include information retrieval problems and finding effective methods to aid us in understanding how programs work. There is a philosophical epilogue which stresses the importance of having realistic expectations about the benefits of software reuse.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010272","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010272","Software factories;software productivity;software reuse","Concrete;Power generation economics;Productivity;Environmental economics;Software reusability;Programming profession;Computer aided manufacturing;Cost function;Propellants;Programming environments","","","","92","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Bayesian analysis of empirical software engineering cost models","S. Chulani; B. Boehm; B. Steece","Centre for Software Eng., IBM Res., San Jose, CA, USA; NA; NA","IEEE Transactions on Software Engineering","","1999","25","4","573","583","Many parametric software estimation models have evolved in the last two decades (L.H. Putnam and W. Myers, 1992; C. Jones, 1997; R.M. Park et al., 1992). Almost all of these parametric models have been empirically calibrated to actual data from completed software projects. The most commonly used technique for empirical calibration has been the popular classical multiple regression approach. As discussed in the paper, the multiple regression approach imposes a few assumptions frequently violated by software engineering datasets. The paper illustrates the problems faced by the multiple regression approach during the calibration of one of the popular software engineering cost models, COCOMO II. It describes the use of a pragmatic 10 percent weighted average approach that was used for the first publicly available calibrated version (S. Chulani et al., 1998). It then moves on to show how a more sophisticated Bayesian approach can be used to alleviate some of the problems faced by multiple regression. It compares and contrasts the two empirical approaches, and concludes that the Bayesian approach was better and more robust than the multiple regression approach.","0098-5589;1939-3520;2326-3881","","10.1109/32.799958","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=799958","","Bayesian methods;Software engineering;Costs;Predictive models;Programming;Calibration;Accuracy;Scheduling;Software quality;Parametric statistics","software cost estimation;Bayes methods;statistical analysis;calibration;project management","Bayesian analysis;empirical software engineering cost models;parametric software estimation models;empirical calibration;software projects;classical multiple regression approach;software engineering datasets;multiple regression approach;software engineering cost models;COCOMO II;weighted average approach;publicly available calibrated version;Bayesian approach;empirical approaches","","124","","35","","","","","","IEEE","IEEE Journals & Magazines"
"Hypercharts: extended statecharts to support hypermedia specification","F. Borges Paulo; P. C. Masiero; M. C. Ferreira de Oliveira","Anderson Consulting, Sao Paulo, Brazil; NA; NA","IEEE Transactions on Software Engineering","","1999","25","1","33","49","Introduces hypercharts, a novel and effective notation that extends the well-known statechart formalism to make it suitable for the specification of temporal and information synchronization requirements of hypermedia applications. Three new definitions are added: timed history, timed transitions, and a set of synchronization mechanisms. The proposed extensions are based on the major characteristics of some Petri net-based multimedia models, and have their semantics described in terms of conventional statechart models. Therefore, any hyperchart construction can be transformed into a statechart that exhibits the desired behavior, giving hyperchart models the same semantic behavior as statecharts. The new constructs are illustrated using a case study based on a hypermedia-modeling example.","0098-5589;1939-3520;2326-3881","","10.1109/32.748917","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=748917","","Multimedia databases;History;Information retrieval;Navigation;Timing;Writing;Computer science;Web sites;Distributed databases;Internet","hypermedia;synchronisation;Petri nets;formal specification;finite state machines","hypercharts;statecharts;hypermedia specification;temporal synchronization;information synchronization;timed history;timed transitions;synchronization mechanisms;Petri net-based multimedia models;semantic behavior;case study;requirements specification","","10","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Reliability of systems with Markov transfer of control, II","K. Siegrist","Dept. of Math. & Stat., Alabama Univ., Huntsville, AL, USA","IEEE Transactions on Software Engineering","","1988","14","10","1478","1480","A software/hardware system is considered that can be decomposed into a finite number of modules. It is assumed that control of the system is transferred among the modules according to a Markov process. Each module has an associated reliability that gives the probability that the module will operate correctly when called and will transfer control successfully when finished. The measure of reliability considered is the mean number of transitions until failure, starting in a designated initial state. This measure of system reliability is studied in terms of the module reliability and the transition probabilities. Methods of predicting system reliability are obtained and special branching and sequential systems are studied.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6192","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6192","","Control systems;State-space methods;Probability;Markov processes;Software reliability;Software systems;Hardware;Mathematics;Statistics","Markov processes;probability;software reliability","software reliability;Markov process;probability;system reliability","","16","","5","","","","","","IEEE","IEEE Journals & Magazines"
"Message logging: pessimistic, optimistic, causal, and optimal","L. Alvisi; K. Marzullo","Dept. of Comput. Sci., Texas Univ., Austin, TX, USA; NA","IEEE Transactions on Software Engineering","","1998","24","2","149","159","Message-logging protocols are an integral part of a popular technique for implementing processes that can recover from crash failures. All message-logging protocols require that, when recovery is complete, there be no orphan processes, which are surviving processes whose states are inconsistent with the recovered state of a crashed process. We give a precise specification of the consistency property ""no orphan processes"". From this specification, we describe how different existing classes of message-logging protocols (namely optimistic, pessimistic, and a class that we call causal) implement this property. We then propose a set of metrics to evaluate the performance of message-logging protocols, and characterize the protocols that are optimal with respect to these metrics. Finally, starting from a protocol that relies on causal delivery order, we show how to derive optimal causal protocols that tolerate f overlapping failures and recoveries for a parameter f (1/spl les/f/spl les/n).","0098-5589;1939-3520;2326-3881","","10.1109/32.666828","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=666828","","Computer crashes;Multicast protocols;Fault tolerant systems;Measurement;Checkpointing;Context","protocols;electronic messaging;system recovery;fault tolerant computing;formal specification;performance evaluation","message-logging protocols;crash failure recovery;orphan processes;inconsistent states;recovered state;consistency property specification;optimistic protocols;pessimistic protocols;causal protocols;performance evaluation metrics;optimal protocols;causal delivery order;overlapping failures;checkpoint-restart protocols;resilient processes;fault-tolerance techniques","","98","","22","","","","","","IEEE","IEEE Journals & Magazines"
"The POSTGRES rule manager","M. Stonebraker; E. N. Hanson; S. Potamianos","Dept. of Electr. Eng. & Comput. Sci., California Univ., Berkeley, CA, USA; Dept. of Electr. Eng. & Comput. Sci., California Univ., Berkeley, CA, USA; Dept. of Electr. Eng. & Comput. Sci., California Univ., Berkeley, CA, USA","IEEE Transactions on Software Engineering","","1988","14","7","897","907","The rule subsystem that is being implemented in the POSTGRES DBMS is explained. It is novel in several ways. First, it gives users the capability of defining rules as well as data. Moreover, depending on the scope of each rule defined, optimization is handled differently. This leads to good performance both when there are many rules each of small scope and when there are a few rules each of large scope. In addition, rules provide either a forward-chaining or a backward-chaining control flow, and the system chooses the control mechanism that optimizes performance whenever possible. Priority rules can be defined, allowing a user to specify rule systems that have conflicts. This use of exceptions seems necessary in many applications. Database services such as views, protection, integrity constraints, and referential integrity can be obtained simply by applying the rules system in the appropriate way. Consequently, no special-purpose code need be included in POSTGRES to handle these tasks.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.42733","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=42733","","Databases;Control systems;Expert systems;Application software;Birds;Protection;Software systems;Memory management;Data security;Laboratories","expert systems;knowledge engineering;relational databases","priority rules;relational databases;inferencing;knowledge engineering;expert systems;query languages;POSTGRES rule manager;rule subsystem;DBMS;optimization;forward-chaining;backward-chaining;exceptions;integrity constraints;referential integrity","","74","","28","","","","","","IEEE","IEEE Journals & Magazines"
"On a Class of Linear Maps for Data Compression","S. Kundu","Electronics and Communication Science Unit, Indian Statistical Institute","IEEE Transactions on Software Engineering","","1982","SE-8","5","530","532","A method for data compression with linear maps has been developed which is found to produce further reduction in overhead storage requirement, compression/decompression time, and clustering overhead as compared to the affine map method in certain cases. Algorithms have been developed for cluster minimization, cluster identification, and compression matrix calculation that may be applied with advantage in both the methods.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235877","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702981","Cluster analysis;computer algebra;data compression;dimensionality reduction;linear transformation;overhead storage;redundancy reduction","Data compression;Clustering algorithms;Minimization methods;Vectors;Data analysis;Algebra;Pattern recognition;Costs","","Cluster analysis;computer algebra;data compression;dimensionality reduction;linear transformation;overhead storage;redundancy reduction","","","","5","","","","","","IEEE","IEEE Journals & Magazines"
"On the statistical analysis of the number of errors remaining in a software design document after inspection","N. B. Ebrahimi","Div. of Stat., Northern Illinois Univ., DeKalb, IL, USA","IEEE Transactions on Software Engineering","","1997","23","8","529","532","Sometimes, complex software systems fail because of faults introduced in the requirements and design stages of the development process. Reviewing documents related to requirements and design by several reviewers can remove some of these faults, but often a few remain undetected until the software is developed. In this paper, we propose a procedure leading to the estimation of the number of faults which are not discovered. The main advantage of our procedure is that we do not need the standard assumption of independence among reviewers.","0098-5589;1939-3520;2326-3881","","10.1109/32.624308","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=624308","","Statistical analysis;Software design;Software systems;Smoothing methods;Software engineering;Programming;Fault detection;Inspection;Parameter estimation;Phase estimation","system documentation;systems analysis;statistical analysis;coding errors;inspection","statistical analysis;remaining errors;software design document;inspection;complex software systems;system failure;software fault estimation;requirements stage;software design stage;software development process;document review;reviewer independence;likelihood function;confidence interval;Chi-squared distribution;nonparametric estimation;smoothing parameter;undiscovered faults","","27","","8","","","","","","IEEE","IEEE Journals & Magazines"
"SADATAn Automated Testing Tool","U. Voges; L. Gmeiner; A. A. Von Mayrhauser","Kernforschungszentrum Karlsruhe GmbH, Institut ftlr Datenverarbeitung in der Technik; NA; NA","IEEE Transactions on Software Engineering","","1980","SE-6","3","286","290","This paper describes the automated testing tool SADAT, which supports the testing of single Fortran modules. The different functions which are integrated in this system are explained, the usage of the tool is demonstrated, and some output results are presented. The special benefits of the SADAT system are summarized. The history and the present status of the system are outlned. Finaly, a listing of further reference material and information on the program availability are included.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230474","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702730","Automated test systems;dynamic analysis;path predicate program testing;software tool;static analysis;symbolic execution;test case generation;test data generation","Automatic testing;Software testing;System testing;Computer errors;Software tools;Algorithms;Databases;History;Computer science;Information analysis","","Automated test systems;dynamic analysis;path predicate program testing;software tool;static analysis;symbolic execution;test case generation;test data generation","","10","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Hierarchical structuring of superposed GSPNs","P. Buchholz","Dept. of Comput. Sci., Dortmund Univ., Germany","IEEE Transactions on Software Engineering","","1999","25","2","166","181","Superposed generalized stochastic Petri nets (SGSPNs) and stochastic automata networks (SANs) are formalisms to describe Markovian models as a collection of synchronously communicating components. Both formalisms allow a compact representation of the generator matrix of the Markov chain, which can be exploited for very space efficient analysis techniques. The main drawback of the approaches is that for many models the compositional description introduces a large number of unreachable states, such that the gain due to the compact representation of the generator matrix is completely lost. This paper proposes a new approach to avoid unreachable states without losing the possibility to represent the generator matrix in a compact form. The central idea is to introduce a preprocessing step to generate a hierarchical structure which defines a block structure of the generator matrix, where every block can be represented in a compact form similar to the representation of generator matrices originally proposed for SGSPNs or SANs. The resulting structure includes no unreachable states, needs only slightly more space than the compact representation developed for SANs and can still be exploited in efficient numerical solution techniques. Furthermore, the approach is a very efficient method to generate and represent huge reachability sets and graphs.","0098-5589;1939-3520;2326-3881","","10.1109/32.761443","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=761443","","State-space methods;Sparse matrices;Stochastic processes;Numerical analysis;Reachability analysis;Performance analysis;Algebra;Tensile stress;Petri nets;Automata","Petri nets;stochastic automata;reachability analysis;software performance evaluation;Markov processes;matrix algebra;numerical analysis","superposed generalized stochastic Petri nets;stochastic automata networks;hierarchical structuring;Markovian models;synchronously communicating components;space efficient analysis techniques;compositional description;unreachable states;compact generator matrix representation;preprocessing step;block structure;reachability sets;reachability graphs;numerical solution techniques","","32","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Software support for multiprocessor latency measurement and evaluation","Yong Yan; Xiaodong Zhang; Qian Ma","High Performance Comput. & Software Lab., Texas Univ., San Antonio, TX, USA; NA; NA","IEEE Transactions on Software Engineering","","1997","23","1","4","16","Parallel computing scalability evaluates the extent to which parallel programs and architectures can effectively utilize increasing numbers of processors. In this paper, we compare a group of existing scalability metrics and evaluation models with an experimental metric which uses network latency to measure and evaluate the scalability of parallel programs and architectures. To provide insight into dynamic system performance, we have developed an integrated software environment prototype for measuring and evaluating multiprocessor scalability performance, called Scale-Graph. Scale-Graph uses a graphical instrumentation monitor to collect, measure and analyze latency-related data, and to display scalability performance based on various program execution patterns. The graphical software tool is X-Windows based and is currently implemented on standard workstations to analyze performance data of the KSR-1, a hierarchical ring-based shared-memory architecture.","0098-5589;1939-3520;2326-3881","","10.1109/32.581326","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=581326","","Delay;Software measurement;Scalability;Computer architecture;Data analysis;Performance analysis;Parallel processing;System performance;Software performance;Software prototyping","shared memory systems;parallel architectures;parallel programming;performance evaluation;graphical user interfaces;system monitoring;software metrics;software tools;software performance evaluation;engineering graphics","software support;multiprocessor latency measurement;multiprocessor latency evaluation models;parallel computing scalability;parallel programs;parallel architectures;processor number;scalability metrics;network latency;dynamic system performance;integrated software environment prototype;Scale-Graph;graphical instrumentation monitor;program execution patterns;X-Windows based software tool;workstations;KSR-1 performance data analysis;hierarchical ring-based shared-memory architecture;performance graphical presentation","","3","","16","","","","","","IEEE","IEEE Journals & Magazines"
"An experiment to assess the cost-benefits of code inspections in large scale software development","A. A. Porter; H. P. Siy; C. A. Toman; L. G. Votta","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1997","23","6","329","346","We conducted a long term experiment to compare the costs and benefits of several different software inspection methods. These methods were applied by professional developers to a commercial software product they were creating. Because the laboratory for this experiment was a live development effort, we took special care to minimize cost and risk to the project, while maximizing our ability to gather useful data. The article has several goals: (1) to describe the experiment's design and show how we used simulation techniques to optimize it; (2) to present our results and discuss their implications for both software practitioners and researchers; and (3) to discuss several new questions raised by our findings. For each inspection, we randomly assigned three independent variables: (1) the number of reviewers on each inspection team (1, 2, or 4); (2) the number of teams inspecting the code unit (1 or 2); and (3) the requirement that defects be repaired between the first and second team's inspections. The reviewers for each inspection were randomly selected without replacement from a pool of 11 experienced software developers. The dependent variables for each inspection included inspection interval (elapsed time), total effort, and the defect detection rate. Our results showed that these treatments did not significantly influence the defect detection effectiveness, but that certain combinations of changes dramatically increased the inspection interval.","0098-5589;1939-3520;2326-3881","","10.1109/32.601071","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=601071","","Inspection;Large-scale systems;Programming;Costs;Analysis of variance;Software quality;Switches;Computer Society;Laboratories;Design optimization","software cost estimation;cost-benefit analysis;inspection;software quality;professional aspects","code inspection cost benefits;large scale software development;long term experiment;software inspection methods;professional developers;commercial software product;live development effort;experiment design;simulation techniques;software practitioners;independent variables;reviewers;inspection team;code unit;experienced software developers;inspection interval;defect detection rate;defect detection effectiveness","","74","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Reply To: Comments On ""towards A Framework Of Software Measurement Validation""","B. Kitchenham; S. L. Pfleeger; N. Fenton","Keele University; NA; NA","IEEE Transactions on Software Engineering","","1997","23","3","189","189","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1997.585507","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=585507","","Software measurement;Size measurement;Logic;Software engineering;Impedance;Time measurement;Size control;Performance analysis;Volume measurement","","","","8","","1","","","","","","IEEE","IEEE Journals & Magazines"
"Device Monitors","A. P. Ravn","Institute of Datalogy, University of Copenhagen","IEEE Transactions on Software Engineering","","1980","SE-6","1","49","53","A driver is the part of an I/O system used for processing of an I/O request for a specific channel. The interaction of the CPU with a channel is described through the monitor concept of Hoare and Brinch Hansen. The implementation of monitors using hardware interrupt facilities is described. The resulting device monitor is compared pared with the device processes of Wirth's Modula. The concept is illustrated through an extension to Concurrent Pascal with examples drawn from the PDP11 system. Problems of missing interrupts and power failure are also discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230462","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702694","Channel processors;drivers;interrupt systems;I/O systems;monitors;synchronization","Registers;Hardware;Computer languages;Centralized control;Process control;Kernel;Fault tolerant systems;Power system modeling;Software engineering","","Channel processors;drivers;interrupt systems;I/O systems;monitors;synchronization","","","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Correction to 'A4 logic-based approach to reverse engineering tools production (Dec 92 1053-1064)","G. Canfora; A. Cimitile; U. de Carlini","Dipartimento di Inf. e Sistemistica, Naples Univ., Italy; Dipartimento di Inf. e Sistemistica, Naples Univ., Italy; Dipartimento di Inf. e Sistemistica, Naples Univ., Italy","IEEE Transactions on Software Engineering","","1993","19","6","640","","A typographic error in rule 10 in the above-titled paper (see ibid., vol.18, no.12, p.1053-64, Dec. 1992), is corrected.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.232029","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=232029","","Reverse engineering;Production","software engineering","logic-based approach;reverse engineering tools production","","","","1","","","","","","IEEE","IEEE Journals & Magazines"
"Sloan research project","T. Bergin","NA","IEEE Transactions on Software Engineering","","2000","26","5","478","478","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.2000.846303","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=846303","","History;Computer languages;Software engineering;Computer science;Software tools;Collaborative tools;Writing;Permission;Programming profession","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Experiences using lightweight formal methods for requirements modeling","S. Easterbrook; R. Lutz; R. Covington; J. Kelly; Y. Ampo; D. Hamilton","NASA IV&V Fac., Fairmont, WV, USA; NA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","1","4","14","The paper describes three case studies in the lightweight application of formal methods to requirements modeling for spacecraft fault protection systems. The case studies differ from previously reported applications of formal methods in that formal methods were applied very early in the requirements engineering process to validate the evolving requirements. The results were fed back into the projects to improve the informal specifications. For each case study, we describe what methods were applied, how they were applied, how much effort was involved, and what the findings were. In all three cases, formal methods enhanced the existing verification and validation processes by testing key properties of the evolving requirements and helping to identify weaknesses. We conclude that the benefits gained from early modeling of unstable requirements more than outweigh the effort needed to maintain multiple representations.","0098-5589;1939-3520;2326-3881","","10.1109/32.663994","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=663994","","Application software;Protection;Computer Society;NASA;Space vehicles;Embedded software;Feedback;Software safety;Aerospace engineering;Testing","formal specification;systems analysis;program verification;space vehicles;fault tolerant computing;aerospace computing","lightweight formal methods;requirements modeling;case studies;lightweight application;spacecraft fault protection systems;requirements engineering process;evolving requirements validation;informal specifications;validation processes;unstable requirements;multiple representations","","69","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Safe Data Type Specifications","N. C. K. Phillips","Department of Computer Science, University of Natal, Pietermaritzburg, South Africa.","IEEE Transactions on Software Engineering","","1984","SE-10","3","285","289","This paper discusses the current style of algebraic data type specifications. Some simple examples illustrate that whether or not two objects of the type being specified are equal can be implementation dependent, even for very simple objects of the type. To remedy this, it is proposed that specifications should be safe, where safety is a stronger requirement than Guttag's sufficient completeness. The paper also discusses when an operator should be part of a specification and when it should be introduced by extension, and concludes with safe specifications of some common data types.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010237","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010237","Abstract data types;algebraic axioms;type specifications","Safety;Computer science;Africa","","","","1","","9","","","","","","IEEE","IEEE Journals & Magazines"
"SYGRAF: implementing logic programs in a database style","M. Kifer; E. L. Lozinskii","Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA; NA","IEEE Transactions on Software Engineering","","1988","14","7","922","935","It is shown how Horn logic programs can be implemented using database techniques, namely, mostly bottom-up in combination with certain top-down elements (as opposed to the top-down implementations of logic programs prevailing so far). The proposed method is sound and complete. It easily lends itself to a parallel implementation and is free of nonlogical features like backtracking. As an extension to the common approach to deductive databases, function symbols are allowed to appear in programs, and it is shown that much of database query optimization can be applied to optimize logic programs. An important advantage of present approach is its ability to evaluate successfully many programs that terminate under neither pure top-down nor bottom-up evaluation strategies.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.42735","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=42735","","Logic programming;Spatial databases;Deductive databases;Query processing;Database systems;Computer science;Termination of employment;Safety;Computational efficiency;Councils","database theory;formal logic;logic programming;programming theory","logic programming;parallel programming;SYGRAF;Horn logic programs;deductive databases;function symbols;query optimization;bottom-up evaluation","","11","","52","","","","","","IEEE","IEEE Journals & Magazines"
"A fourth-order algorithm with automatic stepsize control for the transient analysis of DSPNs","A. Heindl; R. German","Inst. fur Tech. Inf., Tech. Univ. Berlin, Germany; NA","IEEE Transactions on Software Engineering","","1999","25","2","194","206","This paper presents an efficient and numerically reliable method for the transient analysis of deterministic and stochastic Petri nets. The transient behavior is described by state equations derived by the method of supplementary variables. Significant features of the proposed solution algorithm of fourth order are an automatic stepsize control and a two-stage relative error control. Furthermore, a formal way of dealing with discontinuities in the transient state equations is developed. This resolves the problems posed by initially enabled deterministic transitions and also improves the accuracy of numerical results. Experiments with a queueing system with failure and repair illustrate the efficiency (with respect to both CPU-time and memory space) and the numerical quality of the new algorithm.","0098-5589;1939-3520;2326-3881","","10.1109/32.761445","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=761445","","Automatic control;Transient analysis;Equations;Stochastic processes;Petri nets;Algorithm design and analysis;Error correction;Programmable control;Adaptive control;Software tools","Petri nets;numerical analysis;software performance evaluation","fourth-order algorithm;automatic stepsize control;transient analysis;deterministic stochastic Petri nets;numerically reliable method;efficient method;state equations;supplementary variable;two-stage relative error control;discontinuities;transient state equations;initially enabled deterministic transitions;queueing system;failure;repair;numerical quality","","6","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Achieving strong consistency in a distributed file system","P. Triantafillou; C. Neilson","Dept. of Comput. Eng., Crete Tech. Univ., Greece; NA","IEEE Transactions on Software Engineering","","1997","23","1","35","55","Distributed file systems need to provide for fault tolerance. This is typically achieved with the replication of files. Existing approaches to the construction of replicated file systems sacrifice strong semantics (i.e. the guarantees the systems make to running computations when failures occur and/or files are accessed concurrently). This is done mainly for efficiency reasons. This paper puts forward a replicated file system protocol that enforces strong consistency semantics. Enforcing strong semantics allows for distributed systems to behave more like their centralized counterparts-an essential feature in order to provide the transparency that is so strived for in distributed computing systems. One characteristic of our protocol is its distributed nature. Because of it, the extra cost needed to ensure the stronger consistency is kept low (since the bottleneck problem noticed in primary-copy systems is avoided), load balancing is facilitated, clients can choose physically close servers, and the work required during failure handling and recovery is reduced. Another characteristic is that, instead of optimizing each operation type on its own, file system activity is viewed at the level of a file session and the costs of individual operations were able to be spread over the life of a file session. We have developed a prototype and compared its performance to both NFS and a nonreplicated version of the prototype that also achieves strong consistency semantics. Through these comparisons, the cost of replication and the cost of enforcing the strong consistency semantics are shown.","0098-5589;1939-3520;2326-3881","","10.1109/32.581328","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=581328","","File systems;File servers;Prototypes;Concurrent computing;Access protocols;Distributed computing;Fault tolerant systems;Load management;Cost function;Availability","replicated databases;concurrency control;distributed databases;system recovery;client-server systems;access protocols","strong consistency semantics enforcement;distributed file system;fault tolerance;replicated file system protocol;transparency;system failure recovery;concurrent access;efficiency;load balancing;physically close server selection;file system activity;operation costs;file session;prototype;performance;NFS;nonreplicated version;availability;caching","","8","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Generalization of queueing network product form solutions to stochastic Petri nets","G. Florin; S. Natkin","Centre d'Etudes et de Recherche en Inf. du CNAM, Paris, France; Centre d'Etudes et de Recherche en Inf. du CNAM, Paris, France","IEEE Transactions on Software Engineering","","1991","17","2","99","107","A new solution is given for the steady-state probability computation of closed synchronized queuing networks. A closed synchronized queuing network is a particular Markov stochastic Petri net (a bounded and monovaluated Petri net with a strongly connected reachability graph and constant firing rates independent of markings). It is shown that the steady-state probability distribution can be expressed using matrix products. The results generalize the Gordon-Newell theorem. The solution is similar to the Gordon-Newell product form using matrix and vectors instead of scalars. A prototype solver developed from this result is presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.67591","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=67591","","Stochastic processes;Petri nets;Steady-state;Probability distribution;Prototypes;Queueing analysis;Computer networks;Helium;Network theory (graphs);Algorithm design and analysis","performance evaluation;Petri nets;queueing theory","performance evaluation;queueing network product form solutions;stochastic Petri nets;steady-state probability;closed synchronized queuing networks;Markov stochastic Petri net;strongly connected reachability graph;constant firing rates;matrix products;Gordon-Newell theorem","","8","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Response To: Comments On ""property-based Software Engineering Measurement: Refining The Additivity Properties""","L. C. Briand; S. Morasca; V. R. Basili","Fraunlwfer Institute for Experimental Software Engineering (IESE); NA; NA","IEEE Transactions on Software Engineering","","1997","23","3","196","197","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1997.585509","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=585509","","Software engineering;Software measurement;Computer Society;Merging","","","","11","","1","","","","","","IEEE","IEEE Journals & Magazines"
"Specification and verification using dependent types","F. K. Hanna; N. Daeche; M. Longley","Fac. of Inf. Technol., Kent Univ., Canterbury, UK; Fac. of Inf. Technol., Kent Univ., Canterbury, UK; Fac. of Inf. Technol., Kent Univ., Canterbury, UK","IEEE Transactions on Software Engineering","","1990","16","9","949","964","VERITAS/sup +/, a specification logic based on dependent types, is described. The overall aim is to demonstrate how the use of dependent types together with subtypes and datatypes allows the writing of specifications that are clear, concise, and generic. The development of theories of arithmetic, numerals, and iterative structures is described, and the proof of a theorem that greatly simplifies the formal verification of iterative arithmetic structures is outlined. The VERITAS/sup +/ logic is defined by modeling it as a partial algebra within a purely functional metalanguage. Aspects of the computational implementation of the logic and its associated toolset are briefly described.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58783","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58783","","Specification languages;Logic design;Formal verification;Logic programming;Arithmetic;Computer languages;Writing;H infinity control;Calculus;Councils","formal specification;iterative methods;modelling;theorem proving","theorem proving;dependent types;VERITAS/sup +/;specification logic;numerals;iterative structures;modeling;functional metalanguage;computational implementation","","15","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on ""Elements of Software Configuration Management""","E. H. Bersoff","BTG, Inc.","IEEE Transactions on Software Engineering","","1985","SE-11","8","822","822","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232531","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702091","","Programming;Joining processes;Books;Software maintenance;Software development management;Documentation;Hardware;Quality assurance;Application software;Engineering management","","","","","","4","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on ""A formal semantics for object model diagrams""","R. J. Botting; R. H. Bourdeau; B. H. C. Cheng","Dept. of Comput. Sci., California State Univ., San Bernardino, CA, USA; NA; NA","IEEE Transactions on Software Engineering","","1996","22","12","911","","The author indicates some things that need clarifying in the paper cited in the title. The paper does not make it clear that a class of objects is not equivalent to a set of tuples. In a set of tuples two different tuples cannot contain the same data. Two different objects in a given class can contain the same data. In most of the paper this does not matter. However, the simulation function between a subclass and a superclass must be injective, but the (overloaded) simulation function between the sets of tuples usually cannot be injective.","0098-5589;1939-3520;2326-3881","","10.1109/32.553639","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=553639","","Error correction;Object oriented programming","algebraic specification;formal specification;object-oriented methods;diagrams","formal semantics;object model diagrams;tuples;simulation function;subclass;superclass","","","","2","","","","","","IEEE","IEEE Journals & Magazines"
"A Summary of the Discussion on ""An Analysis of Competing Software Reliability Models""","A. L. Goel","Department of Industrial Engineering and Operations Research, and the School of Computer and Information Science, Syracuse University","IEEE Transactions on Software Engineering","","1980","SE-6","5","501","502","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230791","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702767","","Software reliability;Hazards;Industrial engineering;Operations research;Information science;Computer errors;Data analysis;Testing;Software engineering;Weibull distribution","","","","9","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Foreword","W. E. Howden","NA","IEEE Transactions on Software Engineering","","1985","SE-11","3","241","241","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232206","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701999","","Programming environments;Software engineering;User interfaces;Engineering management;Design engineering;Graphics;Software design;Conference management;Project management;Research and development management","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on ""A metrics suite for object oriented design","N. I. Churcher; M. J. Shepperd; S. Chidamber; C. F. Kemerer","Dept. of Appl. Comput. & Electron., Bournemouth Univ., UK; Dept. of Appl. Comput. & Electron., Bournemouth Univ., UK; NA; NA","IEEE Transactions on Software Engineering","","1995","21","3","263","265","A suite of object oriented software metrics has recently been proposed by S.R. Chidamber and C.F. Kemerer (see ibid., vol. 20, p. 476-94, 1994). While the authors have taken care to ensure their metrics have a sound measurement theoretical basis, we argue that is premature to begin applying such metrics while there remains uncertainty about the precise definitions of many of the quantities to be observed and their impact upon subsequent indirect metrics. In particular, we show some of the ambiguities associated with the seemingly simple concept of the number of methods per class. The usefulness of the proposed metrics, and others, would be greatly enhanced if clearer guidance concerning their application to specific languages were to be provided. Such empirical considerations are as important as the theoretical issues raised by the authors.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.372153","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=372153","","Software metrics;Engineering management;Software systems;Software engineering;Terminology;Application software;Information analysis;Algorithm design and analysis;Software algorithms;Software measurement","object-oriented programming;software metrics;software development management","metrics suite;object oriented design;object oriented software metrics;measurement theoretical basis;indirect metrics;number of methods per class;empirical considerations;complexity measures;software management;object orientation","","41","","7","","","","","","IEEE","IEEE Journals & Magazines"
"SOFL: a formal engineering methodology for industrial applications","Shaoying Liu; A. J. Offutt; C. Ho-Stuart; Y. Sun; M. Ohba","Fac. of Inf. Sci., Hiroshima City Univ., Japan; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","1","24","45","Formal methods have yet to achieve wide industrial acceptance for several reasons. They are not well integrated into established industrial software processes, their application requires significant abstraction and mathematical skills, and existing tools do not satisfactorily support the entire formal software development process. We have proposed a language called SOFL (Structured-Object-based-formal Language) and a SOFL methodology for system development that attempts to address these problems using an integration of formal methods, structured methods and object oriented methodology. Construction of a system uses structured methods in requirements analysis and specifications, and an object based methodology during design and implementation stages, with formal methods applied throughout the development in a manner that best suits their capabilities. The paper describes the SOFL methodology, which introduces some substantial changes from current formal methods practice. A comprehensive, practical case study of an actual industrial Residential Suites Management System illustrates how SOFL is used.","0098-5589;1939-3520;2326-3881","","10.1109/32.663996","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=663996","","Computer industry;Application software;Costs;Computer Society;Programming;Formal specifications;Sun;Software tools;Design methodology;Formal languages","formal specification;structured programming;object-oriented programming;formal languages","system development;formal engineering methodology;industrial applications;formal methods;industrial acceptance;industrial software processes;formal software development process;Structured-Object-based-formal Language;SOFL methodology;structured methods;object oriented methodology;requirements analysis;object based methodology;industrial Residential Suites Management System","","37","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Automatic mapping of system of N-dimensional affine recurrence equations (SARE) onto distributed memory parallel systems","A. Marongiu; P. Palazzari","Dept. of Electron. Eng., Rome Univ., Italy; NA","IEEE Transactions on Software Engineering","","2000","26","3","262","275","The automatic extraction of parallelism from algorithms, and the consequent parallel code generation, is a challenging problem. We present a procedure for automatic parallel code generation in the case of algorithms described through a SARE (Set of Affine Recurrence Equations). Starting from the original SARE description in an N-dimensional iteration space, the algorithm is converted into a parallel code for an (eventually virtual) m-dimensional distributed memory parallel machine (m<N). We demonstrate some theorems which are the mathematical basis for the proposed parallel generation tool. The projection technique used in the tool is based on the polytope model. Some affine transformations are introduced to project the polytope from the original iteration space onto another polytope, preserving the SARE semantic, in the time-processor (t,p) space. Points in (t,p) are individuated through the m-dimensional p coordinate and the n-dimensional t coordinate, resulting in N=n+m. Along with polytope transformation, a methodology to generate the code within processors is given. Finally, a cost function, used to guide the heuristic search for the polytope transformation and derived from the actual implementation of the method on an MPP SIMD machine, is introduced.","0098-5589;1939-3520;2326-3881","","10.1109/32.842951","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=842951","","Difference equations;Signal processing algorithms;Cost function;Parallel machines;Linear algebra;Terminology;Parallel architectures;Sufficient conditions;Solid modeling;Timing","equations;mathematics computing;parallelising compilers;distributed memory systems;heuristic programming;programming theory;parallel programming;iterative methods;search problems","automatic mapping;N-dimensional affine recurrence equations;distributed memory parallel machine;automatic parallelism extraction;automatic parallel code generation;SARE;N-dimensional iteration space;projection technique;polytope transformation;processor-time space;cost function;heuristic search;SIMD machine;massively parallel processor;automatic parallelization;affine functions","","6","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Towards a better understanding of data models through the multilingual database system","S. A. Demurjian; D. K. Hsiao","Dept. of Comput. Sci. & Eng., Connecticut Univ., Storrs, CT, USA; NA","IEEE Transactions on Software Engineering","","1988","14","7","946","958","An approach to the design of a database system, the multilingual database system (MLDS), has been proposed and implemented. MLDS is a single database system that can execute may transactions written respectively in different data languages and support many databases structured correspondingly in various data models, i.e. DL/I transactions on hierarchical databases, CODASYL-DML transactions on network databases, SQL transactions on relational databases, and Daplex transactions on functional databases. The authors describe MLDS, focusing on its motivation and structure. It is shown how MLDS, by providing an integrated environment for experimenting with data models and data languages, also serves as a testbed that provides insight to data models and data-model semantics, using qualitative and quantitative techniques. Related work on data-language comparison and analysis is indicated.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.42737","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=42737","","Data models;Database systems;Relational databases;Transaction databases;Natural languages;Computer science;Taxonomy;Marine vehicles;Testing;Information management","database management systems;query languages","query languages;multilingual database system;data languages;data models;integrated environment;data-model semantics","","20","","40","","","","","","IEEE","IEEE Journals & Magazines"
"A physical database design evaluation system for CODASYL databases","H. Lam; S. Y. W. Su; N. R. Koganti","Database Syst. Res. & Dev. Center, Florida Univ., Gainesville, FL, USA; Database Syst. Res. & Dev. Center, Florida Univ., Gainesville, FL, USA; Database Syst. Res. & Dev. Center, Florida Univ., Gainesville, FL, USA","IEEE Transactions on Software Engineering","","1988","14","7","1010","1022","An interactive design tool for designing CODASYL databases is described. The system is composed of three main modules: a user interface, a transaction analyzer, and a core module. The user interface allows a designer to enter interactively information concerning a database design which is to be evaluated. The transaction analyzer allows the designer to specify the processing requirements in terms of typical logical transactions to be executed against the database and translates these logical transaction into physical transaction which access and manipulate the physical databases. The core module is the implementation of a set of analytical models and cost formulas developed for the manipulation of indexed sequential and hash-based files and CODASYL sets. These models and formulas account for the situation in which occurrences of multiple record types are stored in the same area. Also presented are the results of a series of experiments in which key design parameters are varied. The system is implemented in UCSD Pascal running on IBM PCs.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.42741","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=42741","","Transaction databases;Analytical models;Costs;Spatial databases;Process design;User interfaces;Marine vehicles;Database systems;Research and development;Terminology","database management systems;file organisation;IBM computers;program testing;software tools;user interfaces","IBM PC;software tools;file organisation;DBMS;network data model;physical database design evaluation system;CODASYL databases;interactive design tool;user interface;transaction analyzer;core module;processing requirements;logical transactions;physical transaction;analytical models;cost formulas;multiple record types;UCSD Pascal","","2","","34","","","","","","IEEE","IEEE Journals & Magazines"
"Optimal semijoins for distributed database systems","J. K. Mullin","Dept. of Comput. Sci., Western Ont. Univ., London, Ont., Canada","IEEE Transactions on Software Engineering","","1990","16","5","558","560","A Bloom-filter-based semijoin algorithm for distributed database systems is presented. This algorithm reduces communications costs to process a distributed natural join as much as possible with a filter approach. An optimal filter is developed in pieces. Filter information is used both to recognize when the semijoin will cease to be effective and to optimally process the semijoin. An ineffective semijoin will be quickly and cheaply recognized. An effective semijoin will use all of the transmitted bits optimally.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.52778","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=52778","","Database systems;Costs;Filters;Relational databases;Distributed databases;Remuneration;Computer science","database theory;distributed databases","optimal semijoins;filter information;distributed database systems;Bloom-filter-based semijoin algorithm;communications costs;distributed natural join;optimal filter;recognize;transmitted bits","","71","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Estimation methods for nonregenerative stochastic Petri nets","P. J. Haas","IBM Res. Div., Almaden Res. Center, San Jose, CA, USA","IEEE Transactions on Software Engineering","","1999","25","2","218","236","When a computer, manufacturing, telecommunication, or transportation system is modeled as a stochastic Petri net (SPN), many long-run performance characteristics of interest can be expressed as time-average limits of the associated marking process. For nets with generally-distributed firing times, such limits often cannot be computed analytically or numerically, but must be estimated using simulation. Previous work on estimation methods for SPNs has focused on the case in which there exists a sequence of regeneration points for the marking process of the net, so that point estimates and confidence intervals for time-average limits can be obtained using the regenerative method for analysis of simulation output. This paper is concerned with SPNs for which the regenerative method is not applicable. We provide conditions on the clock-setting distributions and new-marking probabilities of an SPN under which time-average limits are well defined and the output process of the simulation obeys a multivariate functional central limit theorem. It then follows from results of Glynn and Iglehart (1990) that methods based on standardized time series can be used to obtain strongly consistent point estimates and asymptotic confidence intervals for time-average limits. In particular, the method of batch means is applicable. Moreover, the methods of Munoz and Glynn can be used to obtain point estimates and confidence intervals for ratios of time-average limits. We illustrate our results using an SPN model of an interactive video-on-demand system.","0098-5589;1939-3520;2326-3881","","10.1109/32.761447","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=761447","","Stochastic processes;Petri nets;Computer aided manufacturing;Telecommunication computing;Analytical models;Manufacturing processes;Virtual manufacturing;Transportation;Stochastic systems;Computational modeling","Petri nets;simulation;performance evaluation;discrete event systems;stochastic systems;time series;Markov processes","estimation methods;nonregenerative stochastic Petri nets;long-run performance characteristics;time-average limits;marking process;generally-distributed firing times;simulation;regeneration point sequence;point estimates;confidence intervals;clock-setting distributions;new-marking probabilities;multivariate functional central limit theorem;standardized time series;interactive video-on-demand system","","1","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Foreword Special Issue on Distributed Systems","F. Cristian; D. Skeen","NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","1","1","2","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232558","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702125","","Computer networks;Delay;Prototypes;Electronic mail;Distributed databases;Software prototyping;Manufacturing automation;Process control;Application software","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Foreword","S. Jajodia; S. K. Tripathy","NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","8","869","870","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233504","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702304","","Local area networks;Operating systems;Protocols;Resource management;Application software;Broadcasting;LAN interconnection;Microcomputers;Network servers;Prototypes","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Ergodicity and throughput bounds of Petri nets with unique consistent firing count vector","J. Campos; G. Chiola; M. Silva","Dept. de Ingenieria Electr. e Inf., Zaragoza Univ., Spain; NA; NA","IEEE Transactions on Software Engineering","","1991","17","2","117","125","Ergodicity and throughput bound characterization are addressed for a subclass of timed and stochastic Petri nets, interleaving qualitative and quantitative theories. The nets considered represent an extension of the well-known subclass of marked graphs, defined as having a unique consistent firing count vector, independently of the stochastic interpretation of the net model. In particular, persistent and mono-T-semiflow net subclasses are considered. Upper and lower throughput bounds are computed using linear programming problems defined on the incidence matrix of the underlying net. The bounds proposed depend on the initial marking and the mean values of the delays but not on the probability distributions (thus including both the deterministic and the stochastic cases). From a different perspective, the considered subclasses of synchronized queuing networks; thus, the proposed bounds can be applied to these networks.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.67593","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=67593","","Throughput;Petri nets;Stochastic processes;Probability distribution;Linear programming;Timing;Delay estimation;Interleaved codes;Vectors;Queueing analysis","linear programming;Petri nets","persistent nets;ergodicity;throughput bounds;Petri nets;unique consistent firing count vector;marked graphs;mono-T-semiflow net subclasses;linear programming;incidence matrix;synchronized queuing networks","","68","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Constructive protocol specification using Cicero","Y. -. Huang; C. V. Ravishankar","IBM Corp., Research Triangle Park, NC, USA; NA","IEEE Transactions on Software Engineering","","1998","24","4","252","267","This paper describes Cicero, a set of language constructs to allow constructive protocol specifications. Unlike other protocol specification languages, Cicero gives programmers explicit control over protocol execution, and facilitates both sequential and parallel implementations, especially for protocols above the transport-layer. It is intended to be used in conjunction with domain-specific libraries, and is quite different in philosophy and mode of use from existing protocol specification languages. A feature of Cicero is the use of event patterns to control synchrony, asynchrony, and concurrency in protocol execution, which helps programmers build robust protocol implementations. Event-pattern driven execution also enables implementers to exploit parallelism of varying grains in protocol execution. Event patterns can also be translated into other formal models, so that existing verification techniques may be used.","0098-5589;1939-3520;2326-3881","","10.1109/32.677183","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=677183","","Transport protocols;Specification languages;Programming profession;Fault tolerance;Throughput;Network synthesis;Testing;Debugging;Communication system control;Libraries","protocols;specification languages;distributed processing","protocol specification;Cicero;protocol specification languages;language constructs;protocol execution;event patterns;synchrony;asynchrony;concurrency","","","","43","","","","","","IEEE","IEEE Journals & Magazines"
"A Property of Normalization Constants for Closed Queueing Networks","H. Kameda","Department of Computer Science, University of Electro-Communications, Chofu-shi, Tokyo 182, Japan.","IEEE Transactions on Software Engineering","","1984","SE-10","6","856","857","A property of the normalization constants for closed single-class product-form queueing networks is derived under the condition that the service rate at each service center is not decreasing with the increase of the number of jobs staying at the center. The result implies that the throughput at each service center is monotonically increasing with the increase of the total number of jobs contained in the queueing network considered.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010314","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010314","Closed queueing networks;load dependent servers;normalization constants;product form;throughput","Throughput;Computer science","","","","","","1","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on: evaluating alternative software production functions","L. Pickard; B. Kitchenham; P. Jones; Qing Hu","Dept. of Comput. Sci., Keele Univ., UK; NA; NA; NA","IEEE Transactions on Software Engineering","","1999","25","2","282","285","Software development projects are notorious for cost overruns and schedule delays. While dozens of software cost models have been proposed, few of them seem to have any degree of consistent accuracy. One major factor contributing to this persistent and widespread problem is an inadequate understanding of the real behavior of software development processes. We believe that software development could be studied as an economic production process and that established economic theories and methods could be used to develop and validate software production and cost models. We present the results of evaluating four alternative software production models using the P-test, a statistical procedure developed specifically for testing the truth of a hypothesis in the presence of alternatives in econometric studies. We found that the truth of the widely used Cobb-Douglas type of software production and cost models (e.g., COCOMO) cannot be maintained in the presence of quadratic or translog models. Overall, the quadratic software production function is shown to be the most plausible model for representing software production processes. Limitations of this study and future directions are also discussed.","0098-5589;1939-3520;2326-3881","","10.1109/32.761451","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=761451","","Production;Econometrics;Parameter estimation;Programming;Cost function;Software testing;Delay;Software maintenance;Maintenance engineering;Data engineering","software cost estimation;project management;economic cybernetics;statistical analysis;economics","alternative software production function evaluation;software development projects;cost overruns;schedule delays;software cost models;software development process behavior;economic production process;economic theories;software production models;P-test;statistical procedure;hypothesis testing;econometric studies;Cobb-Douglas type model;COCOMO;translog models;quadratic software production function;software production processes","","8","","7","","","","","","IEEE","IEEE Journals & Magazines"
"Approximate reasoning about the semantic effects of program changes","M. Moriconi; T. C. Winkler","SRI Int., Menlo Park, CA, USA; SRI Int., Menlo Park, CA, USA","IEEE Transactions on Software Engineering","","1990","16","9","980","992","It is pointed out that the incremental cost of a change to a program is often disproportionately high because of inadequate means of determining the semantic effects of the change. A practical logical technique for finding the semantic effects of changes through a direct analysis of the program is presented. The programming language features considered include parametrized modules, procedures, and global variables. The logic described is approximate in that weak (conservative) results sometimes are inferred. Isolating the exact effects of a change is undecidable in general. The basis for an approximation is a structural interpretation of the information-flow relationships among program objects. The approximate inference system is concise, abstract, extensible, and decidable, giving it significant advantages over the main alternative formalizations. The authors' implementation of the logic records the justification for each dependency to facilitate the interpretation of results.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.58785","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=58785","","Costs;Computer languages;Logic programming;Marine vehicles;Information analysis;Specification languages;Computer science;Functional programming","formal specification;inference mechanisms;program verification","approximate reasoning;semantic effects;program changes;logical technique;direct analysis;parametrized modules;procedures;global variables;structural interpretation;inference system","","19","","34","","","","","","IEEE","IEEE Journals & Magazines"
"Software Reliability: The Stopping Rule Problem","S. M. Ross","Department of Industrial Engineering and Operations Research, University of California","IEEE Transactions on Software Engineering","","1985","SE-11","12","1472","1476","When a new computer software package is developed and all obvious erros removed, a testing procedure is often put into effect to eliminate the remaining errors in the package. One common procedure is to try the package on a set of randomly chosen problems. We suppose that whenever a program encounters an error, a system failure results. At this point the software is inspected to determine and remove the error responsible for the failure. This goes on for some time and two problems of interest are 1) to estimate the error rate of the software at a given time t, and 2) to develop a stopping rule for determining when to discontinue the testing and declare that the software is ready for use. In this paper, a model for the above is proposed as an estimation and stopping rule procedure.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231891","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701970","Failure rates;software reliability;stopping times","Software reliability;Computer errors;Software packages;Software testing;Packaging;Error analysis;Random variables;Industrial engineering;Operations research;Reactive power","","Failure rates;software reliability;stopping times","","15","","3","","","","","","IEEE","IEEE Journals & Magazines"
"Current trends in exception handling","D. E. Perry; A. Romanovsky; A. Tripathi","University of Texas at Austin; NA; NA","IEEE Transactions on Software Engineering","","2000","26","9","817","819","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.2000.877843","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=877843","","Computer languages;Operating systems;Object oriented modeling;Robustness;Computer science;Computer Society;Software design;Software systems;Reliability engineering","","","","3","","2","","","","","","IEEE","IEEE Journals & Magazines"
"Measuring the Productivity of Computer Systems Development Activities with Function Points","C. A. Behrens","Cooper, Behrens and McMullen, Inc.","IEEE Transactions on Software Engineering","","1983","SE-9","6","648","652","The function point method of measuring application development productivity developed by Albrecht is reviewed and a productivity improvement measure introduced. The measurement methodology is then applied to 24 development projects. Size, environment, and language effects on productivity are examined. The concept of a productivity index which removes size effects is defined and an analysis of the statistical significance of results is presented.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.235429","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703111","Development;function points;measurement;productivity","Productivity;Application software;Particle measurements;Data processing;Costs;Investments;Programming profession;Measurement techniques","","Development;function points;measurement;productivity","","49","","7","","","","","","IEEE","IEEE Journals & Magazines"
"The AETG system: an approach to testing based on combinatorial design","D. M. Cohen; S. R. Dalal; M. L. Fredman; G. C. Patton","IDA Center for Comput. Sci., Bowie, MD, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1997","23","7","437","444","This paper describes a new approach to testing that uses combinatorial designs to generate tests that cover the pairwise, triple, or n-way combinations of a system's test parameters. These are the parameters that determine the system's test scenarios. Examples are system configuration parameters, user inputs and other external events. We implemented this new method in the AETG system. The AETG system uses new combinatorial algorithms to generate test sets that cover all valid n-way parameter combinations. The size of an AETG test set grows logarithmically in the number of test parameters. This allows testers to define test models with dozens of parameters. The AETG system is used in a variety of applications for unit, system, and interoperability testing. It has generated both high-level test plans and detailed test cases. In several applications, it greatly reduced the cost of test plan development.","0098-5589;1939-3520;2326-3881","","10.1109/32.605761","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=605761","","System testing;Application software;Telephony;Costs;Computer Society;Design for experiments;Programming;Software testing;Asynchronous transfer mode;Monitoring","program testing;software tools;open systems;software cost estimation","AETG system;software testing;combinatorial design;system test parameters;test scenarios;system configuration parameters;user inputs;test set generation;n-way parameter combination;pairwise parameter combination;triple parameter combination;interoperability testing;unit testing;system testing;high-level test plans","","470","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Expert systems and optimization","A. Kusiak","Dept. of Ind. & Manage. Eng., Iowa Univ., Iowa City, IA, USA","IEEE Transactions on Software Engineering","","1989","15","8","1017","1020","A problem-solving approach involving the integration of expert systems and optimization techniques is presented. A class of expert systems called tandem expert systems is introduced. Three variants of the tandem expert system, the data-reducing, model-based, and model-modifying expert systems, are explained with examples. It is emphasized that optimization techniques can be used more frequently in future expert systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.31358","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=31358","","Expert systems;Operations research;Heuristic algorithms;Mathematical model;Manufacturing;Problem-solving;Large-scale systems;Industrial plants;Humans;Optimization methods","expert systems;optimisation;problem solving","data-reducing expert system;model-based expert systems;model-modifying expert systems;problem-solving;optimization techniques;tandem expert systems;future expert systems","","9","","6","","","","","","IEEE","IEEE Journals & Magazines"
"Validating Halstead's theory with system 3 data","M. Trachtenberg","RCA Corporation, Moorestown, NJ 08057","IEEE Transactions on Software Engineering","","1986","SE-12","4","584","584","Gaffney (ibid., vol.SE-10, no.7, pp.459-463, 1984) concludes that the number of faults per line of code is independent of whether Assembly language or a high order language is used. This is contrary to the results published by the commenter (ibid. vol.SE-8, pp.437-439, July 1982). It is contended that the paper by Gaffney contains some technical errors and uses erroneous data. An explanation of the source of the erroneous data is given. Also, previously published information by the commenter on the average number of operators plus operands per line of Assembly language code is corrected.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312906","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312906","","Software;Assembly;Software reliability;Programming;Psychology;Predictive models;System testing","programming theory","faults per line of code;Assembly language;high order language;average number of operators;operands per line","","1","","","","","","","","IEEE","IEEE Journals & Magazines"
"Foreword Computers Come and Go But Data Go On Forever","P. B. Berra","NA","IEEE Transactions on Software Engineering","","1985","SE-11","7","573","573","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232500","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702060","","Data engineering;Hardware;Knowledge management;Engineering management;Computer aided manufacturing;Relational databases;Manufacturing processes;Optimal control;Management information systems;Power engineering computing","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Is proof more cost-effective than testing?","S. King; J. Hammond; R. Chapman; A. Pryor","Dept. of Comput. Sci., York Univ., UK; NA; NA; NA","IEEE Transactions on Software Engineering","","2000","26","8","675","686","The paper describes the use of formal development methods on an industrial safety-critical application. The Z notation was used for documenting the system specification and part of the design, and the SPARK subset of Ada was used for coding. However, perhaps the most distinctive nature of the project lies in the amount of proof that was carried out: proofs were carried out both at the Z level (approximately 150 proofs in 500 pages) and at the SPARK code level (approximately 9000 verification conditions generated and discharged). The project was carried out under UK Interim Defence Standards 00-55 and 00-56, which require the use of formal methods on safety-critical applications. It is believed to be the first to be completed against the rigorous demands of the 1991 version of these standards. The paper includes comparisons of proof with the various types of testing employed, in terms of their efficiency at finding faults. The most striking result is that the Z proof appears to be substantially more efficient at finding faults than the most efficient testing phase. Given the importance of early fault detection, we believe this helps to show the significant benefit and practicality of large-scale proof on projects of this kind.","0098-5589;1939-3520;2326-3881","","10.1109/32.879807","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=879807","","Sparks;Helicopters;Formal specifications;Marine vehicles;Information systems;Fault detection;Large-scale systems;Software testing;Computer industry;Code standards","safety-critical software;formal specification;theorem proving;Ada;program testing;military computing","formal development methods;industrial safety-critical application;Z notation;system specification;SPARK subset;Ada;Z level;SPARK code level;verification conditions;UK Interim Defence Standards;00-55;00-56;formal methods;safety-critical applications;rigorous demands;Z proof;testing phase;fault detection;large-scale proof","","35","","","","","","","","IEEE","IEEE Journals & Magazines"
"Repository evaluation of software reuse","R. D. Banker; R. J. Kauffman; D. Zweig","Dept. of Accounting & Inf. Syst., Minnesota Univ., Minneapolis, MN, USA; NA; NA","IEEE Transactions on Software Engineering","","1993","19","4","379","389","The use and benefits of repository evaluation of software reuse are illustrated through an analysis of the evolving repositories of two large firms that recently implemented integrated CASE development tools. The analysis shows that these tools have supported high levels of software reuse, but it also suggests that there remains considerable unexploited reuse potential. The findings indicate that organizational changes will be required before the full potential of the new technology can be realized.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.223805","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=223805","","Computer aided software engineering;Software tools;Software quality;Project management;Application software;Productivity;Computerized monitoring;Costs;Software maintenance;Control system analysis","programming environments;software reusability","software reuse;repository evaluation;integrated CASE development tools;organizational changes","","40","","47","","","","","","IEEE","IEEE Journals & Magazines"
"Validation of an approach for improving existing measurement frameworks","M. G. Mendonca; V. R. Basili","Comput. Networks Res. Group, Salvador Univ., Brazil; NA","IEEE Transactions on Software Engineering","","2000","26","6","484","499","Software organizations are in need of methods to understand, structure, and improve the data their are collecting. We have developed an approach for use when a large number of diverse metrics are already being collected by a software organization (M.G. Mendonca et al., 1998; M.G. Mendonca, 1997). The approach combines two methods. One looks at an organization's measurement framework in a top-down goal-oriented fashion and the other looks at it in a bottom-up data-driven fashion. The top-down method is based on a measurement paradigm called Goal-Question-Metric (GQM). The bottom-up method is based on a data mining technique called Attribute Focusing (AF). A case study was executed to validate this approach and to assess its usefulness in an industrial environment. The top-down and bottom-up methods were applied in the customer satisfaction measurement framework at the IBM Toronto Laboratory. The top-down method was applied to improve the customer satisfaction (CUSTSAT) measurement from the point of view of three data user groups. It identified several new metrics for the interviewed groups, and also contributed to better understanding of the data user needs. The bottom-up method was used to gain new insights into the existing CUSTSAT data. Unexpected associations between key variables prompted new business insights, and revealed problems with the process used to collect and analyze the CUSTSAT data. The paper uses the case study and its results to qualitatively compare our approach against current ad hoc practices used to improve existing measurement frameworks.","0098-5589;1939-3520;2326-3881","","10.1109/32.852739","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=852739","","Software measurement;Customer satisfaction;Data mining;Laboratories;Software maintenance;Data analysis;Current measurement;Knowledge management;Software development management;Time measurement","data mining;DP industry;software metrics;software quality","business insights;data user needs;CUSTSAT measurement;customer satisfaction measurement framework;industrial environment;case study;Attribute Focusing;data mining technique;Goal-Question-Metric;measurement paradigm;bottom-up data-driven method;top-down goal-oriented method;diverse metrics;software organizations;measurement frameworks","","34","","55","","","","","","IEEE","IEEE Journals & Magazines"
"View Modeling and Integration Using the Functional Data Model","S. B. Yao; V. E. Waddle; B. C. Housel","Database Systems Research Center, College of Business and Management, University of Maryland; NA; NA","IEEE Transactions on Software Engineering","","1982","SE-8","6","544","553","Conventional database design techniques rely heavily on the designer's skill and experience, which are neither efficient nor effective for large, realistic design problems. A computer design aid can help by storing many design parameters and performing simple preprocessing before design decisions are made. In this paper, we report on the development of such a system.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235883","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702987","Database design;database model;database system;data conversion;program conversion;requirement analysis;requirement specification;transaction","Data models;Transaction databases;Spatial databases;Heuristic algorithms;Database systems;Process design;Specification languages;Algorithm design and analysis;Filters;Data conversion","","Database design;database model;database system;data conversion;program conversion;requirement analysis;requirement specification;transaction","","22","","27","","","","","","IEEE","IEEE Journals & Magazines"
"When to stop testing for large software systems with changing code","S. R. Dalal; A. A. McIntosh","Inf. Sci. & Technol. Lab., Bellcore, Morristown, NJ, USA; Inf. Sci. & Technol. Lab., Bellcore, Morristown, NJ, USA","IEEE Transactions on Software Engineering","","1994","20","4","318","323","Developers of large software systems must decide how long software should be tested before releasing it. A common and usually unwarranted assumption is that the code remains frozen during testing. We present a stochastic and economic framework to deal with systems that change as they are tested. The changes can occur because of the delivery of software as it is developed, the way software is tested, the addition of fixes, and so on. Specifically, we report the details of a real time trial of a large software system that had a substantial amount of code added during testing. We describe the methodology, give all of the relevant details, and discuss the results obtained. We pay particular attention to graphical methods that are easy to understand, and that provide effective summaries of the testing process. Some of the plots found useful by the software testers include: the Net Benefit Plot, which gives a running chart of the benefit; the Stopping Plot, which estimates the amount of additional time needed for testing; and diagnostic plots. To encourage other researchers to try out different models, all of the relevant data are provided.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.277579","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=277579","","Software testing;System testing;Software systems;Costs;Fault detection;Stochastic systems;Real time systems;Software metrics;Software reliability;Lead","program testing;software metrics;software reliability;computer graphics","large software systems;changing code;economic framework;real time trial;software testers;Net Benefit Plot;Stopping Plot;diagnostic plots;optimal stopping rule;graphical methods;software metrics;statistical inference;software reliability model;software fault detection","","35","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Connectors for mobile programs","M. Wermelinger; J. L. Fiadeiro","Dept. de Inf., Lisbon Univ., Portugal; NA","IEEE Transactions on Software Engineering","","1998","24","5","331","341","Software architecture has put forward the concept of connector to express complex relationships between system components, thus facilitating the separation of coordination from computation. This separation is especially important in mobile computing due to the dynamic nature of the interactions among participating processes. We present connector patterns, inspired in Mobile UNITY, that describe three basic kinds of transient interactions: action inhibition, action synchronization, and message passing. The connectors are given in COMMUNITY, a UNITY-like program design language which has a semantics in category theory. We show how the categorical framework can be used for applying the proposed connectors to specific components and how the resulting architecture can be visualized by a diagram showing the components and the connectors.","0098-5589;1939-3520;2326-3881","","10.1109/32.685257","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=685257","","Connectors;Computer architecture;Mobile computing;Message passing;Software architecture;Visualization;Software systems;Proposals;Quantum computing;Computational modeling","software engineering;diagrams;portable computers;message passing;synchronisation;category theory;software portability;high level languages","mobile programs;software architecture;connectors;system components;coordination;computation;mobile computing;connector patterns;Mobile UNITY;action inhibition;action synchronization;message passing;COMMUNITY;category theory;diagram","","27","","14","","","","","","IEEE","IEEE Journals & Magazines"
"An intelligent tutoring system for the Dijkstra-Gries methodology","F. Ng; G. Butler; J. Kay","ISSC Australia, Sydney, NSW, Australia; NA; NA","IEEE Transactions on Software Engineering","","1995","21","5","415","428","The paper describes the design and implementation of an intelligent tutoring system for the Dijkstra-Gries programming methodology as defined by Gries (1981) in ""The Science of Programming"". The first part of the paper identifies the requirements of intelligent tutoring systems in general and those of the methodology in particular. It shows the suitability of the Smalltalk environment for developing expandable intelligent systems and the compatibility of Smalltalk's object-oriented paradigm with the Gries methodology's goal/plan approach to programming. We then describe how these requirements are met: an overview of the system's support of the methodology and the modules that enable the system to respond intelligently. As an example, a reusable tutorial part is presented, first from a student's perspective, then from an author's perspective. Finally the results of an evaluation of the system drawn from actual student experience are presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.387471","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=387471","","Intelligent systems;Object oriented programming;Logic programming;Libraries;Mathematical programming;Algebra;Education;Parallel programming;Computer science;Object oriented modeling","intelligent tutoring systems;Smalltalk;knowledge engineering;software reusability;object-oriented programming;object-oriented methods;computer science education","intelligent tutoring system;Dijkstra-Gries programming methodology;requirements;Smalltalk environment;expandable intelligent systems development;object-oriented paradigm;system support;modules;reusable tutorial part;student's perspective;author's perspective;actual student experience;system evaluation","","3","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Towards a Formal Basis for the Formal Development Method and the Ina Jo Specification Language","D. M. Berry","SDC, A Burroughs Company, Santa Monica, CA. 90405, and the Department of Computer Science, University of California","IEEE Transactions on Software Engineering","","1987","SE-13","2","184","201","In carrying out SDC's Formal Development Method, one writes a specification of a system under design in the Ina Jo&#8482; specification language and proves that the specification meets the requirements of the system. This paper develops an abstract machine model of what is specified by a level specification in an Ina Jo specification. It describes the state as defined by the front matter, computations as defined by initial states and transforms, and invariants, criteria, and constraints as properties of computations. The paper then describes a number of formal design methods and the kinds of abstractions that they require. For each of these kinds of abstractions, there is a characteristic relationship between refinements that should be proved as one is carrying out the method.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232891","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702199","Abstract machine;correctness;formal specification;invariants;refinement methods;simulation;verification","Specification languages;Formal specifications;Design methodology;Computer security;Computer science;Trademarks;Humans;Contracts","","Abstract machine;correctness;formal specification;invariants;refinement methods;simulation;verification","","2","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Performance of MAP in the remote operation of a CNC","B. Mortazavi","Lab. d'Inf. Tech., Ecole Polytech. Federale de Lausanne, Switzerland","IEEE Transactions on Software Engineering","","1990","16","2","231","237","A major issue for the users of the Manufacturing Automation Protocol (MAP) is its performance in servicing time-critical applications. The author describes an experiment in which a computerized numerical controller (CNC) is remotely operated using MAP. A set of critical timing parameters is defined, a performance analysis of the system from the user's point of view is carried out, and a comparison with other similar systems is made. The transfer time between two front-end processors, implementing the seven MAP layers, for a 100-byte-long message is found to be about 18 ms, and the transfer time for the same message between two user processes on the hosts is about 40 ms.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44386","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44386","","Computer numerical control;Performance analysis;Protocols;Application software;Open systems;Software performance;EMP radiation effects;Manufacturing;Timing","computerised numerical control;program testing;protocols","MAP performance analysis;remote operation;Manufacturing Automation Protocol;servicing time-critical applications;computerized numerical controller;CNC;critical timing parameters;transfer time;front-end processors","","3","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Auditing and Inference Control in Statistical Databases","F. Y. Chin; G. Ozsoyoglu","Department of Computer Science, University of Alberta; NA","IEEE Transactions on Software Engineering","","1982","SE-8","6","574","582","A statistical database (SDB) may be defined as an ordinary database with the capability of providing statistical information to user queries. The security problem for the SDB is to limit the use of the SDB so(that only statistical information is available and no sequence of queries is sufficient to infer protected information about any individual. When such information is obtained, the SDB is said to be compromised.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.236161","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702991","Auditing;inference control;security;statistical databases","Databases;Protection;Data security;Information security;Sampling methods;Data models;History;Frequency;Councils","","Auditing;inference control;security;statistical databases","","77","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Approximate analysis of load dependent general queueing networks","I. F. Akyildiz; A. Sieber","Dept. of Comput. Sci., Louisiana State Univ., Baton Rouge, LA, USA; Dept. of Comput. Sci., Louisiana State Univ., Baton Rouge, LA, USA","IEEE Transactions on Software Engineering","","1988","14","11","1537","1545","A method for obtaining approximate solutions to load-dependent closed queueing networks containing general service-time distributions and first-come-first-served scheduling disciplines is presented. The technique demonstrated is an extension of the well-known method of R. Marie (1979). A formula for the conditional throughputs is derived. After each iteration a check is performed to guarantee that the results obtained are within a tolerance level epsilon . These iterations are repeated whenever invalid results are detected. On the average, the solutions obtained vary by less than 5% from their respective exact and simulation results.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9042","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9042","","Queueing analysis;Computer science;Throughput;Computational modeling;Performance analysis;Computer networks;Communication networks;Computational efficiency;Predictive models;Computer architecture","performance evaluation;queueing theory;scheduling","performance evaluation;queueing networks;load-dependent;service-time distributions;scheduling;conditional throughputs;tolerance level","","12","","39","","","","","","IEEE","IEEE Journals & Magazines"
"Rule-based design methodology for solving control problems","F. A. Etessami; G. S. Hura","Dept. of Comput. Sci. & Eng., Wright State Univ., Dayton, OH, USA; Dept. of Comput. Sci. & Eng., Wright State Univ., Dayton, OH, USA","IEEE Transactions on Software Engineering","","1991","17","3","274","282","A rule-based design methodology for solving control problems is presented. For the representation of various constraints, activities, and other dependency properties of the control problem, abstract Petri nets (APNs) which are an extended form of Petri net modeling are used as a specification and formalism tool which can be analyzed using the analysis techniques of Petri-net-based models. The APN provides a compact, consistent, and verifiable description of the dynamic behaviour of the system under consideration in a structured mode. The proposed design methodology supports specification, validation, and analysis through high-level interaction with the modeled system. The various steps which were taken towards the development of such a design paradigm are explained. An example which shows the APN modeling of an elevator system is given.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.75416","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=75416","","Design methodology;Petri nets;Power system modeling;Computer science;Student members;Problem-solving;Performance evaluation;Protocols;Information systems;Joining processes","formal specification;knowledge engineering;Petri nets;software tools","control problems;rule-based design methodology;abstract Petri nets;specification;formalism tool;dynamic behaviour;validation;high-level interaction;elevator system","","12","","17","","","","","","IEEE","IEEE Journals & Magazines"
"A decomposition of a formal specification: an improved constraint-oriented method","Kentaro Go; N. Shiratori","Dept. of Comput. Sci., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA; NA","IEEE Transactions on Software Engineering","","1999","25","2","258","273","In this paper, the authors propose a decomposition method for a formal specification that divides the specification into two subspecifications composed by a parallel operator. To make these specification behaviors equivalent before and after decomposition, the method automatically synthesizes an additional control specification, which contains the synchronization information of the decomposed subspecifications. The authors prove that a parallel composition of the decomposed subspecifications synchronized with the control specification is strongly equivalent with the original (monolithic) specification. The authors also write formal specifications of the OSI application layer's association-control service and decompose it using their method as an example of decomposition of a practical specification. Their decomposition method can be applied to top-down system development based on stepwise refinement.","0098-5589;1939-3520;2326-3881","","10.1109/32.761449","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=761449","","Formal specifications;Automatic control;Open systems;Protocols;Computer Society;System analysis and design;Costs;Collaborative software;Collaborative work;Productivity","formal specification","formal specification decomposition;improved constraint-oriented method;subspecifications;parallel operator;equivalent specification behavior;control specification;parallel composition;OSI application layer association-control service;top-down system development;stepwise refinement","","3","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Executable logic specifications for protocol service interfaces","D. P. Sidhu; C. S. Crall","Dept. of Comput. Sci., Iowa State Univ., Ames, IA, USA; Dept. of Comput. Sci., Iowa State Univ., Ames, IA, USA","IEEE Transactions on Software Engineering","","1988","14","1","98","112","A general, formal modeling technique for protocol service interfaces is discussed. An executable description of the model using a logic-programming-based language, Prolog, is presented. The specification of protocol layers consists of two parts, the specification of the protocol interfaces and the specification of entities within the protocol layer. The specification of protocol interfaces forms the standard against which protocols are verified. When a protocol has been implemented, the correctness of its implementation can be tested using the sequences of events generated at the service interface. If the behavior of the protocol implementation is consistent with the behavior at the service interface, the implementation conforms to its standard. To illustrate how it works, the model is applied to the service interfaces of protocol standards developed for the transport layer of the ISO/OSI architecture. The results indicate that Prolog is a very useful formal language for specifying protocol interfaces.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4626","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4626","","Logic programming;ISO standards;Open systems;Computer science;Prototypes;Testing;Transport protocols;Standards development;NIST;Data communication","formal languages;PROLOG;protocols;specification languages","executable logic specifications;protocol service interfaces;formal modeling technique;logic-programming-based language;Prolog;protocol layers;correctness;protocol standards;transport layer;ISO/OSI;formal language","","14","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Local Distributed Deadlock Detection by Cycle Detection and Clusterng","I. Cidon; J. M. Jaffe; M. Sidi","IBM Thomas J. Watson Research Center; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","1","3","14","A distributed algorithm for the detection of deadlocks in store-and-forward communication networks is presented. At first, we focus on a static environment and develop an efficient knot detection algorithm for general graphs. The knot detection algorithm uses at most O(n<sup>2</sup>+ m) messages and O(log (n)) bits of memory to detect all deadlocked nodes in the static network. Using the knot detection algorithm as a building block, a deadlock detection algorithm in a dynamic environment is developed. This algorithm has the following properties: It detects all the nodes which cause the deadlock. The algorithm is triggered only when there is a potential for deadlock and only those nodes which are potentially deadlocked perform the algorithm. The algorithm does not affect other processes at the nodes.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232560","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702127","Clustering;computer networks;cycle detection;deadlock detection;distributed algorithms","System recovery;Detection algorithms;Distributed algorithms;Computer networks;Buffer storage;Software algorithms;Communication networks;Distributed computing;Cities and towns","","Clustering;computer networks;cycle detection;deadlock detection;distributed algorithms","","8","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Modeling a Multiprocessor Architecture","J. R. Menand; M. Becker","Institut de Programmation, L. A. 248, Universit&#233;Pierre et Marie Curie; NA","IEEE Transactions on Software Engineering","","1983","SE-9","2","201","210","Instead of using a very expensive and powerful central processing unit, the Hypercube F8 uses independent parallel microprocessors that are slow and inexpensive. This architecture is modeled in order to determine the proper number of microprocessors and to validate the system. The model is hierarchical. Different levels of the model are considered. Each level model corresponds to a subsystem of the Hypercube F8. Most of the common analytical methods are used and direct calculations are made. For each level several methods are compared and the approximations validated. The level 1 direct method is a general solution of polling models. The global model gives the throughput of the system the utilizations of the processors and the service times. We discuss the values of the parameters of the system.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236598","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703038","Computer modeling;computer performance evaluation;distributed computing;multiprocessing;parallel architecture;parallel processing;polling;queueing analysis","Power system modeling;Microprocessors;Computer architecture;Central Processing Unit;Hypercubes;Throughput;Computer performance;Distributed computing;Parallel architectures;Parallel processing","","Computer modeling;computer performance evaluation;distributed computing;multiprocessing;parallel architecture;parallel processing;polling;queueing analysis","","1","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Local Area Networks: Software and Related Issues","S. K. Tripathi; Yennun Huang; S. Jajodia","UMIACS and the Department of Computer Science, University of Maryland; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","8","872","879","In this paper, we present a review of the issues that affect the software requirements for a local area network. We introduce protocols for the local area networks and characterize their software needs. Two approaches to operating systems are outlined and examples of each approach are presented. Various applications which use local area networks and performance issues are also discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233506","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702306","LAN software;local area networks;network operating systems;protocols;remote procedure calls","Local area networks;Protocols;Operating systems;Application software;Software performance;Computer networks;System software;Delay;Computer architecture;Communication system software","","LAN software;local area networks;network operating systems;protocols;remote procedure calls","","","","75","","","","","","IEEE","IEEE Journals & Magazines"
"Architectural tradeoffs for a meaning-preserving program restructuring tool","W. G. Griswold; D. Notkin","Dept. of Comput. Sci. & Eng., California Univ., San Diego, La Jolla, CA, USA; NA","IEEE Transactions on Software Engineering","","1995","21","4","275","287","Maintaining the consistency of multiple program representations in a program manipulation tool is difficult. I describe a hybrid software architecture for a meaning-preserving program restructuring tool. Layering is the primary architectural paradigm, which successively provides increasingly integrated and unified abstract machines to implement the tool. However, layering does not provide adequate control over extensibility or the independence of components, so I also adopt the paradigm of keeping the key program abstractions separate throughout the layering, providing independent columns of abstract data types. A pair of columns is integrated by a mapping column that translates elements in one column's data type into related elements in the other column's data type. Thus, integration of function and separation of representation can be achieved simultaneously. This hybrid architecture was crucial in overcoming severe performance problems that became apparent once the basic tool was completed. By taking advantage of the independence of the columns and the special characteristics of meaning-preserving restructuring, it was possible to extend one representation column of the architecture to the uppermost layer to provide the required access for efficient updating without compromising independence. The cost of the extended architecture is that the upper layers are no longer as simple because they expose operations that only guarantee consistency under careful usage. However, the structural constraints of the hybrid architecture and the models for building the more complicated layers minimizes the negative impact of this tradeoff.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.385967","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=385967","","Computer architecture;Operating systems;Tree graphs;Computer science;Software architecture;Costs;Buildings;Software design;Software systems;Protocols","software tools;computer aided software engineering;abstract data types;program compilers","architectural tradeoffs;meaning-preserving program restructuring tool;consistency maintenance;multiple program representations;program manipulation tool;hybrid software architecture;layering;performance problems;abstract machines;extensibility;component independence;key program abstractions;abstract data type columns;mapping column;updating;structural constraints;software design;modularization;system evolution;layered systems","","15","","36","","","","","","IEEE","IEEE Journals & Magazines"
"A procedure for analyzing unbalanced datasets","B. Kitchenham","Dept. of Comput. Sci., Keele Univ., UK","IEEE Transactions on Software Engineering","","1998","24","4","278","301","This paper describes a procedure for analyzing unbalanced datasets that include many nominal- and ordinal-scale factors. Such datasets are often found in company datasets used for benchmarking and productivity assessment. The two major problems caused by lack of balance are that the impact of factors can be concealed and that spurious impacts can be observed. These effects are examined with the help of two small artificial datasets. The paper proposes a method of forward pass residual analysis to analyze such datasets. The analysis procedure is demonstrated on the artificial datasets and then applied to the COCOMO dataset. The paper ends with a discussion of the advantages and limitations of the analysis procedure.","0098-5589;1939-3520;2326-3881","","10.1109/32.677185","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=677185","","Data analysis;Productivity;Cause effect analysis;Analysis of variance;Statistical analysis;Software quality;Computer Society;Computer industry;Software measurement;Assembly","software metrics","unbalanced datasets;benchmarking;productivity assessment;COCOMO dataset;forward pass residual analysis;software metrics;statistical analysis;analysis of variance;residual analysis","","66","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Discarding Obsolete Information in a Replicated Database System","S. K. Sarin; N. A. Lynch","Computer Corporation of America; NA","IEEE Transactions on Software Engineering","","1987","SE-13","1","39","47","A replicated database architecture is described in which updates processed at a site must be saved to allow reconcilliation of newly arriving updates in a way that preserves mutual consistency. The storage space occupied by the saved updates increases indefinitely, and periodic discarding of old updates is needed to avoid running out of storage. A protocol is described which allows sites in the system to agree that updates older than a given timestamp are no longer needed and can be discarded. This protocol uses a ""distributed snapshot"" algorithm of Chandy and Lamport and represents a practical application of that algorithm. A protocol for permanent removal of sites is also described, which will allow the discarding of updates to continue when one or more sites crash and are expected not to recover.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232564","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702131","Distributed databases;distributed snapshots;mutual consistency;network partitions;replicated data;timestamps","Database systems;Protocols;Pipelines;Partitioning algorithms;Computer crashes;Distributed databases;Availability;Government;Computer science;Protection","","Distributed databases;distributed snapshots;mutual consistency;network partitions;replicated data;timestamps","","19","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Key Concepts of the INCAS Multicomputer Project","J. Nehmer; D. Haban; F. Mattern; D. Wybranietz; H. D. Rombach","Department of Computer Science, University of Kaiserslautern; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","8","913","923","This paper gives an overview of the INCAS (INCremental Architecture for distributed Systems) multicomputer project, which aims at the development of a comprehensive methodology for the design and implementation of locally distributed systems. A structuring concept for distributed operating systems has been developed and integrated into the system implementation language LADY. The concurrent high-level programming language CSSA, based on the actor model, has been designed for the implementation of distributed applications. A substantial effort in the INCAS project is directed towards the development of a distributed test methodology. An experimental system has been implemented on a network of ten MC68000 microcomputers. Preliminary experience with the methodology has been gained from a small number of prototype applications.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233510","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702310","Distributed operating systems;distributed programming languages;distributed systems;distributed testing;message passing;multicast communication;multicomputer","Operating systems;Application software;Design methodology;Computer languages;System testing;Computer science;Runtime;Microcomputers;Prototypes;Message passing","","Distributed operating systems;distributed programming languages;distributed systems;distributed testing;message passing;multicast communication;multicomputer","","15","","41","","","","","","IEEE","IEEE Journals & Magazines"
"Specification and analysis of system architecture using Rapide","D. C. Luckham; J. J. Kenney; L. M. Augustin; J. Vera; D. Bryan; W. Mann","Comput. Syst. Lab., Stanford Univ., CA, USA; Comput. Syst. Lab., Stanford Univ., CA, USA; Comput. Syst. Lab., Stanford Univ., CA, USA; Comput. Syst. Lab., Stanford Univ., CA, USA; Comput. Syst. Lab., Stanford Univ., CA, USA; Comput. Syst. Lab., Stanford Univ., CA, USA","IEEE Transactions on Software Engineering","","1995","21","4","336","354","Rapide is an event-based, concurrent, object-oriented language specifically designed for prototyping system architectures. Two principle design goals are: (1) to provide constructs for defining executable prototypes of architectures and (2) to adopt an execution model in which the concurrency, synchronization, dataflow, and timing properties of a prototype are explicitly represented. This paper describes the partially ordered event set (poset) execution model and outlines with examples some of the event-based features for defining communication architectures and relationships between architectures. Various features of Rapide are illustrated by excerpts from a prototype of the X/Open distributed transaction processing reference architecture.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.385971","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=385971","","Object oriented modeling;Prototypes;Timing;Computer architecture;Concurrent computing;System testing;Desktop publishing;Virtual prototyping;Discrete event simulation;Analytical models","software prototyping;transaction processing;distributed processing;object-oriented languages;specification languages;synchronisation;open systems;parallel languages;formal specification","Rapide;system architecture prototyping;event-based concurrent object-oriented language;executable prototypes;execution model;specification language;synchronization;dataflow;timing properties;partially ordered event set;poset execution model;communication architectures;X/Open distributed transaction processing reference architecture;architecture definition language;simulation;formal constraints;constraint-based specification;event patterns;causality","","314","","43","","","","","","IEEE","IEEE Journals & Magazines"
"SARA (System ARchitects Apprentice): Modeling, analysis, and simulation support for design of concurrent systems","G. Estrin; R. S. Fenchel; R. R. Razouk; M. K. Vernon","Department of Computer Science, University of California, Los Angeles, CA 90024; Department of Computer Science, University of Wisconsin-Madison, Madison, WI 53706; Department of Information and Computer Science, University of California, Irvine, CA 92664; Department of Computer Science, University of Wisconsin-Madison, Madison, WI 53706","IEEE Transactions on Software Engineering","","1986","SE-12","2","293","311","An environment to support designers in the modeling, analysis, and simulation of concurrent systems is described. It is shown how a fully nested structure model supports multilevel design and focuses attention on the interfaces between the modules which serve to encapsulate behavior. Using simple examples, it is shown how a formal graph model can be used to model behavior in three domains: control flow, data flow, and interpretation. The effectiveness of the explicit environment model in SARA is discussed and the capability to analyze correctness and evaluate performance of a system model is demonstrated. A description of the integral help designed into SARA shows how the designer can be offered consistent use of any new tool introduced to support the design process.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312945","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312945","Concurrent systems;graph models;hierarchical design;integral help;interactive simulation;performance models;queueing models;reachability analysis","Analytical models;Data models;Manuals;Semantics;User interfaces;Grammar;Syntactics","parallel processing;programming environments","SARA;modeling;analysis;simulation support;concurrent systems;environment;fully nested structure model;multilevel design;interfaces;graph model;control flow;data flow;interpretation","","26","","","","","","","","IEEE","IEEE Journals & Magazines"
"Achieving service rate objectives with decay usage scheduling","J. L. Hellerstein","IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA","IEEE Transactions on Software Engineering","","1993","19","8","813","825","Decay usage scheduling is a priority- and usage-based approach to CPU allocation in which preference is given to processes that have consumed little CPU in the recent past. The author develops an analytic model for decay usage schedulers running compute-bound workloads, such as those found in many engineering and scientific environments; the model is validated from measurements of a Unix system. This model is used in two ways. First, ways to parameterize decay usage schedulers are studied to achieve a wide range of service rates. Doing so requires a fine granularity of control and a large range of control. The results show that, for a fixed representation of process priorities a larger range of control makes the granularity of control coarser, and a finer granularity of control decreases the range of control. A second use of the analytic model is to construct a low overhead algorithms for achieving service rate objectives. Existing approaches require adding a feedback loop to the scheduler. This overhead is avoided by exploiting the feedback already present in decay usage schedulers. Using both empirical and analytical techniques, it is shown that the algorithm is effective and that it provides fairness when the system is over- or under-loaded.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.238584","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=238584","","Processor scheduling;Central Processing Unit;Control systems;Algorithm design and analysis;Operating systems;Scheduling algorithm;Delay;Tellurium;Feedback loop;Throughput","resource allocation;scheduling;Unix","usage-based approach;CPU allocation;analytic model;decay usage schedulers;compute-bound workloads;scientific environments;Unix system;fine granularity;process priorities;low overhead algorithms;service rate objectives;feedback loop","","18","","22","","","","","","IEEE","IEEE Journals & Magazines"
"An executable language for modeling simple behavior","S. Lee; S. Sluizer","GTE Lab. Inc., Waltham, MA, USA; GTE Lab. Inc., Waltham, MA, USA","IEEE Transactions on Software Engineering","","1991","17","6","527","543","SXL, a modeling language that describes system behavior rather that software structure, is discussed. Using a conventional state-transition framework, model behavior is determined by rules that define pre- and postconditions for each transition. Behavior is also specified by constraints (logical invariants) that are automatically enforced during the execution of the model. Rules and constraints are expressed solely in terms of entity-relationship structure and declarative logic; the language lacks machine-oriented data or control structures, and has no facilities for specifying or implementing software. Application of SXL is demonstrated by its translation of a simple behavioral description (a scenario from an actual requirements document) into an executable model. Comparisons are made to software- and specification-oriented methods to illustrate the tradeoffs resulting from SXL's restriction to simple behavioral modeling. A brief account is given of one software development group's experience with SXL.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.87279","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=87279","","Laboratories;Intelligent systems;Logic;Application software;Programming;Engineering management;Software tools;Computer languages;Testing;Computer science","formal specification;logic programming;specification languages","state transition language;executable language;simple behavior;modeling language;system behavior;conventional state-transition framework;model behavior;logical invariants;entity-relationship structure;declarative logic;SXL;behavioral description;requirements document;executable model;specification-oriented methods;software development","","8","","29","","","","","","IEEE","IEEE Journals & Magazines"
"A specification and verification method for preventing denial of service","C. -. Yu; V. D. Gligor","Dept. of Electr. Eng., Maryland Univ., College Park, MD, USA; Dept. of Electr. Eng., Maryland Univ., College Park, MD, USA","IEEE Transactions on Software Engineering","","1990","16","6","581","592","A specification and verification method is presented for preventing denial of service in absence of failures and of integrity violations. The notion of user agreements is introduced, and it is argued that lack of specifications for these agreements and for simultaneity conditions makes it impossible to demonstrate denial-of-service prevention, in spite of demonstrably fair service access. The use of this method is illustrated with an example and it is explained why current methods for specification and verification of safety and liveness properties of concurrent programs do not handle this problem. The proposed specification and verification method is meant to augment current methods for secure system design.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.55087","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=55087","","Computer crime;Safety;Security;Logic;Laboratories;Delay;Fault tolerance;Access control","formal specification;security of data","specification method;failure absence;verification method;integrity violations;user agreements;simultaneity conditions;denial-of-service prevention;concurrent programs","","20","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Assessing (Software) Reliability Growth Using a Random Coefficient Autoregressive Process and Its Ramifications","N. D. Singpurwalla; R. Soyer","Institute for Reliability and Risk Analysis, School of Engineering and Applied Science, George Washington University; NA","IEEE Transactions on Software Engineering","","1985","SE-11","12","1456","1464","In this paper we motivate a random coefficient autoregressive process of order 1 for describing reliability growth or decay. We introduce several ramifications of this process, some of which reduce it to a Kalman Filter model. We illustrate the usefulness of our approach by applying these processes to some real life data on software failures. Finally, we make a pairwise comparison of the models in terms of the ratio of likelihoods of their predictive distributions, and identify the ""best"" model.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231889","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701968","Dynamic linear and nonlinear models;Kalman Filtering;likelihood ratios;predictive distributions;prequential analysis;random coefficient autoregressive processes;reliability growth;software reliability","System testing;Autoregressive processes;Predictive models;Software reliability;Kalman filters;Nonlinear filters;Filtering;Software testing;Life testing;Risk analysis","","Dynamic linear and nonlinear models;Kalman Filtering;likelihood ratios;predictive distributions;prequential analysis;random coefficient autoregressive processes;reliability growth;software reliability","","59","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Why is software late? An empirical study of reasons for delay in software development","M. van Genuchten","Dept. of Manage. Inf. Syst. & Autom., Eindhoven Univ. of Technol., Netherlands","IEEE Transactions on Software Engineering","","1991","17","6","582","590","A study of the reasons for delay in software development is described. The aim of the study was to gain an insight into the reasons for differences between plans and reality in development activities in order to be able to take actions for improvement. A classification was used to determine the reasons. 160 activities, comprising over 15000 hours of work, have been analyzed. The results and interpretations of the results are presented. Insight into the predominant reasons for delay enabled actions for improvements to be taken in the department concerned. Because the distribution of reasons for delay varied widely from one department to another, it is recommended that every department should gain an insight into its reasons for delay in order to be able to take adequate actions for improvement.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.87283","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=87283","","Delay;Programming;Software engineering;Project management;Job shop scheduling;Software measurement;Software development management;Engineering management;Management information systems;Automation","project engineering;software engineering","software development;development activities;classification;delay enabled actions","","103","","12","","","","","","IEEE","IEEE Journals & Magazines"
"A language for specifying program transformations","D. Hildum; J. Cohen","Dept. of Comput. & Inf. Sci., Massachusetts Univ., Amherst, MA, USA; NA","IEEE Transactions on Software Engineering","","1990","16","6","630","638","A language is described for specifying program transformations, from which programs can be generated to perform the transformations on sequences of code. The main objective of this work has been to develop a language that would allow the user to quickly and easily specify a wide range of transformations for a variety of programming languages. The rationale for the language constructs is given, as well as the details of an implementation which was prototyped using Prolog. Numerous examples of the language usage are provided.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.55091","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=55091","","Pattern matching;Computer languages;Specification languages;Formal specifications;Assembly;Data analysis;Performance analysis;Prototypes","specification languages","specification language;program transformations;language constructs;Prolog","","2","","17","","","","","","IEEE","IEEE Journals & Magazines"
"The N-Version Approach to Fault-Tolerant Software","A. Avizienis","Department of Computer Science, University of California","IEEE Transactions on Software Engineering","","1985","SE-11","12","1491","1501","Evolution of the N-version software approach to the tolerance of design faults is reviewed. Principal requirements for the implementation of N-version software are summarized and the DEDIX distributed supervisor and testbed for the execution of N-version software is described. Goals of current research are presented and some potential benefits of the N-version approach are identified.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231893","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701972","Design diversity;fault tolerance;multiple computation;N-version programming;N-version software;software reliability;tolerance of design faults","Fault tolerance;Circuit faults;Fault tolerant systems;Hardware;Application software;Humans;Computer science;Computer errors;Software testing;Software reliability","","Design diversity;fault tolerance;multiple computation;N-version programming;N-version software;software reliability;tolerance of design faults","","501","","53","","","","","","IEEE","IEEE Journals & Magazines"
"State constraints and pathwise decomposition of programs","J. C. Huang","Dept. of Comput. Sci., Houston Univ., TX, USA","IEEE Transactions on Software Engineering","","1990","16","8","880","896","A state constraint is a programming construct designed to restrict a program's domain of definition. It can be used to decompose a program pathwise, i.e. dividing the program into subprograms along the control flow, as opposed to dividing the program across the control flow when the program is decomposed into functions and procedures. As a result, a program consisting of one or more execution paths of another program can be constructed and manipulated. The author describes the idea involved, examines the properties of state constraints, establishes a formal basis for pathwise decomposition and discusses their uses in program simplification, testing and verification.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.57625","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=57625","","Testing;Computer science;Aggregates;Capacitive sensors","computational complexity;program testing;software engineering","state constraint;programming construct;program pathwise;subprograms;control flow;execution paths;formal basis;pathwise decomposition;program simplification;testing;verification","","7","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Efficient detection and resolution of generalized distributed deadlocks","A. D. Kshemkalyani; M. Singhal","IBM Corp., Research Triangle Park, NC, USA; NA","IEEE Transactions on Software Engineering","","1994","20","1","43","54","We present an efficient one-phase algorithm that consists of two concurrent sweeps of messages to detect generalized distributed deadlocks. In the outward sweep, the algorithm records a snapshot of a distributed wait-for-graph (WFG). In the inward sweep, the algorithm performs reduction of the recorded distributed WFG to check for a deadlock. The two sweeps can overlap in time at a process. We prove the correctness of the algorithm. The algorithm has a worst-case message complexity of 4e/spl minus/2n+2l and a time complexity of 2d hops, where e is the number of edges, n is the number of nodes, l is the number of leaf nodes, and d is the diameter of the WFG. This is a notable improvement over the existing algorithms to detect generalized deadlocks.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.263754","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=263754","","System recovery;Topology;Information science;Phase detection;Associate members;Software algorithms;Sufficient conditions;Detection algorithms;Algorithm design and analysis","concurrency control;computational complexity;directed graphs;operating systems (computers)","generalized distributed deadlock resolution;one-phase algorithm;concurrent sweeps;messages;generalized distributed deadlock detection;outward sweep;distributed wait-for-graph;inward sweep;distributed snapshot;algorithm correctness;worst-case message complexity;time complexity;leaf nodes;graph reduction;distributed system;directed graph","","46","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Testing the completeness of specifications","P. Jalote","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA","IEEE Transactions on Software Engineering","","1989","15","5","526","531","A system is described that tests for the completeness of axiomatic specifications of abstract data types. For testing, the system generates a set of test cases and an implementation of the data type from the specifications. The generated implementation is such that if the specifications are not complete, the implementation is not complete, and the behavior of all of the sequences of valid operations on the data type is not defined. This implementation is tested with the generated test cases to detect the incompleteness of specifications. The system is implemented on a VAX system running Unix.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24701","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24701","","System testing;Formal specifications;Computer science;Software testing;Costs","conformance testing;data structures;program testing","completeness testing;axiomatic specifications;abstract data types;test cases;VAX system;Unix","","11","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Automated Protocol Validation in Argos: Assertion Proving and Scatter Searching","G. J. Holzmann","AT&amp; T Bell Laboratories","IEEE Transactions on Software Engineering","","1987","SE-13","6","683","696","Argos is a validation language for data communication protocols. To validate a protocol, a model in Argos is constructed consisting of a control flow specification and a formal description of the correctness requirements. This model can be compiled into a minimized lower level description that is based on a formal model of communicating finite state machines. An automated protocol validator trace uses these minimized descriptions to perform a partial symbolic execution of the protocol to establish its correctness for the given requirements.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233206","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702274","Assertion proving;guarded command languages;protocol design;protocol validation;scatter searching;symbolic execution","Scattering;Performance analysis;Logic;Access protocols;Data communication;Automatic control;Communication system control;Automata;Command languages;Humans","","Assertion proving;guarded command languages;protocol design;protocol validation;scatter searching;symbolic execution","","19","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Selecting Software Test Data Using Data Flow Information","S. Rapps; E. J. Weyuker","Courant Institute of Mathematical Sciences, Department of Computer Science, New York University; NA","IEEE Transactions on Software Engineering","","1985","SE-11","4","367","375","This paper defines a family of program test data selection criteria derived from data flow analysis techniques similar to those used in compiler optimization. It is argued that currently used path selection criteria, which examine only the control flow of a program, are inadequate quate. Our procedure associates with each point in a program at which a variable is defined, those points at which the value is used. Several test data selection criteria, differing in the type and number of these associations, are defined and compared.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232226","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702019","Data flow;program testing;test data selection","Software testing;Error correction;Data analysis;Information analysis;Program processors;Optimizing compilers;Computer science;System testing;Intelligent systems","","Data flow;program testing;test data selection","","482","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Timing Constraints of Real-Time Systems: Constructs for Expressing Them, Methods of Validating Them","B. Dasarathy","GTE Laboratories Inc.","IEEE Transactions on Software Engineering","","1985","SE-11","1","80","86","This paper examines timing constraints as features of realtime systems. It investigates the various constructs required in requirements languages to express timing constraints and considers how automatic test systems can validate systems that include timing constraints. Specifically, features needed in test languages to validate timing constraints are discussed. One of the distinguishing aspects of three tools developed at GTE Laboratories for real-time systems specification and testing is in their extensive ability to handle timing constraints. Thus, the paper highlights the timing constraint features of these tools.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231845","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701900","Real-time systems;requirements specification;test generation;test language;timing constraints;validation","Timing;Real time systems;System testing;Automatic testing;Laboratories;Delay;Project management","","Real-time systems;requirements specification;test generation;test language;timing constraints;validation","","164","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Internal Scheduling and Memory Contention","A. J. Smith","Computer Science Division, Department of Electrical Engineering and Computer Sciences, University of California","IEEE Transactions on Software Engineering","","1981","SE-7","1","135","146","It has been suggested that the algorithm used to schedule those processes active and in main memory can have an effect on memory contention. We create models for memory contention in a system that uses global LRU replacement and either round robin or priority internal scheduling. Parameters to our model include the ratio of secondary storage to primary storage access times, thus allowing consideration of a variety of storage technologies. The round robin quantum size is included and is shown to have some effect. Our model uses LRU miss ratio curves and thus reflects actual program characteristics. Trace driven simulations are used to verify the accuracy of the models. We find that in most cases internal scheduling has only a small effect on page fault rates and CPU utilization. In certain cases, however priority scheduling is found to besignificant in relieving thrashing.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230820","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702811","LRU;memory contention;paging;priority scheduling;program behavior;round robin scheduling;scheduling;storage technology;thrashing;virtual memory","Round robin;Scheduling algorithm;Processor scheduling;Partitioning algorithms;Costs;Contracts;Linear accelerators;Computer science;Interference;Protection","","LRU;memory contention;paging;priority scheduling;program behavior;round robin scheduling;scheduling;storage technology;thrashing;virtual memory","","","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Discrete Time Stochastic Petri Nets","M. K. Molloy","Department of Computer Science, University of Texas at Austin","IEEE Transactions on Software Engineering","","1985","SE-11","4","417","423","Basic graph models of processes, such as Petri nets, have usually omitted the concept of time as a parameter. Time has been added to the Petri net model in two ways. The timed Petri net (TPN) uses a fixed number of discrete time intervals. The stochastic Petri net (SPN) uses an exponentially distributed random variable. In this paper, a discrete time stochastic Petri model is described. These discrete time SPN's fill the gap between TPN and normal SPN. However, the use of discrete time complicates the SPN model in that more than one transition may fire at a time step. Finally, an example of a live and bounded Petri net which has nonempty, disjoint, recurrent subsets of markings is given.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232230","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702023","Markovian processes;performance;Petri nets;stochastic models","Stochastic processes;Petri nets;Delay;Performance analysis;Power system modeling;Random variables;Fires;Protocols;System recovery;Timing","","Markovian processes;performance;Petri nets;stochastic models","","89","","23","","","","","","IEEE","IEEE Journals & Magazines"
"The exception handling effectiveness of POSIX operating systems","P. Koopman; J. DeVale","Dept. of Electr. & Comput. Eng., Carnegie Mellon Univ., Pittsburgh, PA, USA; NA","IEEE Transactions on Software Engineering","","2000","26","9","837","848","Operating systems form a foundation for robust application software, making it important to understand how effective they are at handling exceptional conditions. The Ballista testing system was used to characterize the handling of exceptional input parameter values for up to 233 POSIX functions and system calls on each of 15 widely used operating system (OS) implementations. This identified ways to crash systems with a single call, ways to cause task hangs within OS code, ways to cause abnormal task termination within OS and library code, failures to implement defined POSIX functionality, and failures to report unsuccessful operations. Overall, only 55 percent to 76 percent of the exceptional tests performed generated error codes, depending on the operating system being tested. Approximately 6 percent to 19 percent of tests failed to generate any indication of error despite exceptional inputs. Approximately 1 percent to 3 percent of tests revealed failures to implement defined POSIX functionality for unusual, but specified, situations. Between 18 percent and 33 percent of exceptional tests caused the abnormal termination of an OS system call or library function, and five systems were completely crashed by individual system calls with exceptional parameter values. The most prevalent sources of these robustness failures were illegal pointer values, numeric overflows, and end-of-file overruns.","0098-5589;1939-3520;2326-3881","","10.1109/32.877845","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=877845","","Operating systems;Robustness;Application software;System testing;Vehicle crash testing;Computer crashes;Libraries;Telecommunication computing;Programming profession;Performance evaluation","exception handling;operating systems (computers);program testing","exception handling effectiveness;POSIX operating systems;application software;Ballista testing system;system calls;system crash;task hangs;abnormal task termination;library code;error codes;illegal pointer values;numeric overflows;end-of-file overruns;robustness failures","","56","","35","","","","","","IEEE","IEEE Journals & Magazines"
"A comparison of some structural testing strategies","S. C. Ntafos","Comput. Sci. Program, Texas Univ., Richardson, TX, USA","IEEE Transactions on Software Engineering","","1988","14","6","868","874","Several structural testing strategies are compared in terms of their relative coverage of the program's structure and also in terms of the number of test cases needed to satisfy each strategy. Some of the deficiencies of such comparisons are discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6165","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6165","","Costs;Data analysis;Error correction;Software testing;Software tools;Computer science;Linear code","program testing;programming theory;structured programming","program testing;structural testing","","136","","17","","","","","","IEEE","IEEE Journals & Magazines"
"An Intrusion-Detection Model","D. E. Denning","SRI International","IEEE Transactions on Software Engineering","","1987","SE-13","2","222","232","A model of a real-time intrusion-detection expert system capable of detecting break-ins, penetrations, and other forms of computer abuse is described. The model is based on the hypothesis that security violations can be detected by monitoring a system's audit records for abnormal patterns of system usage. The model includes profiles for representing the behavior of subjects with respect to objects in terms of metrics and statistical models, and rules for acquiring knowledge about this behavior from audit records and for detecting anomalous behavior. The model is independent of any particular system, application environment, system vulnerability, or type of intrusion, thereby providing a framework for a general-purpose intrusion-detection expert system.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232894","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702202","Abnormal behavior;auditing;intrusions;monitoring;profiles;security;statistical measures","Security;Real time systems;Expert systems;Environmental economics;Invasive software;Computerized monitoring;Object detection;Contracts;Joining processes;Operating systems","","Abnormal behavior;auditing;intrusions;monitoring;profiles;security;statistical measures","","809","","3","","","","","","IEEE","IEEE Journals & Magazines"
"The AdaPIC tool set: supporting interface control and analysis throughout the software development process","A. L. Wolf; L. A. Clarke; J. C. Wileden","Dept. of Comput. & Inf. Sci., Massachusetts Univ., Amherst, MA, USA; Dept. of Comput. & Inf. Sci., Massachusetts Univ., Amherst, MA, USA; Dept. of Comput. & Inf. Sci., Massachusetts Univ., Amherst, MA, USA","IEEE Transactions on Software Engineering","","1989","15","3","250","263","The AdaPIC tool set, an important component of an Ada software development environment, is discussed. The AdaPIC tool set is one particular instantiation, specifically adapted for use with Ada, of the more general collection of language features and analysis capabilities that constitute the PIC approach to describing and analyzing relationships among software system components. This tool set is being tailored to support an incremental approach to the interface control aspects of the software development process. Following a discussion of the PIC interface control and incremental development concepts, the AdaPIC tool set is described, concentrating on its analysis tools and support for incremental development and demonstrating how it contributes to the technology for developing large Ada software systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21753","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21753","","Software systems;Control systems;Software tools;Control system analysis;Programming profession;Software maintenance;Laboratories;Information science;Marine vehicles;Software performance","Ada;programming environments;software tools","AdaPIC tool set;interface control;software development;software development environment;language features;software system components;analysis tools","","12","","21","","","","","","IEEE","IEEE Journals & Magazines"
"An Empirical Study of a Syntactic Complexity Family","V. R. Basili; D. H. Hutchens","Department of Computer Science, University of Maryland; NA","IEEE Transactions on Software Engineering","","1983","SE-9","6","664","672","A family of syntactic complexity metrics is defined that generates several metrics commonly occurring in the literature. The paper uses the family to answer some questions about the relationship of these metrics to error-proneness and to each other. Two derived metrics are applied; slope which measures the relative skills of programmers at handling a given level of complexity and r square which is indirectly related to the consistency of performance of the programmer or team. The study suggests that individual differences have a large effect on the significance of results where many individuals are used. When an individual is isolated, better results are obtainable. The metrics can also be used to differentiate between projects on which a methodology was used and those on which it was not.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.235431","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703113","Control structure metrics;development methods;program changes;software experiments;software metrics;structural complexity;syntactic complexity","Computer science;Programming profession;Current measurement;Particle measurements;Time measurement;Size measurement;Software metrics;Software measurement;Costs;Quality assurance","","Control structure metrics;development methods;program changes;software experiments;software metrics;structural complexity;syntactic complexity","","74","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Making changes to formal specifications: requirements and an example","D. W. Bustard; A. C. Winstanley","Dept. of Comput. Sci., Ulster Univ., Coleraine, UK; NA","IEEE Transactions on Software Engineering","","1994","20","8","562","568","Formal methods have had little impact on software engineering practice, despite the fact that most software engineering practitioners readily acknowledge the potential benefits to be gained from the mathematical modeling involved. One reason is that existing modeling techniques tend not to address basic software engineering concerns. In particular, while considerable attention has been paid to the construction of formal models, less attractive maintenance issues have largely been ignored. The purpose of this paper is to clarify those issues and examine the underlying requirements for change support. The discussion is illustrated with a description of a change technique and tool developed for the formal notation LOTOS. This work was undertaken as part of the SCAFFOLD project, which was concerned with providing broad support for the construction and analysis of formal specifications of concurrent systems. Most of the discussion is applicable to other process-oriented notations such as CCS and CSP.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.310666","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=310666","","Formal specifications;Software engineering;Mathematical model;Carbon capture and storage;Process control;Algebra;Programming;Software design;Instruction sets;Software tools","formal specification;specification languages;software maintenance;configuration management","formal specifications;software engineering;change technique;tool;formal notation LOTOS;SCAFFOLD project;process-oriented notations;concurrent systems;change control;formal specification;process algebra;LOTOS","","5","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Two-dimensional specification of universal quantification in a graphical database query language","K. -. Whang; A. Malhotra; G. H. Sockut; L. Burns; K. -. Choi","Dept. of Comput. Sci., Korea Adv. Inst. of Sci. & Technol., Daejeon, South Korea; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1992","18","3","216","224","A technique is proposed for specifying universal quantification and existential quantification (combined with negation) in a two-dimensional (graphical) database query language. Unlike other approaches that provide set operators to simulate universal quantification, this technique allows a direct representation of universal quantification. Syntactic constructs for specifying universal and existential quantifications, two-dimensional translation of universal quantification to existential quantification (with negation), and translation of existentially quantified two-dimensional queries to relational queries are presented. The resulting relational queries can be processed directly by many existing database systems. The authors claim that this technique renders universal quantifications easy to understand. To substantiate this claim, they provide a simple, easy-to-follow guideline for constructing universally quantified queries.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.126770","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=126770","","Database languages;Relational databases;Calculus;Database systems;Programming profession;Senior members;Guidelines;Computer science;Data models","computer graphics;database theory;formal specification;query languages;relational databases","graphical database query language;universal quantification;existential quantification;direct representation;two-dimensional translation;existentially quantified two-dimensional queries;relational queries","","14","","17","","","","","","IEEE","IEEE Journals & Magazines"
"CSDL: a language for cooperative systems design","F. De Paoli; F. Tisato","Dipartimento di Sci. dell'Inf., Milan Univ., Italy; Dipartimento di Sci. dell'Inf., Milan Univ., Italy","IEEE Transactions on Software Engineering","","1994","20","8","606","616","The aim of a cooperative system is to coordinate and support group activities. Cooperative Systems Design Language (CSDL) is an experimental language designed to support the development of cooperative systems from specification to implementation. In CSDL, a system is defined as a collection of reusable entities implementing floor control disciplines and shared workspaces. CSDL tries to address the difficulties of integrating different aspects of cooperative systems: cooperation control, communication, and system modularization. This paper presents CSDL as a specification language. Basic units are coordinators that can be combined hierarchically. A coordinator is composed of a specification, a body, and a context. The specification defines the cooperation policy; the body controls the underlying communication channels; and the context defines coordinators' interaction in modular systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.310670","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=310670","","Cooperative systems;Control systems;Communication system control;Specification languages;Context;Collaborative work;Application software;Communication channels;Collaborative software;Software design","cooperative systems;groupware;distributed processing;specification languages","cooperative systems design;CSDL;group activities;shared workspaces;floor control;specification language;cooperation policy;CSCW;conferencing systems;groupware;design language;software architecture;distributed systems","","7","","23","","","","","","IEEE","IEEE Journals & Magazines"
"A Comparison of Measures of Control Flow Complexity","A. L. Baker; S. H. Zweben","Department of Computer Science, University of Wisconsin; NA","IEEE Transactions on Software Engineering","","1980","SE-6","6","506","512","In attempting to describe the quality of computer software, one of the more frequently mentioned measurable attributes is complexity of the flow of control. During the past several years, there have been many attempts to quantify this aspect of computer programs, approaching the problem from such diverse points of view as graph theory and software science. Most notable measures in these areas are McCabe's cyclomatic complexity and Halstead's software effort. More recently, Woodward et al. proposed a complexity measure based on the number of crossings, or ""knots,"" of arcs in a linearization of the flowgraph.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230799","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702775","Program complexity;program control flow;software science;source program transformations;structured programs","Fluid flow measurement;Software measurement;Programming profession;Graph theory;Area measurement;Particle measurements;Computer science;Costs;Software quality;Programming environments","","Program complexity;program control flow;software science;source program transformations;structured programs","","25","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Good System Structure Features: Their Complexity and Execution Time Cost","J. A. Stankovic","Departmnent of Electrical and Computer Engineering, University of Massachusetts","IEEE Transactions on Software Engineering","","1982","SE-8","4","306","318","This paper describes a multistep technique that can be applied to improve system structure and to improve performance when necessary. The technique begins with the analysis of system structure via the structured design guidelines of coupling and cohesion. Next, manual system structure improvement transformations are applied. The effect of the transformations on execution time is then determined. Finally, vertical migration is used on the restructured system to improve its performance. Using the results of this paper, system programmers can identify specific cases where both good system structure and good performance are attainable, and others where tradeoffs must be made. The technique is most applicable during the maintenance phase of the software life cycle.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235425","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702954","Execution time performance;hierarchical model;large systems;maintenance;software complexity;software methodology;structured design;transformations;vertical migration","Costs;Software maintenance;Software performance;Programming profession;Software systems;Virtual manufacturing;Guidelines;Application software;Hardware;Design methodology","","Execution time performance;hierarchical model;large systems;maintenance;software complexity;software methodology;structured design;transformations;vertical migration","","1","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Experience with a Software Engineering Project Course","W. M. Mc Keeman","Aiken Computation Laboratories, Harvard University","IEEE Transactions on Software Engineering","","1987","SE-13","11","1182","1192","This paper presents an approach to meeting the academic objectives of advanced software engineering project courses. The objectives are increased competence and confidence of the students in carrying out software development projects. The academic context includes a simulated industrial context. Part of the industrial context consists of industrial roles played for the student team by the instructor and others. The project itself is divided into tasks related to deliverables and collateral responsibilities. The software production model is a combination of the waterfall, iterative enhancement, and document-driven techniques. A software development environment is mentioned although the details are presented elsewhere. Further detail is given for five project courses conducted by the author.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232868","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702166","Design;documentation;project courses;requirements;role playing;software projects;specification;testing","Software engineering;Programming;Context modeling;Documentation;Software testing;Organizing;Education;Proposals;Production systems;Information technology","","Design;documentation;project courses;requirements;role playing;software projects;specification;testing","","2","","15","","","","","","IEEE","IEEE Journals & Magazines"
"ESPRESOA System for Process Control Software Specification","J. Ludewig","Brown Boveri Research Center","IEEE Transactions on Software Engineering","","1983","SE-9","4","427","436","This paper outlines a specification system for process control software, named ESPRESO, which was developed at the Nuclear Research Center, Karlsruhe, West Germany. ESPRESO is based on some new ideas, which are combined with elements taken from other systems. ESPRESO consists of a set of concepts, a specification language, a tool for the management, evaluation and validation of specifications, and the method how to use the system. Language, tool, and method are carefully adapted to the concepts. The primary aim was to demonstrate some features of a specification system which are currently not available, rather than to provide a new tool for the software market.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.234779","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703077","Attribute grammar;language definition;process communication;process control software;software specification","Process control;Specification languages;Software tools;Documentation;Safety;Operating systems;Software design;System testing;Programming;Databases","","Attribute grammar;language definition;process communication;process control software;software specification","","5","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Process synchronization: design and performance evaluation of distributed algorithms","R. Bagrodia","Dept. of Comput. Sci., California Univ., Los Angeles, CA, USA","IEEE Transactions on Software Engineering","","1989","15","9","1053","1065","The author presents a simple solution for the committee coordination problem, which encompasses the synchronization and exclusion problems associated with implementing multiway rendezvous, and shows how it can be implemented to develop a family of algorithms. The algorithms use message counts to solve the synchronization problem, and they solve the exclusion problem by using a circulating token or by using auxiliary resources as in the solutions for the dining or drinking philosophers' problems. Results of a simulation study of the performance of the algorithms are presented. The experiments measured the response time and message complexity of each algorithm as a function of variations in the model parameters, including network topology and level of conflict in the system. The results show that the response time for algorithms proposed is significantly better than for existing algorithms, whereas the message complexity is considerably worse.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.31364","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=31364","","Process design;Algorithm design and analysis;Distributed algorithms;Context;Time measurement;Delay;Network topology;Anthropomorphism;Computer science;Protocols","computational complexity;message switching;network topology;synchronisation","process synchronization;performance evaluation;distributed algorithms;committee coordination problem;multiway rendezvous;message counts;synchronization problem;exclusion problem;circulating token;auxiliary resources;simulation study;response time;message complexity;model parameters;network topology;level of conflict","","48","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Integrating time domain and input domain analyses of software reliability using tree-based models","J. Tian","Dept. of Comput. Sci. & Eng., Methodist Univ., Dallas, TX, USA","IEEE Transactions on Software Engineering","","1995","21","12","945","958","The paper examines two existing approaches to software reliability analysis, time domain reliability growth modeling and input domain reliability analysis, and presents a new approach that combines some of their individual strengths. An analysis method called tree-based modeling is used to build models based on the combined measurement data. This new approach can be used to assess the reliability of software systems, to track reliability change over time, and to identify problematic subparts characterized by certain input states or time periods. The results can also be used to guide various remedial actions aimed at reliability improvement. This approach has been demonstrated to be applicable and effective in the testing of several large commercial software systems developed in the IBM Software Solutions Toronto Laboratory.","0098-5589;1939-3520;2326-3881","","10.1109/32.489071","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=489071","","Time domain analysis;Software reliability;Software testing;Software systems;Failure analysis;Laboratories;System testing;Programming;Data analysis;Sampling methods","software reliability;software reliability;testing;trees (mathematics);software metrics;system monitoring","time domain analyses;input domain analyses;software reliability analysis;tree-based models;time domain reliability growth modeling;input domain reliability analysis;measurement data;reliability change tracking;problematic subparts;time periods;input states;remedial actions;reliability improvement;large commercial software system testing;IBM Software Solutions Toronto Laboratory","","31","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Modeling security-relevant data semantics","G. W. Smith","Inf. Resources Manage. Coll., Nat. Defense Univ., Washington, DC, USA","IEEE Transactions on Software Engineering","","1991","17","11","1195","1203","The use of an extended data model which represents both integrity and secrecy aspects of data is demonstrated. This Semantic Data Model for Security (SDMS) provides a technique that assists domain experts, security officers, and database designers in first understanding their security requirements, and then translating them into a good database design. Identifying security requirements at this semantic level provides the basis for analyzing the security requirements and the database design for inference and signaling vulnerabilities. Another contribution is a comprehensive taxonomy of security-relevant data semantics that must be captured and understood to implement a multilevel secure automated information system.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.106974","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=106974","","Data security;Database systems;Data models;Information security;Operating systems;Application software;Information systems;Humans;Relational databases;Knowledge management","database management systems;security of data","inference vulnerability;extended data model;secrecy;Semantic Data Model for Security;security requirements;database design;signaling vulnerabilities;security-relevant data semantics;multilevel secure automated information system","","10","","31","","","","","","IEEE","IEEE Journals & Magazines"
"A Causal Model for Analyzing Distributed Concurrency Control Algorithms","B. Bhargava; C. T. Hua","Department of Computer Science, University of Pittsburgh; NA","IEEE Transactions on Software Engineering","","1983","SE-9","4","470","486","An event order based model for specifying and analyzing concurrency control algorithms for distributed database systems has been presented. An expanded notion of history that includes the database access events as well as synchronization events is used to study the correctness, degree of concurrency, and other aspects of the algorithms such as deadlocks and reliability. The algorithms are mapped into serializable classes that have been defined based on the order of synchronization events such as lock points, commit point, arrival of a transaction, etc,.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.234783","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703081","Causal graph;concurrency control;correctness;deadlock;degree of concurrency;distributed system;event order;history;reliability;serializability;time stamp","Algorithm design and analysis;Concurrency control;History;Concurrent computing;System recovery;Database systems;Robustness;Control system analysis;Computer science;Management information systems","","Causal graph;concurrency control;correctness;deadlock;degree of concurrency;distributed system;event order;history;reliability;serializability;time stamp","","5","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Error recovery in asynchronous systems","R. H. Campbell; B. Randell","Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL 61801; Computer Laboratory, University of Newcastle upon Tyne, Newcastle upon Tyne NEI 7RU, England","IEEE Transactions on Software Engineering","","1986","SE-12","8","811","826","A framework for the provision of fault tolerance in asynchronous systems is introduced. The proposal generalizes the form of simple recovery facilities supported by nested atomic actions in which the exception mechanisms only permit backward error recovery. It allows the construction of systems using both forward and backward error recovery and thus allows the exploitation of the complementary benefits of the two schemes. Backward recovery, forward recovery, and normal processing activities can occur concurrently within the organization proposed. Exception handling is generalized to provide a uniform basis for fault tolerance schemes with the atomic action structure. The generalization includes a resolution scheme for concurrently raised exceptions based on an exception tree and an abortion scheme that permits the termination of the internal atomic actions. An automatic resolution mechanism is outlined for exceptions in atomic actions which allows users to separate their recovery schemes from the details of the underlying algorithms.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312984","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312984","Asynchronous systems;atomic actions;error recovery;exception mechanism;programming techniques;software fault tolerance;software reliability","Fault tolerance;Fault tolerant systems;Context;Protocols;Atomic measurements;Software;Computers","fault tolerant computing;software reliability;system recovery","exception handling;software reliability;asynchronous systems;fault tolerance;nested atomic actions;error recovery;automatic resolution mechanism","","47","","","","","","","","IEEE","IEEE Journals & Magazines"
"An Object-Oriented Command Language","R. Snodgrass","Department of Computer Science, University of North Carolina","IEEE Transactions on Software Engineering","","1983","SE-9","1","1","8","This paper describes Cola, an object-oriented command language for Hydra; Hydra is a capability-based operating system that runs on C.mmp, a tightly coupled multiprocessor. The two primary aspects of Cola, that it is a command language for Hydra, and that it is based on the object paradigm, are examined. Cola was designed to effect a correspondence between capabilities in Hydra and objects that are supported by the language. Cola is based on Smalltalk in that it uses message-passing as a control structure to allow syntactic freedom in the expression of commands to the system. Cola objects are arranged in a hierarchy, and the message-passing mechanism was designed to exploit this structure by automatically forwarding an unanswered message up the hierarchy. Two ramifications of this mechanism, automatic inheritance and shadowing, are discussed. An evaluation of the design decisions is also given.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236163","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703005","Capabilities;command language;knowledge representation languages;message-passing;multiprocessors;object-based languages;object hierarchies;Simula;Smalltalk","Command languages;Operating systems;Assembly;Control systems;Hardware;Computer science;Computer languages;Automatic control;Shadow mapping;Knowledge representation","","Capabilities;command language;knowledge representation languages;message-passing;multiprocessors;object-based languages;object hierarchies;Simula;Smalltalk","","6","","53","","","","","","IEEE","IEEE Journals & Magazines"
"Software measurement: a necessary scientific basis","N. Fenton","Centre for Software Reliability, City Univ., London, UK","IEEE Transactions on Software Engineering","","1994","20","3","199","206","Software measurement, like measurement in any other discipline, must adhere to the science of measurement if it is to gain widespread acceptance and validity. The observation of some very simple, but fundamental, principles of measurement can have an extremely beneficial effect on the subject. Measurement theory is used to highlight both weaknesses and strengths of software metrics work, including work on metrics validation. We identify a problem with the well-known Weyuker properties (E.J. Weyuker, 1988), but also show that a criticism of these properties by J.C. Cherniavsky and C.H. Smith (1991) is invalid. We show that the search for general software complexity measures is doomed to failure. However, the theory does help us to define and validate measures of specific complexity attributes. Above all, we are able to view software measurement in a very wide perspective, rationalising and relating its many diverse activities.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.268921","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=268921","","Software measurement;Software metrics;Humans;Gain measurement;Counting circuits;Software reliability;Software testing;Blood pressure;Cost function","software metrics;measurement theory;programming theory","software measurement;scientific basis;measurement theory;software metrics work;metrics validation;software complexity measures;complexity attributes","","212","","47","","","","","","IEEE","IEEE Journals & Magazines"
"The location-based paradigm for replication: Achieving efficiency and availability in distributed systems","P. Triantafillou; D. J. Taylor","Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada; NA","IEEE Transactions on Software Engineering","","1995","21","1","1","18","Replication techniques for transaction-based distributed systems generally achieve increased availability but with a significant performance penalty. We present a new replication paradigm, the location-based paradigm, which addresses availability and other performance issues. It provides availability similar to quorum-based replication protocols but with transaction-execution delays similar to one-copy systems. The paradigm further exploits replication to improve performance in two instances. First, it takes advantage of local or nearby replicas to further improve the response time of transactions, achieving smaller execution delays than one-copy systems. Second, it takes advantage of replication to facilitate the independent crash recovery of replica sites-a goal which is unattainable in one-copy systems. In addition to the above the location-based paradigm avoids bottlenecks, facilitates load balancing, and minimizes the disruption of service when failures and recoveries occur. In this paper we present the paradigm, a formal proof of correctness, and a detailed simulation study comparing our paradigm to one-copy systems and to other approaches to replication control.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.341843","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=341843","","Availability;Protocols;Computer crashes;Costs;Concurrency control;Distributed computing;Collaboration;Delay systems;Delay effects;Load management","concurrency control;protocols;system recovery;software fault tolerance;transaction processing;distributed processing","location-based paradigm;replication;transaction-based distributed systems;performance penalty;availability;quorum-based replication protocols;transaction-execution delays;one-copy systems;independent crash recovery;replica sites;bottlenecks;load balancing","","19","","29","","","","","","IEEE","IEEE Journals & Magazines"
"CTDNet-a mechanism for the concurrent execution of lambda graphs","J. P. Gupta; S. C. Winter; D. R. Wilson","Dept. of Electron. & Comput. Eng., Roorkee Univ., India; NA; NA","IEEE Transactions on Software Engineering","","1989","15","11","1357","1367","The authors describe CTDNet, a data-driven reduction machine for the concurrent execution of applicative functional programs in the form of lambda calculus expressions. Such programs are stored as binary-tree-structured process graphs in which all processes maintain pointers to their immediate neighbors (i.e. ancestor and two children). Processes are of two basic types: master processes, which represent the original process graph, and slave processes, which carry out the actual executional work and are dynamically created and destroyed. CTDNet uses a distributed eager evaluation scheme with a modification to evaluate conditional expressions lazily, together with a form of distributed string reduction with some graphlike modifications.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.41329","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=41329","","Calculus;Concurrent computing;Computer architecture;Data flow computing;Pipelines;Hardware;Binary trees;Master-slave;Functional programming;Parallel processing","graph theory;parallel machines;parallel programming","CTDNet;concurrent execution;lambda graphs;data-driven reduction machine;applicative functional programs;lambda calculus expressions;binary-tree-structured process graphs;pointers;neighbors;ancestor;children;master processes;slave processes;distributed eager evaluation scheme;conditional expressions;distributed string reduction","","2","","22","","","","","","IEEE","IEEE Journals & Magazines"
"An application of artificial intelligence to object-oriented performance design for real-time systems","S. Honiden; K. Nishimura; N. Uchihira; K. Itoh","Syst. & Software Eng. Lab., Toshiba Corp., Kawasaki, Japan; Syst. & Software Eng. Lab., Toshiba Corp., Kawasaki, Japan; Syst. & Software Eng. Lab., Toshiba Corp., Kawasaki, Japan; NA","IEEE Transactions on Software Engineering","","1994","20","11","849","867","The paper describes an application of artificial intelligence technology to the implementation of a rapid prototyping method in object-oriented performance design (OOPD) for real-time systems. OOPD consists of two prototyping phases for real-time systems. Each of these phases consists of three steps: prototype construction, prototype execution, and prototype evaluation. We present artificial intelligence based methods and tools to be applied to the individual steps. In the prototype construction step, a rapid construction mechanism using reusable software components is implemented based on planning. In the prototype execution step, a hybrid inference mechanism is used to execute the constructed prototype described in declarative knowledge representation. MENDEL, which is a Prolog based concurrent object-oriented language, can be used as a prototype construction tool and a prototype execution tool. In the prototype evaluation step, an expert system which is based on qualitative reasoning is implemented to detect and diagnose bottlenecks and generate an improvement plan for them.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.368123","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=368123","","Artificial intelligence;Real time systems;Software prototyping;Prototypes;Application software;Algorithm design and analysis;Software performance;Hardware;Productivity;Paper technology","software prototyping;real-time systems;software reusability;expert systems;inference mechanisms;knowledge representation;object-oriented programming;object-oriented languages;parallel languages","artificial intelligence;object-oriented performance design;real-time systems;rapid prototyping method;OOPD;prototyping phases;prototype construction;prototype execution;prototype evaluation;artificial intelligence based methods;rapid construction mechanism;reusable software components;hybrid inference mechanism;declarative knowledge representation;MENDEL;Prolog based concurrent object-oriented language;prototype construction tool;expert system;qualitative reasoning","","3","","48","","","","","","IEEE","IEEE Journals & Magazines"
"Post-Failure Reconfiguration of CSP Programs","S. M. Shatz","Department of Electrical Engineering and Computer Science, University of Illinois","IEEE Transactions on Software Engineering","","1985","SE-11","10","1193","1202","In this paper a technique called process merging is introduced. This technique allows the merging of two communicating sequential processes into a new single process. Thus, this technique can be used to reconfigure a distributed program after a faulty processing element has been detected. The technique is most applicable to dedicated multiple microprocessor systems where the need for continuous operation is critical. A process merging algorithm which operates on distributed programs using the CSP notation is presented in detail and its operation is discussed. In order to illustrate the merging technique, the algorithm's behavior is demonstrated using two classical distributed programs: the Bounded Buffer, Producer, Consumer program and the Dining Philosophers program. Finally, the merging technique is examined with respect to its demands on overall system operation and overhead. This examinatiQn leads to suggestions for future research.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231867","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701935","CSP programs;distributed computing;fault-tolerance;process merging;software reconfiguration","Merging;Fault detection;Microprocessors;Distributed computing;Fault tolerance;Hardware;Fault tolerant systems;Embedded system;Process design;Embedded software","","CSP programs;distributed computing;fault-tolerance;process merging;software reconfiguration","","1","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Software specialization via symbolic execution","A. Coen-Porisini; F. De Paoli; C. Ghezzi; D. Mandrioli","Dipartimento di Elettronica, Politecnico di Milano, Italy; Dipartimento di Elettronica, Politecnico di Milano, Italy; Dipartimento di Elettronica, Politecnico di Milano, Italy; Dipartimento di Elettronica, Politecnico di Milano, Italy","IEEE Transactions on Software Engineering","","1991","17","9","884","899","A technique and an environment-supporting specialization of generalized software components are described. The technique is based on symbolic execution. It allows one to transform a generalized software component into a more specific and more efficient component. Specialization is proposed as a technique that improves software reuse. The idea is that a library of generalized components exists and the environment supports a designer in customizing a generalized component when the need arises for reusing it under more restricted conditions. It is also justified as a reengineering technique that helps optimize a program during maintenance. Specialization is supported by an interactive environment that provides several transformation tools: a symbolic executor/simplifier, an optimizer, and a loop refolder. The conceptual basis for these transformation techniques is described, examples of their application are given, and how they cooperate in a prototype environment for the Ada programming language is outlined.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.92907","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=92907","","Application software;Software libraries;Costs;Software reusability;Software maintenance;Production;Software tools;Software prototyping;Prototypes;Computer languages","Ada;program compilers;software maintenance;software reusability;subroutines","environment-supporting specialization;generalized software components;symbolic execution;software reuse;reengineering technique;maintenance;interactive environment;transformation tools;symbolic executor/simplifier;optimizer;loop refolder;conceptual basis;Ada programming language","","24","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Multiparty interactions for interprocess communication and synchronization","M. Evangelist; N. Francez; S. Katz","MCC, Austin, TX, USA; MCC, Austin, TX, USA; MCC, Austin, TX, USA","IEEE Transactions on Software Engineering","","1989","15","11","1417","1426","The authors consider the essential properties of a multiparty interaction construct which serves as a primitive for interprocess communication and synchronization in distributed programs. It is claimed that more general constructs, which violate the suggested properties, are appropriate for abstraction but should not be seen as a communication primitive, and that both facilities are needed. Several acceptability criteria are posed for multiparty interactions, and various possibilities for constructs satisfying these criteria are presented. These include introducing a novel kind of nondeterminism within the assignments of an interaction, weakening the synchronization among the participants in an interaction, and varying the number of participants in order to provide a high-level treatment of fault tolerance.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.41333","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=41333","","Fault tolerance;Proposals;Veins;Assembly;High level languages;Computer science;Stress","fault tolerant computing;parallel programming","interprocess communication;synchronization;multiparty interaction construct;primitive;distributed programs;acceptability criteria;nondeterminism;weakening;participants;fault tolerance","","21","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Adaptive programming","M. G. Gouda; T. Herman","Dept. of Comput. Sci., Texas Univ., Austin, TX, USA; Dept. of Comput. Sci., Texas Univ., Austin, TX, USA","IEEE Transactions on Software Engineering","","1991","17","9","911","921","An adaptive program is one that changes its behavior base on the current state of its environment. This notion of adaptivity is formalized, and a logic for reasoning about adaptive programs is presented. The logic includes several composition operators that can be used to define an adaptive program in terms of given constituent programs; programs resulting from these compositions retain the adaptive properties of their constituent programs. The authors begin by discussing adaptive sequential programs, then extend the discussion to adaptive distributed programs. The relationship between adaptivity and self-stabilization is discussed. A case study for constructing an adaptive distributed program where a token is circulated in a ring of processes is presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.92911","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=92911","","Adaptive systems;Logic;Parallel programming;Programming theory","adaptive systems;formal logic;parallel programming;programming theory","token ring networks;adaptivity;composition operators;constituent programs;adaptive sequential programs;adaptive distributed programs;self-stabilization","","39","","12","","","","","","IEEE","IEEE Journals & Magazines"
"An Application of Structural Modeling to Software Requirements Analysis and Design","K. Matsumura; H. Mizutani; M. Arai","Systems and Software Engineering Division, Toshiba Corporation; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","4","461","471","In software development, it has been pointed out that software engineers must pay attention to software requirements definition. One of the important problems in software engineering is to rationalize the processes from requirements definition to design. Computer tools are most useful and efficient for this purpose. This paper proposes a computer-aided software design system (CASDS), which supports software engineers with a series of structural modeling. As is well-known in systems planning, structural modeling helps to extract concepts from many fuzzy requirements. This system contains three structural modeling methods. They are used 1) to determine functional terms from fuzzy software requirements, 2) to obtain modules by structuring the functions with respect to the data flows, and 3) to make a program skeleton by imposing control flows on the functional elements obtained by breaking down the modules.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233182","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702237","Clustering;computer-aided tools;control flow;data flow;design methodology;graph theory;module;requirements analysis;structural modeling;system planning","Application software;Software design;Skeleton;Software engineering;Software tools;Programming;Design engineering;Data mining;Fuzzy systems;Fuzzy control","","Clustering;computer-aided tools;control flow;data flow;design methodology;graph theory;module;requirements analysis;structural modeling;system planning","","6","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Broadcasting Sequential Processes (BSP)","N. H. Gehani","AT&amp;T Bell Laboratories, Murray Hill, NJ 07974.","IEEE Transactions on Software Engineering","","1984","SE-10","4","343","351","Communication in a broadcast protocol multiprocessor (BPM) is inherently different from that in distributed systems formed by explicit links between processors. A message broadcast by a processor in a BPM is received directly by all other processors in the network instead of being restricted to only one processor. Broadcasting is an inexpensive way of communicating with a large number of processors on a BPM. In this paper I will describe a new approach to user-level distributed programming called broadcast programming, i.e., distributed programs written as cooperating broadcasting sequential processes (BSP). Existing concurrent programming languages do not provide facilities to exploit the broadcast capability of a BPM. The idea of distributed programs written as BSP is tailored to exploiting a BPM architecture but is not restricted to such an architecture-however, implementation of the broadcast capability may not be as efficient on other architectures. I will illustrate the utility and convenience of broadcast programming with many examples. These examples will also be used to explore the suitability and advantages of BSP and to determine appropriate facilities for BSP.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010247","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010247","","Broadcasting;Protocols;Computer architecture;Local area networks;Computer networks;Hardware;Utility programs;Ethernet networks;Computer languages;Central Processing Unit","","","","38","","24","","","","","","IEEE","IEEE Journals & Magazines"
"The Semantic Database Constructor","D. B. Farmer; R. King; D. A. Myers","Interactive Systems Corporation; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","7","583","591","Sedaco (the semantic database constructor) is a tool which may be used to implement databases. It is based on a semantic data model. Sedaco provides primitives for implementing semantic schemas and buffers the database designer from most low-level data structuring issues. Sedaco also efficiently maintains consistency within complex semantic databases. The tool is written in C and runs under Unix.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232502","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702062","Database implementation;database physical design;semantic implementation;update propagation","Object oriented modeling;Relational databases;Transaction databases;Data models;Object oriented databases;Documentation;Indexes;Interactive systems;Computer science;Application software","","Database implementation;database physical design;semantic implementation;update propagation","","3","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Automatic Identification of Software System Differences","B. Steinholtz; K. Walden","ENEA DATA Svenska AB, Box 232, S-183 23 Taby, Sweden. While performing this work, they were also with SYSLAB, Department of Information Processing and Computer Science, University of Stockholm; NA","IEEE Transactions on Software Engineering","","1987","SE-13","4","493","497","A well-known method for software version control on the source file level is the incremental change technique, which isolates the differences, commonly called a delta, between two versions of a source module, and then stores only the delta. Any version of a source module can then be reconstructed from the original by successive application of deltas. The significant advantages of this approach include accuracy (because it is automatic), visibility (because it highlights differences), and economy (because it conserves storage space).","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233186","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702241","Difference isolation;software configuration management;software control system;software database;version control","Software systems;Control systems;Computer languages;Flowcharts;Documentation;Shape;Algebra;Man machine systems;Functional programming;Automatic control","","Difference isolation;software configuration management;software control system;software database;version control","","","","13","","","","","","IEEE","IEEE Journals & Magazines"
"A logic-based approach to reverse engineering tools production","G. Canfora; A. Cimitile; U. de Carlini","Dipatimento di Inf. e Sistemistica, Naples Univ., Italy; Dipatimento di Inf. e Sistemistica, Naples Univ., Italy; Dipatimento di Inf. e Sistemistica, Naples Univ., Italy","IEEE Transactions on Software Engineering","","1992","18","12","1053","1064","Difficulties arising in the use of documents produced by reverse engineering tools are analyzed. With reference to intermodular data flow analysis for Pascal software systems, an interactive and evolutionary tool is proposed. The tool is based on the production of intermodular data flow information by static analysis of code, its representation in a Prolog program dictionary, and a Prolog abstractor that allows the specific queries to be answered.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.184760","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=184760","","Reverse engineering;Production;Data analysis;Software systems;Information analysis;Dictionaries","logic programming;software maintenance;software tools","interactive tool;query answering;reverse engineering tools;intermodular data flow analysis;Pascal software systems;evolutionary tool;static analysis;Prolog program dictionary;Prolog abstractor","","35","","44","","","","","","IEEE","IEEE Journals & Magazines"
"A Software Engineering Environment (SEE) for Weapon System Software","H. G. Stuebing","Software and Computer Directorate, U.S. Naval Air Development Center, Warminster, PA 18974.","IEEE Transactions on Software Engineering","","1984","SE-10","4","384","397","A software engineering environment (SEE) has been designed, developed, and used for the life-cycle support of weapon system software. This SEE consists of two types of facilities: software production and integration. The software production facility consists of a software system that runs on a commercial multicomputer configuration. The approach features increased management visibility of the software development process, increased programmer productivity through automation, reducing the cost-of-change during maintenance, and the use of automated regression testing to improve software quality. These facilities have been used for eight years to develop and maintain weapon system software for several projects. This paper describes accomplishments, refinements to the code and test functions, and a general approach to extend the capabilities into the requirements and design phases. Techniques are described that simultaneously allow different methodologies, programming languages, and target computers to be implemented on the same host computer. Also discussed is the Implementation of a SEE in a distributed computer network.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010251","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010251","","Software engineering;Weapons;System software;Production facilities;Software systems;Quality management;Software development management;Programming profession;Productivity;Automation","","","","5","","15","","","","","","IEEE","IEEE Journals & Magazines"
"A Priority Based Distributed Deadlock Detection Algorithm","M. K. Sinha; N. Natarajan","National Centre for Software Development and Computing Techniques, Tata Institute of Fundamental Research; NA","IEEE Transactions on Software Engineering","","1985","SE-11","1","67","80","Deadlock handling is an important component of transaction management in a database system. In this paper, we contribute to the development of techniques for transaction management by presenting an algorithm for detecting deadlocks in a distributed database system. The algorithm uses priorities for transactions to minimize the number of messages initiated for detecting deadlocks. It does not construct any wait-for graph but detects cycles by an edge-chasing method. It does not detect any phantom deadlock (in the absence of failures), and for the resolution of deadlocks it does not need any extra computation. The algorithm also incorporates a post-resolution computation that leaves information characterizing dependence relations of remaining transactions of the deadlock cycle in the system, and this will help in detecting and resolving deadlocks which may arise in the future. An interesting aspect of this algorithm is that it is possible to compute the exact number of messages generated for a given deadlock configuration. The complexity is comparable to the best algorithm reported. We first present a basic algorithm and then extend it to take into account shared and exclusive lock modes, simultaneous acquisition of multiple locks, and nested transactions.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231844","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701899","Deadlock;deadlock detection;distributed database;nested transaction;priority;timestamp;transaction","System recovery;Detection algorithms;Database systems;Transaction databases;Imaging phantoms;Laser mode locking;Distributed databases;Programming;Telecommunication network reliability","","Deadlock;deadlock detection;distributed database;nested transaction;priority;timestamp;transaction","","40","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Compiling real-time programs with timing constraint refinement and structural code motion","R. Gerber; Seongsoo Hong","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA","IEEE Transactions on Software Engineering","","1995","21","5","389","404","We present a programming language called TCEL (Time-Constrained Event Language), whose semantics are based on time-constrained relationships between observable events. Such a semantics infers only those timing constraints necessary to achieve real-time correctness, without overconstraining the system. Moreover, an optimizing compiler can exploit this looser semantics to help tune the code, so that its worst-case execution time is consistent with its real-time requirements. In this paper we describe such a transformation system, which works in two phases. First, the TCEL source code is translated into an intermediate representation. Then an instruction-scheduling algorithm rearranges selected unobservable operations and synthesizes tasks guaranteed to respect the original event-based constraints.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.387469","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=387469","","Timing;Computer languages;Equations;Optimizing compilers;Program processors;Delay;Scheduling algorithm;Motion analysis;Real time systems;Time factors","real-time systems;high level languages;optimising compilers;scheduling;program interpreters;programming theory","real-time program compilation;timing constraint refinement;structural code motion;programming language;TCEL;Time-Constrained Event Language;time-constrained relationships;observable events;real-time correctness;optimizing compiler;worst-case execution time;real-time requirements;instruction-scheduling algorithm;event-based constraints","","14","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Two-dimensional program design","S. Rutenstreich; W. E. Howden","Department of Electrical Engineering and Computer Science, the George Washington University, Washington, DC 20052; Department of Electrical Engineering and Computer Science, University of California, San Diego, CA 92093","IEEE Transactions on Software Engineering","","1986","SE-12","3","377","384","One-dimensional design methods focus on one way of looking at data and control relationships in a design. Structured design concentrates on top-down, or vertical relationships. Data flow diagrams concentrate on horizontal relationships, in which the output from one computation flows to the next computation to be done. Two-dimensional design allows the simultaneous consideration of both the functional abstraction of vertical designs and the complex data sharing of horizontal designs through the use of functional and environmental models. The basic defects of one-dimensional approaches are described, followed by a description of a two-dimensional method. The method includes guidelines for transforming a one-dimensional design to a two-dimensional design.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312880","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312880","Data flow;design;modules;structured design","Data models;Abstracts;Object oriented modeling;Computational modeling;Patient monitoring;Analytical models;System analysis and design","software engineering","software engineering;structured design;program design;control relationships;vertical relationships;horizontal relationships;functional abstraction;vertical designs;complex data sharing;environmental models;two-dimensional design","","4","","","","","","","","IEEE","IEEE Journals & Magazines"
"L.0: a truly concurrent executable temporal logic language for protocols","L. Ness","Bellcore, Morristown, NJ, USA","IEEE Transactions on Software Engineering","","1993","19","4","410","423","The semantics L.0, a programming language designed for the specification and simulation of protocols that assumes a true concurrency model, is given in terms of predicate linear temporal logic, and the restricted universe of models assumed in L.0 programs is defined. The execution algorithm for L.0 constructs a model in this universe. The restricted subset of temporal logic exploited permits a nonbacktracking execution algorithm. Fundamental to the semantics of L.0 is a frame assumption, which generalizes the frame assumption of standard imperative programming, and which eases specification of protocols. The data domain assumed in L.0 programs is sets of trees with labeled edges, and the state predicates permitted include existence and nonexistence predicates, as well as the more traditional assignment and equality predicates. These choices for data domain and predicates permit convenient specification of the hierarchical message structure often assumed in telecommunications protocols, for in such message structures, the existence or nonexistence of parts of the message hierarchy is determined by logical properties of the rest of the message hierarchy. A small portion of the logical layer specification of Futurebus+ is taken as the main example in this study.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.223807","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=223807","","Concurrent computing;Access protocols;Logic programming;Interleaved codes;Computer languages;Logic design;Transport protocols;Multimedia communication;Broadcasting","protocols;simulation languages;specification languages;temporal logic","L.0;truly concurrent executable temporal logic language;protocols;specification;simulation;true concurrency model;execution algorithm;standard imperative programming;state predicates;equality predicates;hierarchical message structure;Futurebus+","","2","","46","","","","","","IEEE","IEEE Journals & Magazines"
"A Family of Locking Protocols for Database Systems that Are Modeled by Directed Graphs","A. Silberschatz; Z. M. Kedam","Department of Computer Sciences, University of Texas; NA","IEEE Transactions on Software Engineering","","1982","SE-8","6","558","562","This paper is concerned with the problem of ensuring the integrity of database systems that are accessed concurrently by a number of independent asychronously running transactions. It is assumed that the database system is partitioned into small units that are referred to as the database entities. The relation between the entities is represented by a directed acyclic graph in which the vertices correspond to the database entities and the arcs correspond to certain access rights. We develop a family of non-two-phase locking protocols for such systems that will be shown to ensure serializability and deadlock-freedom. This family is sufficientdy general to encompass all the previously developed non-two-phase lose locking protocols as well as a number of new protocols. One of these new protocols that seems to be particularly useful is also presented in this paper.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235885","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702989","Concurrency;consistency;database systems;deadlocks;locking protocols;transactions","Database systems;Access protocols;Transaction databases;System recovery;Permission;Indexes;Concurrent computing;Proposals","","Concurrency;consistency;database systems;deadlocks;locking protocols;transactions","","14","","12","","","","","","IEEE","IEEE Journals & Magazines"
"An empirical study of evaluating software development environment quality","T. Miyoshi; M. Azuma","Joint Syst. Dev. Corp., Tokyo, Japan; NA","IEEE Transactions on Software Engineering","","1993","19","5","425","435","A study that evaluates new-paradigm-oriented software development environments which have been developed in the five-year formal approach to software environment technology (FASET) project is reviewed. For this study, a software environment evaluation technology based on a software quality evaluation process model defined in ISO/IEC 9126 has been developed. The evaluation technology has been applied to the R&D project at the middle and final phase of development. The evaluation results provide useful information to develop a widely acceptable evaluation technology and to improve the new-paradigm-oriented software development environments that are based on various specification methods: the algebraic specification method, function-oriented specification method, declarative specification method, natural-language-oriented specification method, diagrammatic specification method, state-transition-oriented specification method, and model-based specification method.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.232010","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=232010","","Programming;Software quality;Software tools;Software engineering;IEC standards;ISO standards;Research and development;Formal specifications;International trade;Computer industry","formal specification;programming environments;software quality","software development environment quality;FASET;software quality evaluation process model;ISO/IEC 9126;algebraic specification method;function-oriented specification;declarative specification;natural-language-oriented specification;diagrammatic specification;state-transition-oriented;specification;model-based specification","","16","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Coordinating multiagent applications on the WWW: a reference architecture","P. Ciancarini; R. Tolksdorf; F. Vitali; D. Rossi; A. Knoche","Dept. of Comput. Sci., Bologna Univ., Italy; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","5","362","375","The original Web did not support multiuser, interactive applications. This shortcoming is being studied, and several approaches have been proposed to use the Web as a platform for programming Internet applications. However, most existing approaches are oriented to centralized applications at servers, or local programs within clients. To overcome this deficit, we introduce PageSpace, that is a reference architecture for designing interactive multiagent applications. We describe how we control agents in PageSpace, using variants of the coordination language Linda to guide their interactions. Coordination technology is integrated with the standard Web technology and the programming language Java. Several kinds of agents live in the PageSpace: user interface agents, personal homeagents, agents that implement applications, and agents which interoperate with legacy systems. Within our architecture, it is possible to support fault-tolerance and mobile agents as well.","0098-5589;1939-3520;2326-3881","","10.1109/32.685259","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=685259","","World Wide Web;Java;Application software;Service oriented architecture;Internet;Computer architecture;Electronic commerce;Computer Society;Web server;Computer languages","Internet;software agents;cooperative systems;parallel languages;object-oriented languages;open systems;client-server systems;interactive systems;user interfaces;software fault tolerance","multiagent application coordination;reference architecture;World Wide Web;multiuser interactive applications;programming;Internet applications;centralized applications;client server systems;PageSpace;coordination language;Linda;coordination technology;Java;user interface agents;personal homeagents;legacy systems;fault tolerance;mobile agents;open distributed systems","","52","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Some inference rules for integer arithmetic for verification of flowchart programs on integers","D. C. Sarkar; S. C. De Sarkar","Indian Inst. of Technol., Kharagpur, India; Indian Inst. of Technol., Kharagpur, India","IEEE Transactions on Software Engineering","","1989","15","1","1","9","Significant modifications of the first-order rules have been developed so that they can be applied directly to algebraic expressions. The importance and implication of normalization of formulas in any theorem prover are discussed. It is shown how the properties of the domain of discourse have been taken care of either by the normalizer or by the inference rules proposed. Using a nontrivial example, the following capabilities of the verifier that would use these inference rules are highlighted: (1) closeness of the proof construction process to the human thought process; and (2) efficient handling of user provided axioms. Such capabilities make interfacing with humans easy.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21720","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21720","","Arithmetic;Flowcharts;Humans;Logic;Heart;Calculus;Virtual colonoscopy;Computer science","inference mechanisms;program verification;theorem proving","inference rules;integer arithmetic;verification;flowchart programs;first-order rules;algebraic expressions;theorem prover;proof construction process;human thought process;user provided axioms","","9","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Static analysis of real-time distributed systems","L. Y. Liu; R. K. Shyamasundar","Dept. of Comput. Sci., Pennsylvania State Univ., University Park, PA, USA; Dept. of Comput. Sci., Pennsylvania State Univ., University Park, PA, USA","IEEE Transactions on Software Engineering","","1990","16","4","373","388","A static analysis for reasoning about the temporal behaviors of programs in real-time distributed programming languages is proposed. The analysis is based on the action set semantics using the pure maximal parallelism model. It is shown how to specify and verify various timing properties of real-time programs. The approach provides only an approximate timing behavior, because the state information is ignored. However, many interesting properties such as parallel actions, deadlocks, livelocks, terminations, temporal errors, and failures, can be identified. Furthermore, the approach is compositional and thus makes it possible to reason about the timing properties incrementally. The method not only leads to efficient algorithms for the static analysis of CSP programs but also applies to many other languages.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.54290","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=54290","","Real time systems;Merging;Timing;Algorithm design and analysis;Computer science;Concurrent computing;History;Low earth orbit satellites;System recovery;Automation","distributed processing;parallel programming;programming languages;real-time systems;software engineering","real-time distributed systems;static analysis;reasoning;temporal behaviors;programs;maximal parallelism model;timing properties;parallel actions;deadlocks;livelocks;terminations;temporal errors;failures;CSP programs","","21","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Modeling and improving an industrial software process","S. Bandinelli; A. Fuggetta; L. Lavazza; M. Loi; G. P. Picco","CEFRIEL, Milan, Italy; CEFRIEL, Milan, Italy; CEFRIEL, Milan, Italy; NA; NA","IEEE Transactions on Software Engineering","","1995","21","5","440","454","The paper discusses the problems that a software development organization must address in order to assess and improve its software processes. In particular, the authors are involved in a project aiming at assessing and improving the current practice and the quality manual of the Business Unit Telecommunications for Defense (BUTD) of a large telecommunications company. The paper reports on the usage of formal process modeling languages to detect inconsistencies, ambiguities, incompleteness, and opportunities for improvement of both the software process and its documentation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.387473","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=387473","","Computer industry;Capability maturity model;Programming;Production;Project management;Continuous improvement;Coordinate measuring machines;Business communication;Telecommunications;Companies","telecommunication computing;programming environments;system documentation;DP industry;software quality","software development organization;industrial software process modelling;industrial software process improvement;current practice;quality manual;Business Unit Telecommunications for Defense;large telecommunications company;formal process modeling languages;inconsistency detection;ambiguity detection;incompleteness detection;documentation","","50","","33","","","","","","IEEE","IEEE Journals & Magazines"
"An effective approach to vertical partitioning for physical design of relational databases","D. W. Cornell; P. S. Yu","Digital Equipment Corp., Littleton, MA, USA; NA","IEEE Transactions on Software Engineering","","1990","16","2","248","258","Vertical partitioning can be used to enhance the performance of relational database systems by reducing the number of disk accesses. The authors identify the key parameters for capturing the behavior of an access plan and propose a two-step methodology consisting of a query analysis step to estimate the parameters and a binary partitioning step which can be applied recursively. The partitioning uses an integer linear programming technique to minimize the number of disk accesses. Significant performance benefit would be achieved for join if the partitioned (inner) relation could fit into the memory buffer under the inner-outer loop join method, or if the partitioned relation could fit into the sort buffer under the sort-merge join method, but not the original relation. For cases where a segment scan or a cluster index scan is used, vertical partitioning of the relation with the algorithm described is still often found to lead to substantial performance improvement.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44388","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44388","","Relational databases;Costs;Partitioning algorithms;Linear programming;Performance analysis;Transaction databases;Information retrieval;Algorithm design and analysis;Frequency;Delay","linear programming;relational databases;software engineering","vertical partitioning;physical design;relational databases;disk accesses;two-step methodology;query analysis;binary partitioning;integer linear programming;join;sort-merge;segment scan;cluster index scan","","36","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Unidirectional Transport of Rights and TakeGrant Control","A. Lockman; N. Minsky","Department of Computer Science, Rutgers University; NA","IEEE Transactions on Software Engineering","","1982","SE-8","6","597","604","One of the most critical and least understood aspects of protection is the exercise of control over the movement of rights between the subjects of a system. The conventional Take-Grant mechanism for exercising such control suffers from a puzzling and unfortunate limitation: it cannot enforce strictly unidirectional channels for the flow of rights. That is, if rights can be moved directly or indirectly from some subject p to another subject q, then one cannot prevent rights from flowing in the opposite direction, from q to p. This property limits the applicability of this mechanism and therefore that of any protection scheme utilizing it. We analyze the nature and ramifications of this limitation and demonstrate that its root cause is the fact that (under this mechanism) a right possessed by a sender suffices to authorize a movement of rights. We propose an alternative, ""Take-Receive,"" model in which this limitation is eliminated, thus enabling the implementation of more useful protection disciplines. We prove this result by analyzing tl-e dynamic behavior of the proposed model.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.236020","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702993","Access Control;protection;Take-Grant model;transport of rights","Protection;Control systems;Mechanical factors;Access control;Computer science;Software engineering","","Access Control;protection;Take-Grant model;transport of rights","","6","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Description for a tool specifying and prototyping concurrent programs","N. De Francesco; G. Vaglini","Dept. of Inf., Pisa Univ., Italy; Dept. of Inf., Pisa Univ., Italy","IEEE Transactions on Software Engineering","","1988","14","11","1554","1564","A specification language is introduced, able to define the behavior of concurrent programs. The language is particularly devoted to describing distributed applications, mainly with respect to scheduling problems. For this purpose, the language allows visibility of the past history of a computation and such history may be explicitly used to derive the choices on the future behavior of the computation itself and to define the values exchanged at each communication. A behavior is a partial order on events (communications) accomplished by processes, while the values of the communications are specified by a functional language. The most noticeable characteristic of specifications written in this language is the capability to be easily translated into executable concurrent programs (written into a CSP-like concurrent language), so obtaining an early prototype for these programs. An algorithm is described to accomplish the translation. An environment is provided to support static semantics checks on specifications, while dynamic testing and debugging are accomplished using interactive tools of the concurrent language environment.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9044","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9044","","Prototypes;Specification languages;Processor scheduling;History;Testing;Debugging;Programming environments","automatic programming;parallel programming;program interpreters;programming environments;software tools;specification languages","automatic programming;programming environments;parallel programming;prototyping;specification language;distributed applications;scheduling;functional language;executable concurrent programs;concurrent language;translation;static semantics checks;dynamic testing;debugging;interactive tools","","3","","25","","","","","","IEEE","IEEE Journals & Magazines"
"High performance software testing on SIMD machines","E. W. Krauser; A. P. Mathur; V. J. Rego","Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA; Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA; Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA","IEEE Transactions on Software Engineering","","1991","17","5","403","423","A method for high-performance, software testing, called mutant unification, is described. The method is designed to support program mutation on parallel machines based on the single instruction multiple data stream (SIMD) paradigm. Several parameters that affect the performance of unification have been identified and their effect on the time to completion of a mutation test cycle and speedup has been studied. Program mutation analysis provides an effective means for determining the reliability of large software systems and a systematic method for measuring the adequacy of test data. However, it is likely that testing large software systems using mutation is computation bound and prohibitive on traditional sequential machines. Current, implementations of mutation tools are unacceptably slow and are only suitable for testing relatively small programs. The proposed unification method provides a practical alternative to the current approaches. The method also opens up a new application domain for SIMD machines.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.90444","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=90444","","Software testing;Genetic mutations;Software systems;System testing;Application software;Educational institutions;Software engineering;Parallel machines;Sequential analysis;Life testing","parallel machines;program testing;software reliability","software reliability;software testing;mutant unification;program mutation;parallel machines;single instruction multiple data stream;software systems;SIMD machines","","26","","38","","","","","","IEEE","IEEE Journals & Magazines"
"The Implementation of Run-Time Diagnostics in Pascal","C. N. Fischer; R. J. LeBlanc","Department of Computer Science, University of Wisconsin; NA","IEEE Transactions on Software Engineering","","1980","SE-6","4","313","319","This paper considers the role of run-time diagnostic checking in enforcing the rules of the Pascal programming language. Run-time diagnostic checks must be both complete (covering all language requirements) and efficient. Further, such checks should be implemented so that the cost of enforcing the correct use of a given construct is borne by users of that construct. This paper descxibes simple and efficient mechanisms currently in use with a diagnostic Pascal compiler that monitor the run-time behavior of such sensitive Pascal constructs as pointers, variant records, reference (i.e., var) parameters, and with statements. The use of these mechanisms with related constructs in other languages is considered. Language modifications that simplify run-time checking ate also noted.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230482","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702738","Diagnostic compiler;Pascal;pointer checking;reference parameter checking;run-time checking;variant record checking","Runtime;Computer languages;Costs;Program processors;Testing;Degradation;Condition monitoring;Reactive power;Protection","","Diagnostic compiler;Pascal;pointer checking;reference parameter checking;run-time checking;variant record checking","","9","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Some Results on the Working Set Anomalies in Numerical Programs","W. A. Abu-Sufah; D. A. Padua","Department of Electrical Engineering, Yarmouk University; NA","IEEE Transactions on Software Engineering","","1982","SE-8","2","97","106","This paper shows that the working set parameter-real memory and real memory-fault rate anomalies mentioned by Franklin, Graham, and Gupta in [13] do occur in traces generated by real programs. The results of the detailed investigation of this anomalous behavior in four Fortran programs are presented. In some cases a drop of a factor of two in the average real-time memory allotment is observed when the window size is increased. In some instances a bigger real-time memory allotment means an order of magnitude increase in page faults.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.234952","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702917","Memory management;multiprogramming;program behavior;working set;working set anomaly","Computer science;Frequency;Memory management;Springs;Load flow control","","Memory management;multiprogramming;program behavior;working set;working set anomaly","","4","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Communicating real-time state machines","A. C. Shaw","Dept. of Comput. Sci. & Eng., Washington Univ., Seattle, WA, USA","IEEE Transactions on Software Engineering","","1992","18","9","805","816","Communicating real-time state machines (CRSMs), a complete and executable notation for specifying concurrent real-time systems including the monitored and controlled physical environment, are introduced. They are essentially state machines that communicate synchronously in a manner much like the input-output in Hoare's CSP. In addition, CRSMs have a novel and small set of facilities for describing timing properties and accessing real time. The author defines the CRSM language, gives many examples of its use in requirements specification, outlines an algorithm for executing or simulating CRSMs, introduces some techniques for reasoning about the specifications, and discusses some open problems and issues.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.159840","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=159840","","Real time systems;Timing;Clocks;Condition monitoring;Concurrent computing;Turing machines;Automata;Computer science;Computational modeling","communicating sequential processes;finite state machines;formal specification;parallel machines;real-time systems","communicating real-time state machines;executable notation;concurrent real-time systems;controlled physical environment;state machines;CRSMs;timing properties;CRSM language;requirements specification","","81","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Efficient algorithms for the instantiated transitive closure queries","G. Z. Qadah; L. J. Henschen; J. J. Kim","Dept. of Electr. Eng. & Comput. Sci., Northwestern Univ., Evanston, IL, USA; Dept. of Electr. Eng. & Comput. Sci., Northwestern Univ., Evanston, IL, USA; NA","IEEE Transactions on Software Engineering","","1991","17","3","296","309","The performances of several algorithms suitable for processing an important class of recursive queries called the instantiated transitive closure (TC) queries are studied and compared. These algorithms are the wavefront, delta -wavefront, and a generic algorithm called super-TC. During the evaluation of a TC query, the first two algorithms may read a given disk page more than once, whereas super-TC reads the disk page at most once. A comprehensive performance evaluation of these three algorithms using rigorous analytical and simulation models is presented. The study reveals that the relative performance of the algorithms is a strong function of the parameters which characterize the processed TC query and the relation referenced by that query. The superiority of one of the super-TC variants over all of the other presented algorithms is shown.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.75418","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=75418","","Deductive databases;Analytical models;Logic;Virtual colonoscopy;Performance analysis;Algorithm design and analysis;Relational databases;Helium;Intelligent systems;Database systems","database theory;performance evaluation;query languages","database theory;instantiated transitive closure queries;recursive queries;wavefront;delta -wavefront;generic algorithm;super-TC;disk page;performance evaluation;processed TC query","","13","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Overhead Storage Considerations and a Multilinear Method for Data File Compression","T. Y. Young; P. S. Liu","Department of Electrical Engineering, University of Miami; NA","IEEE Transactions on Software Engineering","","1980","SE-6","4","340","347","The paper is concerned with the reduction of overhead storage, i.e., the stored compression/decompression (C/D) table, in field-level data file compression. A large C/D table can occupy a lage fraction of maim memory space during compression and decompression, and may cause excessve page swapping in virtual memory systems. A two-stage approach is studied, including the reuired additional C/D table decompression time. It appears that the approach has limitations and is not completely satisfactory.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234490","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702742","Cluster analysis;data file compression;data transformation;multilinear approach;overhead storage;performance analyis;piecewise linear transformation;storage reduction techniques","Data compression;Performance analysis;Clustering algorithms;Data analysis;Piecewise linear techniques;Merging;Encoding","","Cluster analysis;data file compression;data transformation;multilinear approach;overhead storage;performance analyis;piecewise linear transformation;storage reduction techniques","","8","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Checkpointing and Rollback-Recovery for Distributed Systems","R. Koo; S. Toueg","Department of Computer Science, Cornell University; NA","IEEE Transactions on Software Engineering","","1987","SE-13","1","23","31","We consider the problem of bringing a distributed system to a consistent state after transient failures. We address the two components of this problem by describing a distributed algorithm to create consistent checkpoints, as well as a rollback-recovery algorithm to recover the system to a consistent state. In contrast to previous algorithms, they tolerate failures that occur during their executions. Furthermore, when a process takes a checkpoint, a minimal number of additional processes are forced to take checkpoints. Similarly, when a process rolls back and restarts after a failure, a minimal number of additional processes are forced to roll back with it. Our algorithms require each process to store at most two checkpoints in stable storage. This storage requirement is shown to be minimal under general assumptions.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232562","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702129","Checkpoint;consistent state;distributed systems;fault-tolerance;rollback-recovery","Checkpointing;Distributed algorithms;Fault tolerant systems;Hardware;Resumes;Fault tolerance;Computer science;Distributed computing","","Checkpoint;consistent state;distributed systems;fault-tolerance;rollback-recovery","","313","","18","","","","","","IEEE","IEEE Journals & Magazines"
"A Local Network Based on the UNIX Operating System","L. A. Rowe; K. P. Birman","Department of Electrical Engineering and Computer Science, University of California; NA","IEEE Transactions on Software Engineering","","1982","SE-8","2","137","146","The design and implementation of a local network operating ystem based on the UNIX<sup>1</sup>operating system is described. UNIX has been extended to allow existing programs to access remote resources with no source program changes. Programs may access remote files, have a remote working directory, execute remote programs, and communicate with remote processes using the standard UNIX interprocess communication mechanism (pipe's). An efficient message-oriented interprocess communication mechanism and asynchronous I/O were added to the system to support the development of distributed applications and to make it easier to connect the local network to packet-switched networks.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.234956","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702921","Interprocess communication;local computer networks;multidestination protocols;network operating systems","Operating systems;Computer networks;Network operating systems;Communication standards;Database systems;Computer architecture;Throughput;Application software;Access protocols;Distributed computing","","Interprocess communication;local computer networks;multidestination protocols;network operating systems","","8","","29","","","","","","IEEE","IEEE Journals & Magazines"
"A Resource Sharing System for Personal Computers in a LAN: Concepts, Design, and Experience","R. C. Summers","IBM Los Angeles Scientific Center","IEEE Transactions on Software Engineering","","1987","SE-13","8","895","904","RM is an experimental prototype that supports the use of distributed services by personal computers in a LAN. Using a service request model, RM allows any PC on the LAN to offer and use services, which can be user-written or off-the-shelf applications. A user can start several activities that proceed concurrently and that use services offered by different machines. Program interfaces are provided for the development of distributed applications. Remote execution is supported within the service-request framework. The paper considers issues in resource sharing and discusses the choices that were made for RM. It provides an overview of RM concepts, design, and implementation, and reviews experience using the system.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233508","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702308","Distributed services;personal-computer LAN's;remote execution;resource sharing;service-request models","Resource management;Microcomputers;Local area networks;Application software;Prototypes;Hardware;Operating systems;Software prototyping;US Department of Transportation;Peer to peer computing","","Distributed services;personal-computer LAN's;remote execution;resource sharing;service-request models","","4","","34","","","","","","IEEE","IEEE Journals & Magazines"
"A syntactic theory of software architecture","T. R. Dean; J. R. Cordy","Dept. of Comput. & Inf. Sci., Queen's Univ., Kingston, Ont., Canada; Dept. of Comput. & Inf. Sci., Queen's Univ., Kingston, Ont., Canada","IEEE Transactions on Software Engineering","","1995","21","4","302","313","Introduces a general, extensible diagrammatic syntax for expressing software architectures based on typed nodes and connections and formalized using set theory. The syntax provides a notion of abstraction corresponding to the concept of a subsystem, and exploits this notion in a general mechanism for pattern matching over architectures. We demonstrate these ideas using a small example architecture language with a limited number of types of nodes and connectors, and a small taxonomy of architectures characterized as sets of patterns in the language.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.385969","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=385969","","Software architecture;Taxonomy;Computer architecture;Pattern matching;Set theory;Connectors;Councils;Information technology;Information science","software engineering;set theory;pattern matching;type theory;diagrams;formal languages","syntactic theory;software architecture;extensible diagrammatic syntax;typed nodes;typed connections;set theory;abstraction;subsystem;pattern matching;architecture language;connectors;taxonomy;software structure","","43","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Distributed Version Management for Read-Only Actions","W. E. Weihl","M. I. T. Laboratory for Computer Science, 545 Technology Square","IEEE Transactions on Software Engineering","","1987","SE-13","1","55","64","Typical concurrency control protocols for atomic actions, such as two-phase locking, perform poorly for long read-only actions. We present four new concurrency control protocols that eliminate all interference between read-only actions and update actions, and thus offer significantly improved performance for read-only actions. The protocols work by maintaining multiple versions of the system state; read-only actions read old versions, while update actions manipulate the most recent version. We focus on the problem of managing the storage required for old versions in a distributed system. One of the protocols uses relatively little space, but has a potentially significant communication cost. The other protocols use more space, but may be cheaper in terms of communication.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232835","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702133","Atomic actions;concurrency;distributed systems;multiple version protocols;read-only actions;storage management","Protocols;Concurrency control;Hardware;Interference elimination;Costs;Concurrent computing;Data mining;Application software;Delay effects;System recovery","","Atomic actions;concurrency;distributed systems;multiple version protocols;read-only actions;storage management","","22","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Virtual Time CSMA Protocols for Hard Real-Time Communication","Wei Zhao; K. Ramamritham","Department of Mathematics, Amherst College; NA","IEEE Transactions on Software Engineering","","1987","SE-13","8","938","952","We study virtual time CSMA protocols for hard real time communication systems, i, e., systems where messages have explicit deadlines. In this class of CSMA protocols, each node maintains two clocks; a real time clock and a virtual time clock. Whenever a node finds the channel to be idle, it resets its virtual clock. The virtual clock then runs at a higher rate than the real clock. A node transmits a waiting message when the time on the virtual clock is equal to some parameter of the message. Using different message parameters in conjunction with the virtual clock, different transmission policies can be implemented. In particular, use of message arrival time, message length, message laxity, and message deadline implements FCFS, Minimum-Length-First, Minimum-Laxity-First, and Minimum-Deadline-First transmission policies, respectively.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233512","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702312","CSMA protocols;multiaccess networks;performance evaluation;real-time communications;simulation;virtual time","Multiaccess communication;Clocks;Access protocols;Real time systems;Measurement;Delay;Delta modulation;Road accidents;Telecommunication traffic;Springs","","CSMA protocols;multiaccess networks;performance evaluation;real-time communications;simulation;virtual time","","59","","33","","","","","","IEEE","IEEE Journals & Magazines"
"Formal specification and analysis of software architectures using the chemical abstract machine model","P. Inverardi; A. L. Wolf","Dipartimento di Matematica Pura ed Applicata, L'Aquila Univ., Italy; NA","IEEE Transactions on Software Engineering","","1995","21","4","373","386","We are exploring an approach to formally specifying and analyzing software architectures that is based on viewing software systems as chemicals whose reactions are controlled by explicitly stated rules. This powerful metaphor was devised in the domain of theoretical computer science by Bana/spl circ/tre and Le Me/spl acute/tayer (1990) and then reformulated as the CHAM (CHemical Abstract Machine) by Berry and Boudol (1992). The CHAM formalism provides a framework for developing operational specifications that does not bias the described system toward any particular computational model. It also encourages the construction and use of modular specifications at different levels of detail. We illustrate the use of the CHAM for architectural description and analysis by applying it to two different architectures for a simple but familiar software system, the multiphase compiler.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.385973","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=385973","","Chemical analysis;Formal specifications;Computer architecture;Software architecture;Software systems;Computer science;Power system modeling;Computational modeling;Modular construction;Software engineering","formal specification;program compilers;chemical reactions;finite automata;programming theory","formal specification;formal analysis;software architectures;chemical abstract machine model;chemical reactions;explicitly stated rules;theoretical computer science;CHAM formalism;operational specifications;computational model;modular specifications;levels of detail;architectural description;multiphase compiler","","106","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Developing interactive information systems with the User Software Engineering methodology","A. I. Wasserman; P. A. Pircher; D. T. Shewmake; M. L. Kersten","Section of Medical Information Science, University of California, San Francisco, CA 94143; Section of Medical Information Science, University of California, San Francisco, CA 94143; Section of Medical Information Science, University of California, San Francisco, CA 94143; Centrum voor Wiskunde en Informatica, Amsterdam, The Netherlands","IEEE Transactions on Software Engineering","","1986","SE-12","2","326","345","User software engineering (USE) is a methodology, supported by automated tools, for the systematic development of interactive information systems. The USE methodology gives particular attention to effective user involvement in the early stages of the software development process, concentrating on external design and the use of rapidly created and modified prototypes of the user interface. The USE methodology is supported by an integrated set of graphically based tools. The USE methodology and the tools that support it are described.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312947","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312947","Human/computer interaction;interactive information systems;rapid prototyping;RAPID/USE;software development methodology;transition diagrams;User Software Engineering","Libraries;Books;Data models;Software engineering;Software;Databases;Information systems","interactive systems;software engineering;user interfaces","interactive information systems;user software engineering methodology;automated tools;user involvement;software development process;prototypes;user interface;graphically based tools;USE methodology","","14","","","","","","","","IEEE","IEEE Journals & Magazines"
"Reusability of mathematical software: a contribution","P. Di Felice","Dipartimento di Ingegneria Elettrica, Univ. di L'Aquila, Italy","IEEE Transactions on Software Engineering","","1993","19","8","835","843","Mathematical software is devoted to solving problems involving matrix computation and manipulation. The main problem limiting the reusability of existing mathematical software is that programs are often not initially designed for being reused. Therefore, it is hard to find programs that can be easily reused. A programming methodology useful for designing and implementing reusable code is presented. A portion of code designed and implemented for being reused is called a unit. The units are self-contained software components featuring a high degree of information hiding. This way of organizing software facilitates the reuse process and improves the understandability of units. To speed up the implementation process, a system supporting the reusability of units from an existing software library is particularly useful. The functionality of the EasyCard system, which creates, maintains, and queries a catalog of units is discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.238586","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=238586","","Software reusability;Programming profession;Software tools;Sparse matrices;Application software;Design methodology;Software libraries;Object oriented programming;Standardization;Organizing","mathematics computing;software reusability","matrix computation;reusability;mathematical software;programming methodology;reusable code;self-contained software components;information hiding;understandability;existing software library;EasyCard system","","6","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Compartmented mode workstation: prototype highlights","J. L. Berger; J. Picciotto; J. P. L. Woodward; P. T. Cummings","MITRE Corp., Bedford, MA, USA; MITRE Corp., Bedford, MA, USA; MITRE Corp., Bedford, MA, USA; MITRE Corp., Bedford, MA, USA","IEEE Transactions on Software Engineering","","1990","16","6","608","618","The primary goal of the MITRE compartmented mode workstation (CMW) project was to articulate the security requirements that workstations must meet to process highly classified intelligence data. As a basis for the validity of the requirements developed, a prototype was implemented which demonstrated that workstations could meet the requirements in an operationally useful manner while still remaining binary compatible with off-the-shelf software. The security requirements not only addressed traditional security concerns but also introduced concepts in areas such as labeling and the use of a trusted window management system. The CMW labeling paradigm is based on associating two types of security labels with objects: sensitivity levels and information labels. Sensitivity levels describe the levels at which objects must be protected. Information labels are used to prevent data overclassification and also provide a mechanism for associating with data those markings that are required for accurate data labeling, but which play no role in access control decisions. The use of a trusted window manager allows users to easily operate at multiple sensitivity levels and provides a convenient mechanism for communicating security information to users in a relatively unobtrusive manner.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.55089","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=55089","","Workstations;Prototypes;Data security;Information security;Computer security;Labeling;Access control;Protection;Power generation economics;Environmental economics","security of data;software engineering;workstations","data overclassification prevention;MITRE compartmented mode workstation;security requirements;highly classified intelligence data;binary compatible;trusted window management system;security labels;objects;sensitivity levels;information labels;markings;accurate data labeling;multiple sensitivity levels","","8","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Engineering software design processes to guide process execution","Xiping Song; L. J. Osterweil","Corporate Res. Inc., Princeton, NJ, USA; NA","IEEE Transactions on Software Engineering","","1998","24","9","759","775","Using systematic development processes is an important characteristic of any mature engineering discipline. In current software practice, software design methodologies (SDMs) are intended to be used to help design software more systematically. This paper shows, however, that one well-known example of such an SDM, Booch Object-Oriented Design (BOOD), as described in the literature is too imprecise and incomplete to be considered as a fully systematic process for specific projects. To provide more effective and appropriate guidance and control in software design processes, we applied the process programming concept to the design process. Given two different sets of plausible design process requirements, we elaborated two more detailed and precise design processes that are responsive to these requirements. We have also implemented, experimented with, and evaluated a prototype (called Debus-Booch) that supports the execution of these detailed processes.","0098-5589;1939-3520;2326-3881","","10.1109/32.713330","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=713330","","Design engineering;Software design;Design methodology;Process design;Software engineering;Programming;Computer Society;Software systems;Software prototyping;Prototypes","object-oriented programming;software engineering","process execution;systematic development processes;software design methodologies;Booch Object-Oriented Design;BOOD;software design processes;process programming","","5","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Information resources management in heterogeneous, distributed environments: A metadatabase approach","C. Hsu; M. Bouziane; L. Rattner; L. Yee","Rensselaer Polytech. Inst., Troy, NY, USA; Rensselaer Polytech. Inst., Troy, NY, USA; Rensselaer Polytech. Inst., Troy, NY, USA; Rensselaer Polytech. Inst., Troy, NY, USA","IEEE Transactions on Software Engineering","","1991","17","6","604","625","The core structure of a metadatabase system for information integration in heterogeneous and distributed environments, the global information resources dictionary (GIRD) model for unified metadata representation and management (both data and knowledge), is discussed. Overviews of metadatabase systems and the two-stage entity relationship (TSER) representation method are presented. To illustrate some major properties of the metadatabase model, and to show how the GIRD elements fit together to deliver these properties, manufacturing information management examples are given. The GIRD and the information resources dictionary system (IRDS) standard are compared.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.87285","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=87285","","Information resources;Environmental management;Information management;Resource management;Dictionaries;Computer aided software engineering;Productivity;Software development management;Engineering management;Knowledge management","CAD/CAM;database management systems;database theory;distributed processing;manufacturing data processing;software engineering","information resource management;core structure;metadatabase system;information integration;distributed environments;global information resources dictionary;unified metadata representation;two-stage entity relationship;TSER;metadatabase model;GIRD elements;manufacturing information management examples;information resources dictionary system;IRDS","","47","","25","","","","","","IEEE","IEEE Journals & Magazines"
"A model for multilevel security in computer networks","W. -. Lu; M. K. Sundareshan","Dept. of Electr. & Comput. Eng., Arizona Univ., Tucson, AZ, USA; Dept. of Electr. & Comput. Eng., Arizona Univ., Tucson, AZ, USA","IEEE Transactions on Software Engineering","","1990","16","6","647","659","A model is presented that precisely describes the mechanism that enforces the security policy and requirements for a multilevel secure network. The mechanism attempts to ensure secure flow of information between entities assigned to different security classes in different computer systems connected to the network. The mechanism also controls the access to the network devices by the subjects (users and processes executed on behalf of the users) with different security clearances. The model integrates the notions of nondiscretionary access control and information flow control to provide a trusted network base that imposes appropriate restrictions on the flow of information among the various devices. Utilizing simple set-theoretic concepts, a procedure is given to verify the security of a network that implements the model.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.55093","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=55093","","Multilevel systems;Intelligent networks;Computer networks;Information security;Protection;Communication system control;Access control;Computer security;Computer architecture;Data security","computer networks;security of data","multilevel security;computer networks;security policy;multilevel secure network;entities;security classes;computer systems;network devices;subjects;security clearances;nondiscretionary access control;information flow control;trusted network base;set-theoretic concepts","","7","","53","","","","","","IEEE","IEEE Journals & Magazines"
"A Theoretical Basis for the Analysis of Multiversion Software Subject to Coincident Errors","D. E. Eckhardt; L. D. Lee","NASA Langley Research Center; NA","IEEE Transactions on Software Engineering","","1985","SE-11","12","1511","1517","Fundamental to the development of redundant software techniques (known as fault-tolerant software) is an understanding of the impact of multiple joint occurrences of errors, referred to here as coincident errors. A theoretical basis for the study of redundant software is developed which 1) provides a probabilistic framework for empirically evaluating the effectiveness of a general multiversion strategy when component versions are subject to coincident errors, and 2) permits an analytical study of the effects of these errors. An intensity function, called the intensity of coincident errors, has a central role in this analysis. This function describes the propensity of programmers to introduce design faults in such a way that software components fail together when executing in the application environment. We give a condition under which a multiversion system is a better strategy than relying on a single version and we study some differences between the coincident errors model developed here and the model that assumes independent failures of component verions.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231895","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701974","Coincident errors;fault-tolerant software;intensity distribution;intensity of coincident errors;multiversion software;N-version programming;reliability of redundant software","Redundancy;Fault tolerance;Application software;Programming profession;Hardware;Probability;Fault tolerant systems;Software safety;Aerospace electronics;Control systems","","Coincident errors;fault-tolerant software;intensity distribution;intensity of coincident errors;multiversion software;N-version programming;reliability of redundant software","","194","","14","","","","","","IEEE","IEEE Journals & Magazines"
"A graph model for software evolution","Luqi","Dept. of Comput. Sci., US Naval Post-graduate Sch., Monterey, CA, USA","IEEE Transactions on Software Engineering","","1990","16","8","917","927","A graph model of software evolution is presented. The author seeks to formalize the objects and activities involved in software evolution in sufficient detail to enable automatic assistance for maintaining the consistency and integrity of an evolving software system. This includes automated support for propagating the consequences of a change to a software system. The evolution of large and complex software systems receives particular attention.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.57627","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=57627","","Software systems;Software maintenance;Software prototyping;Prototypes;Scheduling;Automatic control;Costs;Programming;History;Humans","automatic programming;data integrity;graph theory;software tools","graph model;software evolution;automatic assistance;consistency;integrity;evolving software system;automated support;complex software systems","","45","","14","","","","","","IEEE","IEEE Journals & Magazines"
"A software science model of compile time","W. H. Shaw; J. W. Howatt; R. S. Maness; D. M. Miller","Dept. of Electr. & Comput. Eng., Air Force Inst. of Technol., Wright-Patterson AFB, OH, USA; Dept. of Electr. & Comput. Eng., Air Force Inst. of Technol., Wright-Patterson AFB, OH, USA; Dept. of Electr. & Comput. Eng., Air Force Inst. of Technol., Wright-Patterson AFB, OH, USA; Dept. of Electr. & Comput. Eng., Air Force Inst. of Technol., Wright-Patterson AFB, OH, USA","IEEE Transactions on Software Engineering","","1989","15","5","543","549","The Halstead theory of software science is used to describe the compilation process and generate a compiler performance index. A nonlinear model of compile time is estimated for four Ada compilers. A fundamental relation between compile time and program modularity is proposed. Issues considered include data collection procedures, the development of a counting strategy, the analysis of the complexity measures used, and the investigation of significant relationships between program characteristics and compile time. The results indicate that the model has a high predictive power and provides interesting insights into compiler performance phenomena. The research suggests that the discrimination rate of a compiler is a valuable performance index and is preferred to average compile-time statistics.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24703","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24703","","Military computing;Embedded computing;Software performance;Time measurement;Force control;Performance analysis;Aerospace electronics;Marine vehicles;Predictive models;Statistics","performance evaluation;program compilers","software science model;compile time;Halstead theory of software science;compilation process;compiler performance index;nonlinear model;Ada compilers;fundamental relation;program modularity;data collection;counting strategy;complexity measures;significant relationships;program characteristics;predictive power;compiler performance;discrimination rate;performance index","","2","","11","","","","","","IEEE","IEEE Journals & Magazines"
"A Comparison of Dynamic and Static Virtual Memory Allocation Algorithms","R. L. Budzinski; E. S. Davidson","Central Research Laboratory, Texas Instruments, Inc.; NA","IEEE Transactions on Software Engineering","","1981","SE-7","1","122","131","In this paper we compare the performance of virtual memory allocation algorithms. The primary measure of performance is the space-time product of primary memory occupancy, or space-time cost, used by a program during its execution. Using DMIN, an optimal dynamic aliocation algorithm, we compute the minimum space-time cost achievable for some benchmark program runs. We compare the DMIN space-time cost with the space-time cost from: MIN, an optimal static allocation algorithm, VMIN, an optimal variable space algorithm, and two heuristic dynamic allocation algorithms. the page fault frequency algorithm and the damped working set algorithm.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234515","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702809","DMIN algorithm;dynamic memory;MIN algorithm;page fault frequency algorithm;space-time cost;virtual memory;working set algorithms","Heuristic algorithms;Memory management;Cost function;Frequency;Radio spectrum management;Laboratories;Instruments;Extraterrestrial measurements;Interference;Throughput","","DMIN algorithm;dynamic memory;MIN algorithm;page fault frequency algorithm;space-time cost;virtual memory;working set algorithms","","6","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Analysis of Database System Architectures Using Benchmarks","S. B. Yao; A. R. Hevner; H. Young-Myers","Database Systems Research Center, College of Business and Management, University of Maryland; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","6","709","725","Database machine architectures have been proposed as a promising alternative to improve database system performance, control, and flexibility. While many claims have been made for the database machine concept, few studies have been made to test the performance advantages and disadvantages of a database machine in an application environment. A comprehensive benchmark study comparing the performance of database systems on a conventional computer system and a database machine is reported in this paper. The results show the database machine architecture to have superior performance in most cases. The performance advantage is sensitive to the communication line speed between the host computer and the database machine. The effects of line speed are studied and displayed in the benchmark results. A summary of the similarities and differences between the architectures based upon our benchmark results completes the paper.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233476","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702276","Benchmarking;database machines;database system architectures;performance evaluation","Data analysis;Database systems;Database machines;Computer architecture;Application software;Benchmark testing;Operating systems;Control systems;Hardware;Computer interfaces","","Benchmarking;database machines;database system architectures;performance evaluation","","3","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Processing Implication on Queries","Xian-he Sun; N. N. Kamel; L. M. Ni","Departmcnt of Computer Science. Michigan State University. East Lansing. Ml; NA; NA","IEEE Transactions on Software Engineering","","1989","15","10","1168","1175","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1989.559764","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=559764","","Database systems;Relational databases;Sun;Distributed databases;Costs;Polynomials;Senior members;Protocols;Query processing","","Database;Derivability Problem;Directed Graph;Implication Problem;Mathematical Logic;NP-hard;project-select-joint queries;satisfiability","","8","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Algorithms for the generation of state-level representations of stochastic activity networks with general reward structures","M. A. Qureshi; W. H. Sanders; A. P. A. van Moorsel; R. German","AT&T Bell Labs., Holmdel, NJ, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1996","22","9","603","614","Stochastic Petri nets (SPNs) and extensions are a popular method for evaluating a wide variety of systems. In most cases, their numerical solution requires generating a state-level stochastic process, which captures the behavior of the SPN with respect to a set of specified performance measures. These measures are commonly defined at the net level by means of a reward variable. In this paper, we discuss issues regarding the generation of state-level reward models for systems specified as stochastic activity networks (SANs) with ""step-based reward structures"". Step-based reward structures are a generalization of previously proposed reward structures for SPNs and can represent all reward variables that can be defined on the marking behavior of a net. While discussing issues related to the generation of the underlying state-level reward model, we provide an algorithm to determine whether a given SAN is ""well-specified"" A SAN is well-specified if choices about which instantaneous activity completes among multiple simultaneously-enabled instantaneous activities do not matter, with respect to the probability of reaching next possible stable markings and the distribution of reward obtained upon completion of a timed activity. The fact that a SAN is well specified is both a necessary and sufficient condition for its behavior to be completely probabilistically specified, and hence is an important property to determine.","0098-5589;1939-3520;2326-3881","","10.1109/32.541432","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=541432","","Stochastic processes;Storage area networks;Petri nets;Stochastic systems;Terminology;Sufficient conditions;Markov processes;Computer networks;Fault tolerant systems;Degradation","Petri nets;stochastic systems;Markov processes;probability;performance index","state-level representations;stochastic activity networks;general reward structures;stochastic Petri nets;performance measures;reward model generation;step-based reward structures;reward variables;marking behavior;well-specified networks;multiple simultaneously enabled instantaneous activities;timed activity completion;sufficient condition;completely probabilistically specified behaviour;Markov processes","","11","","13","","","","","","IEEE","IEEE Journals & Magazines"
"A Field Evaluation of Natural Language for Data Retrieval","M. Jarke; J. A. Tuner; E. A. Stohr; Y. Vassiliou; N. H. White; K. Michielsen","Graduate School of Business Administration, Computer Applications and Information Systems Area, New York University; NA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","1","97","114","Although a large number of natural language database interfaces have been developed, there have been few empirical studies of their practical usefulness. This paper presents the design and results of a field evaluation of a natural language system-NLS-used for data retrieval.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231847","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701902","Human-machine interaction;interface design;language evaluation;natural language query;query languages","Natural languages;Information retrieval;Laboratories;Application software;Database languages;Relational databases;Problem-solving;Information systems;Data analysis;Performance evaluation","","Human-machine interaction;interface design;language evaluation;natural language query;query languages","","10","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Representative instances and -acyclic relational schemes","S. Jajodia; P. A. Ng","Department of Computer Science, University of Missouri, Columbia., MO 65211.; Department of Computer Science, University of Missouri, Columbia., MO 65211.","IEEE Transactions on Software Engineering","","1984","SE-10","6","614","618","In this paper, we study under what conditions will a pairwise inconsistent relational database R,r have a universal/representative instance L. If R is -acyclic and r satisfies all existence constraints, then it is possible to construct a universal instance L, using unmarked nulls, whose total projections onto R yield exactly the relations in r. We show that L would actually be a representative instance under a set of functional dependencies if R satisfies the additional mild condition: for any functional dependency X  A where A is a single attribute, whenever XA is contained in two relation schemes R and R' of R, it follows that R R' is a relation scheme of R, having X as one of its keys.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010290","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010290","representative instance;universal instance;universal instance assumption;-acyclic relational scheme","Relational databases;Database systems;Fault detection","","","","3","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Controls for Interorganization Networks","D. Estrin","Department of Computer Science, University of Southern California","IEEE Transactions on Software Engineering","","1987","SE-13","2","249","261","Interorganization computer networks support person-to-person communication via electronic mail; exchange of cad/cam data, software modules, or documents via file transfer; input to an order-entry or accounting system via a database query and update protocol; and use of shared computational resources via an asynchronous message protocol or remote login. In most such interorganization arrangements, the set of resources that an organization wants to make accessible to outsiders is significantly smaller than the set of resources that it wants to remain strictly-internal (i.e., accessible to employees of the organization only). In addition, because the potential user is a person (or machine) outside the boundaries of the organization, the damage associated with undesired use can be high. Because of these characteristics, Interorganization Networks (ION's) have unique usage-control requirements.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233149","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702204","Access control;authentication;network interconnection;network security","Communication system control;Computer networks;Access protocols;Authentication;Electronic mail;Communication system software;CADCAM;Communication system security;Data security;Control systems","","Access control;authentication;network interconnection;network security","","11","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Ada program partitioning language: a notion for distributing Ada programs","R. Jha; J. M. Kamrad; D. T. Cornhill","Honeywell Syst. & Res. Center, Minneapolis, MN, USA; Honeywell Syst. & Res. Center, Minneapolis, MN, USA; Honeywell Syst. & Res. Center, Minneapolis, MN, USA","IEEE Transactions on Software Engineering","","1989","15","3","271","280","Ada Program Partitioning Language (APPL) has been designed as part of Honeywell's Distributed Ada project. The goal of the project is to develop an approach for reducing the complexity of building distributed applications in Ada. In the proposed approach, an application is written as a single Ada program using the full capabilities of the Ada language. It is not necessary to factor the underlying hardware configuration into the program design. Once the program has been completed and tested in the host development environment, it is partitioned into fragments and mapped onto the distributed hardware. The partitioning and mapping are expressed in APPL and do not require changes to the Ada source. The main thrusts of the project include the design of APPL and the development of language translation tools and the run-time system to support Ada and APPL for a distributed target. The authors present an overview of APPL, the goals considered in the design, and issues that impact its implementation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21755","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21755","","Application software;Hardware;Embedded system;Buildings;Embedded software;Software systems;Writing;Testing;Distributed computing;Software design","Ada;distributed processing;program interpreters;software tools","Honeywell;Ada program partitioning language;APPL;Distributed Ada project;complexity;distributed applications;hardware configuration;program design;host development environment;Ada;language translation tools;run-time system","","14","","13","","","","","","IEEE","IEEE Journals & Magazines"
"A Mathematical Framework for the Investigation of Testing","J. S. Gourlay","Department of Computer and Information Science, Ohio State University","IEEE Transactions on Software Engineering","","1983","SE-9","6","686","709","Testing has long been in need of mathematical underpinnings to explain its value as well as its limitations. This paper develops and applies a mathematical framework that 1) unifies previous work on the subject, 2) provides a mechanism for comparing the power of methods of testing programs based on the degree to which the methods approximate program verification, and 3) provides a reasonable and useful interpretation of the notion that successful tests increase one's confidence in the program's correctness.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.235433","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703115","Hardware testing;mutation analysis;path analysis;software reliability;software testing;specifications;testing theory","Software testing;Genetic mutations;Programming profession;Hardware;Software reliability;Formal verification;Computer errors;Computer science;Information science;Reliability theory","","Hardware testing;mutation analysis;path analysis;software reliability;software testing;specifications;testing theory","","37","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Orca: a language for parallel programming of distributed systems","H. E. Bal; M. F. Kaashoek; A. S. Tanenbaum","Dept. of Math. & Comput. Sci., Vrije Univ., Amsterdam, Netherlands; Dept. of Math. & Comput. Sci., Vrije Univ., Amsterdam, Netherlands; Dept. of Math. & Comput. Sci., Vrije Univ., Amsterdam, Netherlands","IEEE Transactions on Software Engineering","","1992","18","3","190","205","A detailed description is given of the Orca language design and the design choices are discussed. Orca is intended for applications programmers rather than systems programmers. This is reflected in its design goals to provide a simple, easy-to-use language that is type-secure and provides clean semantics. Three example parallel applications in Orca, one of which is described in detail, are discussed. One of the existing implementations, which is based on reliable broadcasting, is described. Performance measurements of this system are given for three parallel applications. The measurements show that significant speedups can be obtained for all three applications. The authors compare Orca with several related languages and systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.126768","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=126768","","Parallel programming;Programming profession;Broadcasting;Workstations;Local area networks;Application software;Message passing;Velocity measurement;Costs;Sun","parallel languages;parallel programming","parallel programming;distributed systems;Orca language design;design choices;applications programmers;easy-to-use language;type-secure;clean semantics;parallel applications;Orca;reliable broadcasting","","160","","40","","","","","","IEEE","IEEE Journals & Magazines"
"Program readability: procedures versus comments","T. Tenny","Dept. of Comput. Sci., Texas Christian Univ., Fort Worth, TX, USA","IEEE Transactions on Software Engineering","","1988","14","9","1271","1279","A 3*2 factorial experiment was performed to compare the effects of procedure format (none, internal, or external) with those of comments (absent or present) on the readability of a PL/1 program. The readability of six editions of the program, each having a different combination of these factors, was inferred from the accuracy with which students could answer questions about the program after reading it. Both extremes in readability occurred in the program editions having no procedures: without comments the procedureless program was the least readable and with comments it was the most readable.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6171","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6171","","Testing;Programming profession;Software engineering;Proposals;Costs;Computer science","PL/1;programming","procedures;comments;factorial experiment;procedure format;PL/1 program;readability","","46","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Tractable dataflow analysis for distributed systems","Shing Chi Cheung; J. Kramer","Dept. of Comput. Sci., Hong Kong Univ. of Sci. & Technol., Hong Kong; NA","IEEE Transactions on Software Engineering","","1994","20","8","579","593","Automated behavior analysis is a valuable technique in the development and maintenance of distributed systems. In this paper, we present a tractable dataflow analysis technique for the detection of unreachable states and actions in distributed systems. The technique follows an approximate approach described by Reif and Smolka, but delivers a more accurate result in assessing unreachable states and actions. The higher accuracy is achieved by the use of two concepts: action dependency and history sets. Although the technique does not exhaustively detect all possible errors, it detects nontrivial errors with a worst-case complexity quadratic to the system size. It can be automated and applied to systems with arbitrary loops and nondeterministic structures. The technique thus provides practical and tractable behavior analysis for preliminary designs of distributed systems. This makes it an ideal candidate for an interactive checker in software development tools. The technique is illustrated with case studies of a pump control system and an erroneous distributed program. Results from a prototype implementation are presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.310668","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=310668","","Data analysis;History;Programming;Software engineering;Computational efficiency;Computer errors;Automatic control;Control systems;Software prototyping;Prototypes","distributed processing;software engineering","distributed systems;dataflow analysis;action dependency;history sets;worst-case complexity;pump control system;software development tools;arbitrary loops;nondeterministic structures;labeled transition systems;static analysis;program verification;distributed software engineering;synchronous communicating systems;reachability analysis","","7","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Design and specification of iterators using the swapping paradigm","B. W. Weide; S. H. Edwards; D. E. Harms; D. A. Lamb","Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA; NA; NA","IEEE Transactions on Software Engineering","","1994","20","8","631","643","How should iterators be abstracted and encapsulated in modern imperative languages? We consider the combined impact of several factors on this question: the need for a common interface model for user defined iterator abstractions, the importance of formal methods in specifying such a model, and problems involved in modular correctness proofs of iterator implementations and clients. A series of iterator designs illustrates the advantages of the swapping paradigm over the traditional copying paradigm. Specifically, swapping based designs admit more efficient implementations while offering relatively straightforward formal specifications and the potential for modular reasoning about program behavior. The final proposed design schema is a common interface model for an iterator for any generic collection.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.310672","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=310672","","Formal specifications;Reasoning about programs;Information science;Senior members;Forward contracts;Modems;Packaging;Proposals;Computerized monitoring;Military computing","formal specification;program verification;data encapsulation","iterators;swapping paradigm;imperative languages;common interface model;user defined iterator abstractions;formal methods;modular correctness proofs;iterator designs;formal specification;modular reasoning;program verification;proof of correctness;swapping","","2","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Performance Adjustment of an APL Interpreter","M. Maekawa; Y. Morimoto","Department of Information Science, Faculty of Science, University of Tokyo; NA","IEEE Transactions on Software Engineering","","1982","SE-8","4","331","343","An APL interpreter is analyzed to examine how microprogramming can improve its performance. Also examined is how the modularization method or program structure affects performance improvement. Two basic modularization methods, function and data modularizations, are investigated. We rind that the performance gain may reach 100-time speed-up and that a proper selection of modules is very important to obtain the maximum performance gain under a limited microprogram memory. We also find that both the function and the data modularizations provide the same degree of performance improvement despite the finding that they tend to affect the complementary parts of a program.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235427","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702956","APL interpreter;data modularization;function modularization;high-level language machine;microprogramming;modularization;performance modularization","Microprogramming;Performance gain;Research and development;Performance analysis;High level languages;International trade;Information processing;Information science;Time measurement;Computer aided instruction","","APL interpreter;data modularization;function modularization;high-level language machine;microprogramming;modularization;performance modularization","","","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Early experience with the Visual Programmer's WorkBench","R. V. Rubin; J. Walker; E. J. Golin","GTE Lab., Waltham, MA, USA; GTE Lab., Waltham, MA, USA; NA","IEEE Transactions on Software Engineering","","1990","16","10","1107","1121","The Visual Programmer's WorkBench (VPW) addresses the rapid synthesis and customization of environments for the specification, analysis, and execution of visual programs. The goal of VPW is to enable the easy creation of environments for visual languages. The design of VPW and experience using it to generate a distributed programming environment for a concurrent visual language are described. A visual programming environment for the PetriFSA language generated with VPW is outlined. An overview is provided of the language definition model and its relation to the logical architecture of VPW. Details are given of the language specifications used in VPW, and its application in defining the PetriFSA language. A language-based environment for a specific visual language is generated in VPW from a specification of the syntactic structure, the abstract structure, the static semantics, and the dynamic semantics of the language. VPW is built around a model of distributed processing based on a shared distributed memory. This framework is used in defining the architecture of the environment and for the execution model of visual languages.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.60292","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=60292","","Programming environments;Dynamic programming;Software engineering;Synthesizers;Application software;Visual databases;Interactive systems;Distributed processing;Functional programming","data structures;formal specification;program verification;programming environments;specification languages;visual programming","Visual Programmer's WorkBench;synthesis;customization of environments;specification;visual languages;distributed programming environment;PetriFSA language;syntactic structure;abstract structure;static semantics;dynamic semantics","","18","","39","","","","","","IEEE","IEEE Journals & Magazines"
"Some Stability Measures for Software Maintenance","S. S. Yau; J. S. Collofello","Department of Electrical Engineering and Computer Science, Northwestern University; NA","IEEE Transactions on Software Engineering","","1980","SE-6","6","545","552","Software maintenance is the dominant factor contributing to the high cost of software. In this paper, the software maintenance process and the important software quality attributes that affect the maintenance effort are discussed. One of the most important quality attributes of software maintainability is the stability of a program, which indicates the resistance to the potential ripple effect that the program would have when it is modified. Measures for estimating the stability of a program and the modules of which the program is composed are presented, and an algorithm for computing these stability measures is given. An algorithm for normalizing these measures is also given. Applications of these measures during the maintenance phase are discussed along with an example. An indirect validation of these stability measures is also given. Future research efforts involving application of these measures during the design phase, program restructuring based on these measures, and the development of an overall maintainability measure are also discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234503","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702781","Algorithms;applications;logical stability;module stability;maintenance process;normalization;potential ripple effect;program stability;software maintenance;software quality attributes;validation","Stability;Software measurement;Software maintenance;Software quality;Phase measurement;Costs;Electrical resistance measurement;Application software;Large-scale systems;Software systems","","Algorithms;applications;logical stability;module stability;maintenance process;normalization;potential ripple effect;program stability;software maintenance;software quality attributes;validation","","97","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Technology Selection: An Educational Approach","W. E. Riddle; L. G. Williams","Software Productivity Consortium; NA","IEEE Transactions on Software Engineering","","1987","SE-13","11","1199","1206","Creating and enhancing a software engineering work force requires several different types of continuing education for software professionals, including: task-oriented education, enhancement-oriented education and selection-oriented education. In this paper, we focus on the important, but often neglected, category of selection-oriented education. We begin with a discussion of technology selection, indicating what it involves, how it contributes to improving the state of practice, and why it is key to technology improvement in general. This is followed by a discussion of some criteria for selection-oriented education programs. We then describe the selection-oriented education activities at the Rocky Mountain Institute of Software Engineering and relate some problems encountered in establishing these activities.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232870","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702168","Software engineering education;technology selection;technology transfer","Educational technology;Educational programs;Software engineering;Continuing education;Computer science education;Technology transfer;Personnel;Educational products;Engineering education;Computer science","","Software engineering education;technology selection;technology transfer","","1","","5","","","","","","IEEE","IEEE Journals & Magazines"
"Processes, Tasks, and Monitors: A Comparative Study of Concurrent Programming Primitives","P. Wegner; S. A. Smolka","Department of Computer Science, Brown University; NA","IEEE Transactions on Software Engineering","","1983","SE-9","4","446","462","Three notations for concurrent programming are compared, namely CSP, Ada, and monitors. CSP is an experimental language for exploring structuring concepts in concurrent programming. Ada is a general-purpose language with concurrent programming facilities. Monitors are a construct for managing access by concurrent processes to shared resources. We start by comparing ""lower-level"" communication, synchronization, and nondeterminism in CSP and Ada and then examine ""higher-level"" module interface properties of Ada tasks and monitors.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.234781","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703079","Ada;concurrent programming;CSP;distributed processes;monitors;processes;tasks","Chip scale packaging;Computer science;Concurrent computing;Resource management;Processor scheduling;User interfaces;Computer interfaces;NASA","","Ada;concurrent programming;CSP;distributed processes;monitors;processes;tasks","","16","","20","","","","","","IEEE","IEEE Journals & Magazines"
"A Close Look at Domain Testing","L. A. Clarke; J. Hassell; D. J. Richardson","Department of Computer and Information Science, University of Massachusetts; NA; NA","IEEE Transactions on Software Engineering","","1982","SE-8","4","380","390","White and Cohen have proposed the domain testing method, which attempts to uncover errors in a path domain by selecting test data on and near the boundary of the path domain. The goal of domain testing is to demonstrate that the boundary is correct within an acceptable error bound. Domain testing is intuitively appealing in that it provides a method for satisfying the often suggested guideline that boundary conditions should be tested.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235572","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702960","Program testing;test data selection","Testing;Error correction;Terminology;Guidelines;Boundary conditions;Computer errors;Computer science;Military computing;Information science","","Program testing;test data selection","","41","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Development life cycle of computer networks: the executable model approach","J. Etkin; J. A. Zinky","Coll. of Eng., Boston Univ., MA, USA; NA","IEEE Transactions on Software Engineering","","1989","15","9","1078","1089","An approach is proposed for extending the use of design models to the implementation and operational phases of the network development life cycle. A conceptual approach is offered for using executable models in the day-to-day operation of computer networks. Several strategies are given for integrating models into different development tasks. It is shown why these strategies are feasible. Characteristics of executable models that differ from those of traditional models are identified along with new technologies that reduce the cost of implementing and using executable models.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.31366","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=31366","","Computer networks;Computer network management;Predictive models;Analytical models;Embedded system;Costs;Computational modeling;Performance analysis;Software testing;Computer graphics","computer networks;digital simulation;software engineering","computer networks;design models;network development life cycle;executable models;day-to-day operation;development tasks","","4","","32","","","","","","IEEE","IEEE Journals & Magazines"
"Compositional validation of time-critical systems using communicating time Petri nets","G. Bucci; E. Vicario","Dept. of Syst. & Inf., Florence Univ., Italy; Dept. of Syst. & Inf., Florence Univ., Italy","IEEE Transactions on Software Engineering","","1995","21","12","969","992","An extended Petri net model which considers modular partitioning along with timing restrictions and environment models is presented. Module constructs permit the specification of a complex system as a set of message passing modules with the timing semantics of time Petri nets. The state space of each individual module can be separately enumerated and assessed under the assumption of a partial specification of the intended module operation environment. State spaces of individual modules can be recursively integrated, to permit the assessment of module clusters and of the overall model, and to check the satisfaction of the assumptions made in the separate analysis of elementary component modules. In the intermediate stages between subsequent integration steps, the state spaces of module and module clusters can be projected onto reduced representations concealing local events that are not essential to the purposes of the analysis. The joint use of incremental enumeration and intermediate concealment of local events allows for a flexible management of state explosion, and permits a scalable approach to the validation of complex systems.","0098-5589;1939-3520;2326-3881","","10.1109/32.489073","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=489073","","Time factors;Petri nets;State-space methods;Timing;Reachability analysis;Automata;Message passing;Explosions;System recovery;Real time systems","Petri nets;message passing;timing;formal specification;reachability analysis;program diagnostics;program verification","extended Petri net model;modular partitioning;timing restrictions;environment models;compositional validation;time-critical systems;communicating time Petri nets;module constructs;complex system specification;message passing modules;timing semantics;state space;partial specification;module operation environment;module clusters;elementary component modules;concealed local events;incremental enumeration;state explosion management","","65","","37","","","","","","IEEE","IEEE Journals & Magazines"
"A predicate-transition net model for parallel interpretation of logic programs","T. Murata; D. Zhang","Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA; Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA","IEEE Transactions on Software Engineering","","1988","14","4","481","497","A predicate/transition net model for a subset of Horn clause logic programs is presented. The syntax, transformation procedure, semantics, and deduction process for the net model are discussed. A possible parallel implementation for the net model is described, which is based on the concepts of communicating processes and relations. The proposed net model offers a syntactical variant of Horn clause logic and has two distinctions from other existing schemes for the logic programs: representation formalism and the deduction method. The net model provides an approach towards the solutions of the separation of logic from control and the improvement of the execution efficiency through parallel processing for the logic programs. The abstract nature of the net model also lends itself to different implementation strategies.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4671","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4671","","Logic programming;Petri nets;Automatic control;Parallel processing;Computer languages;Humans;Computer science;Software engineering;Proposals","formal logic;logic programming;parallel programming;programming theory","logic programming;parallel programming;predicate-transition net model;parallel interpretation;logic programs;Horn clause logic;deduction process;parallel processing","","74","","64","","","","","","IEEE","IEEE Journals & Magazines"
"Graph Traversal Techniques and the Maximum Flow Problem in Distributed Computation","To-Yat Cheung","Department of Computer Science, University of Ottawa","IEEE Transactions on Software Engineering","","1983","SE-9","4","504","512","This paper shows that graph traversal techniques have fundamental differences between serial and distributed computations in their behaviors, computational complexities, and effects on the design of graph algorithms. It has three major parts. Section I describes the computational environment for the design and description of distributed graph algorithms in terms of an architectural model for message exchanges. The computational complexity is measured in terms of the number of messages transmitted. Section II presents several distributed algorithms for the pure traversal, depth-first search, and breadth-first search techniques. Their complexities are also given. Through these descriptions are brought out some of the intrinsic differences in the behaviors and complexities of the fundamental traversal techniques between a serial and a distributed computation environment. Section III gives the distributed version of the Ford and Fulkerson algorithm for the maximum flow problem by means of depth-first search, the largest-augmentation search and breadth-first search. The complexities of these methods are found to be 0(f*|A|), 0((l + logM/(M-1)f*|V||A|) and O(|V|6), respectively, where f* is the maximum flow value of the problem, M is the maximum number of ucs in a cut, |V| is the number of vertices, and |A| is the number of arcs. Lastly, it is shown that the largest augmentation search may be a better method than the other two. This is contrary to the known results in serial computation.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.234958","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703083","Distributed computation;distributed graph algorithms;graph traversal techniques;maximum network flow problem;model","Distributed computing;Algorithm design and analysis;Computational complexity;Distributed algorithms;Computer networks;Concurrent computing;Councils;Computer science;Computer architecture;Software algorithms","","Distributed computation;distributed graph algorithms;graph traversal techniques;maximum network flow problem;model","","17","","13","","","","","","IEEE","IEEE Journals & Magazines"
"An empirical comparison of textual and graphical data structure documentation for Cobol programs","J. A. Lehman","Dept. of Manage. Inf. Syst., Alaska Univ., Fairbanks, AK, USA","IEEE Transactions on Software Engineering","","1989","15","9","1131","1135","The author presents the results of an experimental investigation into the comparative usefulness of textual tools and graphical tools for the program understanding phase of Cobol program maintenance. Both novice and experienced programmers are used as subjects. The results show a slight superiority for graphical tools when they are used by less experienced programmers. They cast doubt on the importance of rigid adherence to program design methodologies for experienced programmers and on the extensibility of experiments using relatively inexperienced student subjects.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.31370","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=31370","","Data structures;Documentation;Design methodology;Programming profession;Flowcharts;Displays;Graphics;Modems;Information management;Control systems","COBOL;computer graphics;data structures;system documentation;word processing","textual data structure documentation;graphical data structure documentation;Cobol programs;textual tools;graphical tools;program understanding phase;Cobol program maintenance","","1","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Optimal allocation of file servers in a local network environment","C. M. Woodside; S. K. Tripathi","ISEM Laboratory, Universit&#x00E9; Paris-Sud, 91405 Orsay, France; Centre Mondial Informatique, Paris, France; Department of Systems and Computer Engineering, Carleton University, Ottawa, Ont. K1S 5B6, Canada; ISEM Laboratory, Universit&#x00E9; Paris-Sud, 91405 Orsay, France; Department of Computer Science, University of Maryland, College Park, MD 20742","IEEE Transactions on Software Engineering","","1986","SE-12","8","844","848","A globally optimal allocation for files in a local network environment is presented. The principal concern is the delays due to contention at the file servers; storage space is assumed to be adequate. A queuing network model is used to represent the file servers and the workstations. The workloads generated by the workstations are statistically identical. The model assumes that the communications medium is lightly loaded. In this case there is very little queuing, so that a message transmission requires an approximately constant average delay which can be included in the local processing time of the workstation. Under these assumptions the model can be applied to any of the various LAN technologies. It is shown that all the files of each workstation should be placed on one file server, with the workstations divided as equally as possible among the file servers.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312986","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312986","Design studies;file assignment;local networks;modeling techniques;multiclass closed queueing networks;optimization;performance of systems","File servers;Workstations;Resource management;Educational institutions;Load modeling;Computational modeling;Local area networks","file organisation;local area networks;queueing theory","optimal file allocation;file servers;local network environment;storage space;queuing network model;communications medium;message transmission;LAN","","6","","","","","","","","IEEE","IEEE Journals & Magazines"
"Automating output size and reuse metrics in a repository-based computer-aided software engineering (CASE) environment","R. D. Banker; R. J. Kauffman; C. Wright; D. Zweig","Carlson Sch. of Manage., Minnesota Univ., Minneapolis, MN, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1994","20","3","169","187","Measurement of software development productivity is needed in order to control software costs, but it is discouragingly labor-intensive and expensive. Computer-aided software engineering (CASE) technologies/spl minus/especially repository-based, integrated CASE/spl minus/have the potential to support the automation of this measurement. We discuss the conceptual basis for the development of automated analyzers for function point and software reuse measurement for object-based CASE. Both analyzers take advantage of the existence of a representation of the application system that is stored within an object repository, and that contains the necessary information about the application system. We also discuss metrics for software reuse measurement, including reuse leverage, reuse value, and reuse classification that are motivated by managerial requirements and the efforts, within industry and the IEEE, to standardize measurement. The functionality and the analytical capabilities of state-of-the-art automated software metrics analyzers are illustrated in the context of an investment banking industry application that is similar to systems deployed at the New York City-based investment bank where these tools were developed and tested.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.268919","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=268919","","Software measurement;Computer aided software engineering;Application software;Investments;Programming;Productivity;Automatic control;Costs;Automation;Information analysis","software tools;object-oriented programming;software metrics;software reusability;bank data processing","output size;reuse metrics;repository-based computer-aided software engineering environment;CASE environment;software development productivity;software cost control;integrated CASE;conceptual basis;automated analyzers;function point;software reuse measurement;object-based CASE;object repository;reuse leverage;reuse classification;managerial requirements;state-of-the-art automated software metrics analyzers;investment banking industry application","","27","","70","","","","","","IEEE","IEEE Journals & Magazines"
"Software bottlenecking in client-server systems and rendezvous networks","J. E. Neilson; C. M. Woodside; D. C. Petriu; S. Majumdar","Real-time & Distributed Syst. Group, Carleton Univ., Ottawa, Ont., Canada; Real-time & Distributed Syst. Group, Carleton Univ., Ottawa, Ont., Canada; Real-time & Distributed Syst. Group, Carleton Univ., Ottawa, Ont., Canada; Real-time & Distributed Syst. Group, Carleton Univ., Ottawa, Ont., Canada","IEEE Transactions on Software Engineering","","1995","21","9","776","782","Software bottlenecks are performance constraints caused by slow execution of a software task, in typical client-server systems a client task must wait in a blocked state for the server task to respond to its requests, so a saturated server will slow down all its clients. A rendezvous network generalizes this relationship to multiple layers of servers with send-and-wait interactions (rendezvous), a two-phase model of task behavior, and to a unified model for hardware and software contention. Software bottlenecks have different symptoms, different behavior when the system is altered, and a different cure from the conventional bottlenecks seen in queueing network models of computer systems, caused by hardware limits. The differences are due to the ""push-back"" effect of the rendezvous, which spreads the saturation of a server to its clients. The paper describes software bottlenecks by examples, gives a definition, shows how they can be located and alleviated, and gives a method for estimating the performance benefit to be obtained. Ultimately, if all the software bottlenecks can be removed, the performance limit will be due to a conventional hardware bottleneck.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.464543","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=464543","","Intelligent networks;Client-server systems;Network servers;Hardware;Object oriented modeling;Software performance;Computer networks;Distributed computing;Operating systems;Concurrent computing","software performance evaluation;client-server systems;queueing theory;performance evaluation;resource allocation","software bottlenecks;client-server systems;rendezvous networks;performance constraints;slow task execution;server task;send-and-wait interactions;two-phase model;task behavior;software contention;hardware contention;queueing network models;hardware limits;push-back effect;performance benefit","","44","","18","","","","","","IEEE","IEEE Journals & Magazines"
"A comparison of computed chaining to predictors","K. Tai; A. L. Tharp","Department of Computer Science, North Carolina State University, Raleigh, NC 27695; Department of Computer Science, North Carolina State University, Raleigh, NC 27695","IEEE Transactions on Software Engineering","","1986","SE-12","8","870","874","Computed chaining and predictors are two recent techniques for resolving hashing collisions which use a pseudolink field instead of an actual address link to group records which map to the same home address. With additional computation on the pseudolink, the actual address can be determined. The advantage of the pseudolink is that it often takes much less storage than an actual address would take. The authors note problems with the predictor method which must be overcome if the method is to be used successfully. They also compare the predictor method to computed chaining. They conclude with a discussion of the utility of multiple predictor, i.e. having more than one chain of pseudolinks for records with the same home address.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312990","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312990","Collision;hashing;resolution","Probes;Databases;Computational modeling;Computer science;Equations;Access control","file organisation","computed chaining;hashing collisions;pseudolink field;predictor method;multiple predictor","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"A Generalized Query-by-Example Data Manipulation Language Based on Database Logic","B. E. Jacobs; C. A. Walczak","Department of Computer Science, University of Maryland; NA","IEEE Transactions on Software Engineering","","1983","SE-9","1","40","57","The purpose of this paper is to introduce a Generalized-Query-By-Example (GQBE) data manipulation language (DML) that can be built on top of most existing databases (ie., relational, hierarchical, and network). The data manipulation language supports retrieval, insertion, deletion, and update operations and has a formal semantics based on database logic. It is also seen that GQBE can by used as a DML on external views of an integrated database. We also show the advantages of GQBE on heterogeneous databases over Zloof's QBE on relational external views.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236169","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703011","Database;database logic;generalized Query-By-Example","Logic;Relational databases;Jacobian matrices;Information retrieval;Distributed databases;Image retrieval;Computer science;Systematics;Dentistry","","Database;database logic;generalized Query-By-Example","","3","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Timing constraint Petri nets and their application to schedulability analysis of real-time system specifications","J. J. P. Tsai; S. Jennhwa Yang; Yao-Hsiung Chang","Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA; Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA; NA","IEEE Transactions on Software Engineering","","1995","21","1","32","49","We present timing constraint Petri nets (or TCPN's for short) and describe how to use them to model a real-time system specification and determine whether the specification is schedulable with respect to imposed timing constraints. The strength of TCPN's over other time-related Petri nets is in the modeling and analysis of conflict structures. Schedulability analysis is conducted in three steps: specification modeling, reachability simulation, and timing analysis. First, we model a real-time system by transforming its system specification along with its imposed timing constraints into a TCPN; we call this net N/sub s/. Then we simulate the reachability of N/sub s/ to verify whether a marking, M/sub n/, is reachable from an initial marking, M/sub o/. It is important to note that a reachable marking in Petri nets is not necessarily reachable in TCPN's due to the imposed timing constraints, Therefore, in the timing analysis step, a reachable marking M/sub n/, found in the reachability simulation step is analyzed to verify whether M/sub n/, is reachable with the timing constraints. M/sub n/ is said to be reachable in the TCPN's if and only if we can find at least one firing sequence /spl sigma/ so that all transitions in /spl sigma/ are strongly schedulable with respect to M/sub o/ under the timing constraints. If such M/sub n/ can be found, then we can assert that the specification is schedulable under the imposed timing constraints, otherwise the system specification needs to be modified or the timing constraints need to be relaxed. We also present a synthesis method for determining the best approximation of the earliest fire beginning time (EFBT) and the latest fire ending time (LFET) of each strongly schedulable transition.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.341845","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=341845","","Timing;Petri nets;Real time systems;Job shop scheduling;Monitoring;Analytical models;Fires;Runtime;Logic;Time factors","Petri nets;real-time systems;formal specification;formal verification;scheduling;timing;distributed processing","timing constraint Petri nets;schedulability analysis;real-time system specifications;time-related Petri nets;specification modeling;reachability simulation;real-time system;system specification;reachability simulation step;synthesis method;latest fire ending time;earliest fire beginning time;strongly schedulable transition","","71","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Certifying the reliability of software","P. A. Currit; M. Dyer; H. D. Mills","IBM Corporation, Federal Systems Division, 6600 Rockledge Drive, Bethesda, MD 20817; IBM Corporation, Federal Systems Division, 6600 Rockledge Drive, Bethesda, MD 20817; IBM Corporation, Federal Systems Division, 6600 Rockledge Drive, Bethesda, MD 20817","IEEE Transactions on Software Engineering","","1986","SE-12","1","3","11","A description is given of a procedure for certifying the reliability of software before its release to users. The ingredients of this procedure are a life cycle of executable product increments, representative statistical testing, and a standard estimate of the MTTF (mean time to failure) of the product at the time of its release. The authors also discuss the development of certified software products and the derivation of a statistical model used for reliability projection. Available software test data are used to demonstrate the application of the model in certification process.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312914","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312914","Incremental development;software reliability certification;software reliability models;statistical quality control;statistical testing process","Software;Testing;Software reliability;Certification;Statistical analysis;Standards","reliability theory;software reliability;statistical analysis","reliability;software;life cycle;executable product increments;statistical testing;standard estimate;MTTF;mean time to failure;certified software products;statistical model;reliability projection;certification process","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Yeast: a general purpose event-action system","B. Krishnamurthy; D. S. Rosenblum","Dept. of Software Eng Res., AT&T Bell Labs., Murray Hill, NJ, USA; NA","IEEE Transactions on Software Engineering","","1995","21","10","845","857","Distributed networks of personal workstations are becoming the dominant computing environment for software development organizations. Many cooperative activities that are carried out in such environments are particularly well suited for automated support. Taking the point of view that such activities are modeled most naturally as the occurrence of events requiring actions to be performed, we developed a system called Yeast (Yet another Event Action Specification Tool). Yeast is a client server system in which distributed clients register event action specifications with a centralized server, which performs event detection and specification management. Each specification submitted by a client defines a pattern of events that is of interest to the client's application plus an action that is to be executed in response to an occurrence of the event pattern; the server triggers the action of a specification once it has detected an occurrence of the associated event pattern. Yeast provides a global space of events that is visible to and shared by all users. In particular, events generated by one user can trigger specifications registered by another user. Higher level applications are built as collections of Yeast specifications. We use Yeast on a daily basis for a variety of applications, from deadline notification to software process automation. The paper presents an in depth description of Yeast and an example application of Yeast, in which Yeast specifications are used to automate a software distribution process involving several interdependent software tools.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.469456","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=469456","","Fungi;Application software;Event detection;Software tools;Workstations;Computer networks;Distributed computing;Programming;Client server systems;Automation","client-server systems;network servers;formal specification","Yeast;general purpose event action system;general purpose event-action system;distributed networks;personal workstations;software development organizations;cooperative activities;automated support;Yet another Event Action Specification Tool;client server system;distributed clients;centralized server;event detection;specification management;associated event pattern;global space;higher level applications;deadline notification;software process automation;software distribution process;interdependent software tools","","37","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Schlumberger's software improvement program","H. Wohlwend; S. Rosenbaum","Sematech, Austin, TX, USA; NA","IEEE Transactions on Software Engineering","","1994","20","11","833","839","A corporate-wide software process improvement effort has been ongoing at Schlumberger for several years. Through the motivation efforts of a small group, productive changes have occurred across the company. We see improvements in many development areas, including project planning and requirements management. The catalysts behind these advances include capability assessments, training, and collaboration.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.368125","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=368125","","Software quality;Software engineering;Laboratories;Productivity;Programming;Software measurement;Project management;Industrial training;Management training;Collaboration","DP industry;project management;software development management","Schlumberger;software improvement program;corporate-wide software process improvement effort;productive changes;project planning;requirements management;capability assessments;training;collaboration;software process management;SEI;software engineering","","46","","11","","","","","","IEEE","IEEE Journals & Magazines"
"An Approach to Performance Specification of Communication Protocols Using Timed Petri Nets","K. Garg","Department of Electronics and Communication Engineering, University of Roorkee","IEEE Transactions on Software Engineering","","1985","SE-11","10","1216","1225","There has been a lot of interest in the past decade in using timed Petri nets to model computer systems. In this paper we show how such timed Petri nets can be used to great advantage in describing and algebraically specifying communication system performance. We make use of the time parameter of timed Petri nets to model the delay in performing certain operations of a communication protocol. The specification is borrowed from the recently reported AFFIRM language, and the protocol chosen for illustration is the ECMA transfer protocol, proposed for the ISO reference model. However, the methodology can be used with other protocols as well. We also show how liveness properties can be specified, easily using timed Petri nets.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231869","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701937","Distributed computer systems;natural-deduction theorem proving;performance evaluation;performance modeling and analysis;Petri nets;protocol;protocol specifications;timed Petri nets","Protocols;Petri nets;Performance analysis;Communication systems;Delay effects;ISO;Distributed computing;Concurrent computing;Logic;Timing","","Distributed computer systems;natural-deduction theorem proving;performance evaluation;performance modeling and analysis;Petri nets;protocol;protocol specifications;timed Petri nets","","24","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Semi-automatic program construction from specifications using library modules","F. Nishida; S. Takamatsu; Y. Fujita; T. Tani","Dept. of Electr. Eng., Osaka Prefectural Univ., Japan; Dept. of Electr. Eng., Osaka Prefectural Univ., Japan; NA; NA","IEEE Transactions on Software Engineering","","1991","17","9","853","871","A method of semiautomatic specification refinement and program generation using library modules, is described. Users write their specifications and modify and rearrange them so that they can be refined with the aid of the library modules. When a specification is given, a refinement system, called MAPS (module-aided program construction system) searches for library modules applicable to the given specification, replaces the specification with a more detailed description written in the operation part of the modules, and converts the refined specification into a program written in a programming language designated by the user. Case-like expressions or pseudo-natural language expressions are used for describing user's specifications and specifications for library modules.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.92909","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=92909","","Modular construction;Natural languages;Software libraries;Refining;Computer languages;Documentation;Joining processes;Software quality;Productivity;Software engineering","automatic programming;formal specification;software tools;subroutines","case-like expressions;semiautomatic specification refinement;program generation;library modules;refinement system;MAPS;module-aided program construction system;programming language;pseudo-natural language expressions","","10","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Including scalars in a programming language based on the relational algebra","T. H. Merrett; N. Laliberte","Sch. of Comput. Sci., McGill Univ., Montreal, Que., Canada; Sch. of Comput. Sci., McGill Univ., Montreal, Que., Canada","IEEE Transactions on Software Engineering","","1989","15","11","1437","1443","Scalars, arrays, and records, together with associated operations and syntax, have been introduced as special cases of relations into the relational programming system, relix. This permits all of these data types, as well as relations, to be stored persistently. The requirement in most languages that array elements and record fields can be assigned to leads in this case to the general implementation of QT-selectors as l-expressions, with, in particular, systematic interpretations of assignment to projections and selections of relations. The authors discuss the principles and the implementation of this extension to the relational algebra. They take advantage of the very specialized syntax of array access to build a tuned access method, using B-trees and Z-order. The performance results show the advantage of this implementation over the slower implementation required for general QT-selectors.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.41335","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=41335","","Computer languages;Algebra;Database systems;Writing;Documentation;Functional programming;Councils;Employment;Automation","data structures;database theory;high level languages;relational databases","scalars;programming language;relational algebra;records;syntax;relations;relational programming system;relix;data types;QT-selectors;l-expressions;systematic interpretations;projections;array access;tuned access method;B-trees;Z-order","","","","18","","","","","","IEEE","IEEE Journals & Magazines"
"On the frame problem in procedure specifications","A. Borgida; J. Mylopoulos; R. Reiter","Dept. of Comput. Sci., Rutgers Univ., New Brunswick, NJ, USA; NA; NA","IEEE Transactions on Software Engineering","","1995","21","10","785","798","The paper provides examples of situations where formal specifications of procedures in the standard pre/postcondition style become lengthy, cumbersome and difficult to change, a problem which is particularly acute in the case of object oriented specifications with inheritance. We identify the problem as the inability to express that a procedure changes only those things it has to, leaving everything else unmodified, and review some attempts at dealing with this ""frame problem"" in the software specification community. The second part of the paper adapts a recent proposal for a solution to the frame problem in artificial intelligence-the notion of explanation closure axioms-to provide an approach whereby one can state such conditions succinctly and modularly, with the added advantage of having the specifier be reminded of things that she may have omitted saying in procedure specifications. Since this approach is based on standard predicate logic, its semantics are relatively straightforward. The paper also suggests an algorithm which generates syntactically the explanation closure axioms from the pre/postcondition specifications, provided they are written in a restricted language; it also suggests a model theory supporting it.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.469460","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=469460","","Formal specifications;Databases;Logic;Computer science;Proposals;Artificial intelligence;Object oriented modeling;Specification languages;Computer languages","formal specification;specification languages;object-oriented programming;explanation;formal logic","frame problem;procedure specifications;formal specifications;standard pre/postcondition style;object oriented specifications;inheritance;software specification community;artificial intelligence;explanation closure axioms;standard predicate logic;restricted language;model theory","","61","","34","","","","","","IEEE","IEEE Journals & Magazines"
"Automated module testing in Prolog","D. M. Hoffman; P. Strooper","Dept. of Comput. Sci., Victoria Univ., BC, Canada; Dept. of Comput. Sci., Victoria Univ., BC, Canada","IEEE Transactions on Software Engineering","","1991","17","9","934","943","Tools and techniques for writing scripts in Prolog that automatically test modules implemented in C are presented. Both the input generation and the test oracle problems are addressed, focusing on a balance between the adequacy of the test inputs and the cost of developing the output oracle. The authors investigate automated input generation according to functional testing, random testing, and a novel approach based on trace invariants. For each input generation scheme, a mechanism for generating the expected outputs has been developed. The methods are described and illustrated in detail. Script development and maintenance costs appear to be reasonable, and run-time performance appears to be acceptable.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.92913","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=92913","","Automatic testing;System testing;Sequential analysis;Costs;Production systems;Runtime;Automation;Writing;Design for testability;Power generation economics","C language;logic programming;program testing;PROLOG","Prolog;C;input generation;test oracle problems;test inputs;output oracle;automated input generation;functional testing;random testing;trace invariants;maintenance costs;run-time performance","","22","","27","","","","","","IEEE","IEEE Journals & Magazines"
"A Software Maintainability Evaluation Methodology","D. E. Peercy","BDM Corporation","IEEE Transactions on Software Engineering","","1981","SE-7","4","343","351","This paper describes a conceptual framework of software maintainability and an implemented procedure for evaluating a program's documentation and source code for maintainability characteristics. The evaluation procedure includes use of closed-form questionnaires completed by a group of evaluators. Statistical analysis techniques for validating the evaluation procedure are described. Some preliminary results from the use of this methodology by the Air Force Test and Evaluation Center are presented. Areas of future research are discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234534","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702852","Evaluation by questionnaire;evaluation reliability;quality metrics;software engineering;software maintainability evaluation;software quality assurance","Software maintenance;Software measurement;Software quality;Software tools;Q factor;Documentation;Software testing;System testing;Software systems;Statistical analysis","","Evaluation by questionnaire;evaluation reliability;quality metrics;software engineering;software maintainability evaluation;software quality assurance","","9","","34","","","","","","IEEE","IEEE Journals & Magazines"
"Performance Criteria for Constrained Nonlinear Programming Codes","H. W. Robb; H. R. Weistroffer","Unicorn Lines (Pty) Ltd.; NA","IEEE Transactions on Software Engineering","","1987","SE-13","4","479","489","A set of performance criteria for evaluating optimization software with respect to efficiency, reliability, and accuracy is presented and discussed. A numerical comparison of five constrained nonlinear programming codes is described, which was carried out in order to test the usefulness and general applicability of the proposed performance criteria. The results of the numerical comparison are discussed, and the proposed criteria are compared to the criteria traditionally used in comparative evaluations of nonlinear programming codes, with particular reference to machine dependence and the applicability to test problems with unknown solutions. A separate small scale computational experiment is described which was carried out specifically to test the machine dependence of the criteria. The observed deficiencies of the proposed new criteria are also discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233184","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702239","Constrained optimization;evaluation;mathematical programming;nonlinear programming;numerical comparison;optimization software;performance criteria","Mathematical programming;Robustness;Software performance;Africa;Writing;Councils;Guidelines;Life testing;Particle measurements;Time measurement","","Constrained optimization;evaluation;mathematical programming;nonlinear programming;numerical comparison;optimization software;performance criteria","","1","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Automatic Design of the Internal Schema for a CODASYL Database System","A. Reuter; H. Kinzinger","IBM Research Laboratory, San Jose, CA 95193; University of Kaiserslautern, Kaiserslautern, West Germany.; Data Management Systems Group, University of Kaiserslautern, Kaiserslautern, West Germany.","IEEE Transactions on Software Engineering","","1984","SE-10","4","358","375","This paper describes the concepts and implementation of a design aid for the internal schema of an existing CODASYL-like database system. It allows for tailoring the storage structure level to a given logical schema and a specified workload. According to the 1978 CODASYL report, our DBMS provides two levels of schema declaration, the DDL-level for logical schema description and a DSDL-like level for specifying the storage structures to implement the objects of the logical schema. The repertoire of storage structures supported by our system is a good internal schema are basically heuristic. This approaach is justified by weighing its advantages and shortcomings against those of analytic models and simulation. Finally, some preliminary user experiences with a pilot version are related.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010249","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010249","Analytic modeling;CODASYL;heuristic optimization;performance prediction;physical database design;simulation","Database systems;Predictive models;Design optimization;Stability;Concrete;Physics computing;Computational modeling;Query processing;Performance analysis","","","","3","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Utilizing an Executable Specification Language for an Information System","S. D. Urban; J. E. Urban; W. D. Dominick","Center for Advanced Computer Studies, University of Southwestern Louisiana; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","7","598","605","This paper describes an approach to software specification development with interpretation as applied to an information storage and retrieval system. Machine execution of software specifications is possible with both partial and complete specifications. A partial specification is interpreted using abstract execution. The Descartes specification language is utilized to describe a functional aspect of an existing information storage and retrieval system, namely, the MADAM (Multics Approach to Data Access and Management) system at the University of Southwestern Louisiana. Brief descriptions of both the Descartes language and the MADAM system precede the example specification. The paper concludes with a discussion of the expected results that this methodology could have on the pragmatic development and evolution of information systems.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232504","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702064","Abstract execution;executable specifications;information storage and retrieval;prototyping","Specification languages;Information systems;Software engineering;Information retrieval;Database systems;Application software;Software systems;Management information systems;Statistical analysis;Laboratories","","Abstract execution;executable specifications;information storage and retrieval;prototyping","","2","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Some Comments on ""Transition-Oriented"" Versus ""Structured"" Specification of Distributed Algorithms and Protocols","G. v. Bochmann; J. P. Verjus","Department d'IRO, University of Montreal; NA","IEEE Transactions on Software Engineering","","1987","SE-13","4","501","505","Formal description techniques (FDT's) are being developed for the specification of communication protocols and other distributed systems. Some of them (namely SDL and Estelle) are based on an extended state transition model and promote a ""transition-oriented"" specification style. Another one (namely Lotos) and most highlevel programming languages promote a style which is called ""structured."" The correspondence compares these two specification styles in the framework of rendezvous interactions between different system modules. The advantages of each of the two styles are discussed in relation with an example of a virtual ring mutual exclusion protocol. Transformation rules between the two approaches are given. An extension to the state transition oriented FDT's is also suggested in order to allow for a structured specification style.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233188","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702243","Distributed algorithms;Estelle;exception handling;extended state machines;mutual exclusion;SDL;structured programming","Distributed algorithms;Protocols;Carbon capture and storage;Computer languages;Specification languages;LAN interconnection;ISO;Automata;Signal generators;Modems","","Distributed algorithms;Estelle;exception handling;extended state machines;mutual exclusion;SDL;structured programming","","1","","16","","","","","","IEEE","IEEE Journals & Magazines"
"A hybrid knowledge representation as a basis of requirement specification and specification analysis","J. J. P. Tsai; T. Weigert; H. -. Jang","Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA; NA; NA","IEEE Transactions on Software Engineering","","1992","18","12","1076","1100","A formal requirement specification language, the frame-and-rule oriented requirement specification language FRORL, developed to facilitate the specification, analysis, and development of a software system is presented. The surface syntax of FRORL is based on the concepts of frames and production rules that may bear hierarchical relationships to each other, relying on multiple inheritance. To provide thorough semantic foundations, FRORL is based on a nonmonotonic variant of Horn-clause logic. Using the machinery of Horn-clause logic, various properties of a FRORL specification can be analyzed. Among the external properties of FRORL are formality, object-orientedness, and a wide spectrum of life cycle phases. Intrinsic properties are modularity, provision for incremental development, inheritance, refinement, reusability, prototyping, and executability. A software development environment based on FRORL has been implemented using the C language on a Sun workstation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.184762","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=184762","","Knowledge representation;Specification languages;Logic;Software systems;Production;Machinery;Software prototyping;Prototypes;Programming;Sun","formal specification;Horn clauses;knowledge representation;logic programming languages;specification languages","nonmonotonic Horn clause logic;object oriented;hybrid knowledge representation;formal requirement specification language;frame-and-rule oriented requirement specification language;FRORL;surface syntax;frames;production rules;hierarchical relationships;multiple inheritance;inheritance;reusability;prototyping;executability;software development environment;C language","","39","","54","","","","","","IEEE","IEEE Journals & Magazines"
"Conflicts in policy-based distributed systems management","E. C. Lupu; M. Sloman","Dept. of Comput., Imperial Coll. of Sci., Technol. & Med., London, UK; NA","IEEE Transactions on Software Engineering","","1999","25","6","852","869","Modern distributed systems contain a large number of objects and must be capable of evolving, without shutting down the complete system, to cater for changing requirements. There is a need for distributed, automated management agents whose behavior also has to dynamically change to reflect the evolution of the system being managed. Policies are a means of specifying and influencing management behavior within a distributed system, without coding the behavior into the manager agents. Our approach is aimed at specifying implementable policies, although policies may be initially specified at the organizational level and then refined to implementable actions. We are concerned with two types of policies. Authorization policies specify what activities a manager is permitted or forbidden to do to a set of target objects and are similar to security access-control policies. Obligation policies specify what activities a manager must or must not do to a set of target objects and essentially define the duties of a manager. Conflicts can arise in the set of policies. Conflicts may also arise during the refinement process between the high level goals and the implementable policies. The system may have to cater for conflicts such as exceptions to normal authorization policies. The paper reviews policy conflicts, focusing on the problems of conflict detection and resolution. We discuss the various precedence relationships that can be established between policies in order to allow inconsistent policies to coexist within the system and present a conflict analysis tool which forms part of a role based management framework. Software development and medical environments are used as example scenarios.","0098-5589;1939-3520;2326-3881","","10.1109/32.824414","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=824414","","Authorization;Security;Computer Society;Humans;File systems","distributed processing;authorisation;management of change;systems analysis;bibliographies","policy based distributed systems management;modern distributed systems;changing requirements;automated management agents;management behavior;manager agents;implementable policies;organizational level;implementable action;authorization policies;target objects;security access-control policies;obligation policies;refinement process;high level goals;conflict detection;precedence relationships;conflict analysis tool;role based management framework;software development;medical environments","","284","","59","","","","","","IEEE","IEEE Journals & Magazines"
"Reuse of software through generation of partial systems","F. J. Polster","Kernforschungszentrum Karlsruhe GmbH, Institut f&#x00FC;r Datenverarbeitung in der Technik, Postfach 3640, D-7500 Karlsruhe 1, West Germany; Dornier GmbH, WF30, D-7990 Friedrichshafen 1, West Germany","IEEE Transactions on Software Engineering","","1986","SE-12","3","402","416","The author considers the problem of constructing partial systems, where the program of a partial system is obtained by selecting only those code segments of the complete program that implement the capabilities needed. A heuristic for determining fragments of a program system, which can serve as the building blocks for the programs of partial systems, is presented. The notion of `<i>B</i>-program' is introduced: a <i>B</i>-program contains, in addition to the fragments themselves for each fragment, substitute code and control information specifying the set of partial systems the fragment is relevant for. A representation of <i>B</i>-programs as a string is given such that generating a partial system consists in scanning this string and selecting substrings. A formal model for this type of program generation is developed. <i>B</i>-program reduction is dealt with; transformations for the elimination of superfluous vertices are presented; and the issue of uniqueness and the problem of constructing a minimal reduced <i>B</i>-program are discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312882","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312882","Code fragments;code selection;customizing;general software;generic systems;program generation;program tailoring;reuse of software","Indexes;Algorithm design and analysis;Computer aided software engineering;Software systems","software engineering","software reuse;software engineering;partial systems;code segments;fragments;building blocks;B-program;control information;formal model;program generation;transformations;superfluous vertices;uniqueness;minimal reduced B-program","","7","","","","","","","","IEEE","IEEE Journals & Magazines"
"Compositional semantics of a real-time prototyping language","B. Kramer; Luqi; V. Berzins","Dept. of Comput. Sci., US Naval Postgraduate Sch., Monterey, CA, USA; Dept. of Comput. Sci., US Naval Postgraduate Sch., Monterey, CA, USA; Dept. of Comput. Sci., US Naval Postgraduate Sch., Monterey, CA, USA","IEEE Transactions on Software Engineering","","1993","19","5","453","477","The formal semantics of a prototyping language for hard real-time systems, PSDL, is given. PSDL provides a data flow notation augmented by application-orientation timing and control constraints to describe a system as a hierarchy of networks of processing units communicating via data streams. The semantics of PSDL are defined in terms of algebraic high-level Petri nets. This formalism combines algebraic specifications of abstract data types with process and concurrency concepts of Petri nets. Its data abstraction facilities are used to define the meaning of PSDL data types, while high-level Petri nets serve to model the casual and timing behavior of a system. The net model exposes potential concurrency of computation and makes all synchronization needs implied by timing and control constraints explicit and precise. Time is treated as state of clocks, and clocks are modeled as ordinary system components. The net semantics provides the basis for applying analysis techniques and semantic tools available for high-level Petri nets.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.232012","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=232012","","Prototypes;Timing;Petri nets;Real time systems;Control systems;Concurrent computing;Clocks;Synchronization;Application software;Process control","abstract data types;formal specification;Petri nets;real-time systems;software prototyping;specification languages","compositional semantics;real-time prototyping language;formal semantics;hard real-time systems;PSDL;data flow notation;application-orientation timing;control constraints;algebraic high-level Petri nets;algebraic specifications;abstract data types;concurrency concepts;timing behavior;synchronization","","14","","39","","","","","","IEEE","IEEE Journals & Magazines"
"A microprogramming logic","W. Damm","Dept. of Comput. Sci., Tech. Aachen Univ., West Germany","IEEE Transactions on Software Engineering","","1988","14","5","559","574","A universal syntax-directed proof system is presented for the verification of horizontal computer architectures. The system is based on the axiomatic architecture description language AADL, which is sufficiently rich to allow the specification of target architectures while providing a concise model for clocked microarchitectures. For each description A epsilon AADL of a host, it is shown how to construct systematically a (Hoare-style) axiomatic definition of an A-dependent high-level microprogramming language based on S*. The axiomatization of A's microoperations together with a powerful proof-rule dealing with the inherent low-level parallelism of horizontal architectures allow a complete axiomatic treatment of the timing behavior and dynamic conflicts of microprograms written in S*(A).<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6134","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6134","","Microprogramming;Logic;Computer architecture;Computer science;Architecture description languages;Power system modeling;Clocks;Microarchitecture;Parallel processing;Timing","computer architecture;formal logic;microprogramming;specification languages;theorem proving","microprogramming logic;syntax-directed proof system;horizontal computer architectures;architecture description language;AADL;specification;clocked microarchitectures;axiomatic definition;microoperations;low-level parallelism;timing behavior;dynamic conflicts","","2","","71","","","","","","IEEE","IEEE Journals & Magazines"
"Building knowledge through families of experiments","V. R. Basili; F. Shull; F. Lanubile","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; NA; NA","IEEE Transactions on Software Engineering","","1999","25","4","456","473","Experimentation in software engineering is necessary but difficult. One reason is that there are a large number of context variables and, so, creating a cohesive understanding of experimental results requires a mechanism for motivating studies and integrating results. It requires a community of researchers that can replicate studies, vary context variables, and build models that represent the common observations about the discipline. The paper discusses the experience of the authors, based upon a collection of experiments, in terms of a framework for organizing sets of related studies. With such a framework, experiments can be viewed as part of common families of studies, rather than being isolated events. Common families of studies can contribute to important and relevant hypotheses that may not be suggested by individual experiments. A framework also facilitates building knowledge in an incremental manner through the replication of experiments within families of studies. To support the framework, the paper discusses the experiences of the authors in carrying out empirical studies, with specific emphasis on persistent problems encountered in experimental design, threats to validity, criteria for evaluation, and execution of experiments in the domain of software engineering.","0098-5589;1939-3520;2326-3881","","10.1109/32.799939","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=799939","","Software engineering;Buildings;Design for experiments;Testing;Computer science;Mathematical model;Computer Society;Context modeling;Organizing;Software measurement","software engineering","software engineering experimentation;studies;knowledge building;empirical studies;experimental design","","359","","48","","","","","","IEEE","IEEE Journals & Magazines"
"Heuristics for join processing using nonclustered indexes","E. R. Omiecinski","Sch. of Inf. & Comput. Sci., Georgia Inst. of Technol., Atlanta, GA, USA","IEEE Transactions on Software Engineering","","1989","15","1","18","25","The author examines join processing when the access paths available are nonclustered indexes on the joining attribute(s) for both relations involved in the join. He uses a bipartite graph model to represent the pages from the two relations that contain tuples to be joined. The minimization of the number of page accesses needed to compute a join in the author's database environment is explored from two perspectives. The first is to reduce the maximum buffer size so that no page is accessed more than once, and the second is to reduce the number of page accesses for a fixed buffer size. The author has developed heuristics for these problems. He gives performance comparisons of these heuristics and another method that recently appeared in the literature. Results show that one particular heuristic performs very well for addressing the problem from either perspective.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21722","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21722","","Relational databases;Cost function;Buffer storage;Computational efficiency;Indexes;Bipartite graph;Query processing;Computer science;Indexing","relational databases","relational databases;query optimisation;join processing;nonclustered indexes;access paths;bipartite graph model;relations;tuples;page accesses;database environment;buffer size","","8","","12","","","","","","IEEE","IEEE Journals & Magazines"
"STATEMATE: a working environment for the development of complex reactive systems","D. Harel; H. Lachover; A. Naamad; A. Pnueli; M. Politi; R. Sherman; A. Shtull-Trauring; M. Trakhtenbrot","i-Logix Inc., Burlington, MA, USA; i-Logix Inc., Burlington, MA, USA; i-Logix Inc., Burlington, MA, USA; i-Logix Inc., Burlington, MA, USA; i-Logix Inc., Burlington, MA, USA; i-Logix Inc., Burlington, MA, USA; i-Logix Inc., Burlington, MA, USA; i-Logix Inc., Burlington, MA, USA","IEEE Transactions on Software Engineering","","1990","16","4","403","414","STATEMATE is a set of tools, with a heavy graphical orientation, intended for the specification, analysis, design, and documentation of large and complex reactive systems. It enables a user to prepare, analyze, and debug diagrammatic, yet precise, descriptions of the system under development from three interrelated points of view, capturing structure, functionality, and behavior. These views are represented by three graphical languages, the most intricate of which is the language of statecharts, used to depict reactive behavior over time. In addition to the use of statecharts, the main novelty of STATEMATE is in the fact that it understands the entire descriptions perfectly, to the point of being able to analyze them for crucial dynamic properties, to carry out rigorous executions and simulations of the described system, and to create running code automatically. These features are invaluable when it comes to the quality and reliability of the final outcome.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.54292","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=54292","","Real time systems;Control systems;Embedded software;Software systems;Research and development;Documentation;Communication system control;Communication system software;Software tools;Hardware","programming environments;software engineering;systems analysis","STATEMATE;working environment;development;complex reactive systems;graphical orientation;specification;analysis;design;documentation;debug diagrammatic;functionality;behavior;graphical languages;statecharts","","545","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Quantitative analysis of faults and failures in a complex software system","N. E. Fenton; N. Ohlsson","Dept. of Comput. Sci., Queen Mary & Westfield Coll., London, UK; NA","IEEE Transactions on Software Engineering","","2000","26","8","797","814","The authors describe a number of results from a quantitative study of faults and failures in two releases of a major commercial software system. They tested a range of basic software engineering hypotheses relating to: the Pareto principle of distribution of faults and failures; the use of early fault data to predict later fault and failure data; metrics for fault prediction; and benchmarking fault data. For example, we found strong evidence that a small number of modules contain most of the faults discovered in prerelease testing and that a very small number of modules contain most of the faults discovered in operation. We found no evidence to support previous claims relating module size to fault density nor did we find evidence that popular complexity metrics are good predictors of either fault-prone or failure-prone modules. We confirmed that the number of faults discovered in prerelease testing is an order of magnitude greater than the number discovered in 12 months of operational use. The most important result was strong evidence of a counter-intuitive relationship between pre- and postrelease faults; those modules which are the most fault-prone prerelease are among the least fault-prone postrelease, while conversely, the modules which are most fault-prone postrelease are among the least fault-prone prerelease. This observation has serious ramifications for the commonly used fault density measure. Our results provide data-points in building up an empirical picture of the software development process.","0098-5589;1939-3520;2326-3881","","10.1109/32.879815","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=879815","","Failure analysis;Software systems;Density measurement;Software engineering;Software testing;Computer industry;Benchmark testing;Programming;Software metrics;Phase measurement","software performance evaluation;software metrics;software reliability","quantitative analysis;complex software system faults;quantitative study;commercial software system;basic software engineering hypotheses;Pareto principle;early fault data;failure data;software metrics;fault prediction;benchmarking;prerelease testing;module size;fault density;complexity metrics;failure-prone modules;operational use;counter-intuitive relationship;postrelease faults;fault-prone prerelease;fault-prone postrelease;fault density measure;data-points;software development process","","319","","46","","","","","","IEEE","IEEE Journals & Magazines"
"A layered approach to automating the verification of real-time systems","R. Gerber; I. Lee","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; NA","IEEE Transactions on Software Engineering","","1992","18","9","768","784","A layered approach to the specification and verification of real-time systems is described. Application processes are specified in the CSR Application Language, which includes high-level language constructs such as timeouts, deadlines, periodic processes, interrupts, and exception handling. A configuration schema is used to map the processes to system resources, and to specify the communication links between them. The authors automatically translate the result of the mapping into the CCSR process algebra, which characterizes CSR's resource-based computation model by a prioritized transition system. For the purposes of verification, a reachability analyzer based on the CCSR semantics has been implemented. This tool mechanically evaluates the correctness of the CSR specification by checking whether an exception state can be reached in its corresponding CCSR term. The effectiveness of this technique is illustrated by a multisensor robot example.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.159838","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=159838","","Real time systems;Timing;Algebra;Robots;Patient monitoring;Network topology;Computational modeling;Computer languages;Control systems","calculus of communicating systems;exception handling;formal specification;formal verification;high level languages;real-time systems","layered approach;specification;verification;real-time systems;CSR Application Language;high-level language constructs;timeouts;deadlines;periodic processes;interrupts;exception handling;configuration schema;system resources;communication links;CCSR process algebra;resource-based computation model;prioritized transition system;reachability analyzer;CCSR semantics;correctness;exception state;multisensor robot example","","27","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Analysis of Extendible Hashing","H. Mendelson","Graduate School of Management, University of Rochester","IEEE Transactions on Software Engineering","","1982","SE-8","6","611","619","Extendible hashing is an attractive direct-access technique which has been introduced recently. It is characterized by a combination of database-size flexibility and fast direct access. This paper derives performance measures for extendible hashing, and considers their implecations on the physical database design. A complete characterization of the probability distribution of the directory size and depth is derived, and its implications on the design of the directory are studied. The expected input/output costs of various operations are derived, and the effects of varying physical design parameters on the expected average operating cost and on the expected volume are studied.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.236022","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702995","Database;extendible hashing;hashing;performance analysis","Databases;Costs;Probability distribution;Performance analysis;Information retrieval;Software algorithms","","Database;extendible hashing;hashing;performance analysis","","3","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Effects of response and stability on scheduling in distributed computing systems","T. L. Casavant; J. G. Kuhl","Dept. of Electr. & Comput. Eng., Iowa Univ., Iowa City, IA, USA; Dept. of Electr. & Comput. Eng., Iowa Univ., Iowa City, IA, USA","IEEE Transactions on Software Engineering","","1988","14","11","1578","1588","An examination is made of the effects of response and stability on scheduling algorithms for general-purpose distributed computing systems. Response characterizes the time required, following a perturbation in the system state, to reach a new equilibrium state. Stability is a measure of the ability of a mechanism to detect when the effects of further actions will not improve the system state as defined by a user-defined objective. These results have implications for distributed computations in general. Analysis is based on formal communicating finite automata models of two distinct approaches to the scheduling problem, each using the objective of global optimal load balancing. The results indicate that absolute stability is not always necessary in dynamic systems for the same reasons that relatively small amounts of instability are tolerated in the design of analog control systems. It is shown that response is a very important first-order metric of dynamic scheduling behavior, and that response and stability are related.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9046","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9046","","Stability;Processor scheduling;Distributed computing;Scheduling algorithm;Time factors;Automata;Load management;Automatic control;Control systems;Dynamic scheduling","distributed processing;finite automata;scheduling","response;stability;scheduling;distributed computing systems;user-defined objective;communicating finite automata models;load balancing;dynamic systems;first-order metric","","27","","16","","","","","","IEEE","IEEE Journals & Magazines"
"On the optimal total processing time using checkpoints","B. Dimitrov; Z. Khalil; N. Kolev; P. Petrov","Inst. of Math., Acad. of Sci., Sofia, Bulgaria; NA; NA; NA","IEEE Transactions on Software Engineering","","1991","17","5","436","442","The authors investigate the problem of optimizing the expected blocking time duration by providing a schedule of checkpoints during the required job processing time. They give a general approach for determining the optimal checkpoint schedule and derive some cases when the optimal checkpointing is uniform. The model has applications in unreliable computing systems, multiclient computer service, data transmissions, etc.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.90446","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=90446","","Electric breakdown;Processor scheduling;Checkpointing;Data communication;Testing;Performance evaluation;Councils;Mathematics;Application software;Computer applications","optimisation;programming theory;scheduling","optimal total processing time;optimal checkpoint schedule;unreliable computing systems;multiclient computer service;data transmissions","","7","","9","","","","","","IEEE","IEEE Journals & Magazines"
"An analysis of the Intel 80/spl times/86 security architecture and implementations","O. Sibert; P. A. Porras; R. Lindell","Oxford Syst. Inc., Lexington, MA, USA; NA; NA","IEEE Transactions on Software Engineering","","1996","22","5","283","293","An in depth analysis of the 80/spl times/86 processor families identifies architectural properties that may have unexpected, and undesirable, results in secure computer systems. In addition, reported implementation errors in some processor versions render them undesirable for secure systems because of potential security and reliability problems. We discuss the imbalance in scrutiny for hardware protection mechanisms relative to software, and why this imbalance is increasingly difficult to justify as hardware complexity increases. We illustrate this difficulty with examples of architectural subtleties and reported implementation errors.","0098-5589;1939-3520;2326-3881","","10.1109/32.502221","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=502221","","Computer architecture;Hardware;Computer errors;Computer security;Protection;Microprocessors;Trademarks;Materials testing;Performance analysis;Performance evaluation","microprocessor chips;computer architecture;security of data;computer testing;integrated circuit testing","Intel 80 x 86 security architecture;processor families;architectural properties;secure computer systems;processor versions;secure systems;hardware protection mechanisms;hardware complexity;architectural subtleties;implementation errors","","5","","33","","","","","","IEEE","IEEE Journals & Magazines"
"Queueing Analysis of a Reordering Issue","G. Harrus; B. Plateau","Laboratoire de Recherche en Informatique, Universit&#233;de Paris-Sud; NA","IEEE Transactions on Software Engineering","","1982","SE-8","2","113","123","In this paper an M/G/&#8734;queue is considered that receives a stream of numbered tasks. Results are derived concerning the probabilistic properties of the reordering done by the queue.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.234954","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702919","Network;ordering;performance evaluation;queueing theory;reordering","Queueing analysis;Network servers;Computer network reliability;Distributed databases;Delay;Random variables;Availability;Application software;Resource management","","Network;ordering;performance evaluation;queueing theory;reordering","","26","","6","","","","","","IEEE","IEEE Journals & Magazines"
"Web structures: a tool for representing and manipulating programs","A. Maggiolo-Schettini; M. Napoli; G. Tortora","Dept. of Inf., Pisa Univ., Italy; NA; NA","IEEE Transactions on Software Engineering","","1988","14","11","1621","1639","The authors introduce web structures and their transformations and develop their theory in the framework of category theory. Once a program has been represented as a web structure, software tools, such as a high-level data flow analyzer or other general program transformers, can be written as sets of web structure production rules. An implementation of web structure transformations is in progress. The mathematical theory of web structure transformations allows form proofs of properties both at the metatheoretical and theoretical levels.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9050","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9050","","Data analysis;Software tools;Transformers;Production;Computer languages;Debugging;III-V semiconductor materials;Information analysis;Algorithm design and analysis","data structures;graph theory;program verification;programming theory;set theory;software tools","web structures;category theory;software tools;high-level data flow analyzer;program transformers;production rules;web structure transformations","","6","","11","","","","","","IEEE","IEEE Journals & Magazines"
"The estimation of parameters of the hypergeometric distribution and its application to the software reliability growth model","Y. Tohma; H. Yamano; M. Ohba; R. Jacoby","Dept. of Comput. Sci., Tokyo Inst. of Technol., Japan; Dept. of Comput. Sci., Tokyo Inst. of Technol., Japan; NA; NA","IEEE Transactions on Software Engineering","","1991","17","5","483","489","Six ways to estimate parameters of the hypergeometric distribution are investigated, and their accuracies are examined comparatively. It is demonstrated that the least-squares sum method is the best one among those tried, and can be applied to real test/debug data for estimating the number of faults still resident in a program after test/debugging. By this method the estimation time can be reduced greatly.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.90450","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=90450","","Parameter estimation;Application software;Computer science;Jacobian matrices;Software reliability;Programming profession;Software debugging;Software testing;Costs;Computer science education","least squares approximations;parameter estimation;program debugging;program testing;software reliability","program testing;program debugging;parameter estimation;program fault estimation;software reliability growth model;hypergeometric distribution;least-squares sum method","","34","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Ambiguity in Processing Boolean Queries on TDMS Tree Structures: A Study of Four Different Philosophies","W. T. Hardgrave","Center for Programming Sciences and Technology, Institute for Computer Sciences and Technology, National Bureau of Standards","IEEE Transactions on Software Engineering","","1980","SE-6","4","357","372","This paper defines and demonstrates four philosophies for processing queries on tree structures; shows that the data semantics of queries shuld be described by designating sets of nodes from which v values for attnbutes may be returned to the data consumer; shows that the data semantics of database processing can be specified totally independent of any madhine, file structure, or implementation; shows that set theory is a natural and effective vehicle for analyzing the semantics of queries on tree structures; and finally, shows that Bolts is an adequate formalism for conveying the semantics of tree structure processing.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234492","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702744","Ambiguity;Boolean;database;hierarchical;information;query;query language;semantics;TDMS;tree;tree structures","Time division multiplexing;Tree data structures;Database languages;Database systems;Data models;Set theory;Vehicles;Fasteners;Bars","","Ambiguity;Boolean;database;hierarchical;information;query;query language;semantics;TDMS;tree;tree structures","","","","14","","","","","","IEEE","IEEE Journals & Magazines"
"A VDM case study in mural","B. Fields; M. Elvang-Goransson","ICI, Manchester, UK; NA","IEEE Transactions on Software Engineering","","1992","18","4","279","295","The application of an interactive theorem-proving assistant and specification support tool called mural in the specification and verification of a small Vienna development method (VDM) development is described. It is the authors' intention to give a feel for how mural works and of mural's applicability as a tool in specifying and verifying software.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.129217","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=129217","","Computer aided software engineering;Concrete;Safety;Inductors;Application software;Software tools;Natural languages;Formal specifications;Process design;Refining","formal specification;interactive systems;program verification;software tools;theorem proving","VDM;interactive theorem-proving assistant;specification support tool;mural;specification;verification;Vienna development method","","5","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Performance comparison of three modern DBMS architectures","A. Delis; N. Roussopoulos","Inst. for Adv. Comput. Studies, Maryland Univ., College Park, MD, USA; Inst. for Adv. Comput. Studies, Maryland Univ., College Park, MD, USA","IEEE Transactions on Software Engineering","","1993","19","2","120","138","The introduction of powerful workstations connected through local area networks (LANs) inspired new database management system (DBMS) architectures that offer high performance characteristics. The authors examine three such software architecture configurations: client-server (CS), the RAD-UNIFY type of DBMS (RU), and enhanced client-server (ECS). Their specific functional components and design rationales are discussed. Three simulation models are used to provide a performance comparison under different job workloads. Simulation results show that the RU almost always performs slightly better than the CS, especially under light workloads, and that ECS offers significant performance improvement over both CS and RU. Under reasonable update rates, the ECS over CS (or RU) performance ratio is almost proportional to the number of participating clients (for less than 32 clients). The authors also examine the impact of certain key parameters on the performance of the three architectures and show that ECS is more scalable that the other two.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.214830","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=214830","","Computer architecture;Workstations;Local area networks;Performance analysis;Throughput;Military computing;Computational modeling;Packaging;Software architecture;Indexes","database management systems;performance evaluation;software engineering","simulation results;DBMS architectures;workstations;local area networks;software architecture configurations;client-server;RAD-UNIFY type;functional components;design rationales;simulation models","","18","","26","","","","","","IEEE","IEEE Journals & Magazines"
"A taxonomy of scheduling in general-purpose distributed computing systems","T. L. Casavant; J. G. Kuhl","Dept. of Electr. & Comput. Eng., Iowa Univ., Iowa City, IA, USA; Dept. of Electr. & Comput. Eng., Iowa Univ., Iowa City, IA, USA","IEEE Transactions on Software Engineering","","1988","14","2","141","154","One measure of the usefulness of a general-purpose distributed computing system is the system's ability to provide a level of performance commensurate to the degree of multiplicity of resources present in the system. A taxonomy of approaches to the resource management problem is presented in an attempt to provide a common terminology and classification mechanism necessary in addressing this problem. The taxonomy, while presented and discussed in terms of distributed scheduling, is also applicable to most types of resource management.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4634","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4634","","Taxonomy;Processor scheduling;Distributed computing;Resource management;Energy management;Power system management;Cities and towns;Control theory;Operations research;Terminology","distributed processing;operating systems (computers);scheduling","operating systems;scheduling;distributed computing;resource management;distributed scheduling","","447","","118","","","","","","IEEE","IEEE Journals & Magazines"
"A Stub Generator for Multilanguage RPC in Heterogeneous Environments","P. B. Gibbons","Department of Electrical Engineering and Computer Science, Computer Science Division, University of California","IEEE Transactions on Software Engineering","","1987","SE-13","1","77","87","A stub generator for marshalling the arguments and results of remote procedure calls in heterogeneous environments is presented. The stub generator is itself language and machine independent, and derives all its knowledge of source languages and machine types from a set of language and machine specifications. These specifications can be paired in any combination to accommodate interlanguage calls between differing machines.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232837","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702135","Argument marshalling;distributed systems;heterogeneous environments;interface specification language;interlanguage procedure call;remote procedure call;stub generator","Specification languages;Programming profession;Data structures;Delay systems;Computer languages;Milling machines;Computer science;Hardware","","Argument marshalling;distributed systems;heterogeneous environments;interface specification language;interlanguage procedure call;remote procedure call;stub generator","","30","","23","","","","","","IEEE","IEEE Journals & Magazines"
"A Methodology for Developing Distributed Programs","S. Ramesh; S. L. Mehndiratta","Department of Computer Science and Engineering, Indian Institute of Technology; NA","IEEE Transactions on Software Engineering","","1987","SE-13","8","967","976","A methodology, different from the existing ones, for constructing distributed programs is presented. It is based on the well-known idea of developing distributed programs via synchronous and centralized programs. The distinguishing features of the methodology are: 1) specification include process structure information and distributed programs are developed taking this information into account, 2) a new class of programs, called PPSA's, is used in the development process, and 3) a transformational approach is suggested to solve the problems inherent in the method of developing distributed programs through synchronous and centralized programs. The methodology is illustrated with an example.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233514","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702314","Communicating processes;decentralization;distributed programming;programming methodology;program transformation","Centralized control;Control systems;Computer science;Process design;Network topology","","Communicating processes;decentralization;distributed programming;programming methodology;program transformation","","5","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Real-time software life cycle with the model system","J. S. Tseng; B. Szymanski; Y. Shi; N. S. Prywes","Department of Computer and Information Science, University of Pennsylvania, Philadephia, PA 19104; Naval Air Development Center, Warminster, PA 18974; Department of Computer Science, Rensselaer Polytechnic Institute, Troy, NY 12180; Department of Computer Science, Temple University, Philadelphia, PA 19122; Department of Computer and Information Science, University of Pennsylvania, Phildelphia, PA 19104","IEEE Transactions on Software Engineering","","1986","SE-12","2","358","373","The use of an assertive specification language for real-time software development and maintenance is considered. The language is used for asserting the acts or relations inherent in the problem to be solved; this is in contrast to conventional programming languages, which are used to express the computer solution. Expressing a problem in Model consists of declaring array variables and defining their relationships through equations. This is different from conventional programming, which relates the problem in terms of computer operations. The language is supported by an automatic system which interacts with the user in soliciting missing definitions or correcting inconsistencies, and which translates the specification into a near-optimal computer solution. The main advantages of this approach are indicated. The use of Model in real-time software development and maintenance is reviewed. Differences from conventional programming are stressed through an example, which also illustrates the use of the three automatic components of the Model system.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312949","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312949","Assertive;compiler;configurator;nonprocedural;real time;software-development;timing","Real-time systems;Computers;Computational modeling;Mathematical model;Software;Delay","software engineering;specification languages","software life cycle;Model system;specification language;real-time software development;maintenance;programming languages;array variables;programming;missing definitions;inconsistencies","","1","","","","","","","","IEEE","IEEE Journals & Magazines"
"Semantically extended dataflow diagrams: a formal specification tool","R. B. France","Inst. for Adv. Comput., Maryland Univ., College Park, MD, USA","IEEE Transactions on Software Engineering","","1992","18","4","329","346","A method for associating a dataflow diagram (DFD) with a formal specification is described. The intention is to enhance the use of the DFD as a formal specification tool, thus gaining a tool that can be used to document application functionality in an understandable manner and, at the same time, be capable of producing a formal specification that can be used to rigorously investigate the semantic properties of the application. It is shown how the formal specifications characterizing semantic models of DFDs can be used to investigate desired application properties of verify semantic decompositions of data transforms.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.129221","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=129221","","Formal specifications;Design for disassembly;Documentation;Application software;Programming;Communication system control;Concurrent computing;Formal languages;Testing;Economic forecasting","diagrams;formal specification;systems analysis","dataflow diagram;formal specification tool;application functionality;semantic properties;semantic decompositions;data transforms","","33","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Computational issues in secure interoperation","Li Gong; Xiaolei Qian","Comput. Sci. Lab., SRI Int., Menlo Park, CA, USA; Comput. Sci. Lab., SRI Int., Menlo Park, CA, USA","IEEE Transactions on Software Engineering","","1996","22","1","43","52","Advances in distributed systems and networking technology have made interoperation not only feasible but also increasingly popular. We define the interoperation of secure systems and its security, and prove complexity and composability results on obtaining optimal and secure interoperation. Most problems are NP-complete even for systems with very simple access control structures, while for a general setting the problem is undecidable. Nevertheless, composability reduces complexity in that secure global interoperation can be obtained incrementally by composing secure local interoperation. We illustrate, through an application in secure database interoperation, how these theoretical results can help system designers in practice.","0098-5589;1939-3520;2326-3881","","10.1109/32.481533","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=481533","","Access control;Data security;Information security;Information systems;National security;Intelligent networks;Distributed databases;Algorithm design and analysis;Database systems;Computational complexity","open systems;computational complexity;authorisation;security of data;distributed databases;decidability;software engineering;systems analysis","secure interoperation;distributed systems;networking technology;secure systems;security;complexity;composability;optimal interoperation;NP-complete problems;access control structures;undecidable problem;secure global interoperation;secure local interoperation;secure database interoperation;system designers","","76","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Analyzing Concurrency Control Algorithms When User and System Operations Differ","P. A. Bernstein; N. Goodman; Ming-Yee Lai","Aiken Computation Laboratory, Harvard University; NA; NA","IEEE Transactions on Software Engineering","","1983","SE-9","3","233","239","Concurrency control algorithms for database systems are usually regarded as methods for synchronizing Read and Write operations. Such methods are judged to be correct if they only produce serializable executions. However, Reads and Writes are sometimes inaccurate models of the operations executed by a database system. In such cases, serializability does not capture all aspects of concurrency control executions. To capture these aspects, we describe a proof schema for analyzing concurrency control correctness. We illustrate the proof schema by presenting two new concurrency algorithms for distributed database systems.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236732","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703050","Database systems;nested transactions;serializability theory;transactions","Control system analysis;Algorithm design and analysis;Concurrency control;Database systems;Transaction databases;Strontium;Laboratories;Control systems;Concurrent computing;Distributed databases","","Database systems;nested transactions;serializability theory;transactions","","","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Performance analysis of Time Warp with multiple homogeneous processors","A. Gupta; I. F. Akyildiz; R. M. Fujimoto","Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA; Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA; Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA","IEEE Transactions on Software Engineering","","1991","17","10","1013","1027","The behavior of n interacting processors synchronized by the Time Warp protocol is analyzed using a discrete-state, continuous-time Markov chain model. The performance and dynamics of the processes (or processors) are analyzed under the following assumptions: exponential task times and timestamp increments on messages, each event message generates one new message that is sent to a randomly selected process, negligible rollback, state saving, and communication delay, unbounded message buffers, and homogeneous processors. Several performance measures are determined, such as: the fraction of processed events that commit, speedup, rollback probability, expected length of rollback, the probability mass function for the number of uncommitted processed events, the probability distribution function for the virtual time of a process, and the fraction of time the processors remain idle. The analysis is approximate, thus the results have been validated through performance measurements of a Time Warp testbed executing on a shared-memory multiprocessor.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.99190","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=99190","","Performance analysis;Discrete event simulation;Time measurement;Time warp simulation;Synchronization;Senior members;Protocols;Delay;Length measurement;Velocity measurement","discrete event simulation;Markov processes;multiprocessing systems;performance evaluation;protocols","parallel simulation;interacting processors;Time Warp protocol;discrete-state;continuous-time Markov chain model;exponential task times;timestamp increments;event message;negligible rollback;state saving;communication delay;unbounded message buffers;homogeneous processors;performance measures;processed events;speedup;rollback probability;probability mass function;uncommitted processed events;probability distribution function;virtual time;Time Warp testbed;shared-memory multiprocessor","","20","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Application of a Methodology for the Development and Validation of Reliable Process Control Software","C. V. Ramamoorthy; Y. R. Mok; F. B. Bastani; G. H. Chin; K. Suzuki","Computer Science Division and Electronics Research Laboratory, University of California; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1981","SE-7","6","537","555","This paper discusses the necessity of a good methodology for the development of reliable software, especialy with respect to the final software validation and testing activities. A formal specification development and validation methodology is proposed. This methodology has been applied to the development and validation of a pilot software, incorporating typical features of critical software for nuclear power plant safety protection. The main features of the approach indude the use of a formal specification language and the independent development of two sets of specifications. Analyses on the specifications consists of three-parts: validation against the functional requirements consistency and integrity of the specifications, and dual specification comparison based on a high-level symbolic execution technique. Dual design, implementation, and testing are performed. Automated tools to facilitate the validation and testing activities are developed to support the methodology. These includes the symbolic executor and test data generator/dual program monitor system. The experiences of applying the methodology to the pilot software are discussed, and the impact on the quality of the software is assessed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.226474","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702887","Assertion;dual-programming;methodology;path analysis;process control;reliability;requirement;specification;symbolic execution;testing;validation;verification","Application software;Process control;Software safety;Formal specifications;Software quality;Software testing;Power generation;Protection;Performance evaluation;Automatic testing","","Assertion;dual-programming;methodology;path analysis;process control;reliability;requirement;specification;symbolic execution;testing;validation;verification","","42","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Synthesis of mutual exclusion solutions based on binary semaphores","R. T. Jacob; I. P. Page","Dept. of Comput. Sci., North Texas State Univ., Denton, TX, USA; NA","IEEE Transactions on Software Engineering","","1989","15","5","560","568","A graphical form of the mutual exclusion problem is considered in which each vertex represents a process and each edge represents a mutual exclusion constraint between the critical sections of the processes associated with its endpoints. An edge semaphore solution for mutual exclusion problems is defined, and those graphs which are edge solvable are characterized in terms of both a forbidden subgraph and a graph grammar. Finally, an efficient algorithm is given which generates the entry and exit sections for all processes in an edge-solvable problem.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24705","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24705","","Jacobian matrices;Software engineering;System recovery;Time sharing computer systems;Computer science;Kernel;Programming environments","graph theory;operating systems (computers)","mutual exclusion solutions;binary semaphores;graphical form;mutual exclusion problem;vertex;mutual exclusion constraint;edge semaphore solution;edge solvable;forbidden subgraph;graph grammar;efficient algorithm;entry;exit sections","","1","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Reasoning About Probabilistic Behavior in Concurrent Systems","S. Purushothaman; P. A. Subrahmanyam","Department of Computer Science, Pennsylvania State University; NA","IEEE Transactions on Software Engineering","","1987","SE-13","6","740","745","Certain aspects of the behavior of concurrent systems are intrinsically probabilistic in nature, e.g., the behavior of imperfect communication media used in network protocols. We address the problem of expressing such behavior in an algebraic calculus for communicating systems. The introduction of probabilistic information in the calculus alleviates the problem of proving liveness, as proving liveness now amounts to proving that its probability is 1. A methodology for proving both safety and liveness is developed and used in proving the correctness of the Alternating Bit Protocol.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233478","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702278","Calculus for communicating systems;correctness;liveness;probability;protocol","Protocols;Calculus;Explosions;Automata;Intelligent networks;Probability;Safety;Contracts;Context modeling;Computational modeling","","Calculus for communicating systems;correctness;liveness;probability;protocol","","2","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Conceptual Modeling in the Context of Development","C. H. Kung","Department of Computer Science, University of Iowa. Iowa city, IA 52242.","IEEE Transactions on Software Engineering","","1989","15","10","1176","1187","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1989.559766","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=559766","","Context modeling;Prototypes;Software prototyping;Programming;Design optimization;System testing;Information systems;Software maintenance;Software quality;Costs","","Conceptual modeling;consistency checking;executable specification;formal analysis of model;requirements specification","","25","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Efficient discrete-event simulation of colored Petri nets","R. Gaeta","Dipartimento di Inf., Torino Univ., Italy","IEEE Transactions on Software Engineering","","1996","22","9","629","639","Colored Petri nets are a powerful formalism for the description of complex, asynchronous distributed systems. They can express in a very concise way the behavior of very large systems, especially in case these systems are composed of many replications of a few basic components that individually behave in a similar way. The simulation of such models is, however, difficult to perform in a computationally efficient way. For the specific class of stochastic well-formed nets (SWNs), we present a set of optimizations that allow a very efficient implementation of the event-driven simulation technique. Three approaches are followed to improve simulation efficiency: first, an efficient algorithm for the computation of the occurrences of a transition in a given marking; second, reduction of the amount of work needed to schedule or preempt the occurrence of a transition as a consequence of a marking change, taking into account the restrictions on color functions for the SWN formalism; third, reduction of the average length of the event list in the case of symmetric models where the so-called symbolic simulation technique applies. The approach is validated by performance measurements on several large SWN models taken from the literature.","0098-5589;1939-3520;2326-3881","","10.1109/32.541434","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=541434","","Discrete event simulation;Petri nets;Computational modeling;Analytical models;Engines;Stochastic processes;Virtual prototyping;Power system modeling;Scheduling algorithm;Processor scheduling","Petri nets;graph colouring;discrete event simulation;optimisation;symmetry;stochastic systems;symbol manipulation;mathematics computing","discrete-event simulation;colored Petri nets;asynchronous distributed systems;very large systems;stochastic well-formed nets;optimizations;event-driven simulation technique;simulation efficiency;transition occurrences;marking change;work reduction;scheduling;event list length reduction;symmetric models;symbolic simulation technique;performance measurements;high-level Petri nets","","25","","18","","","","","","IEEE","IEEE Journals & Magazines"
"View Definition and Generalization for Database Integration in a Multidatabase System","U. Dayal; H. Hwang","Computer Corporation of America, Cambridge, MA 02140.; Department of Computer Science, University of Texas, Austin, TX 78712.; Department of Computer Science, University of Iowa, Iowa City, IA 52241.","IEEE Transactions on Software Engineering","","1984","SE-10","6","628","645","Access to a heterogeneous distributed collection of databases can be simplified by providing users with a logically integrated interface or global view. There are two aspects to database integration. Firstly, the local schemas may model objects and relationships differently and, secondly, the databases may contain mutually inconsistent data. This paper identifies several kinds of structural and data inconsistencies that might exist. It describes a versatile view definition facility for the functional data model and illustrates the use of this facility for resolving inconsistencies. In particular, the concept of generalization is extended to this model, and its importance to database integration is emphasized. The query modification algorithm for the relational model is extended to the semantically richer functional data model with generalization.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010292","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010292","Database;database integration;data inconsistency;data modeling;generalization","Relational databases;Data models;Marine vehicles;Database systems;Computer science;Information retrieval;Remuneration;Contracts;Government;Indexes","","","","149","","23","","","","","","IEEE","IEEE Journals & Magazines"
"PELAS-program error-locating assistant system","B. Korel","Dept. of Comput. Sci., Wayne State Univ., Detroit, MI, USA","IEEE Transactions on Software Engineering","","1988","14","9","1253","1260","Error localization in program debugging is the process of identifying program statements which cause incorrect behavior. A prototype of the error localization assistant system which guides a programmer during debugging of Pascal programs is described. The system is interactive: it queries the programmer for the correctness of the program behavior and uses answers to focus the programmer's attention on an erroneous part of the program (in particular, it can localize a faulty statement). The system differs from previous approaches in that it makes use of the knowledge of program structure, which is derived automatically. The knowledge of program structure is represented by the dependence network which is used by the error-locating reasoning mechanism to guide the construction, evaluation, and modification of hypothesis of possible causes of the error. Backtracking reasoning has been implemented in the reasoning mechanism.<<ETX>></ETX>","0098-5589;1939-3520;2326-3881","","10.1109/32.6169","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6169","","Programming profession;Debugging;Prototypes;Computer science;Software tools;Automatic programming;Software prototyping","interactive systems;knowledge based systems;knowledge representation;Pascal;program debugging;program verification;software tools","knowledge based system;knowledge representation;PELAS;program error-locating assistant system;program debugging;error localization assistant;Pascal programs;program structure;dependence network;reasoning","","53","","30","","","","","","IEEE","IEEE Journals & Magazines"
"The Interrogator: Protocol Secuity Analysis","J. K. Millen; S. C. Clark; S. B. Freedman","MITRE Corporation; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","2","274","288","The Interrogator is a Prolog program that searches for security vulnerabilities in network protocols for automatic cryptographic key distribution. Given a formal specification of the protocol, it looks for message modification attacks that defeat the protocol objective. It is still under developement, but is has been able to rediscover a known vulnerability in a published protocol. It is implemented in LM-Prolog on a Lisp Machine, with a graphical user interface.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233151","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702206","Active wiretapping;computer security;key distribution;network security;Prolog;protocol verification","Cryptographic protocols;Cryptography;Computer network management;Formal specifications;Computer security;Graphical user interfaces;User interfaces;Graphics;Mice;Computer displays","","Active wiretapping;computer security;key distribution;network security;Prolog;protocol verification","","35","","10","","","","","","IEEE","IEEE Journals & Magazines"
"A debugger for Ada tasking","A. F. Brindle; R. N. Taylor; D. F. Martin","Aerosp. Corp., El Segundo, CA, USA; NA; NA","IEEE Transactions on Software Engineering","","1989","15","3","293","304","The capabilities needed in an Ada debugger are discussed in light of the language's tasking constructs, and the design for a debugger is presented which operates in concert with a single-processor Ada interpreter. This debugger design demonstrates the extensions to sequential debugging techniques that are necessary to handle concurrency, and shows that significant debugging functionality can be provided even without the inclusion of automatic error diagnosis methods. The issues considered include isolation of effects and display of the full dynamic execution status, both of which are essential to diagnosis of concurrent programs.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21757","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21757","","Debugging;Concurrent computing;Aerodynamics;Testing;Information analysis;Program processors;Displays;Packaging;System recovery;Turning","Ada;parallel programming;program debugging;program interpreters","parallel programming;Ada tasking;Ada debugger;tasking constructs;single-processor Ada interpreter;sequential debugging;concurrency;dynamic execution status","","6","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Specification of Synchronizing Processes","K. Ramamritham; R. M. Keller","Department of Computer and Information Science, University of Massachusetts; NA","IEEE Transactions on Software Engineering","","1983","SE-9","6","722","733","The formalism of temporal logic has been suggested to be an appropriate tool for expressing the semantics of concurrent programs. This paper is concerned with the application of temporal logic to the specification of factors affecting the synchronization of concurrent processes. Towards this end, we first introduce a model for synchronization and axiomatize its behavior. SYSL, a very high-level language for specifying synchronization properties, is then described. It is designed using the primitives of temporal logic and features constructs to express properties that affect synchronization in a fairly natural and modular fashion. Since the statements in the language have intuitive interpretations, specifications are humanly readable. In addition, since they possess appropriate formal semantics, unambiguous specifications result.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.235435","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703117","Abstract model;concurrent processing;specification language;synchronization;temporal logic","Specification languages;High level languages;Logic design;Information science;Computer science;Cities and towns;Message passing;Protection;Process design;Software safety","","Abstract model;concurrent processing;specification language;synchronization;temporal logic","","5","","31","","","","","","IEEE","IEEE Journals & Magazines"
"The Rigorous Development of a System Version Control Program","I. D. Cottam","Department of Computer Science, University of Manchester, Manchester M13 9PL, England.","IEEE Transactions on Software Engineering","","1984","SE-10","2","143","154","A rigorous approach to software development is followed in developing a program to control the various components and versions of systems. This particular approach to systematic program development is known as the Vienna Development Method (VDM). This paper documerits the author's early experiences with VDM on a small, yet nontrivial, application. The functional specification of the version control system is presented in detail. Design decisions taken for a prototype implementation are also included. The version control program developed is based upon the Gandalf System Version Control Environment of Carnegie-Mellon University. Both that system and the subject of this case study support the most common forms of component interdependency relations, and methods of system evolution.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010216","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010216","Correctness;formal specification;program proving;software development environment;version-control","Control systems;Programming;Databases;Prototypes;Formal specifications;Production;Software systems;Laboratories;Computer science;Computer languages","","","","10","","14","","","","","","IEEE","IEEE Journals & Magazines"
"A methodology for testing intrusion detection systems","N. J. Puketza; K. Zhang; M. Chung; B. Mukherjee; R. A. Olsson","Dept. of Comput. Sci., California Univ., Davis, CA, USA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1996","22","10","719","729","Intrusion detection systems (IDSs) attempt to identify unauthorized use, misuse, and abuse of computer systems. In response to the growth in the use and development of IDSs, the authors have developed a methodology for testing IDSs. The methodology consists of techniques from the field of software testing which they have adapted for the specific purpose of testing IDSs. They identify a set of general IDS performance objectives which is the basis for the methodology. They present the details of the methodology, including strategies for test-case selection and specific testing procedures. They include quantitative results from testing experiments on the Network Security Monitor (NSM), an IDS developed at UC Davis. They present an overview of the software platform that has been used to create user-simulation scripts for testing experiments. The platform consists of the UNIX tool expect and enhancements that they have developed, including mechanisms for concurrent scripts and a record-and-replay feature. They also provide background information on intrusions and IDSs to motivate their work.","0098-5589;1939-3520;2326-3881","","10.1109/32.544350","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=544350","","System testing;Intrusion detection;Software testing;Computer security;Computerized monitoring;Computer networks;National security;Expert systems;Computational modeling;Computer simulation","testing;computer crime;security of data","intrusion detection system testing;unauthorized computer system use;computer system misuse;computer system abuse;software testing;test-case selection;testing procedures;Network Security Monitor;user-simulation scripts;UNIX tool expect;concurrent scripts;record-and-replay feature","","64","","35","","","","","","IEEE","IEEE Journals & Magazines"
"Parametric graph drawing","P. Bertolazzi; G. Di Battista; G. Liotta","Istituto di Analisi dei Sistemi ed Inf., CNR, Rome, Italy; NA; NA","IEEE Transactions on Software Engineering","","1995","21","8","662","673","A diagram is a drawing on the plane that represents a graph like structure, where nodes are represented by symbols and edges are represented by curves connecting pairs of symbols. An automatic layout facility is a tool that receives as input a graph like structure and is able to produce a diagram that nicely represents such a structure. Many systems use diagrams in the interaction with the users; thus, automatic layout facilities and algorithms for graphs layout have been extensively studied in the last years. We present a new approach in designing an automatic layout facility. Our approach is based on a modular management of a large collection of algorithms and on a strategy that, given the requirements of an application, selects a suitable algorithm for such requirements. The proposed approach has been used for designing the automatic layout facility of Diagram Server, a network server that offers to its clients several facilities for managing diagrams.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.403790","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=403790","","Tree graphs;Computer aided software engineering;Layout;Joining processes;Algorithm design and analysis;Information systems;Information analysis;Flow production systems;Flow graphs;Software engineering","diagrams;computer graphics;graph theory;network servers;client-server systems","parametric graph drawing;graph like structure;automatic layout facility;graph layout;modular management;Diagram Server;network server;diagram","","8","","53","","","","","","IEEE","IEEE Journals & Magazines"
"Single-site and distributed optimistic protocols for concurrency control","M. A. Bassiouni","Dept. of Comput. Sci., Central Florida Univ., Orlando, FL, USA","IEEE Transactions on Software Engineering","","1988","14","8","1071","1080","The authors consider that, in spite of their advantage in removing the overhead of lock maintenance and deadlock handling, optimistic concurrency control methods have been applied less in practice than locking schemes. Two complementary approaches are introduced that may help render the optimistic approach practically viable. For the high-level approach, integration schemes can be utilized so that the database management system is provided with a variety of synchronization methods each of which can be applied to the appropriate class of transactions. The low-level approach seeks to increase the concurrency of the original optimistic method and improve its performance. The author examines the low-level approach in depth, and presents algorithms that aim at reducing back-ups and improve throughput. Both the single-site and distributed networks are considered. Optimistic schemes using time-stamps for fully duplicated and partially duplicated database networks are presented, with emphasis on performance enhancement and on reducing the overall cost of implementation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.7617","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=7617","","Protocols;Concurrency control;Optimization methods;Database systems;System recovery;Concurrent computing;Control systems;Transaction databases;Synchronization;Throughput","computer networks;distributed databases;protocols;system recovery","distributed protocols;single site protocols;single site networks;distributed databases;optimistic protocols;concurrency control;lock maintenance;deadlock handling;database management system;synchronization methods;distributed networks;time-stamps;performance enhancement","","2","","25","","","","","","IEEE","IEEE Journals & Magazines"
"An automatic physical designer for network model databases","P. Rullo; D. Sacca","CRAI, Rende-Santo Stefano, Italy; NA","IEEE Transactions on Software Engineering","","1988","14","9","1293","1306","Systems EROS is a physical design tool for CODASYL database systems which covers a large spectrum of decision variables, notably location mode, set implementation, set order, and search keys. System EROS is based on a model where the CODASYL physical database design problem is formulated as an extension of the index selection problem in the relational database environment. Optimization algorithms for index selection are extended to solve the more complex problem of selecting a good physical access path configuration for CODASYL databases. The proposed approach represents a unified solution to the physical database design problem for both CODASYL and relational systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6173","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6173","","Relational databases;Design optimization;Indexes;Database systems;Cost function;Process design;Design methodology;Transaction databases;Navigation","automatic programming;distributed databases;file organisation;relational databases;software tools","physical designer;network model databases;EROS;physical design tool;CODASYL;location mode;set implementation;set order;search keys;index selection;relational database;physical access path configuration","","2","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Experience with multiple processor versions of Concurrent C","R. F. Cmelik; N. H. Gehani; W. D. Roome","AT&T Bell Labs., Murray Hill, NJ, USA; AT&T Bell Labs., Murray Hill, NJ, USA; AT&T Bell Labs., Murray Hill, NJ, USA","IEEE Transactions on Software Engineering","","1989","15","3","335","344","Concurrent C, a superset of C providing parallel programming facilities, is considered. A uniprocessor version of Concurrent C was first implemented. After experience with this version, the Concurrent C implementation was extended to run on two types of multiple processor systems: a set of computers connected by a local area network (the distributed version) and a shared-memory multiprocessor (the multiprocessor version). Experience with implementing and using these versions of Concurrent C is described. Specifically, the language changes triggered by the multiple processor implementations, some sample programs, a comparison of the execution times on various systems, and the suitability of these multiple processor architectures are discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21761","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21761","","Concurrent computing;Computer networks;Distributed computing;Local area networks;Parallel programming;Ethernet networks;Feedback;Operating systems;Computer architecture;Abortion","C language;local area networks;multiprocessing programs;multiprocessing systems;parallel programming","multiple processor versions;Concurrent C;parallel programming;uniprocessor version;local area network;shared-memory multiprocessor;execution times","","10","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Cell: A Distributed Computing Modularization Concept","A. Silberschatz","Department of Computer Sciences, University of Texas, Austin, TX 78712.","IEEE Transactions on Software Engineering","","1984","SE-10","2","178","185","This paper presents a new language construct for distributed computing. This construct, called cell, allows one to simulate a variety of language constructs, Its salient features provide the programmer with: 1) an effective communication and synchronization scheme, 2) a mechanism to control the order in which various activities within a cell should be executed. We demonstrate the usefulness of our concepts by providing solutions to a variety of programming exercises.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010220","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010220","Communication;distributed systems;programming languages;scheduling;synchronization","Distributed computing;Programming profession;Microprocessors;Communication system control;Functional programming;Computational modeling;Communication effectiveness;Control systems;Processor scheduling;Memory architecture","","","","10","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Specification and analysis of parallel/distributed software and systems by Petri nets with transition enabling functions","Y. E. Papelis; T. L. Casavant","Dept. of Electr. & Comput. Eng., Iowa Univ., Iowa City, IA, USA; Dept. of Electr. & Comput. Eng., Iowa Univ., Iowa City, IA, USA","IEEE Transactions on Software Engineering","","1992","18","3","252","261","An approach for visually specifying parallel/distributed software using Petri nets (PNs) extend with transition enabling functions (TEFs) is investigated. The approach is demonstrated to be useful in the specification of decision-making activities that control distributed computing systems. PNs are employed because of their highly visual nature that can give insight into the nature of the controller of such a system and because of their analytical properties. In order to increase the expressive power of PNs, the extension of TEFs is used. The main focus is the specification and analysis of parallel/distributed software and systems. A key element of this approach is a set of rules derived to automatically transform such an extended net into a basic PN. Once the rules have been applied to transform the specification, analytical methods can be used to investigate characteristic properties of the system and validate correct operation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.126774","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=126774","","Software systems;Petri nets;Testing;Power system modeling;Control systems;Parallel processing;Decision making;Distributed control;Distributed computing;Concurrent computing","formal specification;parallel programming;Petri nets","parallel/distributed software;Petri nets;transition enabling functions;TEFs;specification;decision-making activities;distributed computing systems;analytical properties;expressive power;PNs;TEFs;parallel/distributed software","","20","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Warm standby in hierarchically structured process-control programs","Ing-Ray Chen; F. B. Bastani","Inst. of Inf. Eng., Nat. Cheng Kung Univ., Tainan, Taiwan; NA","IEEE Transactions on Software Engineering","","1994","20","8","658","663","We classify standby redundancy design space in process-control programs into the following three categories: cold standby, warm standby, and hot standby. Design parameters of warm standby are identified and the reliability of a system using warm standby is evaluated and compared with that of hot standby. Our analysis indicates that the warm standby scheme is particularly suitable for long-lived unmaintainable systems, especially those operating in harsh environments where burst hardware failures are possible. The feasibility of warm standby is demonstrated with a simulated chemical batch reactor system.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.310674","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=310674","","Process control;Control systems;Real time systems;Process design;Hardware;Fault tolerance;Costs;Circuit faults;Delay effects;Redundancy","process computer control;fault tolerant computing;software reliability;software maintenance;computer integrated manufacturing;redundancy","hierarchically structured process-control programs;standby redundancy design space;process-control programs;cold standby;warm standby;hot standby;system reliability;long-lived unmaintainable systems;burst hardware failures;simulated chemical batch reactor system","","3","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Program Testing Complexity and Test Criteria","Kuo-Chung Tai","Department of Computer Science, North Carolina State University","IEEE Transactions on Software Engineering","","1980","SE-6","6","531","538","This paper explores the testing complexity of several classes of programs, where the testing complexity is measured in terms of the number of test data required for demonstrating program correctness by testing. It is shown that even for very restrictive classes of programs, none of the commonly used test criteria, namely, having every statement, branch, and path executed at least once, is nearly sufficient to guarantee absence of errors.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234501","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702779","Program testing;testing complexity;test criteria;test data generation","Software testing;Reliability theory;Automatic testing;Costs;Computer science;Information resources;Data structures;Formal languages;Linear code","","Program testing;testing complexity;test criteria;test data generation","","2","","35","","","","","","IEEE","IEEE Journals & Magazines"
"Software ReliabilityStatus and Perspectives","C. V. Ramamoorthy; F. B. Bastani","Department of Electrical Engineering and Computer Science and the Electronics Research Laboratory, University of California; NA","IEEE Transactions on Software Engineering","","1982","SE-8","4","354","371","It is essential to assess the reliability of digital computer systems used for critical real-time control applications (e.g., nuclear power plant safety control systems). This involves the assessment of the design correctness of the combined hardware/software system as well as the reliability of the hardware. In this paper we survey methods of determining the design correctness of systems as applied to computer programs.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235728","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702958","Correctness probability;error-counting models;error seeding;error size;evaluation of test cases;nonerror-counting models;software fault;software reliability models;testing and debugging phase;testing process;validation phase","Software reliability;Power system reliability;Computer errors;Hardware;Power system modeling;Control systems;Application software;Software testing;Debugging;Error correction","","Correctness probability;error-counting models;error seeding;error size;evaluation of test cases;nonerror-counting models;software fault;software reliability models;testing and debugging phase;testing process;validation phase","","181","","117","","","","","","IEEE","IEEE Journals & Magazines"
"A visual language compiler for information retrieval by visual reasoning","S. -. Chang","Dept. of Comput. Sci., Pittsburgh Univ., PA, USA","IEEE Transactions on Software Engineering","","1990","16","10","1136","1149","When a database increases in size, retrieving the data becomes a major problem. An approach based on data visualization and visual reasoning is described. The main idea is to transform the data objects and present sample data objects in a visual space. The user can use a visual language to incrementally formulate the information retrieval request in the visual space. A prototype system is described with the following features: (1) it is built on top of the SIL-ICON visual language compiler and therefore can be customized for different application domains; (2) it supports a fuzzy icon grammar to define reasonable visual sentences; (3) it incorporates a semantic model of the database for fuzzy visual query translation; and (4) it incorporates a VisualNet which stores the knowledge learned by the system in its interaction with the user so that the VisualReasoner can adapt its behavior.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.60294","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=60294","","Information retrieval;Visual databases;Data visualization;Fuzzy systems;Spatial databases;Information systems;Prototypes;User interfaces;Law;Legal factors","data structures;information retrieval;program compilers;visual programming","visual language compiler;information retrieval;visual reasoning;database;data visualization;data objects;visual language;prototype system;SIL-ICON;fuzzy icon grammar;semantic model;fuzzy visual query translation;VisualNet;VisualReasoner","","21","","34","","","","","","IEEE","IEEE Journals & Magazines"
"*MODA Language for Distributed Programming","R. P. Cook","Department of Computer Sciences, University of Wisconsin","IEEE Transactions on Software Engineering","","1980","SE-6","6","563","571","Distributed programming is characterized by high communications costs and the inability to use shared variables and procedures for interprocessor synchronization and communication. *MOD is a high-level language system which attempts to address these problems by creating an environment conducive to efficient and reliable network software construction. Several of the *MOD distributed programming constructs are discussed as well as an interprocessor communication methodology. Examples illustrating these concepts are drawn from the areas of network communication and distributed process synchronization.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234505","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702783","Computer networks;distributed programming;Modula;processor module;programming languages","High level languages;Costs;Telecommunication network reliability;Communication system software;Computer languages;Contracts;Military computing;Processor scheduling;Programming profession;Delay","","Computer networks;distributed programming;Modula;processor module;programming languages","","43","","37","","","","","","IEEE","IEEE Journals & Magazines"
"A language and system for the construction and tuning of parallel programs","K. Schwan; R. Ramnath; S. Vasudevan; D. Ogle","Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA","IEEE Transactions on Software Engineering","","1988","14","4","455","471","The programming of efficient parallel software typically requires extensive experimentation with program prototypes. To facilitate such experimentation, any programming system that supports rapid prototyping of parallel programs should provide high-level language primitives with which programs can be explicitly, statically, or dynamically tuned with respect to performance and reliability. Such language primitives should be able to refer conveniently to the information about the executing program and the parallel hardware required for tuning. Such information may include monitoring data about the current or previous program or even hints regarding appropriate tuning decisions. Language primitives and an associated programming system for program tuning are presented. The primitives and system have been implemented, and have been tested with several parallel applications on a network of Unix workstations.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4669","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4669","","Parallel programming;Operating systems;Manipulator dynamics;Software prototyping;Prototypes;Hardware;Monitoring;Runtime;Resource management;Dynamic programming","high level languages;parallel programming;program testing;programming environments","parallel programming;programming environments;parallel software;rapid prototyping;high-level language primitives;program tuning","","17","","60","","","","","","IEEE","IEEE Journals & Magazines"
"Load Balancing in Distributed Systems","T. C. K. Chou; J. A. Abraham","Tandem Computers; NA","IEEE Transactions on Software Engineering","","1982","SE-8","4","401","412","In a distributed computing system made up of different types of processors each processor in the system may have different performance and reliability characteristics. In order to take advantage of this diversity of processing power, a modular distributed program should have its modules assigned in such a way that the applicable system performance index, such as execution time or cost, is optimized. This paper describes an algorithm for making an optimal module to processor assignment for a given performance criteria. We first propose a computational model to characterize distributed programs, consisting of tasks and an operational precedence relationship. This model alows us to describe probabilistic branching as well as concurrent execution in a distributed program. The computational model along with a set of seven program descriptors completely specifies a model for dynamic execution of a program on a distributed system. The optimal task to processor assignment is found by an algorithm based on results in Markov decision theory. The algorithm given in this paper is completely general and applicable to N-processor systems.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235574","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702962","Computer networks;distributed processing;optimal scheduling;performance analysis","Load management;Distributed computing;Cost function;System performance;Power system reliability;Computational modeling;Distributed processing;Process control;Processor scheduling;Jacobian matrices","","Computer networks;distributed processing;optimal scheduling;performance analysis","","111","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Linearization of nonlinear recursive rules","D. J. Troy; C. T. Yu; W. Zhang","Dept. of Math. Sci., Purdue Univ., Hammond, IN, USA; NA; NA","IEEE Transactions on Software Engineering","","1989","15","9","1109","1119","The problem of converting a simple nonlinear recursive logic query into an equivalent linear one is considered. A general method is given to transform a nonlinear rule into a sequence of linear ones. For efficient processing it is necessary to convert a nonlinear rule into a single linear rule. For such a conversion, a necessary and sufficient condition is provided for a type of doubly recursive rule to be equivalent to the resulting linear rule. It is also shown that a restricted type of higher order recursive rule is equivalent to the linear rule obtained by its conversion.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.31368","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=31368","","Logic;Deductive databases;Sufficient conditions;Polynomials;Mathematics;Terminology","recursive functions","linearization;nonlinear recursive rules;nonlinear recursive logic query;necessary and sufficient condition;type;doubly recursive rule;equivalent","","13","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Time-by-example query language for historical databases","A. U. Tansel; M. E. Arkun; G. Ozsoyoglu","Dept. of Stat. & Comput. Inf. Syst., City Univ. of New York, NY, USA; NA; NA","IEEE Transactions on Software Engineering","","1989","15","4","464","478","The authors propose a graphical query language, Time-by-Example (TBE), which has suitable constructs for interacting with historical relational databases in a natural way. TBE is user-friendly. It follows the graphical, two-dimensional approach of such previous languages as Query-by-Example (QBE), Aggregation-by-Example (ABE), and Summary-Table-by-Example (STBE). TBE also uses the hierarchical window (subquery) concept of ABE and STBE. TBE manipulates triple-valued (set-triple-valued) attributes and historical relations. Set-theoretic expressions are followed to deal with time intervals. The BNF specification for TBE is given.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.16597","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=16597","","Database languages;Relational databases;Data models;History;Algebra;Upper bound;Query processing;Statistics;Maintenance engineering;Marine vehicles","query languages;relational databases","triple-valued attributes;graphical query language;Time-by-Example;historical relational databases;Summary-Table-by-Example;historical relations","","32","","41","","","","","","IEEE","IEEE Journals & Magazines"
"On the relationships among the all-uses, all-DU-paths, and all-edges testing criteria","A. S. Parrish; S. H. Zweben","Dept. of Comput. Sci., Alabama Univ., Tuscaloosa, AL, USA; NA","IEEE Transactions on Software Engineering","","1995","21","12","1006","1009","The all-du-paths data flow testing criterion was designed to be more demanding than the all-uses criterion, which itself was designed to be more demanding than the all-edges criterion. However, formal comparison metrics developed within the testing community have failed to validate these relationships, without requiring restrictive or undecidable assumptions regarding the universe of programs to which the criteria apply. We show that the formal relationships among these criteria can be made consistent with their intended relative strengths, without making restrictive or undecidable assumptions.","0098-5589;1939-3520;2326-3881","","10.1109/32.489075","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=489075","","Testing;Computer science;Information science;Logic","data flow analysis;data flow analysis;data flow analysis;program diagnostics;program diagnostics;program diagnostics;program testing;program testing;program testing;software metrics;software metrics;software metrics","all-DU-paths testing criteria;all-edges testing criteria;all-uses testing criteria;all-du-paths data flow testing criterion;formal comparison metrics","","6","","11","","","","","","IEEE","IEEE Journals & Magazines"
"A model of visibility control","A. L. Wolf; L. A. Clarke; J. C. Wileden","Dept. of Comput. & Inf. Sci., Massachusetts Univ., Amherst, MA, USA; Dept. of Comput. & Inf. Sci., Massachusetts Univ., Amherst, MA, USA; Dept. of Comput. & Inf. Sci., Massachusetts Univ., Amherst, MA, USA","IEEE Transactions on Software Engineering","","1988","14","4","512","520","A formal model for describing and evaluating visibility control mechanisms is introduced. The model reflects a general view of visibility in which the concepts of requisition of access and provision of access are distinguished. This model provides a means for characterizing and reasoning about the various properties of visibility control mechanisms. Specifically, the notion of preciseness is defined. The utility of the model is illustrated by using it to evaluate and compare the relative strengths and weaknesses, with respect to preciseness, of the visibility control mechanisms found in Algol 60, Ada, Gypsy, and an approach called PIC, which specifically addresses the concerns of visibility control in large software systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4673","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4673","","Software systems;Control systems;Mechanical factors;Application software;Computer science;Programming;Laboratories;Information science;Trademarks;Computer languages","Ada;ALGOL;directed graphs;high level languages;programming theory","directed graphs;programming theory;visibility control;requisition of access;provision of access;Algol 60;Ada;Gypsy;PIC","","7","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Optimal selection of secondary indexes","E. Barcucci; R. Pinzani","Dipartimento di Sistemi e Inf., Firenze Univ., Italy; Dipartimento di Sistemi e Inf., Firenze Univ., Italy","IEEE Transactions on Software Engineering","","1990","16","1","32","38","When planning a database, the problem of index selection is of particular interest. The authors examine a transaction model that includes queries, updates, insertions, and deletions, and they define a function that calculates the transaction's total cost when an index set is used. Their aim is to minimize the function cost in order to identify the optimal set. The algorithms proposed in other studies require an exponential time in the number of attributes in order to solve the problem. The authors propose a heuristic algorithm based on some properties of the cost function that produces an almost optimal set in polynomial time. In many cases, the cost function properties make it possible to prove that the solution obtained is the optimal one.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44361","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44361","","Cost function;Indexes;Transaction databases;Heuristic algorithms;Optimization;Relational databases;Algorithm design and analysis;Testing;Read-write memory","database management systems;heuristic programming;indexing;transaction processing","optimal selection;secondary indexes;database;transaction model;queries;updates;insertions;deletions;heuristic algorithm;polynomial time;cost function properties","","12","","15","","","","","","IEEE","IEEE Journals & Magazines"
"A formal method for composing a network command language","B. Meandzija","Department of Computer Science, School of Engineering and Applied Science, Southern Methodist University, Dallas, TX 75275","IEEE Transactions on Software Engineering","","1986","SE-12","8","860","865","A formal method is introduced for the development and definition of command languages for heterogeneous computer networks. The network command languages are developed from the command languages of the systems constituting the network. This is done by defining a common presentation model for the system command languages and constructing the network command language by applying a composition principle to the commonly represented languages. The common presentation model is defined as a Vienna Development Method (Meta IV) abstract processor for command languages. System command languages are represented by means of predicate functions which are defined on the abstract domains of the abstract processor. This allows a straightforward formulation of the composition principle as a function for the logical combination of predicate functions. Two sample network command languages are composed out of two hypothetical command languages. The results are related to the International Organization for Standardization Open Systems Interconnection model (ISO OSI).","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312988","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312988","Computer networks;design methodology;development system;formal semantics;network command languages","Command languages;Abstracts;Open systems;Semantics;ISO;Computers;Computer networks","computer communications software;computer networks;programming languages","network command language;heterogeneous computer networks;common presentation model;Vienna Development Method;Meta IV;abstract processor;predicate functions;ISO OSI","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Performance Abstract Data Types as a Tool in Software Performance Analysis and Design","T. L. Booth; C. A. Wiecek","Department of Electrical Engineering and Computer Science, University of Connecticut; NA","IEEE Transactions on Software Engineering","","1980","SE-6","2","138","151","The concept of abstract data types is extended to associate performance information with each abstract data type representation. The resulting performance abstract data type contains a functional part which describes the functional properties of the data type and a performance part which describes the performance characteristics of the data type. The performance part depends upon 1) the algorithms and data representation selected to represent the data type, 2) the particular machine on which the software realization of the data type is realized, and 3) the statistical properties of the actual data represented by the data objects involved in the data type. Methods for determining the necessary information to specify the performance part of the representation are discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230465","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702711","Abstract data types;computation structures;performance analysis;software design","Software performance;Performance analysis;Software design;Process design;Design engineering;Information analysis;Software algorithms;Large-scale systems;Computer architecture;Job design","","Abstract data types;computation structures;performance analysis;software design","","24","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Spawn: a distributed computational economy","C. A. Waldspurger; T. Hogg; B. A. Huberman; J. O. Kephart; W. S. Stornetta","Xerox Palo Alto Res. Center, CA, USA; Xerox Palo Alto Res. Center, CA, USA; Xerox Palo Alto Res. Center, CA, USA; Xerox Palo Alto Res. Center, CA, USA; Xerox Palo Alto Res. Center, CA, USA","IEEE Transactions on Software Engineering","","1992","18","2","103","117","The authors have designed and implemented an open, market-based computational system called Spawn. The Spawn system utilizes idle computational resources in a distributed network of heterogeneous computer workstations. It supports both coarse-grain concurrent applications and the remote execution of many independent tasks. Using concurrent Monte Carlo simulations as prototypical applications, the authors explore issues of fairness in resource distribution, currency as a form of priority, price equilibria, the dynamics of transients, and scaling to large systems. In addition to serving the practical goal of harnessing idle processor time in a computer network, Spawn has proven to be a valuable experimental workbench for studying computational markets and their dynamics.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.121753","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=121753","","Distributed computing;Computer networks;Humans;Resource management;Application software;Computer science;Biology computing;Workstations;Virtual prototyping;Microeconomics","computer networks;Monte Carlo methods;parallel programming","distributed computational economy;market-based computational system;Spawn system;idle computational resources;distributed network;heterogeneous computer workstations;coarse-grain concurrent applications;remote execution;concurrent Monte Carlo simulations;fairness;resource distribution;price equilibria;idle processor time;experimental workbench;computational markets","","282","","38","","","","","","IEEE","IEEE Journals & Magazines"
"A three-view model for performance engineering of concurrent software","C. M. Woodside","Dept. of Syst. & Comput. Eng., Carleton Univ., Ottawa, Ont., Canada","IEEE Transactions on Software Engineering","","1995","21","9","754","767","This paper describes a multiview characterization of concurrent software and systems suitable for displaying and analyzing performance information. The views draw from well-known descriptions, and are compatible with established techniques and tools such as execution graphs, Petri Nets, State-Charts, structured design or object-oriented design, and various models for performance. The views are connected by means of a ""Core model"" and are used together to extract information relating to system integration, such as interprocess overheads, and the delay behavior of separate software components in complex systems. The integration of the views in the Core assists by converting results in one view (such as scheduling delay for resources) to parameters in another (such as delays along a path). The ultimate goal of the views is to support designers in making tradeoffs which involve performance, and to provide early assessment of the performance potential of software designs.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.464545","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=464545","","Software performance;Object oriented modeling;Delay;Software design;Hardware;Process planning;Software systems;Information analysis;Performance analysis;Petri nets","software performance evaluation;parallel programming;systems analysis;graph theory","three-view model;performance engineering;concurrent software;multiview characterization;performance information;execution graphs;Petri Nets;State-Charts;structured design;object-oriented design;Core model;system integration;interprocess overheads;scheduling delay;software designs","","28","","37","","","","","","IEEE","IEEE Journals & Magazines"
"A Practical Method for Reducing Weak Precedence Parsers","J. Aoe; Y. Yamamoto; R. Shimada","Department of Information Science and Systems Engineering, Faculty of Engineering, University of Tokushima; NA; NA","IEEE Transactions on Software Engineering","","1983","SE-9","1","25","30","This paper presents a practical method for constructing a more compact matrix structure of the precedence information used in a new weak precedence parsing. The parsing algorithm differs from the conventional weak precedence algorithm in that the precedence relation .&gt; signals a sequence of reduce actions, not just one. The method can be used for any weak precedence grammars without degrading the good error detection capability of the traditional weak precedence parsers. It is shown by the empirical results that the obtained matrices are the very reasonable size and that the presented parsing algorithm is very efficient.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236167","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703009","Parser optimization;parsing algorithm;programming languages;space saving;time efficiency;weak precedence parser","Computer languages;Production;Degradation;Information science;Systems engineering and theory;Error correction","","Parser optimization;parsing algorithm;programming languages;space saving;time efficiency;weak precedence parser","","5","","17","","","","","","IEEE","IEEE Journals & Magazines"
"OmegaA Data Flow Analysis Tool for the C Programming Language","C. Wilson; L. J. Osterweil","AT&T Information Systems; NA","IEEE Transactions on Software Engineering","","1985","SE-11","9","832","838","This paper describes Omega, a prototype system designed to analyze data flow in C programs. Omega is capable of detecting certain types of common programming errors, or assuring their absence. Omega also addresses the problems of analyzing pointer variables.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232542","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702102","Anomaly;data flow;error detection;flowgraph;static analysis","Data analysis;Computer languages;Documentation;Testing;Debugging;Computer errors;Event detection;Prototypes;Error analysis;Information systems","","Anomaly;data flow;error detection;flowgraph;static analysis","","6","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Program Restructuring in a Multilevel Virtual Memory","E. J. Lau; D. Ferrari","Trilogy Systems Corporation; NA","IEEE Transactions on Software Engineering","","1983","SE-9","1","69","79","Program restructuring techniques have proven successful in two-level automatically managed memory hierarchies. The possibility of extending them to multilevel environments is investigated. The performance of strategy-oriented restructuring algorithms in a three-level linear hierarchy managed by sampled working set policies or by a combination of sampled working set and local LRU policies is studied both analytically (assuming an independent reference model of program behavior) and by trace-driven simulation. The results of the study show that strategy-oriented restructuring may be as beneficial in a virtual memory with three levels as it is in one with two levels.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236296","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703013","Independent reference model;LRU policy;multilevel memory hierarchy;page replacement;program restructuring;restructuring algorithms;virtual memory;working set policy","Memory management;Algorithm design and analysis;Operating systems;Performance analysis;Analytical models;Programming profession;Hardware;Degradation;System performance;Control systems","","Independent reference model;LRU policy;multilevel memory hierarchy;page replacement;program restructuring;restructuring algorithms;virtual memory;working set policy","","1","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Hierarchical modeling of availability in distributed systems","S. Hariri; H. Mutlu","Dept. of Electr. & Comput. Eng., Syracuse Univ., NY, USA; NA","IEEE Transactions on Software Engineering","","1995","21","1","50","56","Distributed computing systems are attractive due to the potential improvement in availability, fault-tolerance, performance, and resource sharing. Modeling and evaluation of such computing systems is an important step in the design process of distributed systems. We present a two-level hierarchical model to analyze the availability of distributed systems. At the higher level (user level), the availability of the tasks (processes) is analyzed using a graph-based approach. At the lower level (component level), detailed Markov models are developed to analyze the component availabilities. These models take into account the hardware/software failures, congestion and collisions in communication links, allocation of resources, and the redundancy level. A systematic approach is developed to apply the two-level hierarchical model to evaluate the availability of the processes and the services provided by a distributed computing environment. This approach is then applied to analyze some of the distributed processes of a real distributed system, Unified Workstation Environment (UWE), that is currently being implemented at AT&T Bell Laboratories.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.341847","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=341847","","Availability;Distributed computing;Resource management;Fault tolerant systems;Time sharing computer systems;Throughput;Reliability engineering;Design engineering;Steady-state;Fault trees","distributed processing;redundancy;fault tolerant computing;reliability;Markov processes;computer network reliability","hierarchical modeling;distributed system availability;availability;fault-tolerance;resource sharing;two-level hierarchical model;graph-based approach;Markov models;congestion;communication links;redundancy level;distributed computing environment;Unified Workstation Environment","","19","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Software reliability modeling and analysis","F. -. Scholz","Boeing Computer Services, 565 Andover Park West, Tukwila, WA 98188","IEEE Transactions on Software Engineering","","1986","SE-12","1","25","31","A discrete and, as approximation to it, a continuous model for the software reliability growth process are examined. The discrete model is based on independent multinomial trials and concerns itself with the joint distribution of the first occurrence time of its underlying events (bugs). The continuous model is based on the order statistics of <i>N</i> independent nonidentically distributed exponential random variables. It is shown that the spacings between bugs are not necessarily independent, or exponentially (geometrically) distributed. However, there is a statistical rationale for viewing them so conditionally. Some identifiability problems are pointed out and resolved. In particular, it appears that the number of bugs in a program is not identifiable.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312916","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312916","Conditional inference;confidence bounds;exponential order statistics (non-i.i.d.);identifiability;multinomial trials;order restricted maximum likelihood estimates;spacings","Computer bugs;Random variables;Debugging;Software reliability;Software;Zinc","reliability theory;software reliability","software reliability growth;discrete model;multinomial trials;nonidentically distributed exponential random variables;bugs","","4","","","","","","","","IEEE","IEEE Journals & Magazines"
"Verifying a logic-synthesis algorithm and implementation: a case study in software verification","M. Aagaard; M. Leeser","Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada; NA","IEEE Transactions on Software Engineering","","1995","21","10","822","833","We describe the verification of a logic synthesis tool with the Nuprl proof development system. The logic synthesis tool, Pbs, implements the weak division algorithm. Pbs consists of approximately 1000 lines of code implemented in a functional subset of Standard ML. It is a proven and usable implementation and is an integral part of the Bedroc high level synthesis system. The program was verified by embedding the subset of Standard ML in Nuprl and then verifying the correctness of the implementation of Pbs in the Nuprl logic. The proof required approximately 500 theorems. In the process of verifying Pbs we developed a consistent approach for using a proof development system to reason about functional programs. The approach hides implementation details and uses higher order theorems to structure proofs and aid in abstract reasoning. Our approach is quite general, should be applicable to any higher order proof system, and can aid in the future verification of large software implementations.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.469458","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=469458","","Software algorithms;Computer aided software engineering;Logic;Hardware;Equations;Circuit synthesis;Software tools;Code standards;High level synthesis;Software libraries","high level synthesis;logic design;program verification;theorem proving;formal logic;functional programming","logic synthesis algorithm verification;logic-synthesis algorithm;software verification;logic synthesis tool;Nuprl proof development system;Pbs;weak division algorithm;functional subset;Standard ML;Bedroc high level synthesis system;correctness verification;Nuprl logic;functional programs;higher order theorems;abstract reasoning;higher order proof system;large software implementations","","3","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Optimal scheduling of cooperative tasks in a distributed system using an enumerative method","D. -. Peng; K. G. Shin","Dept. of Electr. Eng. & Comput. Sci., Michigan Univ., Ann Arbor, MI, USA; Dept. of Electr. Eng. & Comput. Sci., Michigan Univ., Ann Arbor, MI, USA","IEEE Transactions on Software Engineering","","1993","19","3","253","267","Preemptive (resume) scheduling of cooperative tasks that have been preassigned to a set of processing nodes in a distributed system, when each task is assumed to consist of several modules is discussed. During the course of their execution, the tasks communicate with each other to collectively accomplish a common goal. Such intertask communications lead to precedence constraints between the modules of different tasks. The objective of this scheduling is to minimize the maximum normalized task response time, called the system hazard. Real-time tasks and the precedence constraints among them are expressed in a PERT/CPM form with activity on arc (AOA), called the task graph (TG), in which the dominance relationship between simultaneously schedulable modules is derived and used to reduce the size of the set of active schedules to be searched for an optimal schedule. Lower-bound costs are estimated, and are used to bound the search. An example of the task scheduling problem and some computational experiences are presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.221134","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=221134","","Optimal scheduling;Hazards;Processor scheduling;Real time systems;Resumes;Costs;Delay effects;Microelectronics;Aerospace engineering","distributed processing;PERT;real-time systems;scheduling","cooperative tasks;enumerative method;processing nodes;distributed system;common goal;intertask communications;precedence constraints;normalized task response time;system hazard;PERT/CPM form;activity on arc;AOA;task graph;dominance relationship;simultaneously schedulable modules;active schedules;optimal schedule;task scheduling problem;computational experiences","","21","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Developing interpretable models with optimized set reduction for identifying high-risk software components","L. C. Briand; V. R. Brasili; C. J. Hetmanski","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA","IEEE Transactions on Software Engineering","","1993","19","11","1028","1044","Applying equal testing and verification effort to all parts of a software system is not very efficient, especially when resources are tight. Therefore, one needs to low/high fault frequency components so that testing/verification effort can be concentrated where needed. Such a strategy is expected to detect more faults and thus improve the resulting reliability of the overall system. The authors present the optimized set reduction approach for constructing such models, which is intended to fulfill specific software engineering needs. The approach to classification is to measure the software system and build multivariate stochastic models for predicting high-risk system components. Experimental results obtained by classifying Ada components into two classes (is, or is not likely to generate faults during system and acceptance rest) are presented. The accuracy of the model and the insights it provides into the error-making process are evaluated.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.256851","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=256851","","Software engineering;System testing;Software systems;Predictive models;Data analysis;Logistics;Classification tree analysis;Machine learning;Software testing;Frequency","program testing;program verification;software reliability","high-risk software components;testing effort;verification effort;optimized set reduction approach;multivariate stochastic model;classifying Ada components;error-making process","","89","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Proving Liveness and Termination of Systolic Arrays Using Communicating Finite State Machines","M. G. Gouda; Hui-Seng Lee","Department of Computer Sciences, University of Texas; NA","IEEE Transactions on Software Engineering","","1985","SE-11","10","1240","1251","We model a systolic array as a network of, mostly identical, communicating finite state machines that exchange messages over one-to-one, unbounded, FIFO channels. Each machine has a cyclic behavior; in each cycle, a machine first receives one message from each of its input channels, then sends one message to each of its output channels. If in a cycle a machine does not have any data message to send to one of its output channels, it sends a null message instead; thus, machines exchange two types of messages, data and null. We characterize the liveness and termination properties for such networks, and discuss two algorithms that can be used to decide these properties for any given network. We apply these algorithms to establish the liveness and termination properties of four systolic array examples. These examples include a linear matrix-vector multiplier, a linear priority queue, and a search tree.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231871","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701939","Communicating finite state machines;communication progress;liveness;systolic array;termination;verification;VLSI","Systolic arrays;Automata;History;Protocols;Very large scale integration;Computer networks;Safety;Joining processes;Wires;Costs","","Communicating finite state machines;communication progress;liveness;systolic array;termination;verification;VLSI","","","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Atomic actions for fault-tolerance using CSP","P. Jalote; R. H. Campbell","Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL 61801; Department of Computer Science, University of Maryland, College Park, MD 20742; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana. IL 61801","IEEE Transactions on Software Engineering","","1986","SE-12","1","59","68","Two complementary techniques have evolved for providing fault-tolerance in software: forward error recovery and backward error recovery. Few implementations permit both approaches to be combined within a particular application. Fewer techniques are available for the construction of fault-tolerant software for systems involving concurrent processes and multiple processors. Many schemes for supporting forward or backward recovery are based on some concept of an atomic action. The authors propose a mechanism for supporting an atomic action in a system of communicating sequential processes (CSP). The atomic action is used as the basic unit for providing fault-tolerance. The atomic action is called an FT-action, and both forward and backward error recovery are performed in the context of an FT-action.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312920","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312920","Atomic actions;backward recovery;communicating sequential processes;forward recovery;software fault-tolerance","Fault tolerance;Fault tolerant systems;Software;Computer languages;Process control;Synchronization","fault tolerant computing;software reliability","software reliability;fault-tolerance;CSP;forward error recovery;backward error recovery;concurrent processes;multiple processors;atomic action;communicating sequential processes","","11","","","","","","","","IEEE","IEEE Journals & Magazines"
"A distributed algorithm for performance improvement through file replication, file migration, and process migration","A. Hac","AT&T Bell Lab., Naperville, IL, USA","IEEE Transactions on Software Engineering","","1989","15","11","1459","1470","The author presents a distributed algorithm that considers the number of read and write accesses to files for every process type, the number of processes and their demands on system resources, the utilization of bottlenecks on all machines, and file sizes. Performance improvement obtained with the algorithm is discussed and proved. A number of experiments executed in a distributed system in order to predict the impact on performance of various algorithm strategies are examined. The experiments show changes in system performance due to file and process placement, file replication, and file and process migration.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.41337","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=41337","","Distributed algorithms;System performance;Resource management;Cost function;Load management;File systems;Databases;Availability;Reliability;Routing","distributed processing;programming theory;system recovery","distributed algorithm;performance improvement;file replication;file migration;process migration;read and write accesses;system resources;bottlenecks;file sizes;distributed system","","30","","11","","","","","","IEEE","IEEE Journals & Magazines"
"On rigorous transaction scheduling","Y. Breitbart; D. Georgakopoulos; M. Rusinkiewicz; A. Silberschatz","Dept. of Comput. Sci., Kentucky Univ., Lexington, KY, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1991","17","9","954","960","The class of transaction scheduling mechanisms in which the transaction serialization order can be determined by controlling their commitment order, is defined. This class of transaction management mechanisms is important, because it simplifies transaction management in a multidatabase system environment. The notion of analogous execution and serialization orders of transactions is defined and the concept of strongly recoverable and rigorous execution schedules is introduced. It is then proven that rigorous schedulers always produce analogous execution and serialization orders. It is shown that the systems using the rigorous scheduling can be naturally incorporated in hierarchical transaction management mechanisms. It is proven that several previously proposed multidatabase transaction management mechanisms guarantee global serializability only if all participating databases systems produce rigorous schedules.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.92915","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=92915","","Scheduling;Database systems;Control systems;Transaction databases;Environmental management;Concurrency control;Helium;Delay;Image databases","concurrency control;database theory;distributed databases;scheduling;transaction processing","rigorous transaction scheduling;transaction scheduling mechanisms;transaction serialization order;commitment order;multidatabase system environment;analogous execution;serialization orders;rigorous schedulers;hierarchical transaction management mechanisms;global serializability","","65","","16","","","","","","IEEE","IEEE Journals & Magazines"
"The Annotated Assistant: A Step Towards Human Engineering","A. Singer; H. Ledgard; J. F. Hueras","E &amp; L Instruments; NA; NA","IEEE Transactions on Software Engineering","","1981","SE-7","4","353","373","The Hatter's watch nicely illustrates the effect of idiosynracy in system design. Really, a watch could provide any number of features, but most watches designed for people put a high priority on telling the correct time of day. Thus, the Hatter's watch is an excellent example of bad human engineering. By human engineering we mean ""the selection among design alternatives so as to relate to people."" Carroll's stopped watch is the ultimate in poor human engineering because the user must do all the work.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234536","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702854","","Ergonomics;Watches;Clocks;Military computing;Human factors;Nose;Permission;Design engineering;Instruments;Pressing","","","","1","","30","","","","","","IEEE","IEEE Journals & Magazines"
"On the Use of an Extended Relational Model to Handle Changing Incomplete Information","A. M. Keller; M. W. Wilkins","Department of Computer Science, Stanford University; NA","IEEE Transactions on Software Engineering","","1985","SE-11","7","620","633","In this paper we consider approaches to updating databases containing null values and incomplete information. Our approach distinguishes between modeling incompletely known worlds and modeling changes in these worlds. As an alternative to the open and closed world assumptions, we propose the expanded closed world assumption. Under this assumption, we discuss how to perform updates on databases containing set nulls, marked nulls, and simple conditional tuples, and address some issues of refining incompletely specified information.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232506","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702066","Databases;incomplete information;null values;relational databases;updates","Relational databases;Economic forecasting;Contracts;Indexes;Algorithm design and analysis;Scholarships;Computer science;Privacy;Data security","","Databases;incomplete information;null values;relational databases;updates","","7","","40","","","","","","IEEE","IEEE Journals & Magazines"
"Timestamp-based orphan elimination","M. P. Herlihy; M. S. McKendry","Dept. of Comput. Sci., Carnegie-Mellon Univ., Pittsburgh, PA, USA; NA","IEEE Transactions on Software Engineering","","1989","15","7","825","831","An orphan in a distributed transaction system is an activity executing on behalf of an aborted transaction. A method is proposed for managing orphans created by crashes and by aborts that ensures that orphans are detected and eliminated in a timely manner, and also prevents them from observing inconsistent states. The method uses timestamps generated at each site. Transactions are assigned timeouts at different sites. These timeouts are related by a global invariant, and they may be adjusted by simple two-phase protocols. The principal advantage of this method is simplicity: it is easy to understand, and to implement, and it can be proved correct. An 'eager' version of this method uses approximately synchronized real-time clocks to ensure that orphans are eliminated within a fixed duration, and a 'lazy' version uses logical clocks to ensure that orphans are eventually eliminated as information propagates through the system. The method is fail-safe: unsynchronized clocks and lost messages may affect performance, but they cannot produce inconsistencies or protect orphans from eventual elimination. Although the method is informally described in terms of two-phase locking, the formal argument shows it is applicable to any concurrency control method that preserved atomicity.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.29482","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=29482","","Computer crashes;Clocks;Synchronization;Real time systems;Protection;Computer networks;Distributed computing;Concurrent computing;Banking;Books","concurrency control;database management systems;distributed processing;transaction processing","timestamp based orphan elimination;distributed transaction system;aborted transaction;two-phase protocols;real-time clocks;concurrency control method","","5","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Virtual Memory Behavior of Some Sorting Algorithms","T. O. Alanko; H. H. A. Erkio; I. J. Haikala","Department of Computer Science, University of Helsinki, SF-00250 Helsinki 25, Finland.; Department of Computer Science, University of Helsinki, SF-00250 Helsinki 25, Finland.; Department of Computer Science, University of Helsinki, SF-00250 Helsinki 25, Finland.","IEEE Transactions on Software Engineering","","1984","SE-10","4","422","431","Experimnental results are given about the performance of six sorting algorithms in a virtual memory based on the working set principle. With one exception, the algorithms are general internal sorting algorithms and not especially tuned for virtual memory. Algorithms are compared in terms of their time requirements, space requirements, and space-time integrals. The relative performances of the algorithms vary from one measure to the other. Especially in terms of a space-time integral, quicksort turns out to be the best algorithm, also in a working set virtual memory environment.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010255","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010255","Locality;performance;sorting algorithms;virtual memory;working set","Sorting;Algorithm design and analysis;Computational modeling;Costs;Computer science;Merging;Instruments;Performance analysis;Analytical models;Computer simulation","","","","9","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Dynamic storage fragmentation and file deterioration","C. H. C. Leung","Department of Computer Science, University College, London University, London WC1E 6BT, England","IEEE Transactions on Software Engineering","","1986","SE-12","3","436","441","As a result of insertions and deletions, a file tends to be cluttered with deleted records which are physically present. These unwanted records cause fragmentation within the file and give rise to additional access overhead because they have to be skipped over during processing. A connection between the dynamic fragmentation characteristics and the pattern of record insertions and deletions over time is presented, and performance degradation is studied in terms of the number of record accesses per reference. Deterioration characteristics are obtained for nonhomogeneous Poisson insertion and general deletion processes. For constant insertion rate, it is found that the deterioration over time is asymptotically linear, with the rate of decline governed by the record deletion rate. An expression for the optimum compaction interval is also given for files subject to a constant insertion rate and an exponentially distributed record lifetime.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312884","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312884","File compaction;fragmentation;performance deterioration;reorganization;volatile files","Compaction;Writing;Degradation;Linear approximation;File systems;Steady-state","storage management","software engineering;storage fragmentation;file deterioration;insertions;deletions;access overhead;dynamic fragmentation;record insertions;performance degradation;nonhomogeneous Poisson insertion;optimum compaction interval;exponentially distributed record lifetime","","1","","","","","","","","IEEE","IEEE Journals & Magazines"
"LISPACK-a methodology and tool for the performance analysis of parallel systems and algorithms","G. Iazeolla; F. Marinuzzi","Dept. of Elecron. Eng., Rome Univ., Italy; NA","IEEE Transactions on Software Engineering","","1993","19","5","486","502","The performance analysis of parallel algorithms and systems is considered. For these, numerical solutions methods quickly show their limits because of the enormous state-space growth. The proposed methodology and software tool, list-manipulation parallel-modeling package (LISPACK) uses string manipulation, lumping, and recursive elimination to define the large Markovian process, its restructuring, and efficient solution. The analysis of a typical parallel system and algorithm model is developed as a case study, to discuss the features of the method. The paper has two contributions. The first is the symbolic-approach methodology proposed for the performance analysis of parallel algorithms and systems. The second is a tool that exploits the capabilities of the symbolic approach in the solution of parallel models, where the numerical techniques reveal their limits.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.232014","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=232014","","Performance analysis;Parallel algorithms;Software tools;Algorithm design and analysis;Software packages;Packaging;Gaussian processes;Costs;Numerical models;Supercomputers","Markov processes;parallel algorithms;parallel processing;performance evaluation;software tools","parallel algorithms;LISPACK;performance analysis;parallel systems;software tool;list-manipulation parallel-modeling package;string manipulation;lumping;recursive elimination;large Markovian process;symbolic-approach methodology","","","","39","","","","","","IEEE","IEEE Journals & Magazines"
"A development environment for horizontal microcode","A. Aiken; A. Nicolau","Dept. of Comput. Sci., Cornell Univ., Ithaca, NY, USA; Dept. of Comput. Sci., Cornell Univ., Ithaca, NY, USA","IEEE Transactions on Software Engineering","","1988","14","5","584","594","A development environment for horizontal microcode is described that uses percolation scheduling-a transformational system for parallelism extraction-and an interactive profiling system to give the user control over the microcode compaction process while reducing the burdensome details of architecture, correctness preservation, and synchronization. Through a graphical interface, the user suggests what can be executed in parallel, while the system performs the actual changes using semantics-preserving transformations. If a request cannot be satisfied, the system reports the problem causing the failure. The user can then help eliminate the problem by supplying guidance or information not explicit in the code.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6136","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6136","","Parallel processing;Humans;Compaction;High level languages;Control systems;Graphical user interfaces;Information analysis;Program processors;Computer science;Reduced instruction set computing","microprogramming;parallel programming;programming environments;scheduling;synchronisation;user interfaces","development environment;horizontal microcode;percolation scheduling;parallelism extraction;interactive profiling system;microcode compaction process;architecture;correctness preservation;synchronization;graphical interface;semantics-preserving transformations","","38","","23","","","","","","IEEE","IEEE Journals & Magazines"
"A pessimistic consistency control algorithm for replicated files which achieves high availability","S. Jajodia; D. Mutchler","US Naval Res. Lab., Washington, DC, USA; US Naval Res. Lab., Washington, DC, USA","IEEE Transactions on Software Engineering","","1989","15","1","39","46","A consistency control algorithm is described for managing replicated files in the face of network partitioning due to node or communication link failures. It adopts a pessimistic approach in that mutual consistency among copies of a file is maintained by permitting files to be accessed only in a single partition at any given time. The algorithm simplifies the Davcev-Burkhard dynamic voting algorithm (1985) and also improves its availability by adding the notion of linearly ordered copies. A proof that any pessimistic algorithm with fresh reads is one-copy serializable is given.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21724","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21724","","Availability;Partitioning algorithms;Communication system control;Voting;Heuristic algorithms;Laboratories;Distributed databases;Protocols;Information systems;Computer science","concurrency control;data integrity;distributed databases","pessimistic consistency control algorithm;replicated files;high availability;network partitioning;communication link failures;mutual consistency;dynamic voting algorithm;fresh reads;one-copy serializable","","16","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Region scheduling: an approach for detecting and redistributing parallelism","R. Gupta; M. L. Soffa","Philips Lab., Briarcliff Manor, NY, USA; NA","IEEE Transactions on Software Engineering","","1990","16","4","421","431","Region scheduling, a technique applicable to both fine-grain and coarse-grain parallelism, uses a program representation that divides a program into regions consisting of source and intermediate level statements and permits the expression of both data and control dependencies. Guided by estimates of the parallelism present in regions, the region scheduler redistributes code, thus providing opportunities for parallelism in those regions containing insufficient parallelism compared to the capabilities of the executing architecture. The program representation and the transformations are applicable to both structured and unstructured programs, making region scheduling useful for a wide range of applications. The results of experiments conducted using the technique in the generation of code for a reconfigurable long instruction word architecture are presented. The advantages of region scheduling over trace scheduling are discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.54294","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=54294","","Program processors;Processor scheduling","parallel programming;program compilers;scheduling","region scheduling;code generation;redistributing parallelism;fine-grain;coarse-grain parallelism;program representation;reconfigurable long instruction word architecture;trace scheduling","","50","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Effective analysis for engineering real-time fixed priority schedulers","A. Burns; K. Tindell; A. Wellings","Dept. of Comput. Sci., York Univ., UK; NA; NA","IEEE Transactions on Software Engineering","","1995","21","5","475","480","There has been considerable activity in recent years in developing analytical techniques for hard real-time systems. Inevitably these techniques make simplifying assumptions so as to reduce the complexity of the problem to be solved. Unfortunately this leads to a gap between theory and engineering practice. The paper presents new analysis that enables the costs of the scheduler (clock overheads, queue manipulations and release delays) to be factored into the standard equations for calculating worst-case response times. As well as predicting the true behavior of realistic systems, the analysis also allows free parameters, such as clock interrupt rate, to be determined.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.387477","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=387477","","Distributed computing;Queueing analysis;Real time systems;Delay;Application software;Information science;Clocks;Aerospace engineering;Timing;Traffic control","real-time systems;processor scheduling;scheduling;operating system kernels;system monitoring;systems re-engineering;systems engineering;systems analysis","real-time fixed priority scheduler engineering;effective analysis;hard real-time systems;scheduler costs;clock overheads;queue manipulations;release delays;standard equations;worst-case response times;true behavior;realistic systems;free parameters;clock interrupt rate","","81","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Exception handling in the spreadsheet paradigm","M. Burnett; A. Agrawal; P. van Zee","Dept. of Comput. Sci., Oregon State Univ., Corvallis, OR, USA; NA; NA","IEEE Transactions on Software Engineering","","2000","26","10","923","942","Exception handling is widely regarded as a necessity in programming languages today and almost every programming language currently used for professional software development supports some form of it. However, spreadsheet systems, which may be the most widely used type of ""programming language"" today in terms of number of users using it to create ""programs"" (spreadsheets), have traditionally had only extremely limited support for exception handling. Spreadsheet system users range from end users to professional programmers and this wide range suggests that an approach to exception handling for spreadsheet systems needs to be compatible with the equational reasoning model of spreadsheet formulas, yet feature expressive power comparable to that found in other programming languages. We present an approach to exception handling for spreadsheet system users that is aimed at this goal. Some of the features of the approach are new; others are not new, but their effects on the programming language properties of spreadsheet systems have not been discussed before in the literature. We explore these properties, offer our solutions to problems that arise with these properties, and compare the functionality of the approach with that of exception handling approaches in other languages.","0098-5589;1939-3520;2326-3881","","10.1109/32.879817","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=879817","","Programming profession;Computer languages;Equations;User interfaces;Software engineering;Power system modeling;Robustness;Logic;Control systems;Marketing and sales","exception handling;spreadsheet programs;software engineering","exception handling;programming language;professional software development;spreadsheet systems;end user programming;professional programmers;equational reasoning model","","4","","68","","","","","","IEEE","IEEE Journals & Magazines"
"Stochastic Petri net analysis of a replicated file system","J. Bechta Dugan; G. Ciardo","Dept. of Comput. Sci., Duke Univ., Durham, NC, USA; Dept. of Comput. Sci., Duke Univ., Durham, NC, USA","IEEE Transactions on Software Engineering","","1989","15","4","394","401","The authors present a stochastic Petri net model of a replicated file system in a distributed environment where replicated files reside on different hosts and a voting algorithm is used to maintain consistency. Witnesses, which simply record the status of the file but contain no data, can be used in addition to or in place of files to reduce overhead. A model sufficiently detailed to include file status (current or out-of-date) as well as failure and repair of hosts where copies or witnesses reside, is presented. The number of copies and witnesses is not fixed, but is a parameter of the model. Two different majority protocols are examined.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.16600","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=16600","","Stochastic systems;File systems;Voting;Availability;Protocols;Algorithm design and analysis;Protection;Databases;Testing;Costs","concurrency control;distributed databases;fault tolerant computing;Petri nets","performance reliability tradeoffs;stochastic Petri net model;replicated file system;distributed environment;voting algorithm;file status;witnesses;majority protocols","","50","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Software prototyping by relational techniques: experiences with program construction systems","S. Ceri; S. Crespi-Reghizzi; A. Di Maio; L. A. Lavazza","Dept. of Electron., Polytech. of Milan, Italy; Dept. of Electron., Polytech. of Milan, Italy; NA; NA","IEEE Transactions on Software Engineering","","1988","14","11","1597","1609","A method for designing and prototyping program construction systems using relational databases is presented. Relations are the only data structures used inside the systems and for interfaces; programs extensively use relational languages, in particular relational algebra. Two large projects are described. The Ada Relational Translator (ART) is an experimental compiler-interpreter for Ada in which all subsystems, including the parser, semantic analyzer, interpreter, kernel, and debugger, use relations as their only data structure; the relational approach has been pushed to the utmost to achieve fast prototyping in a student environment. Multi-Micro Line (MML) is a tool set for constructing programs for multimicroprocessors' targets, in which relations are used for allocation and configuration control. Both experiences validate the approach for managing teamwork in evolving projects, identify areas where this approach is appropriate, and raise critical issues.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9048","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9048","","Software prototyping;Prototypes;Data structures;Design methodology;Relational databases;Algebra;Subspace constraints;Kernel;Project management;Teamwork","Ada;data structures;program compilers;program interpreters;programming environments;relational databases","programming environments;program construction systems;prototyping;relational databases;data structures;relational languages;relational algebra;Ada Relational Translator;ART;compiler-interpreter;parser;semantic analyzer;interpreter;kernel;debugger;Multi-Micro Line;MML;configuration control","","2","","39","","","","","","IEEE","IEEE Journals & Magazines"
"Informal and formal requirements specification languages: bridging the gap","M. D. Fraser; K. Kumar; V. K. Vaishnavi","Georgia State Univ., Atlanta, GA, USA; Georgia State Univ., Atlanta, GA, USA; Georgia State Univ., Atlanta, GA, USA","IEEE Transactions on Software Engineering","","1991","17","5","454","466","The differences between informal and formal requirements specification languages are noted, and the issue of bridging the gap between them is discussed. Using structured analysis (SA) and the Vienna development method (VDM) as surrogates for informal and formal languages, respectively, two approaches are presented for integrating the two. The first approach uses the SA model of a system to guide the analyst's understanding of the system and the development of the VDM specifications. The second approach proposes a rule-based method for generating VDM specifications from a set of corresponding SA specifications. The two approaches are illustrated through a simplified payroll system case. The issues that emerge from the use of the two approaches are reported.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.90448","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=90448","","Specification languages;Design engineering;Information systems;Information analysis;Mathematics;Computer science;Encoding;Process design;Software systems;Systems engineering and theory","formal languages;formal specification;payroll data processing;specification languages;systems analysis","informal languages;requirements specification languages;structured analysis;Vienna development method;VDM;formal languages;rule-based method;payroll system","","66","","46","","","","","","IEEE","IEEE Journals & Magazines"
"PICQUERY: a high level query language for pictorial database management","T. Joseph; A. F. Cardenas","Dept. of Comput. Sci., California Univ., Los Angeles, CA, USA; Dept. of Comput. Sci., California Univ., Los Angeles, CA, USA","IEEE Transactions on Software Engineering","","1988","14","5","630","638","A reasonably comprehensive set of data accessing and manipulation operations that should be supported by a generalized pictorial database management system (PDBMS) is proposed. A corresponding high-level query language, PICQUERY, is presented and illustrated through examples. PICQUERY has been designed with a flavor similar to QBE as the highly nonprocedural and conservational language for the pictorial database management system PICDMS. PICQUERY and a relational QBE-like language would form the language by which a user could access conventional relational databases and at the same time pictorial databases managed by PICDMS or other robust PDBMS. This language interface is part of an architecture aimed toward data heterogeneity transparency over pictorial and nonpictorial databases.<<ETX>></ETX>","0098-5589;1939-3520;2326-3881","","10.1109/32.6140","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6140","","Database languages;Relational databases;Database systems;Robustness;Computer science;Operating systems;Information management;Reconnaissance;Medical services;Biomedical equipment","database management systems;query languages;user interfaces","PICQUERY;high level query language;pictorial database management;conservational language;PICDMS;relational QBE-like language;relational databases;language interface;data heterogeneity transparency","","69","","19","","","","","","IEEE","IEEE Journals & Magazines"
"The design and implementation of a secure auction service","M. K. Franklin; M. K. Reiter","AT&T Bell Labs., Murray Hill, NJ, USA; AT&T Bell Labs., Murray Hill, NJ, USA","IEEE Transactions on Software Engineering","","1996","22","5","302","312","We present the design and implementation of a distributed service for performing sealed bid auctions. This service provides an interface by which clients, or ""bidders"", can issue secret bids to the service for an advertised auction. Once the bidding period has ended, the auction service opens the bids, determines the winning bid, and provides the winning bidder with a ticket for claiming the item bid upon. Using novel cryptographic techniques, the service is constructed to provide strong protection for both the auction house and correct bidders, despite the malicious behavior of any number of bidders and fewer than one third of the servers comprising the auction service. Specifically, it is guaranteed that: bids of correct bidders are not revealed until after the bidding period has ended; the auction house collects payment for the winning bid; losing bidders forfeit no money; and only the winning bidder can collect the item bid upon. We also discuss techniques to enable anonymous bidding.","0098-5589;1939-3520;2326-3881","","10.1109/32.502223","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=502223","","Consumer electronics;Protection;Vehicles;Electronic commerce;Humans;Proposals;Cryptography;Cryptographic protocols;Data security;Ink","retail data processing;computer networks;cryptography","secure auction service;distributed service;sealed bid auctions;clients;secret bids;advertised auction;bidding period;cryptographic techniques;auction house;correct bidders;anonymous bidding;distributed systems;Byzantine failures;electronic commerce;verifiable signature sharing","","116","","32","","","","","","IEEE","IEEE Journals & Magazines"
"Software complexity and its impact on software reliability","K. S. Lew; T. S. Dillon; K. E. Forward","L.M. Ericsson Pty. Ltd., Broadmeadows, Vic., Australia; NA; NA","IEEE Transactions on Software Engineering","","1988","14","11","1645","1655","To produce reliable software, its complexity must be controlled by suitably decomposing the software system into smaller subsystems. A software complexity metric is developed that includes both the internal and external complexity of a module. This allows analysis of a software system during its development and provides a guide to system decomposition. The basis of this complexity metric is in the development of an external complexity measure that characterizes module interaction.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9052","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9052","","Software reliability;Software systems;Hardware;Computer errors;Redundancy;Fault tolerance;Software measurement;Control systems;Real time systems;Computer science","software reliability","software reliability;software complexity metric;system decomposition","","37","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Generalized stochastic Petri nets: a definition at the net level and its implications","G. Chiola; M. A. Marsan; G. Balbo; G. Conte","Dipartimento di Inf., Torino Univ., Italy; NA; NA; NA","IEEE Transactions on Software Engineering","","1993","19","2","89","107","The class of Petri nets obtained by eliminating timing from generalized stochastic Petri net (GSPN) models while preserving the qualitative behavior is identified. Structural results for those nets are derived, obtaining the first structural analysis of Petri nets with priority and inhibitor arcs. A revision of the GSPN definition based on the structural properties of the models is presented. It is shown that for a (wide) class of nets, the definition of firing probabilities of conflicting immediate transitions does not require the information on reachable markings. Identification of the class of models for which the net-level specification is possible is also based on the structural analysis results. The procedure for the model specification is illustrated by means of an example. It is also shown that a net-level specification of the model associated with efficient structural analysis techniques can have a substantial impact on model analysis.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.214828","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=214828","","Stochastic processes;Petri nets;Power system modeling;Computational modeling;Concurrent computing;Performance analysis;Switches;Distributed computing;Senior members;Proposals","formal specification;performance evaluation;Petri nets;stochastic processes","generalized stochastic Petri net;qualitative behavior;structural analysis;structural properties;firing probabilities;net-level specification;model specification","","132","","46","","","","","","IEEE","IEEE Journals & Magazines"
"Incorporating System Overhead in Queuing Network Models","P. S. Kritzinger; A. E. Krzesinski; P. Teunissen","Department of Computer Science, University of Stellenbosch; NA; NA","IEEE Transactions on Software Engineering","","1980","SE-6","4","381","390","Multiclass queuing network models of multiprogramming computer systems are frequently used to predict the performance of computing systems as a function of user workload and hardware configuration. This paper examines three different methods for incorporating operating system overhead in multiclass queuing network models. The goal of the resultant model is to provide an accurate account of the processing performance and the system CPU overhead of each of the several different types of jobs (batch, timesharing, transaction processing, etc.) that together make up the multiprogramming workload. The first method introduces an operating sysbtm workload consisting of a fixed number of jobs to represent system CPU overhead processing. The second method extends the jobs' CPU service requests to include explicitly the CPU overhead necessary for system processing. The third method employs a communicating set of user and system job classes so that the CPU overhead can be modeled by switching jobs from user to system class whenever they require system CPU service. The capabilities and accuracy of the three methods are assessed and compared against performance and overhead data measured on a Univac 1110 computer.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234494","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702746","Model validation;performance evaluation;performance modeling;queuing models;queuing networks;system overhead;workload characterization","Intelligent networks;Operating systems;Central Processing Unit;Predictive models;Computer networks;Resource management;Hardware;Computer network reliability;Computer science;Africa","","Model validation;performance evaluation;performance modeling;queuing models;queuing networks;system overhead;workload characterization","","1","","8","","","","","","IEEE","IEEE Journals & Magazines"
"SPARE: a development environment for program analysis algorithms","G. A. Venkatesh; C. N. Fischer","Bellcore Morristown, NJ, USA; NA","IEEE Transactions on Software Engineering","","1992","18","4","304","318","A tool that bridges the gap between the theory and practice of program analysis specifications is described. The tool supports a high-level specification language that enables clear and concise expression of analysis algorithms. The denotational nature of the specifications eases the derivation of formal proofs of correctness for the analysis algorithm. SPARE (structured program analysis refinement environment) is based on a hybrid approach that combines the positive aspects of both the operational and the semantics-driven approach. An extended denotational framework is used to provide specifications in a modular fashion. Several extensions to the traditional denotational specification language have been designed to allow analysis algorithms to be expressed in a clear and concise fashion. This extended framework eases the design of analysis algorithms as well as the derivation of correctness proofs. The tool provides automatic implementation for testing purposes.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.129219","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=129219","","Algorithm design and analysis;Information analysis;Programming environments;Formal verification;Bridges;Specification languages;Automatic testing;Program processors;Data analysis;Programming profession","formal specification;program testing;programming environments;software tools;specification languages","software tools;development environment;program analysis specifications;high-level specification language;SPARE;structured program analysis refinement environment;denotational specification;correctness proofs;testing","","12","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Rapid transaction-undo recovery using twin-page storage management","K. -. Wu; W. K. Fuchs","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; NA","IEEE Transactions on Software Engineering","","1993","19","2","155","164","A twin-page storage method, which is an alternative to the TWIST (twin slot) approach by A. Reuter","0098-5589;1939-3520;2326-3881","","10.1109/32.214832","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=214832","","Transaction databases;Shadow mapping;Performance analysis;Contracts;NASA;Database systems;Computer applications;Application software;Instruments;Laboratories","database management systems;storage management;transaction processing","rapid transaction-undo recovery;twin-page storage management;TWIST;aborted transaction identifiers;disk I/O;CPU overhead","","1","","16","","","","","","IEEE","IEEE Journals & Magazines"
"An algebra for data flow diagram process decomposition","M. Adler","Control Data Corp., Bloomington, MN, USA","IEEE Transactions on Software Engineering","","1988","14","2","169","183","Data flow diagram process decomposition, as applied in the analysis phase of software engineering, is a top-down method that takes a process, and its input and output data flows, and logically implements the process as a network of smaller processes. The decomposition is generally performed in an ad hoc manner by an analyst applying heuristics, expertise, and knowledge to the problem. An algebra that formalizes process decomposition is presented using the De Marco representation scheme. In this algebra, the analyst relates the disjoint input and output sets of a single process by specifying the elements of an input/output connectivity matrix. A directed acyclic graph is constructed from the matrix and is the decomposition of the process. The graph basis, grammar matrix, and graph interpretations, and the operators of the algebra are discussed. A decomposition procedure for applying the algebra, prototype, and production tools and outlook are also discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4636","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4636","","Algebra;Matrix decomposition;Software engineering;Design for disassembly;Software prototyping;Performance analysis;Prototypes;Production;Flow graphs;Data engineering","directed graphs;program verification;programming theory;software engineering","data flow diagram process decomposition;software engineering;top-down method;De Marco representation scheme;input/output connectivity matrix;directed acyclic graph;grammar","","30","","11","","","","","","IEEE","IEEE Journals & Magazines"
"The Design of the Saguaro Distributed Operating System","G. R. Andrews; R. D. Schlichting; R. Hayes; T. D. M. Purdin","Department of Computer Science, University of Arizona; NA; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","1","104","118","This paper describes the design of the Saguaro operating system for computers connected by a local-area network. Systems constructed on such an architecture have the potential advantages of concurrency and robustness. In Saguaro, these advantages are made available to the user through several mechanisms. One is channels, an interprocess communication and synchronization facility that allows the input and output of different commands to be connected to form general graphs of communicating processes. Two additional mechanisms are provided to support semitransparent file replication and access: reproduction sets and metafiles. A reproduction set is a collection of files that the system attempts to keep identical on a ""best effort"" basis. A metafile is a special file that contains symbolic pathnames of other files; when a metafile is opened, the system selects an available constituent file and opens it instead. The advantages of concurrency and robustness are also realized at the system level by the use of pools of server processes and decentralized allocation protocols. Saguaro also makes extensive use of a type system to describe user data such as files and to specify the types of arguments to commands and procedures. This enables the system to assist in type checking and leads to a user interface in which command-specific templates are available to facilitate command invocation.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232839","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702137","Distributed computing;distributed operating system;file systems;type systems;user interfaces","Operating systems;File systems;Concurrent computing;User interfaces;Robustness;Computer networks;Local area networks;Computer architecture;Protocols;Computer interfaces","","Distributed computing;distributed operating system;file systems;type systems;user interfaces","","7","","39","","","","","","IEEE","IEEE Journals & Magazines"
"A Formal Model of Crash Recovery in a Distributed System","D. Skeen; M. Stonebraker","Department of Computer Science, Cornell University; NA","IEEE Transactions on Software Engineering","","1983","SE-9","3","219","228","A formal model for atomic commit protocols for a distributed database system is introduced. The model is used to prove existence results about resilient protocols for site failures that do not partition the network and then for partitioned networks. For site failures, a pessimistic recovery technique, called independent recovery, is introduced and the class of failures for which resilient protocols exist is identified. For partitioned networks, two cases are studied: the pessimistic case in which messages are lost, and the optimistic case in which no messages are lost. In all cases, fundamental limitations on the resiliency of protocols are derived.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236608","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703048","Commit protocols;crash recovery;distributed database systems;distributed systems;fault tolerance;transaction management","Computer crashes;Protocols;Transaction databases;Database systems;Distributed databases;Communication networks;Intelligent networks;Indexes;Fault tolerant systems;Computer science","","Commit protocols;crash recovery;distributed database systems;distributed systems;fault tolerance;transaction management","","109","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Cecil: a sequencing constraint language for automatic static analysis generation","K. M. Olender; L. J. Osterweil","Dept. of Comput. Sci., Colorado Univ., Boulder, CO, USA; Dept. of Comput. Sci., Colorado Univ., Boulder, CO, USA","IEEE Transactions on Software Engineering","","1990","16","3","268","280","A flexible and general mechanism for specifying problems relating to the sequencing of events and mechanically translating them into dataflow analysis algorithms capable of solving those problems is presented. Dataflow analysis has been used for quite some time in compiler code optimization. Most static analyzers have been custom-built to search for fixed and often quite limited classes of dataflow conditions. It is shown that the range of sequences for which it is interesting and worthwhile to search in actually quite broad and diverse. A formalism for specifying this diversity of conditions is created. It is shown that these conditions can be modeled essentially as dataflow analysis problems for which effective solutions are known. It is also shown how these solutions can be exploited to serve as the basis for mechanical creation of analyzers for these conditions.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.48935","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=48935","","Software quality;Computer science;Data analysis;Software tools;Software testing;Security;Software engineering;Algorithm design and analysis;Optimizing compilers;Automata","automatic programming;parallel programming;program compilers;specification languages","Cecil;sequencing constraint language;automatic static analysis generation;general mechanism;dataflow analysis algorithms;compiler code optimization;custom-built;dataflow conditions;dataflow analysis problems","","41","","34","","","","","","IEEE","IEEE Journals & Magazines"
"Update transport: a new technique for update synchronization in replicated database systems","M. Singhal","Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA","IEEE Transactions on Software Engineering","","1990","16","12","1325","1336","A fully distributed approach to update synchronization is presented where each site completely executes every update. This approach has several features-higher resiliency to different kinds of failures, higher parallelism, improved response to user requests, and low communication overhead. A fully distributed algorithm for concurrency control obtained by rehashing a previously published semidistributed algorithm into the fully distributed model of update execution is presented. A performance model of replicated database systems is presented and used to study the performance of the proposed algorithm and its semidistributed version. The results of the performance study reveal that the proposed approach can substantially improve the performance at the cost of moderate input/output overhead.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.62441","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=62441","","Database systems;Concurrency control;Distributed algorithms;Costs;System recovery;Throughput;Communication system control;Maintenance;Delay;NASA","concurrency control;distributed databases;redundancy","update transport;update synchronization;replicated database systems;fully distributed approach;parallelism;user requests;low communication overhead;fully distributed algorithm;concurrency control;semidistributed algorithm;fully distributed model;update execution;performance model;performance study;moderate input/output overhead","","9","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Property-based software engineering measurement","L. C. Briand; S. Morasca; V. R. Basili","Centre de Recherche Inf. de Montreal, Montreal, Que., Canada; NA; NA","IEEE Transactions on Software Engineering","","1996","22","1","68","86","Little theory exists in the field of software system measurement. Concepts such as complexity, coupling, cohesion or even size are very often subject to interpretation and appear to have inconsistent definitions in the literature. As a consequence, there is little guidance provided to the analyst attempting to define proper measures for specific problems. Many controversies in the literature are simply misunderstandings and stem from the fact that some people talk about different measurement concepts under the same label (complexity is the most common case). There is a need to define unambiguously the most important measurement concepts used in the measurement of software products. One way of doing so is to define precisely what mathematical properties characterize these concepts, regardless of the specific software artifacts to which these concepts are applied. Such a mathematical framework could generate a consensus in the software engineering community and provide a means for better communication among researchers, better guidelines for analysts, and better evaluation methods for commercial static analyzers for practitioners. We propose a mathematical framework which is generic, because it is not specific to any particular software artifact, and rigorous, because it is based on precise mathematical concepts. We use this framework to propose definitions of several important measurement concepts (size, length, complexity, cohesion, coupling). It does not intend to be complete or fully objective; other frameworks could have been proposed and different choices could have been made. However, we believe that the formalisms and properties we introduce are convenient and intuitive. This framework contributes constructively to a firmer theoretical ground of software measurement.","0098-5589;1939-3520;2326-3881","","10.1109/32.481535","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=481535","","Software engineering;Software measurement;Size measurement;Software quality;Proposals;Software design;Costs;Virtual reality;Computer science;Job shop scheduling","software metrics;computational complexity;system monitoring","property-based software engineering measurement;software system measurement;complexity;coupling;cohesion;software products;mathematical properties;evaluation methods;commercial static analyzers","","320","","28","","","","","","IEEE","IEEE Journals & Magazines"
"DEVS formalism: a framework for hierarchical model development","A. I. Concepcion; B. P. Zeigler","Dept. of Comput. Sci., Michigan State Univ., East Lansing, MI, USA; NA","IEEE Transactions on Software Engineering","","1988","14","2","228","241","A methodology is being developed to map hierarchical, modular discrete event models onto distributed simulator architectures. Concept developed for the first step of the methodology concerning model representation are discussed. The DEVS (Discrete Event System Specification) is extended to facilitate modular, hierarchical model specification. Procedures for top-down model development are expressed with the extended formalism and illustrated with a computer system model design.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4640","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4640","","Computational modeling;Discrete event simulation;Application software;Microcomputers;Distributed processing;Power system modeling;Computer architecture;System recovery;Discrete event systems;Software design","distributed processing;programming theory;software engineering","DEVS;hierarchical model development;discrete event models;distributed simulator architectures;model representation;Discrete Event System Specification;hierarchical model specification;top-down model development","","60","","38","","","","","","IEEE","IEEE Journals & Magazines"
"Semi-distributed load balancing for massively parallel multicomputer systems","I. Ahmad; A. Ghafoor","Sch. of Comput. & Inf. Sci., Syracuse Univ., NY, USA; NA","IEEE Transactions on Software Engineering","","1991","17","10","987","1004","A semidistributed approach is given for load balancing in large parallel and distributed systems which is different from the conventional centralized and fully distributed approaches. The proposed strategy uses a two-level hierarchical control by partitioning the interconnection structure of a distributed or multiprocessor system into independent symmetric regions (spheres) centered at some control points. The central points, called schedulers, optimally schedule tasks within their spheres and maintain state information with low overhead. The authors consider interconnection structures belonging to a number of families of distance transitive graphs for evaluation, and, using their algebraic characteristics, show that identification of spheres and their scheduling points is in general an NP-complete problem. An efficient solution for this problem is presented by making exclusive use of a combinatorial structure known as the Hadamard matrix. The performance of the proposed strategy has been evaluated and compared with an efficient fully distributed strategy through an extensive simulation study. The proposed strategy yielded much better results.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.99188","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=99188","","Load management;Concurrent computing;Delay;Power engineering computing;Control systems;Resource management;Multiprocessor interconnection networks;Processor scheduling;Partitioning algorithms;Scheduling algorithm","computational complexity;multiprocessor interconnection networks;parallel architectures;parallel machines;scheduling","massively parallel multicomputer systems;semidistributed approach;load balancing;distributed systems;fully distributed approaches;two-level hierarchical control;interconnection structure;multiprocessor system;independent symmetric regions;state information;interconnection structures;distance transitive graphs;scheduling points;NP-complete problem;combinatorial structure;Hadamard matrix;fully distributed strategy;simulation study","","54","","45","","","","","","IEEE","IEEE Journals & Magazines"
"InputOutput Tools: A Language Facility for Interactive and Real-Time Systems","J. Van Den Bos; M. J. Plasmeijer; P. H. Hartel","Department of Computer Science and the Computer Graphics Group, University of Nijmegen; NA; NA","IEEE Transactions on Software Engineering","","1983","SE-9","3","247","259","A conceptual model is discussed which allows the hierarchic definition of high-level input driven objects, called input-output tools, from any set of basic input primitives. An input-output tool is defined as a named object. Its most important elements are the input rule, output rule, internal tool definitions, and a tool body consisting of executable statements. The input rule contains an expression with tool designators as operands and with operators allowing for sequencing, selection, interleaving, and repetition. Input rules are similar in appearance to production rules in grammars. The input expression specifies one or more input sequences, or input patterns, in terms of tool designators. An input parser tries, at run-time, to match (physical) input tokens against active input sequences. If a match between an input token and a tool designator is found, the corresponding tool body is executed, and the output is generated according to specifications in the tool body. The control structures in the input expression allow a variety of input patterns from any number of sources. Tool definitions may occur in-line or be stored in a library. All tools are ultimately encompassed in one tool representing the program.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236734","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703052","Computer graphics;dialogue;input functions;input tools;interaction language;process control;programming language;real time;specification language","Real time systems;Computer languages;Computer science;Computer graphics;Impedance matching;Specification languages;Process control;Interactive systems;Interleaved codes;Production","","Computer graphics;dialogue;input functions;input tools;interaction language;process control;programming language;real time;specification language","","4","","22","","","","","","IEEE","IEEE Journals & Magazines"
"The automatic inversion of attribute grammars","D. M. Yellin; E. M. Mueckstein","Department of Computer Science, Columbia University, New York, NY 10027; IBM Thomas J. Watson Research Center, Yorktown Heights, NY 10598; IBM Information Services, Bethesda, MD 20817","IEEE Transactions on Software Engineering","","1986","SE-12","5","590","599","Attribute grammars constitute a formal mechanism for specifying translations between languages; from a formal description of the translation, a translator can be automatically constructed. This process is taken one step further; given an attribute grammar specifying the translation from language <i>L</i><sub>1</sub> to language <i>L</i><sub>2</sub>, the question of whether the inverse attribute grammar specifying the inverse translation from <i>L</i><sub>2</sub> to <i>L</i><sub>1</sub> can be automatically generated is addressed. It is shown how to solve this problem for a restricted subset of attribute grammars. This inversion process allows compatible two-way translators to be generated from a single description. To show the practical feasibility of attribute grammar inversion, experience in inverting an attribute grammar used as an interface for a formal database accessing language, SQL, is related. The attributed grammar is used to paraphrase SQL database queries in English.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312955","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312955","Automatic software generation;bidirectional translators;formal specifications;inversion of attribute grammars;natural language interfaces to databases","Grammar;Production;Semantics;Context;Program processors;Databases","context-free grammars;database theory;program interpreters;query languages","automatic inversion;attribute grammars;specifying translations;formal description;inverse translation;formal database accessing language;SQL;database queries","","1","","","","","","","","IEEE","IEEE Journals & Magazines"
"MIDAS: integrated design and simulation of distributed systems","R. L. Bagrodia; C. -. Shen","Dept. of Comput. Sci., California Univ., Los Angeles, CA, USA; Dept. of Comput. Sci., California Univ., Los Angeles, CA, USA","IEEE Transactions on Software Engineering","","1991","17","10","1042","1058","An approach called MIDAS is described that supports the design of distributed systems via iterative refinement of hybrid models. A hybrid model is a partially implemented design where some components exist as simulation models and others as operational subsystems. It is an executable model and may be used to determine the stochastic performance characteristics of a partially elaborated design. MIDAS enhances the applicability of hybrid models in system design with its support for interrupts and its inclusion of distributed components in the partially implemented design. The authors describe how an existing simulation language may be extended to program hybrid models, and show how simulation algorithms may be adapted to execute hybrid models. A prototype MIDAS implementation is operational and was used to develop a set of applications. The experimental results of the exercise are also described.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.99192","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=99192","","Analytical models;Iterative methods;Performance analysis;Stochastic processes;Prototypes;Helium;Timing;Hardware;Humans;Aircraft","distributed processing;interrupts;simulation languages;virtual machines","MIDAS;distributed systems;iterative refinement;hybrid models;partially implemented design;simulation models;operational subsystems;executable model;stochastic performance characteristics;partially elaborated design;system design;interrupts;distributed components;simulation language;simulation algorithms","","35","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Collision-Free Access Control for Computer Communication Bus Networks","K. P. Eswaran; V. C. Hamacher; G. S. Shedler","IBM Research Laboratory; NA; NA","IEEE Transactions on Software Engineering","","1981","SE-7","6","574","582","This paper considers access control for local area computer communication networks. We propose two distributed access control schemes for a bus network. The schemes are simple and asynchronous, and provide for collision-free communication among ports. In addition, one of the schemes provides a bounded, guaranteed time to transmisidon for each port. We also show that this scheme is efficient in the use of the bus bandwidth, in the sense that there is only a small fraction of time during which the bus is idle when there is at least one packet available for transmission.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.226468","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702889","Access protocols;asynchronous distributed control;broadcast bus;collision avoidance;guaranteed time to transmission;local area networks","Access control;Computer networks;Communication networks;Broadcasting;Communication system control;Access protocols;Bandwidth;Distributed control;Collision avoidance;Local area networks","","Access protocols;asynchronous distributed control;broadcast bus;collision avoidance;guaranteed time to transmission;local area networks","","19","","7","","","","","","IEEE","IEEE Journals & Magazines"
"An analytic/empirical study of distributed sorting on a local area network","W. S. Luk; F. Ling","Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada; Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada","IEEE Transactions on Software Engineering","","1989","15","5","575","586","A model for distributed sorting on a local area network (LAN) is presented. This model, contrary to the conventional model, takes into account both local processing time and communication time. This model is intended to provide a framework within which the performances of various distributed sorting algorithms are analyzed and implemented on Ethernet-connected Sun workstations. The empirical results by and large agree with the predictions derivable from the model. They show that local processing, particularly sorting of local subfiles, dominates the whole process, as far as response time is concerned. All algorithms examined have similar asymptotic behavior for large files. For medium-sized files, the degree of communication parallelism has a great impact on algorithm performance.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24707","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24707","","Sorting;Local area networks;Algorithm design and analysis;Parallel processing;Workstations;Distributed algorithms;Costs;Predictive models;Performance analysis;Sun","distributed processing;local area networks;sorting","local area network;LAN;local processing time;communication time;distributed sorting algorithms;Ethernet-connected Sun workstations;local processing;local subfiles;asymptotic behavior;large files;communication parallelism;algorithm performance","","4","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Task Scheduling on the PASM Parallel Processing System","D. L. Tuomenoksa; H. J. Siegel","AT&amp;T Information Systems; NA","IEEE Transactions on Software Engineering","","1985","SE-11","2","145","157","PASM is a proposed large-scale distributed/parallel processing system which can be partitioned into independent SIMD/MIMD machines of various sizes. One design problem for systems such as PASM is task scheduling. The use of multiple FIFO queues for nonpreemptive task scheduling is described. Four multiple-queue scheduling algorithms with different placement policies are presented and applied to the PASM parallel processing system. Simulation of a queueing network model is used to compare the performance of the algorithms. Their performance is also considered in the case where there are faulty control units and processors. The multiple-queue scheduling algorithms can be adapted for inclusion in other multiple-SIMD and partitionable SIMD/MIMD systems that use similar types of interconnection networks to those being considered for PASM.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232189","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701982","Distributed processing;multimicroprocessor systems;multiple-SIMD systems;parallel processing;partitionable SIMD/MIMD systems;PASM;performance evaluation;reconfigurable computer systems;scheduling","Parallel processing;Scheduling algorithm;Processor scheduling;Large-scale systems;Switches;Laboratories;Partitioning algorithms;Process control;Multiprocessor interconnection networks;Concurrent computing","","Distributed processing;multimicroprocessor systems;multiple-SIMD systems;parallel processing;partitionable SIMD/MIMD systems;PASM;performance evaluation;reconfigurable computer systems;scheduling","","9","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Scale Economies in New Software Development","R. D. Banker; C. F. Kemerer","NA; NA","IEEE Transactions on Software Engineering","","1989","15","10","1199","1205","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1989.559768","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=559768","","Programming;Economies of scale;Production;Productivity;Data envelopment analysis;Costs;Software measurement;Software engineering;Industrial economics;Assembly","","Data envelopment analysis;function points;productivity measurement;scale economies;software development;source lines of code","","110","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Approximate mean value analysis for stochastic marked graphs","M. Sereno","Dipartimento di Inf., Torino Univ., Italy","IEEE Transactions on Software Engineering","","1996","22","9","654","664","An iterative technique for the computation of approximate performance indices of a class of stochastic Petri net models is presented. The proposed technique is derived from the mean value analysis algorithm for product-form solution stochastic Petri nets. In this paper, we apply the approximation technique to stochastic marked graphs. In principle, the proposed technique can be used for other stochastic Petri net subclasses. In this paper, some of these possible applications are presented. Several examples are presented in order to validate the approximate results.","0098-5589;1939-3520;2326-3881","","10.1109/32.541436","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=541436","","Stochastic processes;Petri nets;Performance analysis;Algorithm design and analysis;Approximation algorithms;Equations;Iterative algorithms;Concurrent computing;Steady-state;Linear systems","stochastic systems;approximation theory;Petri nets;graph colouring;iterative methods;performance index","approximate mean value analysis;stochastic marked graphs;iterative technique;approximate performance indices;stochastic Petri nets;product-form solution;computational algorithms;approximation techniques","","7","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Operating System Models in a Concurrent Pascal Environment: Complexity and Performance Considerations","A. Pashtan","Gould Research Center","IEEE Transactions on Software Engineering","","1985","SE-11","1","136","141","Empirical observations of computer operating systems have shown that operating systems are designed with one of two object oriented strategies: a process or a monitor oriented approach. This paper compares the two design approaches in a Concurrent Pascal environment. Resource manager programs that are implemented in conformity with each model are evaluated using software complexity measures and program performance measures. The average complexity of resource manager processes is 94 percent larger than the average complexity of resource manager monitors. The runtime synchronization overhead of the process model program is two-eight times higher than that of its counterpart.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231538","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701906","Concurrent Pascal;monitor model;operating system;process model;program effort;program performance;resource manager object;software complexity","Operating systems;Object oriented modeling;Resource management;Data structures;Software performance;Software measurement;Computer architecture;Computerized monitoring;High level languages;Runtime","","Concurrent Pascal;monitor model;operating system;process model;program effort;program performance;resource manager object;software complexity","","1","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Improving quicksort performance with a codeword data structure","J. -. Baer; Y. -. Lin","Dept. of Comput. Sci., Washington Univ., Seattle, WA, USA; Dept. of Comput. Sci., Washington Univ., Seattle, WA, USA","IEEE Transactions on Software Engineering","","1989","15","5","622","631","The problem is discussed of how the use of a new data structure, the codeword structure, can help improve the performance of quicksort when the records to be sorted are long and the keys are alphanumeric sequences of bytes. The codeword is a compact representation of a key with respect to some codeword generator. It consists of a byte for a character count of equal bytes, a byte for the first nonequal byte, and a pointer to the record. It is shown how the ordering of keys is preserved by an adequate choice of the code generator and how this can be applied to the quicksort algorithm. An analysis of the potential saving son various architectures and actual measurements shows the improvements that can be attained by using codewords rather than pointers. Architecturally independent parameters, such as the number of bytes to be compared, the number of swaps, architecture-dependent parameters such as caches and their write policies, and compiler optimizations such as in-line expansion and register allocation are considered.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24711","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24711","","Data structures;Optimizing compilers;Memory management;Computer science;Sorting;Indexing","data structures;sorting","performance improvement;codeword data structure;records;long;keys;alphanumeric sequences;bytes;codeword generator;character count;first nonequal byte;pointer;ordering;quicksort algorithm;swaps;architecture-dependent parameters;caches;write policies;compiler optimizations;in-line expansion;register allocation","","5","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Statistical relational tables for statistical database management","S. P. Ghosh","Department of Computer Science, IBM Research Laboratory, San Jose, CA 94193","IEEE Transactions on Software Engineering","","1986","SE-12","12","1106","1116","E.F. Codd's (1970) relational view is extended to represent statistical data and to achieve its analysis. A new view called a statistical relational table is presented to meet the needs of statisticians, and some of Codd's relational operators are extended to statistical relational tables. New operators based on these tables are introduced for communicating requests for statistical analysis. A new query language called the query-by-statistical-relational-table (which has some similarities to query-by-example) is introduced. Extensions of the SQL language for processing the commands of the new query language are also discussed. Creation and storage of metadata for fast statistical analysis are considered. Some problems related to privacy in statistical databases are also examined.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313006","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313006","Codd's relational model;metadata;statistical data;statistical relational table","Databases;Remuneration;Database languages;Data models;Statistical analysis;Computational modeling","database theory;mathematics computing;query languages;relational databases;statistics","mathematics computing;statistical database management;statistical data;statistical relational table;relational operators;query language;query-by-statistical-relational-table;SQL language;privacy","","17","","","","","","","","IEEE","IEEE Journals & Magazines"
"Service combinators for Web computing","L. Cardelli; R. Davies","Microsoft Res., Cambridge, UK; NA","IEEE Transactions on Software Engineering","","1999","25","3","309","316","The World Wide Web is rich in content and services, but access to these resources must be obtained mostly through manual browsers. We would like to be able to write programs that reproduce human browsing behavior, including reactions to slow transmission-rates and failures on many simultaneous links. We thus introduce a concurrent model that directly incorporates the notions of failure and rate of communication, and then describe programming constructs based on this model.","0098-5589;1939-3520;2326-3881","","10.1109/32.798321","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=798321","","Web sites;Computational modeling;Uniform resource locators;Distributed databases;Humans;LAN interconnection;Computer architecture;Counting circuits;Protection","information resources;information retrieval","service combinators;Web computing;World Wide Web;human browsing behavior;slow transmission rate reaction;failure reaction;simultaneous links;concurrent model;programming constructs","","25","","","","","","","","IEEE","IEEE Journals & Magazines"
"Modular algebraic nets to specify concurrent systems","E. Battiston; F. De Cindio; G. Mauri","Dipartimento di Sci. dell'Inf., Milan Univ., Italy; Dipartimento di Sci. dell'Inf., Milan Univ., Italy; Dipartimento di Sci. dell'Inf., Milan Univ., Italy","IEEE Transactions on Software Engineering","","1996","22","10","689","705","The authors present the basic features of a specification language for concurrent distributed systems, developed at the Department of Information Sciences of the University of Milan, Italy. The language is based on a class of modular algebraic high-level nets, OBJSA nets, which result from the synthesis of superposed automata (SA) nets and of the algebraic specification language OBJ. It is supported by the OBJSA Net Environment (ONE). OBJSA nets stress the possibility of building the system model by composing its components and encourage the incremental development of the specification and its reusability. An OBJSA net consists of an SA net inscribed with terms of an OBJ module. The ONE environment supports the user in producing and executing a specification, hiding from her/him, as much as possible, the technical details of the algebraic part of the specification. The paper provides a complete presentation of OBJSA nets, including a user-oriented introduction, the definition of OBJSA nets (as subclass of SPEC-inscribed nets), of their occurrence rule (the semantics) and of the composition operation. In addition it presents the kernel of the support environment.","0098-5589;1939-3520;2326-3881","","10.1109/32.544348","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=544348","","Petri nets;Specification languages;Concurrent computing;Automata;Stress;Kernel;Carbon capture and storage;Algebra","algebraic specification;formal specification;specification languages;parallel processing;Petri nets;software reusability","modular algebraic nets;concurrent system specification;specification language;concurrent distributed systems;modular algebraic high-level nets;OBJSA nets;superposed automata net synthesis;OBJ algebraic specification language;OBJSA Net Environment;system model;incremental specification development;specification reusability;OBJ module;composition operation;occurrence rule;support environment kernel","","12","","63","","","","","","IEEE","IEEE Journals & Magazines"
"A Methodology for Data Schema Integration in the Entity Relationship Model","C. Batini; M. Lenzerini","Department of Computer and Systemrs Sciences, University of Rome, Rome, Italy.; Department of Computer and Systemrs Sciences, University of Rome, Rome, Italy.","IEEE Transactions on Software Engineering","","1984","SE-10","6","650","664","The conceptual design of databases is usually seen as divided into two steps: view modeling, during which user requirements are formally expressed by means of several user oriented conceptual schemata, and schema integration, whose goal is to merge such schemata into a unique global conceptual schema. This paper is devoted to describe a methodology for schema integration. An enriched entity relationship model is chosen as the data model. The integration process consists of three steps: first, several types of conflicts between the different user schemata are checked and solved; second, schemata are merged into a draft integrated schema, that is, third, enriched and restructured according to specific goals.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010294","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010294","Conceptual design;data models;database design;schema integration;schema restructuring","Databases;Data models;Design methodology;Aging;Maintenance","","","","92","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Complexity measure evaluation and selection","J. Tian; M. V. Zelkowitz","Software Solutions Toronto Lab., IBM, North York, Ont., Canada; NA","IEEE Transactions on Software Engineering","","1995","21","8","641","650","A formal model of program complexity developed earlier by the authors is used to derive evaluation criteria for program complexity measures. This is then used to determine which measures are appropriate within a particular application domain. A set of rules for determining feasible measures for a particular application domain are given, and an evaluation model for choosing among alternative feasible measures is presented. This model is used to select measures from the classification trees produced by the empirically guided software development environment of R.W. Selby and A.A. Porter, and early experiments show it to be an effective process.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.403788","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=403788","","Software measurement;Particle measurements;Application software;Programming;Boundary conditions;Classification tree analysis;Software engineering;Software quality;Maintenance;Fluid flow measurement","software metrics;software quality;software selection;software performance evaluation","complexity measure evaluation;program complexity measures;evaluation criteria;application domain;feasible measures;evaluation model;alternative feasible measures;classification trees;empirically guided software development environment","","27","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Covert Channels in LAN's","C. G. Girling","Topexpress Ltd.","IEEE Transactions on Software Engineering","","1987","SE-13","2","292","296","An information transfer path that allows information to be transferred in a manner that violates the security policy of a trusted network is called a covert channel.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233153","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702208","Covert channels;encipherment;local area computer networks;protocols;traffic stereotyping;wiretapping","Local area networks;Bandwidth;Protocols;Telecommunication traffic;Working environment noise;Information security;Timing;Intelligent networks;Design methodology;Computer networks","","Covert channels;encipherment;local area computer networks;protocols;traffic stereotyping;wiretapping","","64","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Detection of Ada static deadlocks using Petri net invariants","T. Murata; B. Shenker; S. M. Shatz","Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA; Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA; Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA","IEEE Transactions on Software Engineering","","1989","15","3","314","326","A method is presented for detecting deadlocks in Ada tasking programs using structural; and dynamic analysis of Petri nets. Algorithmic translation of the Ada programs into Petri nets which preserve control-flow and message-flow properties is described. Properties of these Petri nets are discussed, and algorithms are given to analyze the nets to obtain information about static deadlocks that can occur in the original programs. Petri net invariants are used by the algorithms to reduce the time and space complexities associated with dynamic Petri net analysis (i.e. reachability graph generation).<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21759","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21759","","System recovery;Petri nets;Algorithm design and analysis;Information analysis;Programming profession;Monitoring;Dynamic scheduling;Computer science;Terminology","Ada;computational complexity;concurrency control;Petri nets;program testing;system recovery","Ada static deadlocks;Petri net invariants;Ada tasking programs;control-flow;message-flow;complexities","","100","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Correct and Robust Programs","F. Cristian","IBM Research Laboratory, San Jose, CA 95193.","IEEE Transactions on Software Engineering","","1984","SE-10","2","163","174","The design of programs which are both correct and robust is investigated. It is argued that the notion of an exception is a valuable tool for structuring the specification, design, verification, and modification of such programs. The syntax and semantics of a language with procedures and exception handling are presented. A deductive system is proposed for proving total correctness and robustness properties of programs written in this language. The system is both sound and complete. It supports proof modularization, in that it allows one to reason separately about fault-free and fault-tolerant system properties. Since the programming languages considered closely resembles CLU or Ada, the presented deductive system is easily adaptable for verifying total correctness and robustness properties of programs written in these, or similar, languages.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010218","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010218","Exception handling;program robustness;structured programming;total correctness","Robustness;Computer languages;Sufficient conditions;Algorithm design and analysis;Software design;Fault tolerant systems;Transformers;Measurement standards;Mechanical factors;Runtime","","","","36","","18","","","","","","IEEE","IEEE Journals & Magazines"
"A validation of object-oriented design metrics as quality indicators","V. R. Basili; L. C. Briand; W. L. Melo","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; NA; NA","IEEE Transactions on Software Engineering","","1996","22","10","751","761","This paper presents the results of a study in which we empirically investigated the suite of object-oriented (OO) design metrics introduced in (Chidamber and Kemerer, 1994). More specifically, our goal is to assess these metrics as predictors of fault-prone classes and, therefore, determine whether they can be used as early quality indicators. This study is complementary to the work described in (Li and Henry, 1993) where the same suite of metrics had been used to assess frequencies of maintenance changes to classes. To perform our validation accurately, we collected data on the development of eight medium-sized information management systems based on identical requirements. All eight projects were developed using a sequential life cycle model, a well-known OO analysis/design method and the C++ programming language. Based on empirical and quantitative analysis, the advantages and drawbacks of these OO metrics are discussed. Several of Chidamber and Kemerer's OO metrics appear to be useful to predict class fault-proneness during the early phases of the life-cycle. Also, on our data set, they are better predictors than ""traditional"" code metrics, which can only be collected at a later phase of the software development processes.","0098-5589;1939-3520;2326-3881","","10.1109/32.544352","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=544352","","Programming;Object oriented modeling;Software systems;Software maintenance;Design methodology;Computer languages;Predictive models;Resource management;System testing;Costs","object-oriented methods;software metrics;software quality;software maintenance;information systems;object-oriented languages;C language","object-oriented design metrics;software quality indicators;fault-prone classes;class maintenance changes;metric validation;information management systems;sequential life cycle model;object oriented analysis;C++ programming language;data set;software development","","746","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Exact analysis of Bernoulli superposition of streams into a least recently used cache","H. Levy; R. J. T. Morris","RUTCOR, Rutgers Univ., New Brunswick, NJ, USA; NA","IEEE Transactions on Software Engineering","","1995","21","8","682","688","We present an exact analysis of the superposition of address streams into a cache buffer which is managed according to a least recently used (LRU) replacement policy. Each of the streams is characterized by a stack depth distribution, and we seek the cache hit ratio for each stream, when the combined, or superposed, stream is applied to a shared LRU cache. The combining process is taken to be a Bernoulli switching process. This problem arises in a number of branches of computer science, particularly in database systems and processor architecture. Previously, a number of approximation techniques of various complexities have been proposed for the solution of this problem. The main contribution of the paper is the description of an exact technique. We evaluate the performance of the exact and an approximate technique on realistic data, both in a lab environment and a large database installation. The results allow comparisons of the techniques, and provide insight into the validity of the Bernoulli switching assumption.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.403792","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=403792","","Computer science;Database systems;Cache memory;Memory management;Predictive models;Information analysis;Approximation methods;Computational complexity","cache storage;storage allocation;storage management","Bernoulli superposition;streams;least recently used cache;exact analysis;cache buffer;LRU replacement policy;cache hit ratio;shared LRU cache;Bernoulli switching process;approximation techniques;realistic data;large database installation;Bernoulli switching assumption","","6","","9","","","","","","IEEE","IEEE Journals & Magazines"
"A distributed specification model and its prototyping","Y. Wang","GTE Labs. Inc., Waltham, MA, USA","IEEE Transactions on Software Engineering","","1988","14","8","1090","1097","A specification model is described that is based on the finite-state machine but is distributed. The model allows the user to decompose a large system into separate views. Each view is a complete system in itself, and reveals how the whole system would behave as seen from a certain angle. Put together, the combined views present a complete picture of the whole system. The complexity of a large centralized system is thus distributed and subdued. The author offers a simple execution scheme for the model. Using a high-level state-transition language called SXL, constructs in the model are expressed as preconditions and postconditions of transitions. The execution scheme allows all the views in the model to proceed in a parallel but harmonious way, producing a working prototype for the modeled system.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.7619","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=7619","","Prototypes;Automata;Switching systems;Computer errors;Feedback;Vehicles;Software prototyping;Design engineering;Proposals;Programming","distributed processing;finite automata;high level languages;software engineering;specification languages","Boolean expressions;switching systems;software engineering;distributed specification model;prototyping;finite-state machine;complexity;execution scheme;high-level state-transition language;SXL;preconditions;postconditions","","8","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Optimizing join queries in distributed databases","S. Pramanik; D. Vineyard","Dept. of Comput. Sci., Michigan State Univ., East Lansing, MI, USA; NA","IEEE Transactions on Software Engineering","","1988","14","9","1319","1326","A reduced cover set of the set of full reducer semijoin programs for an acyclic query graph for a distributed database system is given. An algorithm is presented that determines the minimum cost full reducer program. The computational complexity of finding the optimal full reducer for a single relation is of the same order as that of finding the optimal full reducer for all relations. The optimization algorithm is able to handle query graphs where more than one attribute is common between the relations. A method for determining the optimum profitable semijoin program is presented. A low-cost algorithm which determines a near-optimal profitable semijoin program is outlined. This is done by converting a semijoin program into a partial order graph. This graph also allows one to maximize the concurrent processing of the semijoins. It is shown that the minimum response time is given by the largest cost path of the partial order graph. This reducibility is used as a post optimizer for the SSD-1 query optimization algorithm. It is shown that the least upper bound on the length of any profitable semijoin program is N(N-1) for a query graph of N nodes.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6175","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6175","","Distributed databases;Cost function;Query processing;Data communication;Database systems;Computational complexity;Delay;Computer science;Upper bound;Greedy algorithms","computational complexity;database theory;distributed databases;graph theory;optimisation","join queries;distributed databases;reduced cover set;acyclic query graph;distributed database;computational complexity;optimization;partial order graph;concurrent processing;minimum response time","","33","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Database Support for Versions and Alternatives of Large Design Files","R. H. Katz; T. J. Lehman","Department of Computer Sciences, University of Wisconsin, Madison, WI 53706.; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA 94720.; Department of Computer Sciences, University of Wisconsin, Madison, WI 53706.","IEEE Transactions on Software Engineering","","1984","SE-10","2","191","200","We identify the roles played by design versions and alternatives in an engineering database. The obvious way to implement versions is to maintain each in a separate collection of files. Because several versions must be kept on line in a design environment, the approach leads to large disk requirements. We develop B-tree-based storage structures to encode versions as ``negative'' differential files. Our objective is to keep the disk requirements small. We discuss the effect of enormous amounts of cheap archival storage (write-once optical digital disks) on the proposed structures. We have implemented versions in the Wisconsin storage system (WiSS), an experimental database component developed at the University of Wisconsin-Madison.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010222","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010222","","Optical design;Process design;Maintenance engineering;Data engineering;Design engineering;Spatial databases;Software systems;Circuit synthesis;Logic circuits;Data processing","","","","54","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Towards complexity metrics for Ada tasking","S. M. Shatz","Dept. of Elect. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA","IEEE Transactions on Software Engineering","","1988","14","8","1122","1127","Using Ada as a representative distributed programming language, the author discusses some ideas on complexity metrics that focus on Ada tasking and rendezvous. Concurrently active rendezvous are claimed to be an important aspect of communication complexity. A Petri net graph model of Ada rendezvous is used to introduce a rendezvous graph, an abstraction that can be useful in viewing and computing effective communication complexity.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.7623","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=7623","","Distributed computing;Software maintenance;Software measurement;Software testing;Complexity theory;Petri nets;Programming;Software design;Guidelines;Software metrics","Ada;computational complexity;directed graphs;distributed processing;software engineering","concurrently active rendezvous;software engineering;software complexity;complexity metrics;Ada tasking;representative distributed programming language;communication complexity;Petri net graph model;Ada rendezvous;rendezvous graph","","22","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Visual knowledge engineering","M. Eisenstadt; J. Domingue; T. Rajan; E. Motta","Human Cognition Res. Lab., Open Univ., Milton Keynes, UK; Human Cognition Res. Lab., Open Univ., Milton Keynes, UK; Human Cognition Res. Lab., Open Univ., Milton Keynes, UK; Human Cognition Res. Lab., Open Univ., Milton Keynes, UK","IEEE Transactions on Software Engineering","","1990","16","10","1164","1177","The knowledge engineer is only weakly supported at three critical stages in the knowledge engineering life cycle: (1) knowledge acquisition during which problem conceptualization must largely be tackled with paper and pencil; (2) knowledge encoding, during which it is frequently necessary to be able to navigate across a variety of knowledge representation formalisms; and (3) large-scale debugging, in which the graphical rule traces cannot cope with enormous rule sets involving hundreds or thousands of rules. The research described attempts to provide just such support through complementary visual programming (VP) and program visualization (PV) techniques embedded in a fully implemented software environment called KEATS: the knowledge engineer's assistant. Several novel visual programming and program visualization techniques aimed at knowledge engineers have been developed, which include (1) a hypertext transcript analyzer from which conceptual models can be generated, (2) a direct graph manipulation sketchpad which allows the knowledge engineer to sketch out objects and relations (including control flow and rule dependencies) from which code can be generated, and (3) dependency viewers which allow the knowledge engineer to examine and manipulate temporal and logical rule dependencies at different levels of granularity. How these facilities are incorporated into KEATS and the key themes that emerge from this approach to visual knowledge engineering are discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.60296","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=60296","","Knowledge engineering;Visualization;Knowledge acquisition;Encoding;Navigation;Knowledge representation;Large-scale systems;Debugging;Embedded software;Logic programming","knowledge engineering;programming environments;visual programming","visual knowledge engineering;knowledge acquisition;knowledge encoding;knowledge representation formalisms;large-scale debugging;graphical rule traces;complementary visual programming;program visualization;software environment;KEATS;hypertext transcript analyzer;direct graph manipulation sketchpad;dependency viewers;logical rule dependencies","","30","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Reasoning about places, times, and actions in the presence of mobility","C. D. Wilcox; G. -. Roman","6746 W. Robin Lane, Glendale, AZ, USA; NA","IEEE Transactions on Software Engineering","","1996","22","4","225","247","The current trend toward portable computing systems (e.g., cellular phones, laptop computers) brings with it the need for a new paradigm to facilitate thinking about and designing distributed applications. We use the term mobile to refer to distributed systems that include moving, autonomous agents which loosely cooperate to accomplish a task. The fluid nature of the interconnections among components of a mobile system provides new challenges and opportunities for the research community. While we do not claim to have fully grasped all the issues involved in specifying and modeling such systems, we believe that the notions of place, time, and action will play a central role in any model that is developed. We show that these concepts can be expressed and reasoned about in the UNITY logic with a minimal amount of additional notation. The formal derivation of a control system for a radio-dispatched elevator is used to show how considerations involving place, time, and actions impact the design process, be it formal or semiformal.","0098-5589;1939-3520;2326-3881","","10.1109/32.491647","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=491647","","Portable computers;Distributed computing;Cellular phones;Application software;Autonomous agents;Logic;Radio control;Control systems;Elevators;Process design","mobile radio;mobile communication;formal specification;distributed processing;portable computers;program verification","portable computing systems;mobility;distributed applications;distributed systems;moving autonomous agents;agent cooperation;component interconnections;specification;modeling;UNITY logic;formal control system derivation;radio-dispatched elevator;place reasoning;time reasoning;action reasoning","","3","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Redundancy in Data Structures: Improving Software Fault Tolerance","D. J. Taylor; D. E. Morgan; J. P. Black","Department of Computer Science and the Computer Communications Networks Group, University of Waterloo; NA; NA","IEEE Transactions on Software Engineering","","1980","SE-6","6","585","594","The increasing cost of computer system failure has stimulated interest in improving software reliability. One way to do this is by adding redundant structural data to data structures. Such redundancy can be used to detect and correct (structural) errors in instances of a data structure. The intuitive approach of this paper, which makes heavy use of examples, is complemented by the more formal development of the companion paper, ""Redundancy in Data Structures: Some Theoretical Results.""","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234507","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702785","Binary trees;error correction;error detection;linear lists;redundancy;robust data structures;software fault tolerance;software reliability","Redundancy;Data structures;Fault tolerance;Error correction;Computer errors;Costs;Hardware;Fault tolerant systems;Software reliability;Fault detection","","Binary trees;error correction;error detection;linear lists;redundancy;robust data structures;software fault tolerance;software reliability","","60","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Formal specification and design time testing","C. P. Gerrard; D. Coleman; R. M. Gallimore","Gerrard Software, Macclesfield, UK; NA; NA","IEEE Transactions on Software Engineering","","1990","16","1","1","12","It is shown how design time testing can be used in conjunction with formal specification. Emphasis is placed on the benefits of using an executable specification language OBJ, of having a design controlled by requirements specification, and of adherence to the regularity and uniformity hypotheses in dynamic validation. It is shown that such an approach offers positive benefits by providing early design validation and a controlled, disciplined design process.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44359","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44359","","Formal specifications;Software testing;Equations;Specification languages;Process design;Costs;Process control;Software design;Computer languages;System testing","formal specification;specification languages","formal specification;design time testing;executable specification language OBJ;regularity;uniformity","","6","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Performance of Synchronized Iterative Processes in Multiprocessor Systems","M. Dubois; F. A. Briggs","Thomson-CSF; NA","IEEE Transactions on Software Engineering","","1982","SE-8","4","419","431","A general methodology for studying the degree of matching between an architecture and an algorithm is introduced and applied to the case of synchronized iterative algorithms in MIMD machines.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235576","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702964","MIMD computers;multiprocessor systems;order statistics;performance evaluation;synchronized iterative algorithms","Multiprocessing systems;Iterative algorithms;Partitioning algorithms;Performance analysis;Analytical models;Iterative methods;Interference;Costs;Statistics;Parallel algorithms","","MIMD computers;multiprocessor systems;order statistics;performance evaluation;synchronized iterative algorithms","","16","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Stochastic Petri net representation of discrete event simulations","P. J. Haas; G. S. Shedler","IBM Almaden Res. Center, San Jose, CA, USA; IBM Almaden Res. Center, San Jose, CA, USA","IEEE Transactions on Software Engineering","","1989","15","4","381","393","In the context of discrete event simulation, the marking of a stochastic Petri net (SPN) corresponds to the state of the underlying stochastic process of the simulation and the firing of a transition corresponds to the occurrence of an event. A study is made of the modeling power of SPNs with timed and immediate transitions, showing that such Petri nets provide a general framework for simulation. The principle result is that for any (finite or) countable state GSMP (generalized semi-Markov process) there exists an SPN having a marking process that mimics the GSMP in the sense that the two processes (and their underlying general state-space Markov chains) have the same finite dimensional distributions.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.16599","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=16599","","Stochastic processes;Discrete event simulation;State-space methods;Context modeling;Petri nets;Bipartite graph;Fires;Markov processes;Steady-state;State estimation","formal specification;Markov processes;Petri nets;simulation","transition firings;timed transitions;Petri net simulation;discrete event simulation;stochastic Petri net;countable state GSMP;generalized semi-Markov process","","27","","25","","","","","","IEEE","IEEE Journals & Magazines"
"A User-Oriented Software Reliability Model","R. C. Cheung","Bell Laboratories","IEEE Transactions on Software Engineering","","1980","SE-6","2","118","125","A user-oriented reliability model has been developed to measure the reliability of service that a system provides to a user community. It has been observed that in many systems, especially software systems, reliable service can be provided to a user when it is known that errors exist, provided that the service requested does not utilize the defective parts. The reliability of service, therefore, depends both on the reliability of the components and the probabilistic distribution of the utilization of the components to provide the service. In this paper, a user-oriented software reliability figure of merit is defined to measure the reliability of a software system with respect to a user environment. The effects of the user profile, which summarizes the characteristics of the users of a system, on system reliability are discussed. A simple Markov model is formulated to determine the reliability of a software system based on the reliability of each individual module and the measured intermodular transition probabilities as the user profile. Sensitivity analysis techniques are developed to determine modules most critical to system reliability. The applications of this model to develop cost-effective testing strategies and to determine the expected penalty cost of failures are also discussed. Some future refinements and extensions of the model are presented.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234477","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702709","Self-metric software;software reliability;software reliability model;user profile","Software reliability;Software systems;Software measurement;Sensitivity analysis;Application software;Testing;Costs;Hardware;Computer bugs","","Self-metric software;software reliability;software reliability model;user profile","","273","","30","","","","","","IEEE","IEEE Journals & Magazines"
"A performance comparison of multimicro and mainframe database architectures","P. Heidelberger; M. S. Lakshmi","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA","IEEE Transactions on Software Engineering","","1988","14","4","522","531","The performance of a hypothetical multiprocessor back-end database machine is compared to that of a mainframe database system. The hypothetical database machine uses standard microprocessors and disks as well as processors and disks projected to be available in the future. The class of workloads considered is high-volume transaction processing. Analytic queueing models of the two architectures are constructed and used in parametric performance studies. The performance sensitivities with respect to transactions complexity, the amount of overhead required to implement the distributed database function, the amount of skew in the data access pattern, and the buffer miss ratio are determined.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4675","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4675","","Database machines;Transaction databases;Relational databases;Microprocessors;Performance analysis;Costs;Queueing analysis;Delay;Database systems;Distributed databases","database management systems;mainframes;microcomputers;multiprocessing systems;performance evaluation;queueing theory;special purpose computers","multimicro database machines;mainframe database machines;performance comparison;database architectures;transaction processing;queueing models;distributed database;data access","","9","","","","","","","","IEEE","IEEE Journals & Magazines"
"Multidimensional Timestamp Protocols for Concurrency Control","Pei-Jyun Leu; B. Bhargava","Department of Computer Sciences, Purdue University; NA","IEEE Transactions on Software Engineering","","1987","SE-13","12","1238","1253","We propose multidimensional timestamp protocols for concurrency control in database systems where each transaction is assigned a timestamp vector containing multiple elements. The timestamp vectors for two transactions can be equal if timestamp elements are assigned the same values. The serializability order among the transactions is determined by a topological sort of the corresponding timestamp vectors. The timestamp in our protocols is assigned dynamically and is not just based on the starting/finishing time as in conservative and optimistic timestamp methods. The concurrency control can be enforced based on more precise dependency information derived dynamically from the operations of the transactions. Several classes of logs have been identified based on the degree of concurrency or the number of logs accepted by a concurrency controller. The class recognized by our protocols is within D-serializable (DSR), and is different from all previously known classes such as two phase locking (2PL), strictly serializable (SSR), timestamp ordering (TO), which have been defined in literature. The protocols have been analyzed to study the complexity of recognition of logs. We briefly discuss the implementation of the concurrency control algorithm for the new class, and give a timestamp vector processing mechanism. The extension of the protocols for nested transaction and distributed database models has also been included.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232878","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702176","Concurrency control algorithms;database systems;degree of concurrency;k-dimensional timestamp ordering;logs;parallel processing;serializability;transactions","Multidimensional systems;Protocols;Concurrency control;Concurrent computing;Database systems;Finishing;Optimization methods;Distributed databases;Transaction databases;Control systems","","Concurrency control algorithms;database systems;degree of concurrency;k-dimensional timestamp ordering;logs;parallel processing;serializability;transactions","","4","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Verifying general safety properties of Ada tasking programs","L. K. Dillon","Dept. of Comput. Sci., California Univ., Santa Barbara, CA, USA","IEEE Transactions on Software Engineering","","1990","16","1","51","63","The isolation approach to symbolic execution of Ada tasking programs provides a basis for automating partial correctness proofs. The strength of this approach lies in its isolation nature; tasks are symbolically executed and verified independently, and then checked for cooperation where interference can occur. This keeps the verification task computationally feasible and enhances its compositionality. Safety, however, is a more appropriate notion of correctness for concurrent programs than partial correctness. The author shows how the isolation approach to symbolic execution of Ada tasking program supports the verification of general safety properties. Specific safety properties that are considered include mutual exclusion, freedom from deadlock, and absence of communication failure. The techniques are illustrated using a solution to the readers and writers problem.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44363","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44363","","Interference;System recovery;Interleaved codes;Mechanical factors;Logic;Computer science;Concurrent computing;Software safety","Ada;multiprocessing programs;program verification","safety properties verification;Ada tasking programs;isolation approach;symbolic execution;automating partial correctness proofs;concurrent programs;mutual exclusion;deadlock","","5","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Weighted Processor Sharing-Results for Hyperexponential Servers","M. J. Ferguson","Bell-Northern Research Ltd., Ottawa, Ont., Canada and INRS-Tlcommunications","IEEE Transactions on Software Engineering","","1983","SE-9","4","531","535","In a recent paper by Fayolle, Mitrani, and Iasnogorodski [2], some general multidimensional integral equations were derived in order to solve for the mean response time of each of several classes in a queue whose service discipline was weighted processor sharing. The arrival processes were Poisson. The weighting means that each job within a class k is given an amount of processing proportional to the priority weight gk associated with that class. For exponential service times, the general equations were solved. In this note, a simple observation allows use of the exponential solution directly for the case of hyperexponential servers. As a result, it is possible to state the following. Characterization of a server in terms of its mean and coefficient of variation is not sufficient to predict even the mean response time for a class using weighted processor sharing. In unweighted or egalitarian processor sharing, only the mean is sufficient. The Kleinrock conservation law [4] does not hold for nonexponential servers. Fayolie et al. [2] had showed that it did hold for exponential servers.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.234962","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703087","","Delay;Integral equations;Multidimensional systems;Poisson equations;Processor scheduling","","","","","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Functional Program Testing","W. E. Howden","Department of Mathematics, University of Victoria","IEEE Transactions on Software Engineering","","1980","SE-6","2","162","169","An approach to functional testing is described in which the design of a program is viewed as an integrated collection of functions. The selection of test data depends on the functions used in the design and on the value spaces over which the functions are defined. The basic ideas in the method were developed during the study of a collection of scientific programs containing errors. The method was the most reliable testing technique for discovering the errors. It was found to be significantly more reliable than structural testing. The two techniques are compared and their relative advantages and limitations are discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230467","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702713","Effectiveness;experiments;Fortran;functional;reliability;scientific;structural;testing","Packaging;NIST;Mathematics;Logic testing;Numerical analysis;Error correction;Error analysis","","Effectiveness;experiments;Fortran;functional;reliability;scientific;structural;testing","","74","","19","","","","","","IEEE","IEEE Journals & Magazines"
"A Generalized Timed Petri Net Model for Performance Analysis","M. A. Holliday; M. K. Vernon","Department of Computer Science, Duke University; NA","IEEE Transactions on Software Engineering","","1987","SE-13","12","1297","1310","We have developed a Generalized Timed Petri Net (GTPN) model for evaluating the performance of computer systems. Our model is a generalization of the TPN model proposed by Zuberek [1] and extended by Razouk and Phelps [2]. In this paper, we define the GTPN model and present how performance estimates are obtained from the GTPN. We demonstrate the use of our automated GTPN analysis techniques on the dining philosophers example. This example violates restrictions made in the earlier TPN models. Finally, we compare the GTPN to the stochastic Petri net (SPN) models. We show that the GTPN model has capabilities for modeling and analyzing parallel systems lacking in existing SPN models. The GTPN provides an efficient, easily used method of obtaining accurate performance estimates for models of computer systems which include both deterministic and geometric holding times.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233141","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702180","Deterministic delays;dining philosophers;embedded Markov chain;Markov models;performance analysis;Petri nets","Performance analysis;Petri nets;Stochastic processes;Solid modeling;Delay;Frequency;Interference;Computational modeling;System performance;Reachability analysis","","Deterministic delays;dining philosophers;embedded Markov chain;Markov models;performance analysis;Petri nets","","112","","24","","","","","","IEEE","IEEE Journals & Magazines"
"X-ware reliability and availability modeling","J. -. Laprie; K. Kanoun","LAAS-CNRS, Toulouse, France; LAAS-CNRS, Toulouse, France","IEEE Transactions on Software Engineering","","1992","18","2","130","147","The problem of modeling a system's reliability and availability with respect to the various classes of faults (physical and design, internal and external) which may affect the service delivered to its users is addressed. Hardware and software models are currently exceptions in spite of the user's requirements; these requirements are expressed in terms of failures independently of their sources, i.e., the various classes of faults. The causes of this situation are analyzed; it is shown that there is no theoretical impediment to deriving such models, and that the classical reliability theory can be generalized in order to cover both hardware and software viewpoints that are X-Ware.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.121755","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=121755","","Availability;Hardware;Electronic switching systems;Maintenance;Software safety;Software performance;Performance evaluation;Impedance;Reliability theory;Software reliability","fault tolerant computing;performance evaluation;reliability theory;software reliability","availability modeling;faults;software models;classical reliability theory;software viewpoints;X-Ware","","70","","78","","","","","","IEEE","IEEE Journals & Magazines"
"The Programmers' Playground: I/O abstraction for user-configurable distributed applications","K. J. Goldman; B. Swaminathan; P. McCartney; M. D. Anderson; R. Sethuraman","Dept. of Comput. Sci., Washington Univ., St. Louis, MO, USA; Dept. of Comput. Sci., Washington Univ., St. Louis, MO, USA; Dept. of Comput. Sci., Washington Univ., St. Louis, MO, USA; NA; NA","IEEE Transactions on Software Engineering","","1995","21","9","735","746","I/O abstraction is offered as a new high-level approach to interprocess communication. Functional components of a distributed system are written as encapsulated modules that act upon local data structures, some of which may be published for external use. Relationships among modules are specified by logical connections among their published data structures. Whenever a module updates published data, I/O takes place implicitly according to the configuration of logical connections. The Programmers' Playground, a software library and runtime system supporting I/O abstraction, is described. Design goals include the separation of communication from computation, dynamic reconfiguration of the communication structure, and the uniform treatment of discrete and continuous data types. Support for end-user configuration of distributed multimedia applications is the motivation for the work.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.464547","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=464547","","Programming profession;Application software;Data structures;Software libraries;Programming environments;Dynamic programming;Asynchronous transfer mode;Streaming media;Bandwidth;Collaborative work","program compilers;software libraries;distributed processing;multimedia computing;programming environments;software tools;data structures","Programmers' Playground;I/O abstraction;user-configurable distributed applications;interprocess communication;distributed system;encapsulated modules;local data structures;logical connections;software library;runtime system;continuous data types;discrete data types;end-user configuration;distributed multimedia applications;input/output abstraction;programming environments","","29","","46","","","","","","IEEE","IEEE Journals & Magazines"
"Automatic synthesis of SARA design models from system requirements","K. -. E. Lor; D. M. Berry","AT&T Bell Labs., Middletown, NJ, USA; NA","IEEE Transactions on Software Engineering","","1991","17","12","1229","1240","In this research in design automation, two views are employed as the requirements of a system-namely, the functional requirements and the operations concept. A requirement analyst uses data flow diagrams and system verification diagrams (SVDs) to represent the functional requirements and the operations concept, respectively. System Architect's Apprentice (SARA) is an environment-supported method for designing hardware and software systems. A knowledge-based system, called the design assistant, was built to help the system designer to transform requirements stated in one particular collection of design languages. The SVD requirement specification features and the SARA design models are reviewed. The knowledge-based tool for synthesizing a particular domain of SARA design from the requirements is described, and an example is given to illustrate this synthesis process. This example shows the rules used and how they are applied. An evaluation of the approach is given.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.106984","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=106984","","Design automation;Process design;Humans;Hardware;Design methodology;Software design;Computer science;Systems engineering and theory;Buildings;Software systems","diagrams;knowledge based systems;software tools;systems analysis","computer aided software engineering;software design automation;SARA design models;functional requirements;requirement analyst;data flow diagrams;system verification diagrams;System Architect's Apprentice;hardware;software;knowledge-based system;design assistant;design languages;SVD requirement specification;knowledge-based tool","","8","","25","","","","","","IEEE","IEEE Journals & Magazines"
"The gains from computer communication","H. Kameda","Department of Computer Science, University of Electro-Communications, 1-5-1 Chofugaoka, Chofu-shi, Tokyo 182, Japan","IEEE Transactions on Software Engineering","","1986","SE-12","11","1049","1055","The effects of providing communication channels among computer systems located at different sites are studied. It is shown that the maximum utility at every site with computer communication can be greater (or at least not less) than that without communication. This can be achieved in such a way that, with communication, each computer system is more specialized in processing transactions of the types in which the system has comparative advantage and mutually exchanges the processed transactions through communication channels; the utility here is assumed to depend on performance. It is shown, however, that growth in computing resources at a site toward a higher degree of specialization may sometimes lead to a decrease in the maximum utility at the site.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312994","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312994","Comparative advantage;computer communication;computer network;computer system performance;immiserizing growth;processing capacity;processing rate;specialization;transaction exchanging;utility","Computers;Exchange rates;Communities;Production;Communication channels;Computer networks","computer networks;telecommunication channels","transactions processing;computer communication;communication channels","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Design Stability Measures for Software Maintenance","S. S. Yau; J. S. Collofello","Department of Electrical Engineering and Computer Science, Northwestern University; NA","IEEE Transactions on Software Engineering","","1985","SE-11","9","849","856","The high cost of software during its life cycle can be attributer largely to software maintenance activities, and a major portion of these activities is to deal with the modifications of the software. In this paper, design stability measures which indicate the potential ripple effect characteristics due to modifications of the program at the design level are presented. These measures can be generated at any point in the design phase of the software life cycle which enables early maintainability feedback to the software developers. The validation of these measures and future research efforts involving the development of a user-oriented maintainability measure, which incorporates the design stability measures as well as other design measures, are discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232544","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702104","Design stability measures;program modifications;software maintenance","Stability;Software measurement;Software maintenance;Costs;Phase measurement;Military computing;Hardware;Productivity;Application software;Software quality","","Design stability measures;program modifications;software maintenance","","69","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Analysis of Secondary Storage Fragmentation","C. H. C. Leung","Department of Computer Science, University College, London University","IEEE Transactions on Software Engineering","","1983","SE-9","1","87","93","Fragmentation of storage is a common phenomenon in both main storage and secondary storage. Fragmentation in secondary storage not only jeopardizes the allocation of space but also, since secondary storage access timeunlike that in main storageis typically nonuniform, a decrease in efficiency arising from additional head movement may also result. A fragmented storage exhibits a checkerboard like pattern with free and occupied space alternating one another. Such alternating storage configuration is analyzed using alternating renewal processes. Two main types of storage processing are distinguished: contiguous storage allocation and noncontiguous storage allocation. The latter allows a request to be scattered over different locations while the former requires it to be allocated in a single continuous area. It is found that the reduction in operating efficiency due to fragmentation is quite substantial for both types of processing. The deterioration is especially marked in the former and is strongly affected by 1) the request size and 2) the storage utilization. Expressions for the generating functions of the performance penalties are derived. The results of the model are compared with published measurements and satisfactory agreement is obtained.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236298","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703015","Contiguous allocation;linear storage;noncontiguous allocation;renewal process;secondary storage fragmentation","Scattering;Degradation;Information retrieval;Frequency locked loops;Computer science;System performance;Magnetic heads;Terminology","","Contiguous allocation;linear storage;noncontiguous allocation;renewal process;secondary storage fragmentation","","","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Theory of fault-based predicate testing for computer programs","Kuo-Chung Tai","Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA","IEEE Transactions on Software Engineering","","1996","22","8","552","562","Predicates appear in both the specification and implementation of a program. One approach to software testing, referred to as predicate testing, is to require certain types of tests for a predicate. In this paper, three fault-based testing criteria are defined for compound predicates, which are predicates with one or more AND/OR operators. BOR (boolean operator) testing requires a set of tests to guarantee the detection of (single or multiple) boolean operator faults, including incorrect AND/OR operators and missing/extra NOT operators. BRO (boolean and relational operator) testing requires a set of tests to guarantee the detection of boolean operator faults and relational operator faults (i.e., incorrect relational operators). BRE (boolean and relational expression) testing requires a set of tests to guarantee the detection of boolean operator faults, relational operator faults, and a type of fault involving arithmetical expressions. It is shown that for a compound predicate with n, n>0, AND/OR operators, at most n+2 constraints are needed for BOR testing and at most 2*n+3 constraints for BRO or BRE testing, where each constraint specifies a restriction on the value of each boolean variable or relational expression in the predicate. Algorithms for generating a minimum set of constraints for BOR, BRO, and BRE testing of a compound predicate are given, and the feasibility problem for the generated constraints is discussed. For boolean expressions that contain multiple occurrences of some boolean variables, how to combine BOR testing with the meaningful impact strategy (Weyuker et al., 1994) is described.","0098-5589;1939-3520;2326-3881","","10.1109/32.536956","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=536956","","Software testing;Fault detection;Materials testing;Software engineering;Computer science;Digital arithmetic","programming theory;program testing;Boolean functions;program debugging","fault-based predicate testing;program testing;compound predicates;formal specification;program implementation;AND/OR operators;BOR testing;boolean operator testing;NOT operators;BRO testing;boolean relational operator testing;relational operator faults;boolean operator faults;BRE testing;boolean relational expression testing;arithmetical expressions;boolean variable;feasibility problem;boolean expressions;meaningful impact strategy","","56","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Distributed program reliability analysis","V. K. P. Kumar; S. Hariri; C. S. Raghavendra","Department of Electrical Engineering - Systems, University of Southern California, Los Angeles, CA 90089; Department of Electrical Engineering - Systems, University of Southern California, Los Angeles, CA 90089; Department of Electrical Engineering - Systems, University of Southern California, Los Angeles, CA 90089","IEEE Transactions on Software Engineering","","1986","SE-12","1","42","50","The reliability of distributed processing systems can be expressed in terms of the reliability of the processing elements that run the programs, the reliability of the processing elements holding the required files, and the reliability of the communication links used in file transfers. The authors introduce two reliability measures, namely distributed program reliability and distributed system reliability, to accurately model the reliability of distributed systems. The first measure describes the probability of successful execution of a distributed program which runs on some processing elements and needs to communicate with other processing elements for remote files, while the second measure describes the probability that all the programs of a given set can run successfully. The notion of minimal file spanning trees is introduced to efficiently evaluate these reliability measures. Graph theory techniques are used to systematically generate file spanning trees that provide all the required connections. The technique is general and can be used in a dynamic environment for efficient reliability evaluation.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312918","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312918","Distributed program;distributed system;graph theory;reliability;spanning tree","Computer network reliability;Software reliability;Distributed processing;Reliability theory;Indexes;Reliability engineering","distributed processing;software reliability;trees (mathematics)","distributed processing systems;reliability;files;communication links;file transfers;reliability measures;distributed program reliability;distributed system reliability;probability;minimal file spanning trees","","43","","","","","","","","IEEE","IEEE Journals & Magazines"
"Support algorithms for incremental attribute evaluation of asynchronous subtree replacements","J. Micallef; G. E. Kaiser","Bellcore, Morristown, NJ, USA; NA","IEEE Transactions on Software Engineering","","1993","19","3","231","252","A solution to the problem of incremental attribute evaluation for multiple asynchronous subtree replacements that is applicable to arbitrary noncircular attribute grammars is discussed. The algorithm supports multiple independent editing cursors. Concurrent evaluation processes proceed independently as long as they cover disjoint regions of the derivation tree. Evaluation processes are merged when they overlap, to prevent unnecessary attribute evaluations. The complexity of these three parts of the algorithm is discussed. The algorithm ensures that when evaluation terminates, the tree is consistently attributed. The results solve two open problems that arose in connection with the original algorithm for asynchronous subtree replacements reported by S.M. Kaplan and G.F. Kaiser (1986).<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.221136","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=221136","","Programming profession;User interfaces;Computer languages;Collaborative work;Law;Legal factors;Writing;Error correction;Sun;Telecommunication computing","attribute grammars;computational complexity;text editing;tree data structures;trees (mathematics)","incremental attribute evaluation;multiple asynchronous subtree replacements;arbitrary noncircular attribute grammars;multiple independent editing cursors;disjoint regions;derivation tree;complexity;open problems","","1","","43","","","","","","IEEE","IEEE Journals & Magazines"
"In-process evaluation for software inspection and test","J. K. Chaar; M. J. Halliday; I. S. Bhandari; R. Chillarege","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA","IEEE Transactions on Software Engineering","","1993","19","11","1055","1070","The goal of software inspection and test is to reduce the expected cost of software failure over the life of a product. The authors extend the use of defect triggers, the events that cause defects to be discovered, to help evaluate the effectiveness of inspections and test scenarios. In the case of inspections, the defect trigger is defined as a set of values that associate the skills of the inspector with the discovered defect. Similarly, for test scenarios, the defect trigger values embody the deferring strategies being used in creating these scenarios. The usefulness of triggers in evaluating the effectiveness of software inspections and tests is demonstrated by evaluating the inspection and test activities of some software products. These evaluations are used to point to deficiencies in inspection and test strategies, and to progress made in improving such strategies. The trigger distribution of the entire inspection or test series may then be used to highlight areas for further investigation, with the aim of improving the design, implementation, and test processes.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.256853","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=256853","","Inspection;Software testing;Software quality;Life testing;Costs;Programming;Senior members;Software reliability;Software development management;Software maintenance","program testing;software quality;software reliability","in-process evaluation;software inspection;software testing;expected cost;software failure;defect triggers;test scenarios","","34","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Modular redundancy in a message passing system","L. Mancini","Computing Laboratory, University of Newcastle-upon-Tyne, Newcastle-upon-Tyne, NE1 7RU, England","IEEE Transactions on Software Engineering","","1986","SE-12","1","79","86","Modular redundancy in the form of replicated computations in a concurrent programming model consisting of communicating sequential processes is investigated. Some conditions are given which must always be verified to ensure correctness in the presence of nondeterminism. Then some implementations which satisfy the given conditions are proposed. This approach permits redundant systems to be robust with respect to failures in redundant processors, and also permits the use of software fault tolerance techniques such as <i>N</i>-version programming. The concurrent programming model which has been chosen is based on a set of active entities, i.e. processes, each running in a local protected environment. The processes interact using message passing only.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312922","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312922","Agreement;communicating sequential processes;fault tolerance;guarded commands;nondeterminism;replicated processing;voting","Redundancy;Semantics;Receivers;Kernel;Program processors;Programming;Message passing","fault tolerant computing;parallel processing;software reliability","modular redundancy;parallel programming;software reliability;message passing system;concurrent programming model;communicating sequential processes;correctness;nondeterminism;software fault tolerance techniques;N-version programming;active entities","","14","","","","","","","","IEEE","IEEE Journals & Magazines"
"The consistent comparison problem in N-version software","S. S. Brilliant; J. C. Knight; N. G. Leveson","Dept. of Math. Sci., Virginia Commonwealth Univ., Richmond, VA, USA; NA; NA","IEEE Transactions on Software Engineering","","1989","15","11","1481","1485","The authors have identified a difficulty in the implementation of N-version programming. The problem, called the consistent comparison problem, arises for applications in which decisions are based on the results of comparing finite-precision numbers. It is shown that when versions make comparisons involving the results of finite-precision calculations, it is impossible to guarantee the consistency of their results. It is therefore possible that correct versions may arrive at completely different outputs for an application that does not apparently have multiple correct solutions. If this problem is not dealt with explicitly, an N-version system may be unable to reach consensus even when none of its component versions falls.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.41339","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=41339","","Application software;Temperature sensors;Arithmetic;Fault tolerance;Computer science;Pressure measurement;Software reliability;Large-scale systems;NASA;Aircraft","fault tolerant computing;programming","consistent comparison problem;N-version software;N-version programming;decisions;finite-precision numbers;finite-precision calculations","","36","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Precise documentation of well-structured programs","D. Lorge Parnas; J. Madey; M. Iglewski","Telecommun. Res. Inst., McMaster Univ., Hamilton, Ont., Canada; NA; NA","IEEE Transactions on Software Engineering","","1994","20","12","948","976","Describes a new form of program documentation that is precise, systematic and readable. This documentation comprises a set of displays supplemented by a lexicon and an index. Each display presents a program fragment in such a way that its correctness can be examined without looking at any other display. Each display has three parts: (1) the specification of the program presented in the display, (2) the program itself, and (3) the specifications of programs invoked by this program. The displays are intended to be used by software engineers as a reference document during inspection and maintenance. This paper also introduces a specification technique that is a refinement of H.D. Mills's (1975) functional approach to program documentation and verification; programs are specified and described in tabular form.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.368133","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=368133","","Documentation;Displays;Programming profession;Software maintenance;Inspection;Heart;Councils;Informatics;Humans","structured programming;system documentation;program verification;formal specification;software maintenance","precise documentation;well-structured programs;displays;lexicon;index;program fragments;program correctness;specification;software engineering;reference document;software inspection;software maintenance;functional approach;program documentation;program verification;tabular form","","52","","29","","","","","","IEEE","IEEE Journals & Magazines"
"A 15 Year Perspective on Automatic Programming","R. Balzer","Information Sciences Institute, University of Southern California","IEEE Transactions on Software Engineering","","1985","SE-11","11","1257","1268","Automatic programming consists not only of an automatic compiler, but also some means of acquiring the high-level specification to be compiled, some means of determining that it is the intended specification, and some (interactive) means of translating this high-level specification into a lower-level one which can be automatically compiled.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231877","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701945","Automatic programming;evolution;explanation;knowledge base;maintenance;prototyping;specification;transformation","Automatic programming;Hardware;Program processors;Prototypes;Costs;Software development management;System testing;Vehicles;Genetic programming","","Automatic programming;evolution;explanation;knowledge base;maintenance;prototyping;specification;transformation","","183","","39","","","","","","IEEE","IEEE Journals & Magazines"
"Safety analysis of timing properties in real-time systems","F. Jahanian; A. K. Mok","Department of Computer Sciences, University of Texas at Austin, Austin, TX 78712; Department of Computer Sciences, University of Texas at Austin, Austin, TX 78712","IEEE Transactions on Software Engineering","","1986","SE-12","9","890","904","The authors formalize the safety analysis of timing properties in real-time systems. The analysis is based on a formal logic, RTL (real-time logic), which is especially suitable for reasoning about the timing behavior of systems. Given the formal specification of a system and a safety assertion to be analyzed, the goal is to relate the safety assertion to the systems specification. There are three distinct cases: (1) the safety assertion is a theorem derivable from the systems specification; (2) the safety assertion is unsatisfiable with respect to the systems specification; or (3) the negation of the safety assertion is satisfiable under certain conditions. A systematic method for performing safety analysis is presented.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313045","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313045","Real time;real-time logic;safety analysis;systems specification;time-critical system;verification","Real-time systems;Timing;Safety;Clocks;Syntactics;Computational modeling;Time factors","formal logic;real-time systems;safety;systems analysis","timing properties;real-time systems;safety analysis;formal logic;RTL;real-time logic;formal specification;systems specification;safety assertion","","210","","","","","","","","IEEE","IEEE Journals & Magazines"
"Describing software architecture styles using graph grammars","D. Le Metayer","IRISA, Rennes, France","IEEE Transactions on Software Engineering","","1998","24","7","521","533","We believe that software architectures should provide an appropriate basis for the proof of properties of large software. This goal can be achieved through a clearcut separation between computation and communication and a formal definition of the interactions between individual components. We present a formalism for the definition of software architectures in terms of graphs. Nodes represent the individual agents and edges define their interconnection. Individual agents can communicate only along the links specified by the architecture. The dynamic evolution of an architecture is defined independently by a ""coordinator"". An architecture style is a class of architectures specified by a graph grammar. The class characterizes a set of architectures sharing a common communication pattern. The rules of the coordinator are statically checked to ensure that they preserve the constraints imposed by the architecture style.","0098-5589;1939-3520;2326-3881","","10.1109/32.708567","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=708567","","Software architecture;Computer architecture;Computer languages;Application software;Engineering drawings;Costs;Organizing;Software standards;Software design;Mathematical model","formal verification;graph grammars","software architecture styles;graph grammars;formal definition;individual agents;interconnection","","119","","32","","","","","","IEEE","IEEE Journals & Magazines"
"Representing Roles in Universal Scheme Interfaces","D. Maier; D. Rozenshtein; J. Stein","Oregon Graduate Center; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","7","644","652","Users of a relational database must explicitly navigate between relations in order to establish a connection among a set of attributes spanning several relation schemes. While a universal scheme interface to a relational database provides users with automatic navigation, it usually imposes on the database a unique role assumption. This assumption requires every attribute name to represent a unique role in the database, so that connections among sets of attributes are unambiguous.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232508","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702068","Access path;automatic database navigation;database query language;generalization hierarchy;relational database;unique role assumption;universal scheme interface","Relational databases;Navigation;Jacobian matrices;Database languages;Automatic logic units","","Access path;automatic database navigation;database query language;generalization hierarchy;relational database;unique role assumption;universal scheme interface","","","","18","","","","","","IEEE","IEEE Journals & Magazines"
"A Symmetrical Exponential Open Queue Network with Blocking and Feedback","H. G. Perros","Department of Quantitative Methods, College of Business Administration, University of Illinois at Chicago Circle","IEEE Transactions on Software Engineering","","1981","SE-7","4","395","402","The exponential open queue network model studied here consists of n symmetrical queues in parallel served by independent first-level servers in tandem with a second-level server. Blocking of the flow of units through a first-level server occurs each time the server completes a service. The server remains blocked until its blocking unit completes its service at the second-level server. An approximate expression of the probability distribution of the number of blocked first-level servers conditioned upon a service completion of a first-level server is obtained. This expression compares well with simulation data. Based on this distribution, an approximate expression of the queue-length probability distribution is derived assuming a processor-sharing type of service. The exact condition for stability of the queue network is also derived. Some potential applications are discussed, and a quantitative evaluation of the model is given through a case study.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234542","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702860","Approximations;blocking;exponential;feedback;open queue networks;two-level service","Feedback;Network servers;Probability distribution;Stability;Stochastic systems;Pipelines;Throughput;Mathematical programming;Telecommunication traffic;Traffic control","","Approximations;blocking;exponential;feedback;open queue networks;two-level service","","15","","12","","","","","","IEEE","IEEE Journals & Magazines"
"The accuracy of the clock synchronization achieved by TEMPO in Berkeley UNIX 4.3BSD","R. Gusella; S. Zatti","Dept. of Electr. Eng. & Comput. Sci., California Univ., Berkeley, CA, USA; NA","IEEE Transactions on Software Engineering","","1989","15","7","847","853","The authors discuss the upper and lower bounds on the accuracy of the time synchronization achieved by the algorithm implemented in TEMPO, the distributed service that synchronizes the clocks of the University of California, Berkeley, UNIX 4.3BSD systems. The accuracy is shown to be a function of the network transmission latency; it depends linearly upon the drift rate of the clocks and the interval between synchronizations. TEMPO keeps the clocks of the VAX computers in a local area network synchronized with an accuracy comparable to the resolution of single-machine clocks. Comparison with other clock synchronization algorithms shows that TEMPO, in an environment with no Byzantine faults, can achieve better synchronization at a lower cost.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.29484","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=29484","","Clocks;Synchronization;Master-slave;Delay;Computer science;Nominations and elections;Costs;Local area networks;Time measurement;Computer networks","fault tolerant computing;local area networks;synchronisation;Unix","upper bounds;clock synchronization;TEMPO;Berkeley UNIX 4.3BSD;lower bounds;distributed service;network transmission latency;VAX computers;local area network","","74","","12","","","","","","IEEE","IEEE Journals & Magazines"
"The effectiveness of software development technical reviews: a behaviorally motivated program of research","C. Sauer; D. R. Jeffery; L. Land; P. Yetton","Templeton Coll., Oxford Univ., UK; NA; NA; NA","IEEE Transactions on Software Engineering","","2000","26","1","1","14","Software engineers use a number of different types of software development technical review (SDTR) for the purpose of detecting defects in software products. This paper applies the behavioral theory of group performance to explain the outcomes of software reviews. A program of empirical research is developed, including propositions to both explain review performance and identify ways of improving review performance based on the specific strengths of individuals and groups. Its contributions are to clarify our understanding of what drives defect detection performance in SDTRs and to set an agenda for future research. In identifying individuals' task expertise as the primary driver of review performance, the research program suggests specific points of leverage for substantially improving review performance. It points to the importance of understanding software reading expertise and implies the need for a reconsideration of existing approaches to managing reviews.","0098-5589;1939-3520;2326-3881","","10.1109/32.825763","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=825763","","Programming;Software quality;Inspection;Management training;Engineering management;Software safety;Costs;Humans;Technology management;Australia","software quality;program testing;program debugging","software development technical reviews;software defect detection;behavioral theory;group performance;research;software reading;software quality","","100","","88","","","","","","IEEE","IEEE Journals & Magazines"
"An Evaluation of Random Testing","J. W. Duran; S. C. Ntafos","Southwest Research Institute, San Antonio, TX 78284.; Division of Mathematics, Computer Science, and Systems Design, University of Texas, San Antonio, TX 78285.; Computer Science Program, University of Texas at Dallas, Richardson, TX 75080.","IEEE Transactions on Software Engineering","","1984","SE-10","4","438","444","Random testing of programs has usually (but not always) been viewed as a worst case of program testing. Testing strategies that take into account the program structure are generally preferred. Path testing is an often proposed ideal for structural testing. Path testing is treated here as an instance of partition testing, where by partition testing is meant any testing scheme which forces execution of at least one test case from each subset of a partition of the input domain. Simulation results are presented which suggest that random testing may often be more cost effective than partition testing schemes. Also, results of actual random testing experiments are presented which confirm the viability of random testing as a useful validation tool.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010257","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010257","Partition testing;path testing;random testing;software testing experiments","Software testing;Costs;Software tools;Performance evaluation;Design methodology;Probability","","","","302","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Management of performance requirements for information systems","B. A. Nixon","Dept. of Comput. Sci., Toronto Univ., Ont., Canada","IEEE Transactions on Software Engineering","","2000","26","12","1122","1146","The management of performance requirements is a major challenge for information systems as well as other software systems. This is because performance requirements can have a global impact on the target system. In addition, there are interactions and trade-offs among performance requirements, other nonfunctional requirements (NFRs), and the numerous alternatives for the target system. To provide a systematic approach to managing performance requirements, this paper presents a performance requirements framework (PeRF). It integrates and catalogues a variety of kinds of knowledge of information systems and performance. These include: performance concepts, software performance engineering principles for building performance into systems, and information systems development knowledge. In addition, layered structures organize performance knowledge and the development process. All this knowledge is represented using an existing goal-oriented approach, the ""NFR framework"", which offers a developer-directed graphical treatment for stating NFRs, analyzing and interrelating them, and determining the impact of decisions upon NFRs. This approach allows customized solutions to be built, taking into account the characteristics of the particular domain. The use of PeRF in managing performance requirements is illustrated in a study of performance requirements and other NFRs for a university student record system. This paper concludes with a summary of other studies of information systems, tool support and directions for future work.","0098-5589;1939-3520;2326-3881","","10.1109/32.888627","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=888627","","Management information systems;Knowledge engineering;Delay;Software quality;Software performance;Information systems;Software systems;Design engineering;Data engineering;Knowledge management","information systems;software performance evaluation;systems analysis;educational administrative data processing;software quality;software management","performance requirements management;information systems;nonfunctional requirements;performance requirements framework;PeRF;performance concepts;software performance engineering principles;systems development knowledge;layered structures;goal-oriented approach;NFR framework;developer-directed graphical treatment;decision impact;customized solutions;university student record system;tool support;requirements engineering;semantic data models;catalogues;Year-2000 compliance","","21","","65","","","","","","IEEE","IEEE Journals & Magazines"
"Test Data Selection and Quality Estimation Based on the Concept of Essential Branches for Path Testing","T. Chusho","Systems Development Laboratory, Hitachi Ltd.","IEEE Transactions on Software Engineering","","1987","SE-13","5","509","517","A new coverage measure is proposed for efficient and effective software testing. The conventional coverage measure for branch testing has such defects as overestimation of software quality and redundant test data selection because all branches are treated equally. These problems can be avoided by paying attention to only those branches essential for path testing. That is, if one branch is executed whenever another particular branch is executed, the former branch is nonessential for path testing. This is because a path covering the latter branch also covers the former branch. Branches other than such nonessential branches will be referred to as essential branches.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233196","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702251","Algorithm;branch testing;control flow graph;coverage measure;path testing;program testing;quality estimation;test data selection","Software testing;Software measurement;Logic testing;Software quality;Flow graphs;Software tools;Linearity;Monitoring;Redundancy;Fluid flow measurement","","Algorithm;branch testing;control flow graph;coverage measure;path testing;program testing;quality estimation;test data selection","","33","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Approximate analysis of open networks of queues with blocking: Tandem configurations","H. G. Perros; T. Altiok","Department of Computer Science, North Carolina State University, Raleigh, NC 27695; Department of Industrial Engineering, Rutgers University, Piscataway, NJ 08854","IEEE Transactions on Software Engineering","","1986","SE-12","3","450","461","An approximation procedure is developed for the analysis of tandem configurations consisting of single server finite queues linked in series. External arrivals occur at the first queue which may be either finite or infinite. Departures from the queuing network may only occur from the last queue. All service times and interarrival times are assumed to be exponentially distributed. The approximation algorithm gives results in the form of the marginal probability distribution of the number of units in each queue of the tandem configuration. Other performance measures, such as mean queue-length and throughput, can be readily obtained. The approximation procedure was validated using exact and simulation data. The approximate results seem to have an acceptable error level.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312886","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312886","Approximations;blocking;Coxian queues;exponential distribution;finite queues;queues in tandem","Servers;Approximation methods;Approximation algorithms;Queueing analysis;Throughput;Algorithm design and analysis;Delay","programming theory;queueing theory","software engineering;open networks;queues;blocking;Tandem configurations;single server finite queues;service times;interarrival times;approximation algorithm;marginal probability distribution;performance measures;mean queue-length;throughput","","16","","","","","","","","IEEE","IEEE Journals & Magazines"
"A learning agent that assists the browsing of software libraries","C. G. Drummond; D. Ionescu; R. C. Holte","Sch. of Inf. Technol. & Eng., Ottawa Univ., Ont., Canada; NA; NA","IEEE Transactions on Software Engineering","","2000","26","12","1179","1196","Locating software items is difficult, even for knowledgeable software designers, when searching in large, complex and continuously growing libraries. This paper describes a technique we term ""active browsing"". An active browser suggests to the designer items it estimates to be close to the target of the search. The novel aspect of active browsing is that it is entirely unobtrusive: it infers its similarity measure from the designer's normal browsing actions, without any special input. Experiments are presented in which the active browsing system succeeds 40% of the time in identifying the target before the designer has found it. An additional experiment indicates that this approach does, indeed, speed up searches.","0098-5589;1939-3520;2326-3881","","10.1109/32.888631","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=888631","","Software libraries;Software design;Programming;Humans;Documentation;Costs;Information retrieval;Power system reliability;Organizing","software libraries;online front-ends;learning (artificial intelligence);software agents;software reusability;user modelling;utility programs","learning agent;software library browsing assistant;software items location;active browsing;similarity measure;search speed;software reuse;software library searching;simulated human users","","17","","47","","","","","","IEEE","IEEE Journals & Magazines"
"A comparison of function point counting techniques","D. R. Jeffery; G. C. Low; M. Barnes","Sch. of Inf. Syst., New Sotuh Wales Univ., Kensington, NSW, Australia; Sch. of Inf. Syst., New Sotuh Wales Univ., Kensington, NSW, Australia; Sch. of Inf. Syst., New Sotuh Wales Univ., Kensington, NSW, Australia","IEEE Transactions on Software Engineering","","1993","19","5","529","532","Effective management of the software development process requires that management be able to estimate total development effort and cost. One of the fundamental problems associated with effort and cost estimation is the a priori estimation of software size. Function point analysis has emerged over the last decade as a popular tool for this task. Criticisms of the method that relate to the way in which function counts are calculated and the impact of the processing complexity adjustment on the function point count have arisen. SPQR/20 function points among others are claimed to overcome some of these criticisms. The SPQR/20 function point method is compared to traditional function point analysis as a measure of software size in an empirical study of MIS environments. In a study of 64 projects in one organization it was found that both methods would appear equally satisfactory. However consistent use of one method should occur since the individual counts differ considerably.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.232016","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=232016","","Size measurement;Software measurement;Software development management;Costs;Productivity;Performance analysis;Programming;Application software;Appropriate technology;Information systems","DP management;project management;software engineering","function point counting techniques;software development process;a priori estimation;software size;processing complexity adjustment;SPQR/20 function points","","54","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Naming and binding in a vertical migration environment","R. I. Winner","Inst. for Defense Anal., Alexandria, VA, USA","IEEE Transactions on Software Engineering","","1988","14","5","599","607","Achieving maximum performance through migration of functions from software to microcode requires rethinking the linkage editing process. An object-oriented model of naming and binding clarifies the alternative abstractions available in naming and linking across the macro-micro machine boundary. Alternative abstractions for sharing micro-objects and for dynamic use of micro-objects are presented and their implementations discussed. The conclusions are based on actual implementations.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6138","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6138","","Couplings;Compaction;Timing;Microprogramming;Processor scheduling;Production;Large Hadron Collider;Dynamic scheduling;Degradation;Programmable logic arrays","data structures;microprogramming;program compilers","compilers;vertical migration environment;maximum performance;microcode;linkage editing process;object-oriented model;naming;binding;abstractions;micro-objects","","","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Deduction graphs: an algorithm and applications","Chao-Chih Yang","Dept. of Comput. Sci., North Texas Univ., Denton, TX, USA","IEEE Transactions on Software Engineering","","1989","15","1","60","67","A deduction graph (DG) for logically deducing a new functional dependency (FD) or function-free Horn formula (extended from Horn clauses) from a subset of a given FDs or function-free headed Horn clauses in a relational database or rule-based expert systems is defined. An algorithm with a polynomial time complexity for constructing a DG based on a number of rules is designed. Applications of DGs to relational databases, rule-based expert systems, logic programming, and artificial intelligence are investigated. In addition to graphically solving the inference problem by DGs, many logic queries can be answered by DGs with substitutions for unifying expressions.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21726","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21726","","Relational databases;Expert systems;Artificial intelligence;Inference algorithms;Polynomials;Algorithm design and analysis;Deductive databases;Control systems;Logic programming;Terminology","database theory;expert systems;inference mechanisms;logic programming;relational databases","deduction graph;functional dependency;function-free Horn formula;Horn clauses;relational database;rule-based expert systems;polynomial time complexity;logic programming;artificial intelligence;inference problem;logic queries","","5","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Modeling of hierarchical distributed systems with fault-tolerance","Y. -. Shieh; D. Ghosal; P. R. Chintamaneni; S. K. Tripathi","IBM Research Triangle Park, NC, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1990","16","4","444","457","Since each of the levels in a hierarchical system could have various characteristics, different fault-tolerant schemes could be appropriate at different levels. A stochastic Petri net (SPN) is used to investigate various fault-tolerant schemes in this context. The basic SPN is augmented by parameterized subnet primitives to model the fault-tolerant schemes. Both centralized and distributed fault-tolerant schemes are considered. The two schemes are investigated by considering the individual levels in a hierarchical system independently. In the case of distributed fault tolerance, two different checkpointing strategies are considered. The first scheme is called the arbitrary checkpointing strategy. Each process in this scheme does its checkpointing independently; thus, the domino effect may occur. The second scheme is called the planned strategy. Here, process checkpointing is constrained to ensure no domino effect. The results show that, under certain conditions, an arbitrary checkpointing strategy can perform better than a planned strategy. The effect of integration on the fault-tolerant strategies of the various levels of a hierarchy are studied.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.54296","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=54296","","Fault tolerant systems;Fault tolerance;Checkpointing;Application software;Costs;LAN interconnection;Manufacturing automation;Stochastic processes;Petri nets;Hierarchical systems","distributed processing;fault tolerant computing;Petri nets","hierarchical distributed systems modelling;fault-tolerance;stochastic Petri net;parameterized subnet primitives;centralized;checkpointing strategies;arbitrary checkpointing strategy;planned strategy","","6","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Formal methods for protocol testing: a detailed study","D. P. Sidhu; T. -. Leung","Dept. of Comput. Sci., Maryland Univ., Baltimore, MD, USA; NA","IEEE Transactions on Software Engineering","","1989","15","4","413","426","The authors present a detailed study of four formal methods (T-, U-, D-, and W-methods) for generating test sequences for protocols. Applications of these methods to the NBS Class 4 Transport Protocol are discussed. An estimation of fault coverage of four protocol-test-sequence generation techniques using Monte Carlo simulation is also presented. The ability of a test sequence to decide whether a protocol implementation conforms to its specification heavily relies on the range of faults that it can capture. Conformance is defined at two levels, namely, weak and strong conformance. This study shows that a test sequence produced by T-method has a poor fault detection capability, whereas test sequences produced by U-, D-, and W-methods have comparable (superior to that for T-method) fault coverage on several classes of randomly generated machines used in this study. Also, some problems with a straightforward application of the four protocol-test-sequence generation methods to real-world communication protocols are pointed out.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.16602","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=16602","","Automatic testing;Computer networks;Software testing;NIST;Communication networks;ISO standards;Transport protocols;Fault detection;Modems","conformance testing;failure analysis;Monte Carlo methods;protocols","protocol testing;test sequences;NBS Class 4 Transport Protocol;fault coverage;protocol-test-sequence generation techniques;Monte Carlo simulation;protocol implementation;fault detection;fault coverage;real-world communication protocols","","192","","26","","","","","","IEEE","IEEE Journals & Magazines"
"An analysis of test data selection criteria using the RELAY model of fault detection","D. J. Richardson; M. C. Thompson","Dept. of Inf. & Comput. Sci., California Univ., Irvine, CA, USA; NA","IEEE Transactions on Software Engineering","","1993","19","6","533","553","RELAY is a model of faults and failures that defines failure conditions, which describe test data for which execution will guarantee that a fault originates erroneous behavior that also transfers through computations and information flow until a failure is revealed. This model of fault detection provides a framework within which other testing criteria's capabilities can be evaluated. Three test data selection criteria that detect faults in six fault classes are analyzed. This analysis shows that none of these criteria is capable of guaranteeing detection for these fault classes and points out two major weaknesses of these criteria. The first weakness is that the criteria do not consider the potential unsatisfiability of their rules. Each criterion includes rules that are sufficient to cause potential failures for some fault classes, yet when such rules are unsatisfiable, many faults may remain undetected. Their second weakness is failure to integrate their proposed rules.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.232020","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=232020","","Data analysis;Relays;Fault detection;Software testing;Failure analysis;Computer science;Data flow computing;Software measurement;Aircraft manufacture;Computer errors","program debugging;program testing;software reliability","test data selection criteria;fault detection;RELAY;failure conditions;erroneous behavior;information flow","","36","","51","","","","","","IEEE","IEEE Journals & Magazines"
"Exception Handling: Formal Specification and Systematic Program Construction","M. Bidoit; B. Biebow; M. -. Gaudel; C. Gresse; G. D. Guiho","Laboratoire de Recherche en Informatique, University of Paris-Sud; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","3","242","252","We present an algebraic specification language (PLUSS) and a program construction method. Programs are built systematically from an algebraic specification of the data they deal with. The method was tested on a realistic problem (part of a telephone switching system). In these experiments, it turned out that error handling was the difficult part to specify and to program. This paper shows how to cope with this problem at the specification level and during the program development process.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232207","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702000","Abstract data types;algebraic specification;decomposition schemes;error handling;industrial experiment;program construction","Formal specifications;Specification languages;System testing;Telephony;Switching systems;Programming profession;Contracts;Construction industry;Context;Manufacturing","","Abstract data types;algebraic specification;decomposition schemes;error handling;industrial experiment;program construction","","2","","20","","","","","","IEEE","IEEE Journals & Magazines"
"A new method of image compression using irreducible covers of maximal rectangles","Y. Cheng; S. S. Iyengara; R. L. Kashyap","Louisiana State Univ., Baton Rouge, LA, USA; Louisiana State Univ., Baton Rouge, LA, USA; NA","IEEE Transactions on Software Engineering","","1988","14","5","651","658","The binary-image-compression problem is analyzed using irreducible cover of maximal rectangles. A bound on the minimum-rectangular-cover problem for image compression is given under certain conditions that previously have not been analyzed. It is demonstrated that for a simply connected image, the irreducible cover proposed uses less than four times the number of the rectangles in a minimum cover. With n pixels in a square, the parallel algorithm for obtaining the irreducible cover uses (n/log n) concurrent-read-exclusive write (CREW) processors in O(log n) time.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6142","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6142","","Image coding;Image analysis;Pixel;Parallel algorithms;Image processing;Length measurement;Particle measurements;Mathematics;Computer science;NP-complete problem","computerised picture processing;data compression;parallel algorithms","data structures;image compression;irreducible covers;maximal rectangles;pixels;parallel algorithm;concurrent-read-exclusive write","","9","","9","","","","","","IEEE","IEEE Journals & Magazines"
"A simplified framework for reduction in strength","K. J. Ottenstein","Dept. of Comput. Sci., Michigan Technol. Univ., Houghton, MI, USA","IEEE Transactions on Software Engineering","","1989","15","1","86","92","Reduction in strength is a traditional transformation for speeding up loop execution on sequential processors. The inverse transformation, induction variable substitution, can also speed up loops by decreasing register requirements, although it is typically a normalizing step in the detection of array dependences by parallelizing compilers. The author presents a simple framework for performing these transformations. In contrast to previous approaches to strength reduction, no unnecessary temporary variables or dead code fragments are introduced, only relevant intermediate language fragments are examined, iteration test replacement is not handled as a special case, and the execution time of the target code is never increased. The method is particularly easy to visualize, making it a useful teaching tool as well.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21730","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21730","","Error analysis;Predictive models;Software systems;Frequency;Equations;Large-scale systems;Testing;Fluctuations;Programming profession;Linear regression","program compilers","loop execution;sequential processors;inverse transformation;induction variable substitution;register requirements;array dependences;parallelizing compilers;language fragments;iteration test replacement;execution time;target code;teaching tool","","1","","20","","","","","","IEEE","IEEE Journals & Magazines"
"A network pump","M. H. Kang; I. S. Moskowitz; D. C. Lee","Naval Res. Lab., Washington, DC, USA; Naval Res. Lab., Washington, DC, USA; Naval Res. Lab., Washington, DC, USA","IEEE Transactions on Software Engineering","","1996","22","5","329","338","A designer of reliable multi level secure (MLS) networks must consider covert channels and denial of service attacks in addition to traditional network performance measures such as throughput, fairness, and reliability. We show how to extend the NRL data Pump to a certain MLS network architecture in order to balance the requirements of congestion control, fairness, good performance, and reliability against those of minimal threats from covert channels and denial of service attacks. We back up our claims with simulation results.","0098-5589;1939-3520;2326-3881","","10.1109/32.502225","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=502225","","Multilevel systems;Computer crime;Information security;Communication system security;B-ISDN;Asynchronous transfer mode;Switches;Throughput;Control systems;Information theory","multi-access systems;security of data","network pump;reliable multi level secure networks;covert channels;network performance measures;NRL data Pump;MLS network architecture;congestion control","","53","","25","","","","","","IEEE","IEEE Journals & Magazines"
"The join algorithms on a shared-memory multiprocessor database machine","G. Z. Qadah; K. B. Irani","Dept. of Electr. Eng. & Comput. Sci., Northwestern Univ., Evanston, IL, USA; NA","IEEE Transactions on Software Engineering","","1988","14","11","1668","1683","The authors develop and present a large set of parallel algorithms for implementing the join operation on a shared-memory multiprocessor database machine. The development of these algorithms follows a structured approach. The major steps involved in the processing of the join operation by the machine are first identified. Then, alternative join algorithms are constructed by concatenating the different ways of performing these steps. A study of the performance of the proposed algorithms is presented. This study shows, among other things, that for a given hardware configuration there is not just one overall best performing join algorithm, but rather different algorithms score the best performance, depending on the characteristics of the data participating in the join operation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9054","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9054","","Database machines;Parallel algorithms;Hardware;Database systems;Computer architecture;Parallel processing;Software systems;Relational databases;Concurrent computing;Data processing","parallel algorithms;parallel architectures;performance evaluation;relational databases;special purpose computers","parallel architectures;relational databases;performance evaluation;join algorithms;shared-memory multiprocessor database machine;parallel algorithms","","23","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Linear complexity assertions for sorting","N. R. Saxena; E. J. McCluskey","HaL Comput. Syst., Campbell, CA, USA; NA","IEEE Transactions on Software Engineering","","1994","20","6","424","431","Correctness of the execution of sorting programs can be checked by two assertions: the order assertion and the permutation assertion. The order assertion checks if the sorted data is in ascending or descending order. The permutation assertion checks if the output data produced by sorting is a permutation of the original input data. Permutation and order assertions are sufficient for the detection of errors in the execution of sorting programs; however, in terms of execution time these assertions cost the same as sorting programs. An assertion, called the order-sum assertion, that has lower execution cost than sorting programs is derived from permutation and order assertions. The reduction in cost is achieved at the expense of incomplete checking. Some metrics are derived to quantify the effectiveness of order-sum assertion under various error models. A natural connection between the effectiveness of the order-sum assertion and the partition theory of numbers is shown. Asymptotic formulae for partition functions are derived.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.295891","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=295891","","Sorting;Computer errors;Error correction;Hardware;Costs;Change detection algorithms;Computer aided instruction;Testing;Counting circuits;Registers","sorting;program debugging;program diagnostics;program verification;programming theory","linear complexity assertions;sorting programs;programs correctness checking;program execution;order assertion;permutation assertion;sorted data;descending order;ascending order;output data;input data;error detection;execution time;order-sum assertion;partition theory;partition functions;error checking;watchdog checker","","4","","12","","","","","","IEEE","IEEE Journals & Magazines"
"On the expected number of failures detected by subdomain testing and random testing","T. Y. Chen; Y. T. Yu","Dept. of Comput. Sci., Melbourne Univ., Parkville, Vic., Australia; Dept. of Comput. Sci., Melbourne Univ., Parkville, Vic., Australia","IEEE Transactions on Software Engineering","","1996","22","2","109","119","We investigate the efficacy of subdomain testing and random testing using the expected number of failures detected (the E-measure) as a measure of effectiveness. Simple as it is, the E-measure does provide a great deal of useful information about the fault detecting capability of testing strategies. With the E-measure, we obtain new characterizations of subdomain testing, including several new conditions that determine whether subdomain testing is more or less effective than random testing. Previously, the efficacy of subdomain testing strategies has been analyzed using the probability of detecting at least one failure (the P-measure) for the special case of disjoint subdomains only. On the contrary, our analysis makes use of the E-measure and considers also the general case in which subdomains may or may not overlap. Furthermore, we discover important relations between the two different measures. From these relations, we also derive corresponding characterizations of subdomain testing in terms of the P-measure.","0098-5589;1939-3520;2326-3881","","10.1109/32.485221","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=485221","","Software testing;System testing;Failure analysis;Computer science;Electronic mail;Fault detection","program testing;software metrics;programming theory","subdomain testing;random testing;expected number;failure detection;E measure;E-measure;fault detecting capability;testing strategies;disjoint subdomains;partition testing;software testing","","81","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Trust requirements and performance of a fast subtransport-level protocol for secure communication","P. V. Rangan","Dept. of Comput. Sci., California Univ., San Diego, CA, USA","IEEE Transactions on Software Engineering","","1993","19","2","181","186","A secure network protocol called the authenticated datagram protocol (ADP) that optimizes the performance of global networks by establishing host-to-host secure channels and building agent-to-agent channels on top of host-to-host channels is presented. The performance advantages of ADP come with an accompanying set of trust requirements that are stringent for a network spanning mutually distrustful organizations. The cause for this stringency is shown to be propagation of trust relationships in ADP. Methods of breaking their propagation and thereby accomplishing a significant reduction in ADP's trust requirements are presented. ADP, being a protocol for establishing host-to-host channels, can be handled at the subtransport level of the protocol hierarchy. A prototype of ADP implemented on Sun workstations connected by an Ethernet is described. Experimental measurements confirm that both the average latency of messages and the maximum throughput are substantially better than other secure protocols.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.214834","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=214834","","Protocols;Cryptography;Public key;Computer networks;Authentication;Privacy;Prototypes;Sun;Workstations;Ethernet networks","data integrity;protocols;security of data","trust requirements;performance;fast subtransport-level protocol;secure communication;authenticated datagram protocol;host-to-host secure channels;agent-to-agent channels;Sun workstations;Ethernet;average latency;maximum throughput","","1","","7","","","","","","IEEE","IEEE Journals & Magazines"
"An automated software design assistant","J. Karimi; B. R. Konsynsky","Coll. of Bus. & Adm., Colorado Univ., Denver, CO, USA; NA","IEEE Transactions on Software Engineering","","1988","14","2","194","210","An automated software design assistant was implemented as a part of a long-term project with the objectives of applying the computer-aided technique to the tools in a software engineering environment. A set of quantitative measures are derived based on the degree to which a particular design satisfied the attributes associated with a structured software design. The measure are then used as decision rules for a computer-aided methodology for structured design. The feasibility of the approach is also demonstrated by a case study using a small application system design problem.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4638","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4638","","Software design;Process design;Software tools;Software measurement;Design methodology;Software engineering;Particle measurements;Application software;Information management","automatic programming;software tools;structured programming","software tools;automated software design assistant;software engineering environment;quantitative measures;structured software design","","7","","40","","","","","","IEEE","IEEE Journals & Magazines"
"TuringTool: a user interface to aid in the software maintenance task","J. R. Cordy; N. L. Eliot; M. G. Robertson","Dept. of Comput. & Inf. Sci., Queen's Univ., Kingston, Ont., Canada; Dept. of Comput. & Inf. Sci., Queen's Univ., Kingston, Ont., Canada; NA","IEEE Transactions on Software Engineering","","1990","16","3","294","301","TuringTool is a source program viewing and editing system specifically designed to support the software maintenance task. TuringTool bases all of its views of the program on a single comprehensive viewing paradigm borrowed from program development environments: source text elision. It is shown how this paradigm can be used to represent several kinds of views appropriate to the maintenance of large source programs, including structural views and nonstructural views appropriate to the maintenance task and how it can be extended to allow dynamic creation of complex programmer-specified views using simple set theoretic operators to combine the effects of several views into one. The system exploits the highly structured nature of the Turing programming language to allow seamless viewing of programs consisting of many separately compiled source modules as one uniform source.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.48937","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=48937","","User interfaces;Software maintenance;Computer languages;Programming environments;Synthesizers;Programming profession;Councils;Tree graphs;Knowledge based systems;Large screen displays","high level languages;programming environments;software engineering;user interfaces","user interface;software maintenance task;source program;editing system;TuringTool;single comprehensive viewing paradigm;program development environments;source text elision;large source programs;structural views;nonstructural views;dynamic creation;complex programmer-specified views;simple set theoretic operators;Turing programming language;seamless viewing;separately compiled source modules;uniform source","","13","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Incremental generation of parsers","J. Heering; P. Klint; J. Rekers","Dept. of Software Technol., Centre for Math. & Comput. Sci., Amsterdam, Netherlands; Dept. of Software Technol., Centre for Math. & Comput. Sci., Amsterdam, Netherlands; Dept. of Software Technol., Centre for Math. & Comput. Sci., Amsterdam, Netherlands","IEEE Transactions on Software Engineering","","1990","16","12","1344","1351","An LR-based parser generator for arbitrary context-free grammars that generates parsers by need and handles modifications to its input grammar by updating the parser it has generated so far is described. The need for these techniques is discussed in the context of interactive language definition environments. All required algorithms are presented. Measurements are given comparing their performance with that of conventional techniques.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.62443","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=62443","","Computer science;Mathematics;Delay","context-free grammars;program compilers","incremental parser generation;LR-based parser generator;arbitrary context-free grammars;input grammar;interactive language definition environments;algorithms;performance;conventional techniques","","13","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Compilation of Nonprocedural Specifications into Computer Programs","N. S. Prywes; A. Pnueli","Department of Computer and Information Science, Moore School, University of Pennsylvania; NA","IEEE Transactions on Software Engineering","","1983","SE-9","3","267","279","The paper describes the compilation of a program specification, written in the very high level nonprocedural MODEL language, into an object, PL/1 or Cobol, procedural language program. Nonprocedural programming languages are descriptive and devoid of procedural controls. They are therefore easier to use and require less programming skills than procedural languages. The MODEL language is briefly presented and illustrated followed by a description of the compilation process. An important early phase in the compilation is the representation of the specification by a dependency graph, denoted as array graph, which expresses the data flow interdependencies between statements. Two classes of algorithms which utilize this graph are next described. The first class checks various completeness, nonambiguity, and consistency aspects of the specification. Upon detecting any problems, the system attempts some automatic correcting measures which are reported to the user, or alternately, when no corrections appear as reasonable, it reports the error and solicits a modification from the user. The second class of algorithms produces an intermediate design of an object program in a language independent form. Finally, PL/1 or Cobol code is generated.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236736","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703054","Automatic program generation;compilers and generators;dataflow languages;nonprocedural languages;program specifications;very high level languages","Algorithm design and analysis;Phased arrays;High level languages;Debugging;Computer languages;Flow graphs;Error correction;Documentation;Program processors;Data structures","","Automatic program generation;compilers and generators;dataflow languages;nonprocedural languages;program specifications;very high level languages","","18","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Edmas: An Object-Oriented, Locally Distributed Mail System","G. T. Almes; C. L. Holman","Department of Computer Science, Rice University; NA","IEEE Transactions on Software Engineering","","1987","SE-13","9","1001","1009","The Eden Project conducts research in the design and implementation of a distributed computing environment for a local area network. A specific goal in designing Eden was to provide users the advantages of both physical distribution and logical integration. Edmas, the Eden mail system, provided an early test of Eden as a base for building distributed applications. This paper discusses Edmas, and shows how Eden's advanced functionality aided us in structuring a distributed mail system, particularly in the areas of replying and distribution lists.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233522","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702322","Capability;concurrent programming;deadlock avoidance;distributed program;Eden;electronic mail;local area network;object-oriented system;remote procedure call","Postal services;Local area networks;Page description languages;Buildings;Computer science;Operating systems;Application software;Testing;Computer languages;Data structures","","Capability;concurrent programming;deadlock avoidance;distributed program;Eden;electronic mail;local area network;object-oriented system;remote procedure call","","3","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Towards banishing the cut from Prolog","S. K. Debray; D. S. Warren","Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA; Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA","IEEE Transactions on Software Engineering","","1990","16","3","335","349","Logic programs can often be inefficient. The usual solution to this problem has been to return some control to the user in the form of impure language features like cut. The authors argue that it is not necessary to resort to such impure features for efficiency. This point is illustrated by considering how most of the common uses of cut can be eliminated from Prolog source programs, relying on static analysis to generate them at compile time. Three common situations where the cut is used are considered. Static analysis techniques are given to detect such situations, and applicable program transformations are described. Two language constructs, firstof and oneof, for situations involving don't-care nondeterminism, are suggested. These constructs have better declarative readings than the cut and extend better to parallel evaluation strategies. Together, these proposals result in a system where users need rely much less on cuts for efficiency, thereby promoting a purer programming style without sacrificing efficiency.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.48941","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=48941","","Logic programming;Computer science;Proposals;Programming profession;Costs","logic programming;PROLOG","logic programs;impure language features;impure features;Prolog source programs;static analysis;compile time;program transformations;language constructs;firstof;oneof;nondeterminism;declarative readings;cut;parallel evaluation strategies;purer programming style","","7","","24","","","","","","IEEE","IEEE Journals & Magazines"
"The cloze procedure and software comprehensibility measurement","W. E. Hall; S. H. Zweben","AT&T Bell Laboratories, 6200 E. Broad St., Columbus, OH 43213; Department of Computer and Information Science, Ohio State University, Columbus, OH 43210","IEEE Transactions on Software Engineering","","1986","SE-12","5","608","623","Cloze tests (i.e. fill-in-missing-parts tests) have been a long-standing measure of prose comprehension. Through human-subject experimentation, evidence was gathered to support the practical advantages of using the cloze procedure for measuring software comprehension. Cloze tests were found to be easy to construct, administer, and score and to be capable of discriminating between programs of varying comprehensibility. However, discrepancies between multiple-choice comprehension quiz results and some cloze test results for the same software suggested that certain forms of software cloze tests may not be valid. A model of software cloze tests was developed to identify a software cloze test characteristic that may produce invalid results. The test characteristic was concerned with the relative proportion of `program-dependent' and `program-independent' cloze items within a test. The developed model was shown to be consistent with software cloze test results of another researcher and led to suggestions for improving software cloze testing.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312957","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312957","Cloze;human-subject experimentation;multiple-choice test;software comprehension;validity","Software;Software measurement;Materials;Testing;Guidelines;Syntactics;Programming","program testing;software reliability","software comprehensibility measurement;prose comprehension;cloze procedure;software cloze testing","","2","","","","","","","","IEEE","IEEE Journals & Magazines"
"PIE: a dynamic failure-based technique","J. M. Voas","Reliable Software Technologies Corp., Arlington, VA, USA","IEEE Transactions on Software Engineering","","1992","18","8","717","727","A dynamic technique called PIE (propagation, infection, and execution) is presented for statistically estimating three program characteristics that affect a program's computational behavior: (1) the probability that a particular section of a program is executed, (2) the probability that the particular section affects the data state, and (3) the probability that a data state produced by that section has an effect on program output. These three characteristics can be used to predict whether faults are likely to be uncovered by software testing.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.153381","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=153381","","Software testing;Genetic mutations;Frequency estimation;State estimation;Automatic testing;Information analysis;Failure analysis;Humans;Fault diagnosis;Councils","program testing","propagation;infection;execution;PIE;dynamic failure-based technique;statistically estimating;program characteristics;computational behavior;data state;software testing","","187","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Managing conflicts in goal-driven requirements engineering","A. van Lamsweerde; R. Darimont; E. Letier","Dept. d'Ingeniere Inf., Univ. Catholique de Louvain, Belgium; NA; NA","IEEE Transactions on Software Engineering","","1998","24","11","908","926","A wide range of inconsistencies can arise during requirements engineering as goals and requirements are elicited from multiple stakeholders. Resolving such inconsistencies sooner or later in the process is a necessary condition for successful development of the software implementing those requirements. The paper first reviews the main types of inconsistency that can arise during requirements elaboration, defining them in an integrated framework and exploring their interrelationships. It then concentrates on the specific case of conflicting formulations of goals and requirements among different stakeholder viewpoints or within a single viewpoint. A frequent, weaker form of conflict called divergence is introduced and studied in depth. Formal techniques and heuristics are proposed for detecting conflicts and divergences from specifications of goals/requirements and of domain properties. Various techniques are then discussed for resolving conflicts and divergences systematically by the introduction of new goals or by transforming the specifications of goals/objects toward conflict-free versions. Numerous examples are given throughout the paper to illustrate the practical relevance of the concepts and techniques presented. The latter are discussed in the framework of the KAOS methodology for goal-driven requirements engineering.","0098-5589;1939-3520;2326-3881","","10.1109/32.730542","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=730542","","Engineering management;Humans;Labeling","formal specification;configuration management","conflict management;goal-driven requirements engineering;multiple stakeholders;inconsistencies;software development;requirements elaboration;integrated framework;requirements interrelationships;conflicting formulations;stakeholder viewpoints;divergence;formal techniques;heuristics;conflict detection;specification divergence;domain properties;conflict-free versions;KAOS methodology;specification transformation;lightweight formal methods","","235","","57","","","","","","IEEE","IEEE Journals & Magazines"
"Asymptotic analysis of a heterogeneous multiprocessor system in a randomly changing environment","J. Sztrik; D. Kouvatsos","Dept. of Comput., Bradford Univ., UK; Dept. of Comput., Bradford Univ., UK","IEEE Transactions on Software Engineering","","1991","17","10","1069","1075","An asymptotic queuing theoretic approach is proposed to analyze the performance of an FCFS (first-come, first-served) heterogeneous multiprocessor computer system with a single bus operating in a randomly changing environment. All stochastic times in the system are considered to be exponentially distributed and independent of the random environment, while the access and service rates of the processors are subject to random fluctuations. It is shown under the assumption of 'fast' arrivals that the busy period length of the bus converges weakly, under appropriate normalization, to an exponentially distributed random variable. As a consequence, main steady-state performance measures such as system throughput, mean delay time, expected waiting time, and mean number of active processors can be approximately determined. The reliability of the proposed method is validated by comparing the new approximations with known exact results.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.99194","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=99194","","Multiprocessing systems;Queueing analysis;Performance analysis;Stochastic systems;Fluctuations;Random variables;Steady-state;Time measurement;Throughput;Delay systems","multiprocessing systems;performance evaluation;queueing theory;stochastic processes","asymptotic queuing theoretic approach;FCFS;heterogeneous multiprocessor computer system;randomly changing environment;stochastic times;random environment;service rates;busy period length;bus;exponentially distributed random variable;steady-state performance measures;system throughput;mean delay time;expected waiting time;reliability","","7","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Adaptive load sharing in homogeneous distributed systems","D. L. Eager; E. D. Lazowska; J. Zahorjan","Department of Computational Science, University of Saskatchewan, Sask. S7N 0W0, Canada; Department of Computer Science, University of Washington, Seattle, WA 98195; Department of Computer Science, University of Washington, Seattle, WA 98195","IEEE Transactions on Software Engineering","","1986","SE-12","5","662","675","Rather than proposing a specific load sharing policy for implementation, the authors address the more fundamental question of the appropriate level of complexity for load sharing policies. It is shown that extremely simple adaptive load sharing policies, which collect very small amounts of system state information and which use this information in very simple ways, yield dramatic performance improvements. These policies in fact yield performance close to that expected from more complex policies whose viability is questionable. It is concluded that simple policies offer the greatest promise in practice, because of their combination of nearly optimal performance and inherent stability.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312961","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312961","Design;load sharing;local area networks;performance;queueing models;threshold policies","Load modeling;Adaptation models;Analytical models;Program processors;Time factors;Probes;Adaptive systems","distributed processing","load sharing;homogeneous distributed systems;system state information;performance improvements;optimal performance;inherent stability","","307","","","","","","","","IEEE","IEEE Journals & Magazines"
"Numerical operations on a relational database","S. P. Ghosh","IBM Almaden Res. Center, San Jose, CA, USA","IEEE Transactions on Software Engineering","","1989","15","5","600","610","The problem is discussed of defining numerical operations on a relational database to accommodate the statistical analyses associated with a bivariate frequency table. An attempt has been made to extend Codd's relational algebra to include simple bivariate statistical operations preserving the closure of Codd's algebra. This extended algebra is applied to bivariate relational data structures needed for real-time automatic statistical quality control of a manufacturing process. Also discussed are some new category-numeric operations on relational tables.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24709","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24709","","Relational databases;Algebra;Statistical analysis;Frequency;Data structures;Quality control;Set theory;Geometry;Database languages","database theory;relational databases;statistical analysis","Codd;relational database;numerical operations;statistical analyses;bivariate frequency table;relational algebra;bivariate statistical operations;bivariate relational data structures;real-time automatic statistical quality control;manufacturing process;category-numeric operations;relational tables","","3","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Applying Formal Specification to Software Development in Industry","I. J. Hayes","Programming Research Group, Computing Laboratory, Oxford University","IEEE Transactions on Software Engineering","","1985","SE-11","2","169","178","This paper reports experience gained in applying formal specification techniques to an existing transaction processing system. The system is the IBM Customer Information Control System (CICS) and the work has concentrated on specifying a number of modules of the CICS application programmer's interface.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232191","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701984","CICS;formal specification;large scale software","Formal specifications;Computer industry;Control systems;Application software;Electrical equipment industry;Programming profession;Large-scale systems;Communication system control;Transaction databases;Operating systems","","CICS;formal specification;large scale software","","28","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Evaluating testing methods by delivered reliability [software]","P. G. Frankl; R. G. Hamlet; B. Littlewood; L. Strigini","CIS Dept., Polytech.. Univ., Brooklyn, NY, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","8","586","601","There are two main goals in testing software: (1) to achieve adequate quality (debug testing), where the objective is to probe the software for defects so that these can be removed, and (2) to assess existing quality (operational testing), where the objective is to gain confidence that the software is reliable. Debug methods tend to ignore random selection of test data from an operational profile, while for operational methods this selection is all-important. Debug methods are thought to be good at uncovering defects so that these can be repaired, but having done so they do not provide a technically defensible assessment of the reliability that results. On the other hand, operational methods provide accurate assessment, but may not be as useful for achieving reliability. This paper examines the relationship between the two testing goals, using a probabilistic analysis. We define simple models of programs and their testing, and try to answer the question of how to attain program reliability: is it better to test by probing for defects as in debug testing, or to assess reliability directly as in operational testing? Testing methods are compared in a model where program failures are detected and the software changed to eliminate them. The ""better"" method delivers higher reliability after all test failures have been eliminated. Special cases are exhibited in which each kind of testing is superior. An analysis of the distribution of the delivered reliability indicates that even simple models have unusual statistical properties, suggesting caution in interpreting theoretical comparisons.","0098-5589;1939-3520;2326-3881","","10.1109/32.707695","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=707695","","Software testing;Software debugging;System testing;Computer bugs;Software quality;Reliability theory;Probes;Costs;Battery powered vehicles;Accidents","program testing;software reliability;program debugging;software quality;probability","software testing method evaluation;delivered software reliability;software quality;debug testing;software defects;operational testing;random test data selection;accurate assessment;probabilistic analysis;program failure detection;software modification;statistical properties;statistical testing theory","","47","","26","","","","","","IEEE","IEEE Journals & Magazines"
"An efficient distributed protocol for finding shortest paths in networks with negative weights","K. B. Lakshmanan; K. Thulasiraman; M. A. Comeau","Dept. of Comput. Sci., Concordia Univ., Montreal, Que., Canada; Dept. of Comput. Sci., Concordia Univ., Montreal, Que., Canada; NA","IEEE Transactions on Software Engineering","","1989","15","5","639","644","The design is discussed of distributed algorithms for the single-source shortest-path problem to run on an asynchronous directed network in which some of the edges may be associated with negative weights, and thus in which a cycle of negative total weight may also exist. The only existing solution in the literature for this problem is due to K.M. Chandy and J. Misra (1982), and it has, in the worst case, an unbounded message complexity. A synchronous version of the Chandy-Misra algorithm is described and studied, and it is proved that for a network with m edges and n nodes, the worst case message and time complexities of this algorithm are O(mn) and O(n), respectively. This algorithm is then combined with an efficient synchronizer to yield an asynchronous protocol that retains the same message and time complexities.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24713","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24713","","Protocols;Intelligent networks;Distributed algorithms;Algorithm design and analysis;Computer networks;Councils;Computer science;Distributed computing","computational complexity;directed graphs;distributed processing;protocols","efficient distributed protocol;negative weights;distributed algorithms;single-source shortest-path problem;asynchronous directed network;edges;cycle;worst case;unbounded message complexity;synchronous version;Chandy-Misra algorithm;nodes;time complexities;efficient synchronizer;asynchronous protocol","","10","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Axiomatizing software test data adequacy","E. J. Weyuker","Department of Computer Science, Courant Institute of Mathematical Sciences, New York University, New York, NY 10012","IEEE Transactions on Software Engineering","","1986","SE-12","12","1128","1138","A test data adequacy criterion is a set of rules used to determine whether or not sufficient testing has been performed. A general axiomatic theory of test data adequacy is developed, and five previously proposed adequacy criteria are examined to see which of the axioms are satisfied. It is shown that the axioms are consistent, but that only two of the criteria satisfy all of the axioms.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313008","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313008","Software testing;test data adequacy","Testing;Vectors;Syntactics;Shape;Positron emission tomography;Semantics;Software","program testing;programming theory","software test data;test data adequacy;axiomatic theory","","49","","","","","","","","IEEE","IEEE Journals & Magazines"
"Mawl: a domain-specific language for form-based services","D. L. Atkins; T. Ball; G. Bruns; K. Cox","Lucent Technol., Bell Labs., Naperville, IL, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1999","25","3","334","346","A form-based service is one in which the flow of data between service and user is described by a sequence of query/response interactions, or forms. Mawl is a domain-specific language for programming form-based services in a device-independent manner. We focus on Mawl's form abstraction, which is the means for separating service logic from user interface description, and show how this simple abstraction addresses seven issues in service creation, analysis, and maintenance: compile-time guarantees, implementation flexibility, rapid prototyping, testing and validation, support for multiple devices, composition of services, and usage analysis.","0098-5589;1939-3520;2326-3881","","10.1109/32.798323","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=798323","","Domain specific languages;DSL;Web services;Telephony;User interfaces;HTML;Software engineering;Logic testing;Computer languages;Computer Society","high level languages;software prototyping;program testing;software maintenance;program verification;distributed programming;information resources","Mawl;domain-specific language;form-based services;data flow;query/response interaction sequence;device-independent programming;form abstraction;service logic;user interface description;service creation;service analysis;service maintenance;compile-time guarantees;implementation flexibility;rapid prototyping;testing;validation;multiple device support;usage analysis","","30","","23","","","","","","IEEE","IEEE Journals & Magazines"
"On the Optimal Selection of Multilist Database Structures","M. Hatzopoulos; J. G. Kollias","Department of Mathematical and Computer Sciences, Michigan Technological University, Houghton, MI 49931.; Department of Electrical Engineering, Division of Computer Science, National Technical University of Athens, Athens 624, Greece.","IEEE Transactions on Software Engineering","","1984","SE-10","6","681","687","The optimal selection of secondary indexes asks for the quantitative evaluation of the performance of a number of candidate secondary indexes in order to determine the particular combination of indexes which satisfies the anticipated user transactions at a minimal cost. Previous studies determine the optimal selection by assuming that the cost of satisfying a query using a secondary index is not affected by the existence of other indexes in the database. This assumption is realistic when the inverted file organization is used to organize secondary indexes. The main reason is that inverted files do not alter the size of the file. However, the assumption is not valid when the next most popular method for structuring secondary indexes is used, namely, the multilist database structures. This is so, because each multilist increases the size of the file. This paper studies the secondary index selection problem by making the assumption that the multilist organization is utilized to structure secondary indexes and develops a dynamic programming algorithm to solve it. The practical significance of the study lies in the fact that multilists can be easily implemented on network databases.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010296","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010296","Database performance;multilist file organization;optimization algorithm;optimization model;performance optimization;physical database design;secondary index selection","Transaction databases;Indexes;Cost function;Qualifications;Optimization;Indexing;Information processing;Magnetic heads;Application software;Information retrieval","","","","5","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Heterogeneous Data Translations Based on Environment Grammars","M. Ruschitzka","Division of Computer Science, Department of Electrical Engineering and Computer Science, University of California. Davis, CA 95616.","IEEE Transactions on Software Engineering","","1989","15","10","1236","1251","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1989.559774","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=559774","","Software systems;Database systems;Hardware;Relational databases;Computer science;Software maintenance;Mars;Prototypes;Communications technology;Workstations","","design Methodology;environment grammars;heterogenous computer systems;parsing;proprietary data formats;relational database management systems;syntax-driven data translation","","4","","43","","","","","","IEEE","IEEE Journals & Magazines"
"Principles of Program Design Induced from Experience with Small Public Programs","D. Comer","Department of Computer Sciences, Purdue University","IEEE Transactions on Software Engineering","","1981","SE-7","2","169","174","The art of programming is taught, learned, and often practiced as if programs are disposable, personal objects owned, solely by the programmer. This paper uses examples to illustrate why real software is neither personal nor disposable; it shows how even simple programs are shared by others. From the examples, the paper extracts four principles for program development. Finally, it draws conclusions about programming practices and the education of programmers.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230832","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702823","Programming;software design;software engineering","Programming profession;Software maintenance;Military computing;Productivity;Art;Software engineering;Guidelines;Educational products;Educational programs;Software design","","Programming;software design;software engineering","","","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Superviews: Virtual Integration of Multiple Databases","A. Motro","Department of Computer Science, University of Southern California","IEEE Transactions on Software Engineering","","1987","SE-13","7","785","798","An important advantage of a database system is that it provides each application with a custom view of the data. The issue addressed in this paper is how to provide such custom views to applications that access multiple databases. The paper describes a formal method that generates such superviews, in an interactive process of schema editing operations. A mapping of the superview into the individual databases is derived from the editing process, and is stored together with the superview as a virtual database. When this database is interrogated, the mapping is used to decompose each query into a set of queries against the individual databases, and recompose the answers to form an answer to the original query. As this process is transparent to the user, virtual databases may be regarded as a more general type of databases. A prototype database system, that allows users to construct virtual databases and interrogate them, has been developed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233490","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702290","Database;database integration;database view;multidatabase environment;query mapping;superview;virtual database","Relational databases;Database systems;Transaction databases;Virtual prototyping;Application software;Maintenance engineering;Computer science","","Database;database integration;database view;multidatabase environment;query mapping;superview;virtual database","","43","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Specification and validation of a security policy model","A. Boswell","Logica Cambridge Ltd., UK","IEEE Transactions on Software Engineering","","1995","21","2","63","68","The paper describes the development of a formal security policy model in Z for the NATO Air Command and Control System (ACCS): a large, distributed, multilevel-secure system. The model was subject to manual validation, and some of the issues and lessons in both writing and validating the model are discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.345822","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=345822","","Information security;Access control;Computer security;Communication system security;Command and control systems;Writing;Certification;Costs;Production;Cryptography","command and control systems;aerospace control;aircraft computers;specification languages;formal specification;program verification;security of data","specification;validation;security policy model;formal security policy model;Z;NATO Air Command and Control System;multilevel-secure syste;manual validation","","11","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Completeness of Proof Systems for Equational Specifications","D. B. MacQueen; D. T. Sannella","AT&amp;amp;T Bell Laboratories; NA","IEEE Transactions on Software Engineering","","1985","SE-11","5","454","461","Contrary to popular belief, equational logic with induction is not complete for initial models of equational specifications. Indeed, under some regimes (the Clear specification language and most other algebraic specification languages) no proof system exists which is complete even with respect to ground equations. A collection of known results is presented along with some new observations.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232484","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702035","Algebraic specifications;equational logic;proof systems","Equations;Algebra;Specification languages;Councils;Computer science;Automatic logic units;Logic functions;Artificial intelligence","","Algebraic specifications;equational logic;proof systems","","","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Efficient branch-and-bound algorithms on a two-level memory system","C. -. Yu; B. W. Wah","Intel Corp., Santa Clara, CA, USA; NA","IEEE Transactions on Software Engineering","","1988","14","9","1342","1356","Branch-and-bound algorithms in a system with a two-level memory hierarchy were evaluated. An efficient implementation depends on the disparities in the numbers of subproblems expanded between the depth-first and best-first searches as well as the relative speeds of the main and secondary memories. A best-first search should be used when it expands a much smaller number of subproblems than that of a depth-first search, and the secondary memory is relatively slow. In contrast, a depth-first search should be used when the number of expanded subproblems is close to that of a best-first search. The choice is not as clear for cases in between these cases are studied. Two strategies are proposed and analyzed: a specialized virtual-memory system that matches the architectural design with the characteristics of the existing algorithm, and a modified branch-and-bound algorithm that can be tuned to the characteristic of the problem and the architecture. The latter strategy illustrates that designing a better algorithm is sometimes more effective that tuning the architecture alone.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6177","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6177","","Partitioning algorithms;Algorithm design and analysis;Iterative algorithms;Cost function;Guidelines;Artificial intelligence;Operations research;Search problems;Expert systems","storage allocation;storage management;virtual storage","branch-and-bound algorithms;two-level memory system;best-first search;depth-first search;virtual-memory","","9","","43","","","","","","IEEE","IEEE Journals & Magazines"
"Debugging a Distributed Computing System","H. Garcia-Molina; F. Germano; W. H. Kohler","Department of Electrical Engineering and Computer Science, Princeton University, Princeton, NJ 08540.; Apollo Computers, Inc., Chelmsford, MA 01824.; Department of Electrical and Computer Engineering, University of Massachusetts, Amherst, MA 01002; Digital Equipment Corporation, Hudson, MA 01749.","IEEE Transactions on Software Engineering","","1984","SE-10","2","210","219","In this paper we discuss the issues involved in debugging a provide distributed computing system. We describe the major differences between debugging a distributed system and debugging a sequential program. We suggest a methodology for distributed debugging, and we propose various tools or aids.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010224","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010224","Bottom-up debugging;debugging;distributed computing system;monitoring;tracing;two-phase debugging","Distributed computing;Programming profession;Hardware;Computer bugs;Software debugging;Database systems;Management information systems;System software;Monitoring;System testing","","","","47","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Support for reusability in Genesis","C. V. Ramamoorthy; V. Garg; A. Prakash","Div. of Comput. Sci., California Univ., Berkeley, CA, USA; Div. of Comput. Sci., California Univ., Berkeley, CA, USA; Div. of Comput. Sci., California Univ., Berkeley, CA, USA","IEEE Transactions on Software Engineering","","1988","14","8","1145","1154","Genesis is a software-engineering-based programming environment geared to support big software projects. The authors first discuss a reusability-driven development methodology that advocates software development based on reusability considerations. Then, they discuss the tools and techniques provided in Genesis to support this methodology. Techniques are suggested for improving the retrievability, composability, and understandability of software resources. Retrievability is improved by use of ESL (entity specification language) for tying resources through attributes and relations. Composability is improved through a mechanism called functional composition that provides considerably more generality than Unix pipes for composing programs. Understandability is improved by the use of program abstractors.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.7625","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=7625","","Programming profession;Computer bugs;Specification languages;Software reusability;Writing;Programming environments;Productivity;Software systems;Computer interfaces;Software design","database management systems;file organisation;programming environments;query languages;software tools;specification languages","software reusability;software reuse;software tools;file organisation;databases;query languages;Genesis;programming environment;reusability-driven development methodology;software development;software resources;ESL;entity specification language;functional composition;program abstractors","","21","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Incremental scanning and parsing with galaxy","J. F. Beetem; A. F. Beetem","Dept. of Electr. & Comput. Eng., Wisconsin Univ., Madison, WI, USA; NA","IEEE Transactions on Software Engineering","","1991","17","7","641","651","The algorithms and techniques used in incremental scanning and parsing of the Galaxy language are presented. Incremental compilers, programming environments that feature instantaneous change processing as well as the execution time efficiency of compiled programs and code development using the Galaxy language are discussed. It is shown that the algorithms guarantee minimal rescanning and reparsing are space and time efficient and are easily adapted to any language of equivalent class, including such languages as C and Pascal.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.83901","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=83901","","Productivity;Programming environments;Software engineering;Programming profession;Software tools;Software algorithms;Environmental economics;National electric code;Application software;Sampling methods","high level languages;program compilers;programming environments","incremental scanning;parsing;Galaxy language;programming environments;instantaneous change processing;execution time efficiency;compiled programs;code development;algorithms;minimal rescanning;reparsing;time efficient;C;Pascal","","5","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Miro: visual specification of security","A. Heydon; M. W. Maimone; J. D. Tygar; J. M. Wing; A. M. Zaremski","Sch. of Comput. Sci., Carnegie-Mellon Univ., Pittsburgh, PA, USA; Sch. of Comput. Sci., Carnegie-Mellon Univ., Pittsburgh, PA, USA; Sch. of Comput. Sci., Carnegie-Mellon Univ., Pittsburgh, PA, USA; Sch. of Comput. Sci., Carnegie-Mellon Univ., Pittsburgh, PA, USA; Sch. of Comput. Sci., Carnegie-Mellon Univ., Pittsburgh, PA, USA","IEEE Transactions on Software Engineering","","1990","16","10","1185","1197","Miro is a set of languages and tools that support the visual specification of file system security. Two visual languages are presented: the instance language, which allows specification of file system access, and the constraint language, which allows specification of security policies. Miro visual languages and tools are used to specify security configurations. A visual language is one whose entities are graphical, such as boxes and arrows, specifying means stating independently of any implementation the desired properties of a system. Security means file system protection: ensuring that files are protected from unauthorized access and granting privileges to some users, but not others. Tools implemented and examples of how these languages can be applied to real security specification problems are described.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.60298","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=60298","","Security;File systems;Protection;Contracts;Visualization;Operating systems;Control systems;Data structures;Computer displays","security of data;specification languages;visual programming","Miro;visual specification of security;file system security;instance language;constraint language;tools;boxes;arrows;security specification problems","","17","","23","","","","","","IEEE","IEEE Journals & Magazines"
"The SL synchronous language","F. Boussinot; R. de Simone","CMA, Ecole des Mines de Paris, Valbonne, France; NA","IEEE Transactions on Software Engineering","","1996","22","4","256","266","We present SL, a new programming language of the synchronous reactive family in which hypotheses about signal presence/absence are disallowed. One can decide that a signal is absent during an instant only at the end of this instant, and so reaction to this absence is delayed to the next instant. Sources of causal circularities are avoided, while only weak preemption remains. A structural operational semantics is provided through rewrite rules, and an implementation is described. In addition to directly executing programs, this implementation can also be used to produce automata by symbolic evaluation.","0098-5589;1939-3520;2326-3881","","10.1109/32.491649","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=491649","","Automata;Computer languages;Resumes;TV broadcasting;Delay;Concurrent computing;Program processors;Equations;Radio control;Protocols","computational linguistics;rewriting systems;grammars;specification languages;parallel languages;parallel programming;program compilers","SL synchronous language;programming language;synchronous reactive languages;signal presence;signal absence;weak preemption;structural operational semantics;rewrite rules;direct program execution;automata;symbolic evaluation","","30","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Automatic symbolic verification of embedded systems","R. Alur; T. A. Henzinger; Pei-Hsin Ho","Comput. Syst. Res. Center, AT&T Bell Labs., Murray Hill, NJ, USA; NA; NA","IEEE Transactions on Software Engineering","","1996","22","3","181","201","Presents a model-checking procedure and its implementation for the automatic verification of embedded systems. The system components are described as hybrid automata-communicating machines with finite control and real-valued variables that represent continuous environment parameters such as time, pressure and temperature. The system requirements are specified in a temporal logic with stop-watches, and verified by symbolic fixpoint computation. The verification procedure-implemented in the Cornell Hybrid Technology tool, HyTech-applies to hybrid automata whose continuous dynamics is governed by linear constraints on the variables and their derivatives. We illustrate the method and the tool by checking safety, liveness, time-bounded and duration requirements of digital controllers, schedulers and distributed algorithms.","0098-5589;1939-3520;2326-3881","","10.1109/32.489079","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=489079","","Embedded system;Automatic control;Pressure control;Temperature control;Control systems;Logic;Automata;Safety;Digital control;Distributed control","real-time systems;formal verification;temporal logic;finite state machines;software tools","automatic symbolic verification;real-time systems;embedded systems;model-checking procedure;hybrid automata;communicating machines;finite control;real-valued variables;continuous environment parameters;temporal logic;stop-watches;symbolic fixpoint computation;hybrid technology tool;HyTech;continuous dynamics;linear constraints;variable derivatives;safety checking;liveness;time-bounded requirements;duration requirements;digital controllers;schedulers;distributed algorithms","","253","","","","","","","","IEEE","IEEE Journals & Magazines"
"Parallel discrete event simulation using shared memory","D. A. Reed; A. D. Malony; B. D. McCredie","Illinois Univ., Urbana, IL, USA; Illinois Univ., Urbana, IL, USA; Illinois Univ., Urbana, IL, USA","IEEE Transactions on Software Engineering","","1988","14","4","541","553","With traditional event-list techniques, evaluating a detailed discrete event simulation-model can often require hours or even days of computation time. By eliminating the event list and maintaining only sufficient synchronization to ensure causality, parallel simulation can potentially provide speedups that are linear in the numbers of processors. A set of shared-memory experiments using the Chandy-Misra distributed simulation algorithm, to simulate networks of queues is presented. Parameters of the study include queueing network topology and routing probabilities, number of processors, and assignment of network nodes to processors. These experiments show that Chandy-Misra distributed simulation is a questionable alternative to sequential simulation of most queuing network models.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4677","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4677","","Discrete event simulation;Computational modeling;Circuit simulation;Analytical models;Computer simulation;Network topology;Parallel processing;Computer networks;Concurrent computing;Routing","digital simulation;parallel processing;performance evaluation;queueing theory","deadlock recovery;parallel processing;performance evaluation;shared memory;discrete event simulation-model;synchronization;parallel simulation;Chandy-Misra distributed simulation algorithm;queueing network topology;routing probabilities","","41","","27","","","","","","IEEE","IEEE Journals & Magazines"
"A Simulation Study of the Vertical-Migration Microprocessor Architecture","V. Milutinovic","School of Electrical Engineering, Purdue University","IEEE Transactions on Software Engineering","","1987","SE-13","12","1265","1277","Vertical-migration microprocessor architecture was introduced in [1], and results of its analytical study were presented in the same paper. This paper presents results of its simulation study which is based on selected production benchmarks. Vertical-migration architecture enables the constructs typical of HLL's to be mapped into the constructs typical of microcode. This mapping is provided only for selected types of HLL statements and for HLL statements with a relatively small number of operands and parameters, i.e., for-the most frequent HLL constructs. Using an extended subset of Fortran 77, one that matches the typical demands of the targeted application, i.e., dedicated microprocessing, it has been shown how the proposed architecture supports the mapping of HLL constructs into microinstructions. That was done through the description of a flexible register-transfer level simulator which was implemented to support this study. It was used to run benchmarks, typical of various applications, on various configurations of the architecture. Simulation study has shown that this approach is particularly suitable for the time-critical dedicated signal processing and robotics/control applications, as well as for the GaAs implementation.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232880","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702178","Dedicated microprocessing;microprocessor architecture;vertical-migration architecture","Microprocessors;Computer architecture;Application software;Time factors;Signal processing;Hardware;Virtual manufacturing;Production;Computational modeling;Robots","","Dedicated microprocessing;microprocessor architecture;vertical-migration architecture","","1","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Comments analysis and programming errors","W. E. Howden","Dept. of Comput. Sci. & Eng., California Univ., La Jolla, CA, USA","IEEE Transactions on Software Engineering","","1990","16","1","72","81","Software validation is treated as the problem of detecting errors that programmers make during the software development process. This includes fault detection, in which the focus is on techniques for detecting the occurrence of local errors that result in well-defined classes of program statement faults. It also includes detecting other kinds of errors, such as decomposition errors. The main focus of the work is on a decomposition-error analysis technique called comments analysis. In this technique, errors are detected by analyzing special classes of program comments. Comments analysis has been applied to a variety of systems, including a data-processing program and an avionics real-time program. The use of comments analysis for sequential and concurrent systems is discussed, and the basic features of comments analysis tools are summarized. The relationship of comments analysis to other techniques, such as event sequence analysis, is discussed, and the differences between it and earlier work are explained.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44365","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44365","","Error analysis;Testing;Programming profession;Fault detection;Data processing;Real time systems;Genetic mutations;Aerospace electronics;Arithmetic;Computer science","software engineering","comments analysis;software validation;programming errors;software development process;fault detection;decomposition errors;data-processing program;avionics real-time program;event sequence analysis","","10","","23","","","","","","IEEE","IEEE Journals & Magazines"
"State Restoration in Systems of Communicating Processes","D. L. Russell","Bell Laboratories","IEEE Transactions on Software Engineering","","1980","SE-6","2","183","194","In systems of asynchronous processes using messagelists with SENDRECEIVE primitives for interprocess communication recovery primitives are defined to perform state restoration: MARK saves a particular point in the execution of the program; RESTORE resets the system state to an earlier point (saved by MARK); and PURGE discards redundant information when it is no longer needed for possible state restoration.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230469","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702715","Backup;domino effect;error recovery;parallel back-tracking;process communication;recovery blocks;state restoration","Hardware;Data structures;Sufficient conditions;Software systems;Aging;Resumes;Database systems;Computer science;System testing","","Backup;domino effect;error recovery;parallel back-tracking;process communication;recovery blocks;state restoration","","88","","16","","","","","","IEEE","IEEE Journals & Magazines"
"An Evaluation of Two New Inference Control Methods","Y. H. Chin; Weng-Ling Peng","Institute of Computer and Decision Science, National Tsing Hua University; NA","IEEE Transactions on Software Engineering","","1987","SE-13","12","1329","1339","An evaluation method is developed to measure the cost/ effectiveness of two new inference control methods. The factors of the evaluation function consist of: 1) preparation cost for the control method, 2) query complexity, and 3) security level under various attacks. Each control method combines the merit of some popular concepts; the first method is based on restriction, and the second on perturbation. Simulation results indicate that both methods have higher preparation cost, better security, and faster response time than Cox's method and Beck's method. Finally these two new methods are compared to each other.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233143","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702182","Cell suppression;cost factors;data perturbation;evaluation methods;inference control;partitioning;query-set-size control;random-sample-query control;security;statistical database","Control systems;Data security;Cost function;Delay;Information security;Protection;Hospitals;Relational databases","","Cell suppression;cost factors;data perturbation;evaluation methods;inference control;partitioning;query-set-size control;random-sample-query control;security;statistical database","","","","35","","","","","","IEEE","IEEE Journals & Magazines"
"A new approach to the modeling of recovery block structures","G. Pucci","Comput. Lab., Newcastle-upon-Tyne Univ., UK","IEEE Transactions on Software Engineering","","1992","18","2","159","167","A reliability model is proposed for recovery block structures based on error events which can be observed and distinguished during testing. Strategies are then described for the collection of failure histories needed to estimate the model parameters and obtain dependability predictions. Given that the software goes through different testing stages, the model can be employed at different points of the development cycle to assess or forecast the quality of project choices and the resulting product.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.121757","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=121757","","Redundancy;Fault tolerance;Predictive models;Software testing;Software reliability;History;Software quality;Humans;Organizing;Hardware","program testing;reliability theory;software reliability;system recovery","reliability model;recovery block structures;error events;failure histories;model parameters;dependability predictions;testing stages;development cycle;project choices","","11","","26","","","","","","IEEE","IEEE Journals & Magazines"
"The automatic generation of load test suites and the assessment of the resulting software","A. Avritzer; E. R. Weyuker","AT&T Bell Labs., Red Hill, NJ, USA; NA","IEEE Transactions on Software Engineering","","1995","21","9","705","716","Three automatic test case generation algorithms intended to test the resource allocation mechanisms of telecommunications software systems are introduced. Although these techniques were specifically designed for testing telecommunications software, they can be used to generate test cases for any software system that is modelable by a Markov chain provided operational profile data can either be collected or estimated. These algorithms have been used successfully to perform load testing for several real industrial software systems. Experience generating test suites for five such systems is presented. Early experience with the algorithms indicate that they are highly effective at detecting subtle faults that would have been likely to be missed if load testing had been done in the more traditional way, using hand-crafted test cases. A domain-based reliability measure is applied to systems after the load testing algorithms have been used to generate test data. Data are presented for the same five industrial telecommunications systems in order to track the reliability as a function of the degree of system degradation experienced.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.464549","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=464549","","Automatic testing;System testing;Software testing;Software systems;Software algorithms;Resource management;Performance evaluation;Computer industry;Fault detection;Communication industry","program testing;automatic test software;software reliability;Markov processes;resource allocation;telecommunication computing","automatic test case generation algorithms;load test suites;resource allocation mechanisms;telecommunications software;software testing;Markov chain;load testing;industrial software systems;fault detection;domain-based reliability measure;reliability;system degradation","","84","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Requirements validation through viewpoint resolution","J. C. S. P. Leite; P. A. Freeman","Dept. de Inf., Pontificia Univ. Catolica do Rio de Janeiro, Brazil; NA","IEEE Transactions on Software Engineering","","1991","17","12","1253","1269","A specific technique-viewpoint resolution-is proposed as a means of providing early validation of the requirements for a complex system, and some initial empirical evidence of the effectiveness of a semi-automated implementation of the technique is provided. The technique is based on the fact that software requirements can and should be elicited from different viewpoints, and that examination of the differences resulting from them can be used as a way of assisting in the early validation of requirements. A language for expressing views from different viewpoints and a set of analogy heuristics for performing a syntactically oriented analysis of views are proposed. This analysis of views is capable of differentiating between missing information and conflicting information, thus providing support for viewpoint resolution.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.106986","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=106986","","Biomedical engineering;Systems engineering and theory;Performance analysis;Information analysis;Knowledge engineering;Packaging;Software systems;Vacuum systems;Patient monitoring;Airplanes","software engineering;systems analysis","viewpoint resolution;software requirements;analogy heuristics;syntactically oriented analysis of views","","101","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Internet Locus: Extending transparency to an Internet environment","A. B. Sheltzer; G. J. Popek","Department of Computer Science, University of California, Los Angeles, CA 90024; Department of Computer Science, University of California, Los Angeles, CA 90024; Locus Computing Corporation, Santa Monica, CA","IEEE Transactions on Software Engineering","","1986","SE-12","11","1067","1075","Network transparency refers to the ability of a distributed system to hide machine boundaries from people and application programs; i.e. all resources are accessed in the same manner, independent of their locations. It is demonstrated that transparency across a long-haul network is both highly desirable and technically feasible. A case study of the transparent, distributed operating system Locus, extended to operate transparently across an internet system that includes long-haul links, is discussed at length. New protocols, distributed cache management, and process execution site selection are all used to achieve the results reported.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312996","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312996","Internet Locus;long haul network;network transparency","Internet;Delay;Operating systems;Local area networks;Protocols;Logic gates;Bandwidth","computer networks;distributed processing;file organisation;operating systems (computers);protocols","network transparency;distributed system;machine boundaries;application programs;distributed operating system;Locus;internet system;protocols;distributed cache management","","1","","","","","","","","IEEE","IEEE Journals & Magazines"
"Database Integrity Block Construct: Concepts and Design Issues","L. Lilien; B. Bhargava","Department of Electrical Engineering and Computer Science, University of Illinois; NA","IEEE Transactions on Software Engineering","","1985","SE-11","9","865","885","When a crash occurs in a transaction processing system, the database can enter an unacceptable state. To continue the processing, the recovery system has three tasks: 1) verification of the database state for acceptability, 2) restoration of an acceptable database state, and 3) restoration of an acceptable history of transaction processing. Unfortunately these tasks are not trivial and the computational complexity of the algorithms for most of them is either NP-complete or NP-hard. In this paper we discuss the concepts and design issues of a construct called database integrity block (DIB). The implementation of this construct allows for efficient verification of the database state by employing a set of integrity assertions and restoration of transaction history by utilizing any database restoration technique such as audit trail or differential file. This paper presents approximation algorithms for minimizing the costs of evaluation of integrity assertions by modeling the problem as the directed traveling salesman problem, and presents a methodology to compare the costs of audit trail and differential file techniques for database restoration. The applicability of integrity verification research to the problem of multiple-query optimization is also included.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232546","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702106","Approximation algorithms;audit trail;database crash and recovery;database system;differential file;directed traveling salesman problem;NP-completeness;query optimization;semantic database integrity;software fault-tolerance","Transaction databases;History;Computer crashes;Error correction;Costs;Traveling salesman problems;Database systems;Fault tolerant systems;Computational complexity;Approximation algorithms","","Approximation algorithms;audit trail;database crash and recovery;database system;differential file;directed traveling salesman problem;NP-completeness;query optimization;semantic database integrity;software fault-tolerance","","","","54","","","","","","IEEE","IEEE Journals & Magazines"
"An economic model to estimate software rewriting and replacement times","Taizan Chan; Siu Leung Chung; Teck Hua Ho","Nat. Univ. of Singapore, Singapore; NA; NA","IEEE Transactions on Software Engineering","","1996","22","8","580","598","The effort required to service maintenance requests on a software system increases as the software system ages and deteriorates. Thus, it may be economical to replace an aged software system with a freshly written one to contain the escalating cost of maintenance. We develop a normative model of software maintenance and replacement effort that enables us to study the optimal policies for software replacement. Based on both analytical and simulation solutions, we determine the timings of software rewriting and replacement, and hence the schedule of rewriting, as well as the size of the rewriting team as functions of the: user environment, effectiveness of rewriting, technology platform, development quality, software familiarity, and maintenance quality of the existing and the new software systems. Among other things, we show that a volatile user environment often leads to a delayed rewriting and an early replacement (i.e., a compressed development schedule). On the other hand, a greater familiarity with either the existing or the new software system allows for a less-compressed development schedule. In addition, we also show that potential savings from rewriting will be higher if the new software system is developed with a superior technology platform, if programmers' familiarity with the new software system is greater, and if the software system is rewritten with a higher initial quality.","0098-5589;1939-3520;2326-3881","","10.1109/32.536958","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=536958","","Software systems;Software maintenance;Environmental economics;Software quality;Aging;Costs;Analytical models;Timing;Delay;Programming profession","software cost estimation;economics;software maintenance;software development management;software quality;human resource management","economic model;software rewriting time estimation;software replacement time estimation;normative model;software maintenance;optimal policies;simulation;rewriting schedule;user environment;technology platform;development quality;software familiarity;software quality;project management","","23","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Formal derivation of rule-based programs","G. -. Roma; R. F. Gamble; W. E. Ball","Dept. of Comput. Sci., Washington Univ., St. Louis, MO, USA; NA; NA","IEEE Transactions on Software Engineering","","1993","19","3","277","296","It is shown that a combination of specification and program refinement may be applied to deriving efficient concurrent rule-based programs. Specification refinement is used to generate an initial rule-based program that is refined into a program which is highly concurrent and efficient. This program derivation strategy is divided into two major tasks. The first task relies on specification refinement. Techniques similar to those employed in the derivation of UNITY programs are used to produce a correct rule-based program having a static knowledge base. The second task involves program refinement and is specific to the development of concurrent rule-based programs. It relies heavily on the availability of a computational model, such as Swarm, that has the ability to dynamically restructure the knowledge base. The ways in which a Swarm program can be translated to OPS5 specifically, given some restrictions, while maintaining the correctness criteria are discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.221138","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=221138","","Parallel processing;Concurrent computing;Formal specifications;Logic programming;Expert systems;Refining;Formal verification;Parallel programming;Hardware;Parallel algorithms","formal specification;knowledge based systems;logic programming;parallel programming","program refinement;efficient concurrent rule-based programs;initial rule-based program;program derivation strategy;specification refinement;UNITY programs;correct rule-based program;static knowledge base;computational model;Swarm;OPS5;correctness criteria","","8","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Stochastic Modeling of Branch-and-Bound Algorithms with Best-First Search","B. W. Wah; Chee Fen Yu","Department of Electrical and Computer Engineering and the Coordinated Science Laboratory, University of Illinois; NA","IEEE Transactions on Software Engineering","","1985","SE-11","9","922","934","Branch-and-bound algorithms are organized and intelligently structured searches of solutions in a combinatorially large problem space. In this paper, we propose an approximate stochastic model of branch-and-bound algorithms with a best-first search. We have estimated the average memory space required and have predicted the average number of subproblems expanded before the process terminates. Both measures are exponentials of sublinear exponent. In addition, we have also compared the number of subproblems expanded in a best-first search to that expanded in a depth-first search. Depth-first search has been found to have computational complexity comparable to best-first search when the lower-bound function is very accurate or very inaccurate; otherwise, best-fit search is usually better. The results obtained are useful in studying the efficient evaluation of branch-and-bound algorithms in a virtual memory environment. They also confirm that approximations are very effective in reducing the total number of iterations.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232550","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702110","Approximations;best-first search;branch-and-bound algorithms;depth-first search;iterations;memory space;subproblem","Stochastic processes;Partitioning algorithms;Constraint optimization;Intelligent structures;Computational complexity;Artificial intelligence;Operations research;Search problems;Expert systems","","Approximations;best-first search;branch-and-bound algorithms;depth-first search;iterations;memory space;subproblem","","12","","35","","","","","","IEEE","IEEE Journals & Magazines"
"An examination of fault exposure ratio","Y. K. Malaiya; A. von Mayrhauser; P. K. Srimani","Dept. of Comput. Sci., Colorado State Univ., Fort Collins, CO, USA; Dept. of Comput. Sci., Colorado State Univ., Fort Collins, CO, USA; Dept. of Comput. Sci., Colorado State Univ., Fort Collins, CO, USA","IEEE Transactions on Software Engineering","","1993","19","11","1087","1094","The fault exposure ratio, K, is an important factor that controls the per-fault hazard rate, and hence, the effectiveness of the testing of software. The authors examine the variations of K with fault density, which declines with testing time. Because faults become harder to find, K should decline if testing is strictly random. However, it is shown that at lower fault densities K tends to increase. This is explained using the hypothesis that real testing is more efficient than strictly random testing especially at the end of the test phase. Data sets from several different projects (in USA and Japan) are analyzed. When the two factors, e.g., shift in the detectability profile and the nonrandomness of testing, are combined the analysis leads to the logarithmic model that is known to have superior predictive capability.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.256855","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=256855","","Hazards;Software reliability;Fault detection;Density measurement;Software testing;USA Councils;Predictive models;Neural networks;Debugging","program testing;software reliability","fault exposure ratio;per-fault hazard rate;software testing;detectability profile;logarithmic model;predictive capability;software reliability;fault density","","31","","29","","","","","","IEEE","IEEE Journals & Magazines"
"An experimental evaluation of the assumption of independence in multiversion programming","J. C. Knight; N. G. Leveson","Department of Computer Science, University of Virginia, Charlottesville, VA 22903; Department of Computer Science, University of California, Irvine, CA 92717","IEEE Transactions on Software Engineering","","1986","SE-12","1","96","109","<i>N</i>-version programming has been proposed as a method of incorporating fault tolerance into software. Multiple versions of a program (i.e. `<i>N</i>') are prepared and executed in parallel. Their outputs are collected and examined by a voter, and, if they are not identical, it is assumed that the majority is correct. This method depends for its reliability improvement on the assumption that programs that have been developed independently will fail independently. An experiment is described in which the fundamental axiom is tested. In all, 27 versions of a program were prepared independently from the same specification at two universities and then subjected to one million tests. The results of the tests revealed that the programs were individually extremely reliable but that the number of tests in which more than one program failed was substantially more than expected. The results of these tests are presented along with an analysis of some of the faults that were found in the programs. Background information on the programmers used is also summarized.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312924","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312924","Design diversity;fault-tolerant software;multiversion programming;N-version programming;software reliability","Programming;Software;Educational institutions;Software reliability;NASA","fault tolerant computing;programming;software reliability","independence;multiversion programming;N-version programming;fault tolerance;voter;reliability improvement","","205","","","","","","","","IEEE","IEEE Journals & Magazines"
"A decompositional approach to the design of parallel programs","Ying Liu; A. K. Singh; R. L. Bagrodia","Dept. of Comput. Sci., California Univ., Santa Barbara, CA, USA; Dept. of Comput. Sci., California Univ., Santa Barbara, CA, USA; NA","IEEE Transactions on Software Engineering","","1994","20","12","914","932","A methodology for the derivation of parallel implementations from program specifications is developed. The goal of the methodology is to decompose a program specification into a collection of module specifications via property refinement, such that each module may be implemented independently by a subprogram. The correctness of the implementation is then deduced from the correctness of the property refinement procedure and the correctness of the individual subprograms. The refinement strategy is based on identifying frequently occurring control structures such as sequential composition and iteration. The methodology is developed in the context of the UNITY logic and the UC programming language, and illustrated through the solution of diffusion aggregation in fluid flow simulations.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.368135","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=368135","","Computer languages;Computer science;Fluid flow control;Logic programming;Fluid flow;Context modeling;Algorithm design and analysis","complete computer programs;program control structures;parallel programming;formal specification;program verification;flow simulation;digital simulation;diffusion;physics computing","decompositional approach;parallel program design;program specifications;parallel implementation correctness;module specifications;frequently occurring control structures;subprograms;property refinement procedure;sequential composition;iteration;UNITY logic;UC programming language;diffusion aggregation;fluid flow simulations","","2","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Research on Knowledge-Based Software Environments at Kestrel Institute","D. R. Smith; G. B. Kotik; S. J. Westfold","Kestrel Institute; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","11","1278","1295","We present a summary of the CHI project conducted at Kestrel Institute through mid-1984. The objective of this project was to perform research on knowledge-based software environments. Toward this end, key portions of a prototype environment, called CHI, were built that established the feasibility of this approach. One result of this research was the development of a wide-spectrum language that could be used to express all stages of the program development process in the system. Another result was that the prototype compiler was used to synthesize itself from very-high-level description of itself. In this way the system was bootstrapped. We describe the overall nature of the work done on this project, give highlights of implemented prototypes, and describe the implications that this work suggests for the future of software engineering. In addition to this historical perspective, current research projects at Kestrel Institute as well as commercial applications of the technology at Reasoning Systems are briefly surveyed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231879","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701947","Automatic programming;knowledge-based systems;program synthesis;programming environments;software environments very-high-level languages;wide-spectrum languages","Software prototyping;Prototypes;Programming profession;Software performance;Application software;Logic programming;Software engineering;Knowledge based systems;Programming environments;Hardware","","Automatic programming;knowledge-based systems;program synthesis;programming environments;software environments very-high-level languages;wide-spectrum languages","","75","","49","","","","","","IEEE","IEEE Journals & Magazines"
"Loop monotonic statements","M. Spezialetti; R. Gupta","Packard Lab., Lehigh Univ., Bethlehem, PA, USA; NA","IEEE Transactions on Software Engineering","","1995","21","6","497","505","A statement is considered to be monotonic with respect to a loop if its execution, during the successive iterations of a given execution of the loop, assigns a monotonically increasing or decreasing sequence of values to a variable. We present static analysis techniques to identify loop monotonic statements. The knowledge of loop monotonicity characteristics of statements which compute array subscript expressions is of significant value in a number of applications. We illustrate the use of this information in improving the efficiency of run-time array bound checking, run-time dependence testing, and on-the-fly detection of access anomalies. Given that a significant percentage of subscript expressions are monotonic, substantial savings can be expected by using these techniques.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.391376","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=391376","","Runtime;Testing;Computer Society;Parallel processing;Program processors;Computer science;Performance evaluation","program diagnostics;parallel programming;parallelising compilers;program control structures","loop monotonic statements;successive iterations;static analysis techniques;loop monotonicity characteristics;array subscript expressions;run-time array bound checking;run-time dependence testing;on-the-fly detection;access anomalies;array bound checking;run-time dependence checking;static analysis;induction variables;data races","","5","","19","","","","","","IEEE","IEEE Journals & Magazines"
"A Mathematical Model for the Comparison of Static and Dynamic Memory Allocation in a Paged System","G. Jomier","Research Group on Computer Systems Modeling","IEEE Transactions on Software Engineering","","1981","SE-7","4","375","385","In this paper we compare the two classical memory allocation policies in a multiprogrammed system with paged memory: a static policy based on prepaging and a dynamic policy using page allocation on demand. The two policies are modeled by networks of queues.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234540","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702858","Demand paging;paging;performance;prepaging;queueing models","Mathematical model;Delay;Modeling;Memory management;Time sharing computer systems;Guidelines;Telecommunication traffic;Traffic control;Computer networks;Robustness","","Demand paging;paging;performance;prepaging;queueing models","","1","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Design of reliable software in distributed systems using the conversation scheme","A. M. Tyrrell; D. J. Holding","Department of Electrical, Electronic, and Systems Engineering, Coventry (Lanchester) Polytechnic, Coventry CV1 5FB, England; Department of Electrical and Electronic Engineering and Applied Physics, Aston University, Birmingham B4 7ET, England","IEEE Transactions on Software Engineering","","1986","SE-12","9","921","928","The problems of error detection and recovery are examined in a number of concurrent processes expressed as a set of communicating sequential processes (CSP). A method is proposed which uses a Petri net model to formally identify both the state and the state reachability tree of a distributed system. These are used to define systematically the boundaries of a conversation, including the recovery and test lines which are essential parts of the fault-tolerant mechanism. The techniques are implemented using the OCCAM programming language, which is derived from CSP. The application of this method is shown by a control example.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313047","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313047","Communicating sequential processes;concurrent processes;conversation;distributed systems;fault-tolerant software;occam;Petri nets;recovery block","Process control;Robot kinematics;Petri nets;Software;Computer languages;Synchronous motors","distributed processing;error detection","error recovery;reliable software;distributed systems;conversation scheme;error detection;concurrent processes;communicating sequential processes;CSP;Petri net model;state reachability tree;distributed system;fault-tolerant mechanism;OCCAM programming language;CSP;control example","","9","","","","","","","","IEEE","IEEE Journals & Magazines"
"Communication and organization: an empirical study of discussion in inspection meetings","C. B. Seaman; V. R. Basili","Inst. for Adv. Comput. Studies, Maryland Univ., College Park, MD, USA; NA","IEEE Transactions on Software Engineering","","1998","24","7","559","572","This paper describes an empirical study that addresses the issue of communication among members of a software development organization. In particular, data was collected concerning code inspections in one software development project. The question of interest is whether or not organizational structure (the network of relationships between developers) has an effect on the amount of effort expended on communication between developers. The independent variables in this study are various attributes of the organizational structure in which the inspection participants work. The dependent variables are measures of the communication effort expended in various parts of the code inspection process, focusing on the inspection meeting. Both quantitative and qualitative methods were used, including participant observation, structured interviews, generation of hypotheses from field notes, statistical tests of relationships, and interpretation of results with qualitative anecdotes. The study results show that past and present working relationships between inspection participants affect the amount of meeting time spent in different types of discussion, thus affecting the overall inspection meeting length. Reporting relationships and physical proximity also have an effect. The contribution of the study is a set of well-supported hypotheses for further investigation.","0098-5589;1939-3520;2326-3881","","10.1109/32.708569","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=708569","","Inspection;Programming;Productivity;Testing;Information processing;Context;Professional communication;Software engineering","software development management","inspection meetings;software development organization;software development project;organizational structure;inspection participants;communication effort;code inspection process","","34","","21","","","","","","IEEE","IEEE Journals & Magazines"
"The Role of Domain Expenence in Software Design","B. Adelson; E. Soloway","Department of Computer Science, Yale University, New Haven, CT 06520, and the Division of Information Science and Technology, National Science Foundation; NA","IEEE Transactions on Software Engineering","","1985","SE-11","11","1351","1360","A designer's expertise rests on the knowledge and skills which develop with experience in a domain. As a result, when a designer is designing an object in an unfamiliar domain he will not have the same knowledge and skills available to him as when he is designing an object in a familiar domain. In this paper we look at the software designer's underlying constellation of knowledge and skills, and at the way in which this constellation is dependent upon experience in a domain. What skills drop out, what skills, or interactions of skills come forward as experience with the domain changes? To answer the above question, we studied expert designers in experimentally created design contexts with which they were differentially familiar. In this paper we describe the knowledge and skills we found were central to each of the above contexts and discuss the functional utility of each. In addition to discussing the knowledge and skills we observed in expert designers, we will also compare novice and expert behavior.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231883","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701951","Artificial intelligence;cognitive models;cognitive science;software design","Software design;Protocols;Computer science;Cognitive science;Information science;Problem-solving","","Artificial intelligence;cognitive models;cognitive science;software design","","45","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Comparing detection methods for software requirements inspections: a replicated experiment","A. A. Porter; L. G. Votta; V. R. Basili","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; NA; NA","IEEE Transactions on Software Engineering","","1995","21","6","563","575","Software requirements specifications (SRS) are often validated manually. One such process is inspection, in which several reviewers independently analyze all or part of the specification and search for faults. These faults are then collected at a meeting of the reviewers and author(s). Usually, reviewers use Ad Hoc or Checklist methods to uncover faults. These methods force all reviewers to rely on nonsystematic techniques to search for a wide variety of faults. We hypothesize that a Scenario-based method, in which each reviewer uses different, systematic techniques to search for different, specific classes of faults, will have a significantly higher success rate. We evaluated this hypothesis using a 3/spl times/2/sup 4/ partial factorial, randomized experimental design. Forty eight graduate students in computer science participated in the experiment. They were assembled into sixteen, three-person teams. Each team inspected two SRS using some combination of Ad Hoc, Checklist or Scenario methods. For each inspection we performed four measurements: (1) individual fault detection rate, (2) team fault detection rate, (3) percentage of faults first identified at the collection meeting (meeting gain rate), and (4) percentage of faults first identified by an individual, but never reported at the collection meeting (meeting loss rate). The experimental results are that (1) the Scenario method had a higher fault detection rate than either Ad Hoc or Checklist methods, (2) Scenario reviewers were more effective at detecting the faults their scenarios are designed to uncover, and were no less effective at detecting other faults than both Ad Hoc or Checklist reviewers, (3) Checklist reviewers were no more effective than Ad Hoc reviewers, and (4) Collection meetings produced no net improvement in the fault detection rate-meeting gains were offset by meeting losses.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.391380","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=391380","","Inspection;Fault detection;Fault diagnosis;Design for experiments;Computer science;Assembly;Performance evaluation;Gain measurement;Loss measurement;Performance gain","formal specification;formal verification;software development management","detection methods;software requirements inspections;replicated experiment;software requirements specifications;nonsystematic techniques;scenario-based method;individual fault detection rate;team fault detection rate;fault detection rate","","178","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Proofs of Networks of Processes","J. Misra; K. M. Chandy","Department of Computer Sciences, University of Texas; NA","IEEE Transactions on Software Engineering","","1981","SE-7","4","417","426","We present a proof method for networks of processes in which component processes communicate exclusively through messages. We show how to construct proofs of invariant properties which hold at all times during network computation, and terminal properties which hold upon termination of network computation, if network computation terminates. The proof method is based upon specifying a process by a pair of assertions, analogous to pre-and post-conditions in sequential program proving. The correctness of network specification is proven by applying inference rules to the specifications of component processes. Several examples are proved using this technique.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230844","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702862","Communication networks;distributed systems;message passing systems;program proofs","Computer networks;Message passing;System performance;Computer languages","","Communication networks;distributed systems;message passing systems;program proofs","","222","","13","","","","","","IEEE","IEEE Journals & Magazines"
"A statistical methodology for the study of the software failure process and its application to the ARGOS center","R. Troy; Y. Romain","Verilog S.A., 3, Chemin du Pigeonnier de la C&#x00E9;pi&#x00E8;re, 31081 Toulouse Cedex, France; Verilog S.A., 3, Chemin du Pigeonnier de la C&#x00E9;pi&#x00E8;re, 31081 Toulouse Cedex, France","IEEE Transactions on Software Engineering","","1986","SE-12","9","968","978","The authors propose a stepwise statistical methodology for the study of operating system reliability and associated tools. An example of the application of this method for the ARGOS data processing center of France's CNES is presented. It is shown that each evaluation of software reliability is considered as a special case. Two major consequences are that the reliability models need improvement and that every evaluation must be supported by a statistical analysis of the product and process characteristics.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313051","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313051","Software failure;software reliability;software reliability models","Software;Software reliability;Reliability theory;Hardware;Iris;Environmental factors","operating systems (computers);software reliability;statistical analysis","software failure process;ARGOS center;stepwise statistical methodology;operating system reliability;ARGOS data processing center;CNES;software reliability;reliability models;statistical analysis","","4","","","","","","","","IEEE","IEEE Journals & Magazines"
"TUNEX: a knowledge-based system for performance tuning of the UNIX operating system","B. Samadi","AT&T Bell Labs., Holmdel, NJ, USA","IEEE Transactions on Software Engineering","","1989","15","7","861","874","TUNEX, an expert system developed for performance tuning of the UNIX operating system, is described. TUNEX was developed on UNIX system V. It uses the properties, commands and utilities of this version. The tuning activities it is concerned with include: (1) adjusting operating system tunable parameters, such as number of disk buffers; (2) running maintenance routines, i.e. reorganizing file systems; (3) developing operation rules, such as off-peak hour runs of backups; and (4) modifying hardware, buying an additional disk drive. The structure of TUNEX is presented and performance analysis modules which provide quantitative information to this tool are briefly described. The overhead in the resource usage introduced by the performance monitoring and tuning tool itself is discussed; the author points to the areas in which additional resources are required by TUNEX.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.29486","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=29486","","Knowledge based systems;Operating systems;Expert systems;Performance analysis;Encoding;Computerized monitoring;Prototypes;File systems;Hardware;Disk drives","expert systems;Unix","TUNEX;knowledge-based system;performance tuning;UNIX operating system;expert system;UNIX system V;commands;utilities;disk buffers;maintenance routines;reorganizing file systems;operation rules;performance monitoring","","7","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Static Data Flow Analysis of PL/I Programs with the PROBE System","R. F. Sarraga","Department of Computer Science, General Motors Research Laboratories, Warren, MI 48090.","IEEE Transactions on Software Engineering","","1984","SE-10","4","451","459","An experimental data flow analyzer for PL/I programs has been implemented within the PROBE system developed at the GM Research Laboratories. PROBE is an experimental software package that examines the internal structure of PL/I programs in order to expose error-prone design and programming features. This paper describes 1) the algorithms and data structures used by the data flow analyzer, 2) the salient aspects of PL/I usage in the analyzed production-level programs, and 3) the results of the data flow analysis.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010259","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010259","Anomalous variable use;computer software measurement;data flow analysis;PL/I;programming practices","Data analysis;Probes;Performance analysis;Laboratories;Software tools;Software prototyping;Testing;Documentation;Pattern analysis;Algorithm design and analysis","","","","7","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Implementation of an FP-Shell","Y. H. Kamath; M. M. Matthews","AT&T Bell Laboratories; NA","IEEE Transactions on Software Engineering","","1987","SE-13","5","532","539","One of the best features of the UNIX Shell is that it provides a framework which can be used to build complex programs by interconnecting existing simple programs. However, it is limited to linear combinations of programs, and building of more complex programs must be accomplished by executing sequences of commands. This paper introduces Backus' FP (Functional Programming) as an alternative command language for UNIX. In FP, programs are true functions and another distinctive feature of FP languages is that they contain functional forms, which are constructs for combining programs to build new programs. Also, the functional style of programming provides a natural way of exploiting parallel machine architecture.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233198","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702253","Command language;functional language;functional programming environment;shells;UNIX","Functional programming;Central Processing Unit;LAN interconnection;Buildings;Command languages;Parallel programming;Parallel machines;Computer architecture;Concurrent computing;Computer science","","Command language;functional language;functional programming environment;shells;UNIX","","","","22","","","","","","IEEE","IEEE Journals & Magazines"
"The external Heapsort","L. M. Wegner; J. I. Teuhola","Univ.-GH-Kassel, West Germany; NA","IEEE Transactions on Software Engineering","","1989","15","7","917","925","Heapsort is an internal sorting method which sorts an array of n records in place in O(n log n) time. Heapsort is generally considered unsuitable for external random-access sorting. By replacing key comparisons with merge operations on pages, it is shown how to obtain an in-place external sort which requires O(m log m) page references, where m is the number of pages which the file occupies. The new sort method (called Hillsort) has several useful properties for advanced database management systems. Not only does Hillsort operate in place, i.e., no additional external storage space is required assuming that the page table can be kept in core memory, but accesses to adjacent pages in the heap require one seek only if the pages are physically contiguous. The authors define the Hillsort model of computation for external random-access sorting, develop the complete algorithm and then prove it correct. The model is next refined and a buffer management concept is introduced so as to reduce the number of merge operations and page references, and make the method competitive to a basic balanced two-way external merge. Performance characteristics are noted such as the worst-case upper bound, which can be carried over from Heapsort, and the average-case behavior, deduced from experimental findings. It is shown that the refined version of the algorithm which is on a par with the external merge sort.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.29490","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=29490","","Sorting;Database systems;Turning;Merging;Prototypes;Computer science;Resumes;Computational modeling;Upper bound","sorting;storage management","performance characteristics;external Heapsort;sorting method;random-access sorting;Hillsort;database management systems;page table;buffer management concept;merge operations;page references;worst-case upper bound","","12","","21","","","","","","IEEE","IEEE Journals & Magazines"
"A framework for specification-based testing","P. Stocks; D. Carrington","Dept. of Comput. Sci., Rutgers Univ., Piscataway, NJ, USA; NA","IEEE Transactions on Software Engineering","","1996","22","11","777","793","Test templates and a test template framework are introduced as useful concepts in specification-based testing. The framework can be defined using any model-based specification notation and used to derive tests from model-based specifications-in this paper, it is demonstrated using the Z notation. The framework formally defines test data sets and their relation to the operations in a specification and to other test data sets, providing structure to the testing process. Flexibility is preserved, so that many testing strategies can be used. Important application areas of the framework are discussed, including refinement of test data, regression testing, and test oracles.","0098-5589;1939-3520;2326-3881","","10.1109/32.553698","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=553698","","Software testing;Application software;Formal specifications;Computer science;Life testing;Object oriented modeling;Computer Society;Programming;Performance evaluation;Software design","formal specification;program testing;specification languages;statistical analysis","specification-based testing;test templates;model-based specification notation;test oracles;Z notation;test data sets;test data refinement;regression testing","","127","","41","","","","","","IEEE","IEEE Journals & Magazines"
"The delay due to dynamic two-phase locking","C. S. Hartzman","Dept. of Math., Stat. & Comput. Sci., Dalhousie Univ., Halifax, NS, Canada","IEEE Transactions on Software Engineering","","1989","15","1","72","82","An analytic formula for the delay due to two-phase locking is developed in terms of mean values for the input parameters using an open queuing network model in equilibrium. The results of simulations, using various realistic probability distributions governing the number of locks that transactions request, are presented to validate the formula. Reasonably good accuracy is achieved for gamma distributions over a wide range of parameter settings. The simulations also provided evidence that the rate of deadlock, often disregarded in the literature, can be high in certain heavily utilized databases.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21728","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21728","","Concurrency control;Transaction databases;Delay effects;Analytical models;Queueing analysis;Probability distribution;Mathematics;Statistical distributions;System recovery;Costs","database theory;distributed databases;queueing theory","dynamic two-phase locking;open queuing network model;probability distributions;gamma distributions;parameter settings;heavily utilized databases","","7","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Integrated concurrency-coherency controls for multisystem data sharing","D. M. Dias; B. R. Iyer; J. T. Robinson; P. S. Yu","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA","IEEE Transactions on Software Engineering","","1989","15","4","437","448","The authors propose an integrated control mechanism and analyze the performance gain due to its use. An extension to the data sharing system structure is examined in which a shared intermediate memory is used for buffering and for early commit processing. Read-write-synchronization and write-serialization problems arise. The authors show how the integrated concurrency protocol can be used to overcome both problems. A queueing model is used to quantify the performance improvement. Although using intermediate memory as a buffering device produces a moderate performance benefit, the analysis shows that more substantial gains can be realized when this technique is combined with the use of an integrated concurrency-coherency control protocol.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.16604","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=16604","","Control systems;Access protocols;Concurrent computing;Centralized control;Performance analysis;Concurrency control;Costs;Computer buffers;Performance gain;Microprocessors","buffer storage;concurrency control;distributed databases;performance evaluation;protocols;queueing theory","read-write synchronisation;performance analysis;multisystem data sharing;data sharing system structure;shared intermediate memory;buffering;early commit processing;write-serialization;integrated concurrency protocol;queueing model;integrated concurrency-coherency control protocol","","27","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Use of common time base for checkpointing and rollback recovery in a distributed system","P. Ramanathan; K. G. Shin","Dept. of Electr. & Comput. Eng., Wisconsin Univ., Madison, WI, USA; NA","IEEE Transactions on Software Engineering","","1993","19","6","571","583","An approach to checkpointing and rollback recovery in a distributed computing system using a common time base is proposed. A common time base is established in the system using a hardware clock synchronization algorithm. This common time base is coupled with the idea of pseudo-recovery points to develop a checkpointing algorithm that has the following advantages: reduced wait for commitment for establishing recovery lines, fewer messages to be exchanged, and less memory requirement. These advantages are assessed quantitatively by developing a probabilistic model.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.232022","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=232022","","Checkpointing;Testing;Real time systems;Clocks;Synchronization;Distributed computing;Hardware;Fault tolerant systems;Resumes;NASA","distributed processing;fault tolerant computing;system recovery","message exchange;distributed system;checkpointing;rollback recovery;common time base;hardware clock synchronization algorithm;pseudo-recovery points;recovery lines;memory requirement;probabilistic model","","19","","16","","","","","","IEEE","IEEE Journals & Magazines"
"The Modular Structure of Complex Systems","D. L. Parnas; P. C. Clements; D. M. Weiss","University of Victoria, Victoria, B.C., Canada, and the Computer Science and Systems Branch, U.S. Naval Research Laboratory; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","3","259","266","This paper discusses the organization of software that is inherently complex because of very many arbitrary details that must be precisely right for the software to be correct. We show how the software design technique known as information hiding, or abstraction, can be supplemented by a hierarchically structured document, which we call a module guide. The guide is intended to allow both designers and maintainers to identify easily the parts of the software that they must understand, without reading irrelevant details about other parts of the software. The paper includes an extract from a software module guide to illustrate our proposals.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232209","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702002","Abstract interfaces;information hiding;modular structure of software;software engineering","Software engineering;Software maintenance;Laboratories;Project management;Software design;Data mining;Proposals;Computer industry;Documentation;Application software","","Abstract interfaces;information hiding;modular structure of software;software engineering","","139","","10","","","","","","IEEE","IEEE Journals & Magazines"
"A visual user interface for map information retrieval based on semantic significance","M. Tanaka; T. Ichikawa","Dept. of Inf. Syst., Hiroshima Univ., Japan; Dept. of Inf. Syst., Hiroshima Univ., Japan","IEEE Transactions on Software Engineering","","1988","14","5","666","670","User-interface facilities of a map information system HI-MAP that provide visual feedback to the user are presented. The facilities include semantic panning and zooming, overlaying of thematic maps, etc., and are available through an interactive menu system. HI-MAP retrieves map elements in a specified region on the basis of their relevance and their categorical classification. It has a data structure that includes logical and physical hierarchies for the management of semantic relationships and graphic map elements. The software for implementing these facilities is well modularized, and a variety of interfacing modes can be realized by simple communication between modules. The system contributes toward a reduction of the difficulties in obtaining what is really required from databases.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6144","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6144","","User interfaces;Information retrieval;Image databases;Visual databases;Information systems;Database languages;Feedback;Management information systems;Data structures;Graphics","cartography;database management systems;information retrieval;query languages;user interfaces","visual user interface;map information retrieval;semantic significance;HI-MAP;semantic panning;zooming;overlaying;thematic maps;interactive menu system;data structure;semantic relationships;graphic map elements;databases","","19","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Introducing Objectcharts or how to use Statecharts in object-oriented design","D. Coleman; F. Hayes; S. Bear","Hewlett-Packard Lab., Bristol, UK; Hewlett-Packard Lab., Bristol, UK; Hewlett-Packard Lab., Bristol, UK","IEEE Transactions on Software Engineering","","1992","18","1","8","18","A notation called Objectcharts for specifying object classes is introduced. An Objectchart diagram is an extended form of a Statechart, which characterizes the behavior of a class as a state machine. The Objectchart transitions correspond to the state-changing methods that the class provides and those that it requires of other classes. Object attributes and observer methods annotate Objectchart states. Firing and postconditions are used to specify the effect of transitions on class attributes. The Objectchart notions is described through the development of an alarm clock application. How Objectcharts can be used to find subtyping inheritance relationships between classes and a systematic approach for evolving Objectchart specifications are shown.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.120312","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=120312","","Design methodology;Object oriented modeling;Software design;Clocks;Information analysis;Cyclic redundancy check;Laboratories;Object oriented programming;Protocols;Encapsulation","data structures;diagrams;formal specification;object-oriented programming","object classes;Statechart;state machine;Objectchart transitions;state-changing methods;observer methods;Objectchart states;postconditions;Objectchart notions;alarm clock application;subtyping inheritance relationships;Objectchart specifications","","85","","16","","","","","","IEEE","IEEE Journals & Magazines"
"A formal specification framework for object-oriented distributed systems","D. Buchs; N. Guelfi","Software Eng. Lab., Swiss Federal Inst. of Technol., Lausanne, Switzerland; NA","IEEE Transactions on Software Engineering","","2000","26","7","635","652","In this paper, we present the Concurrent Object-Oriented Petri Nets (CO-OPN/2) formalism devised to support the specification of large distributed systems. Our approach is based on two underlying formalisms: order-sorted algebra and algebraic Petri nets. With respect to the lack of structuring capabilities of Petri nets, CO-OPN/2 has adopted the object-oriented paradigm. In this hybrid approach (model- and property-oriented), classes of objects are described by means of algebraic Petri nets, while data structures are expressed by order-sorted algebraic specifications. An original feature is the sophisticated synchronization mechanism. This mechanism allows to involve many partners in a synchronization and to describe the synchronization policy. A typical example of distributed systems, namely the Transit Node, is used throughout this paper to introduce our formalism and the concrete specification language associated with it. By successive refinements of the components of the example, we present, informally, most of the notions of CO-OPN/2. We also give some insights about the coordination layer, Context and Objects Interface Language (COIL), which is built on top of CO-OPN/2. This coordination layer is used for the description of the concrete distributed architecture of the system. Together, CO-OPN/2 and COIL provide a complete formal framework for the specification of distributed systems.","0098-5589;1939-3520;2326-3881","","10.1109/32.859532","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=859532","","Formal specifications;Petri nets;Concrete;Data structures;Concurrent computing;Distributed processing;Communication systems;Algebra;Object oriented modeling;Specification languages","algebraic specification;Petri nets;object-oriented methods","formal specification;object-oriented distributed systems;Concurrent Object-Oriented Petri Nets;Petri nets;order-sorted algebra;data structures;classes of objects;distributed systems","","21","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Algorithms for multidimensional partitioning of static files","D. Rotem; A. Segev","California Univ., Berkeley, CA, USA; California Univ., Berkeley, CA, USA","IEEE Transactions on Software Engineering","","1988","14","11","1700","1710","The problem of multidimensional file partitioning (MDFP) arises in large databases that are subject to frequent range queries on one or more attributes. In an MDFP scheme, the search attribute space is partitioned into cells, which are mapped to physical disk locations. This mapping preserves the order of the search attribute values so that range queries can be answered most efficiently, while maintaining good performance for other types of queries. Recently, MDFP schemes have been suggested to include both dynamic and static file organizations. Optimal and heuristic MDFP algorithms are developed for the static case. The results of extensive computational experiments show that the proposed heuristics perform better than known static ones. It is also shown that incorporating a static algorithm into a dynamic MDFP such as a grid file at conversion and/or periodical reorganization points significantly improves the resulting storage utilization of the data file and decreases the size of the directory file.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9056","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9056","","Partitioning algorithms;Multidimensional systems;Databases;Heuristic algorithms;Frequency;Size measurement;Time measurement;Size control","database management systems;database theory;file organisation","database theory;multidimensional partitioning;static files;multidimensional file partitioning;search attribute space;physical disk locations;range queries;file organizations;static algorithm;storage utilization","","1","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Comprehending object and process models: an empirical study","R. Agarwal; P. De; A. P. Sinha","Dept. of Decision & Inf. Technol., Maryland Univ., College Park, MD, USA; NA; NA","IEEE Transactions on Software Engineering","","1999","25","4","541","556","We report the results of an empirical study comparing user comprehension of object oriented (OO) and process oriented (PO) models. The fundamental difference is that while OO models tend to focus on structure, PO models tend to emphasize behaviour or processes. Proponents of the OO modeling approach argue that it lends itself naturally to the way humans think. However, evidence from research in cognitive psychology and human factors suggests that human problem solving is innately procedural. Given these conflicting viewpoints, we investigate empirically if OO models are in fact easier to understand than PO models. But, as suggested by the theory of cognitive fit, model comprehension may be influenced by task-specific characteristics. We therefore compare OO and PO models based on whether the comprehension activity involves: 1) only structural aspects, 2) only behavioral aspects, or 3) a combination of structural and behavioral aspects. We measure comprehension through subjects' responses to questions designed along these three dimensions. Results show that for most of the simple questions, no significant difference was observed insofar as model comprehension is concerned. For most of the complex questions, however, the PO model was found to be easier to understand than the OO model. In addition to describing the process and the outcomes of the experiments, we present the experimental method employed as a viable approach for conducting research into various phenomena related to the efficacy of alternative systems analysis and design methods. We also identify areas where future research is necessary, along with a recommendation of appropriate research methods for empirical examination.","0098-5589;1939-3520;2326-3881","","10.1109/32.799953","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=799953","","Object oriented modeling;Human factors;Psychology;Problem-solving;System analysis and design;Software testing;System testing;Software systems;Information analysis;Robustness","reverse engineering;object-oriented methods;human factors;cognitive systems;user interfaces;psychology","OO models;empirical study;user comprehension;object oriented models;process oriented models;PO models;OO modeling approach;cognitive psychology;human factors;human problem solving;cognitive fit;model comprehension;task-specific characteristics;comprehension activity;structural aspects;behavioral aspects;experimental method;alternative systems analysis;design methods;empirical examination","","47","","42","","","","","","IEEE","IEEE Journals & Magazines"
"QDA-a method for systematic informal program analysis","W. E. Howden; B. Wieand","Dept. of Comput. Sci. & Eng., California Univ., San Diego, La Jolla, CA, USA; NA","IEEE Transactions on Software Engineering","","1994","20","6","445","462","Formal verification of program properties may be infeasible or impractical, and informal analysis may be sufficient. Informal analysis involves the informal acceptance, by inspection, of the validity of program properties or steps in an analysis. Informal analysis may also involve abstraction. Abstraction can be used to eliminate details and concentrate on more general properties. Abstraction will result in informal analysis if it includes the use of undefined properties. A systematic, informal method for analysis called QDA (Quick Defect Analysis) is described. QDA is a comments analysis process based on facts and hypotheses. Facts are used to create an abstract program model, and hypotheses are selected, nonobvious program properties which are identified as needing verification. Hypotheses are proved from the facts that define an abstraction. QDA is hypothesis-driven in the sense that only those parts of an abstraction that are needed to prove hypotheses are created. The QDA approach was applied to a previously well tested operational flight program (OFP). The QDA method and the results of the OFP experiment are presented. The problems of incomplete or unsound informal analysis are analyzed, the relationship of QDA to other analysis methods is discussed, and suggested improvements to the QDA method are described.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.295893","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=295893","","Inspection;Aerospace electronics;Application software;Testing;Programming profession;Maintenance;Formal verification;Costs;Formal specifications;Computer science","program verification;programming theory;formal specification;program debugging;program diagnostics","QDA;systematic informal program analysis;formal verification;program properties;program validity;Quick Defect Analysis;comments analysis;abstract program model;program verification;hypothesis-driven method;operational flight program;specification;code reading","","8","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Distributed shared abstractions (DSA) on multiprocessors","C. Clemencon; B. Mukherjee; K. Schwan","Integrated Syst. Eng. AG, Zurich, Switzerland; NA; NA","IEEE Transactions on Software Engineering","","1996","22","2","132","152","Any parallel program has abstractions that are shared by the program's multiple processes. Such shared abstractions can considerably affect the performance of parallel programs, on both distributed and shared memory multiprocessors. As a result, their implementation must be efficient, and such efficiency should be achieved without unduly compromising program portability and maintainability. The primary contribution of the DSA library is its representation of shared abstractions as objects that may be internally distributed across different nodes of a parallel machine. Such distributed shared abstractions (DSA) are encapsulated so that their implementations are easily changed while maintaining program portability across parallel architectures. The principal results presented are: a demonstration that the fragmentation of object state across different nodes of a multiprocessor machine can significantly improve program performance; and that such object fragmentation can be achieved without compromising portability by changing object interfaces. These results are demonstrated using implementations of the DSA library on several medium scale multiprocessors, including the BBN Butterfly, Kendall Square Research, and SGI shared memory multiprocessors. The DSA library's evaluation uses synthetic workloads and a parallel implementation of a branch and bound algorithm for solving the traveling salesperson problem (TSP).","0098-5589;1939-3520;2326-3881","","10.1109/32.485223","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=485223","","Libraries;Parallel machines;Topology;Electronic mail;Data structures;Parallel architectures;Computer networks;Concurrent computing;Distributed computing;Workstations","parallel programming;parallel machines;parallel architectures;data structures;software portability;software maintenance;distributed memory systems","distributed shared abstractions;multiprocessors;parallel program;shared memory multiprocessors;parallel architectures;maintainability;DSA library;internally distributed;parallel machine;program portability;object state;multiprocessor machine;object interfaces;medium scale multiprocessors;BBN Butterfly;Kendall Square Research;SGI shared memory multiprocessors;synthetic workloads;parallel implementation;branch and bound algorithm;traveling salesperson problem","","7","","46","","","","","","IEEE","IEEE Journals & Magazines"
"Timing analysis of Ada tasking programs","J. C. Corbett","Dept. of Inf. & Comput. Sci., Hawaii Univ., Honolulu, HI, USA","IEEE Transactions on Software Engineering","","1996","22","7","461","483","Concurrent real-time software is increasingly used in safety-critical embedded systems. Assuring the quality of such software requires the rigor of formal methods. In order to analyze a program formally, we must first construct a mathematical model of its behavior. In this paper, we consider the problem of constructing such models for concurrent real-time software. In particular, we provide a method for building mathematical models of real-time Ada tasking programs that are accurate enough to verify interesting timing properties, and yet abstract enough to yield a tractable analysis on nontrivial programs. Our approach differs from schedulability analysis in that we do not assume that the software has a highly restricted structure (e.g. a set of periodic tasks). Also, unlike most abstract models of real-time systems, we account for essential properties of real implementations, such as resource constraints and run-time overhead.","0098-5589;1939-3520;2326-3881","","10.1109/32.538604","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=538604","","Timing;Real time systems;Mathematical model;Embedded software;Software safety;Embedded system;Software quality;Buildings;Periodic structures;Runtime","Ada;real-time systems;timing;program verification;program diagnostics;multiprogramming;safety-critical software;software quality","timing analysis;schedulability analysis;concurrent real-time software;safety-critical embedded systems;software quality assurance;formal program analysis;mathematical program behaviour model;real-time Ada tasking programs;software structure;resource constraints;run-time overhead;program verification;hybrid systems","","35","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Nested Transactions in Distributed Systems","D. R. Ries; G. C. Smith","Computer Corporation of America; NA","IEEE Transactions on Software Engineering","","1982","SE-8","3","167","172","In database management systems and operating systems, transactions are used as units of consistency, serializability, recovery, and for deadlock control. Normally, the transactions for each of these systems are considered independently. In this paper we describe nested transactions where the transactions from one system interact with the transactions from another system. Such nested transactions can expect to become more important with the introduction of network operating systems and heterogeneous distributed database systems.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235104","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702933","Deadlock;distributed database systems;nested transactions;network operating systems;transactions","Database systems;System recovery;Operating systems;Network operating systems;File systems;Transaction databases;Control systems;Hardware;Computer crashes;Protocols","","Deadlock;distributed database systems;nested transactions;network operating systems;transactions","","1","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Automated test case generation for programs specified by relational algebra queries","W. T. Tsai; D. Volovik; T. F. Keefe","Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA; Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA; Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA","IEEE Transactions on Software Engineering","","1990","16","3","316","324","Black-box software testing requires test cases to be generated from specifications alone. However, it is impossible to automate the process completely for arbitrary specifications. Specifications are thus restricted to being written entirely in terms of relational algebra expressions. An automated test case generation method is developed for such specifications.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.48939","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=48939","","Automatic testing;Computer aided software engineering;Algebra;Software testing;Programming;Process design;Information retrieval;Computer science;System testing;Automatic generation control","automatic programming;formal specification;program testing;relational databases","black-box software testing;relational algebra queries;arbitrary specifications;relational algebra expressions;automated test case generation method","","36","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Mixed programming metaphors in a shared dataspace model of concurrency","G. -. Roman; H. C. Cunningham","Dept. of Comput. Sci., Washington Univ., Saint Louis, MO, USA; NA","IEEE Transactions on Software Engineering","","1990","16","12","1361","1373","A simple language called Swarm is used as a vehicle for the investigation of the shared dataspace approach to concurrent computation. An important feature of Swarm is its ability to bring a variety of programming paradigms under a single, unified model. In a series of related examples Swarm's capacity to express shared-variable, message-passing, and rule-based computations; to specify synchronous and asynchronous processing modes; and to accommodate highly dynamic program and data structure is explored. Several illustrations make use of a programming construct unique to Swarm, the synchrony relation and explain how this feature can be used to construct dynamically structured, partially synchronous computations. An overview of the Swarm programming notation, an examination of Swarm programming strategies via a series of related example programs, and a discussion of the distinctive features of the shared dataspace model are given. A formal operational model for Swarm is presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.62445","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=62445","","Concurrent computing;Data structures;Computer science;Message passing;Vehicle dynamics;Dynamic programming;Technology management;Parallel processing;Protocols;Information science","data structures;parallel languages;parallel programming","mixed programming metaphors;concurrency;simple language;Swarm;shared dataspace approach;concurrent computation;programming paradigms;unified model;shared-variable;message-passing;rule-based computations;asynchronous processing modes;highly dynamic program;data structure;programming construct;synchrony relation;partially synchronous computations;programming notation;programming strategies;example programs;shared dataspace model;formal operational model","","29","","32","","","","","","IEEE","IEEE Journals & Magazines"
"Fundamentals of deductive program synthesis","Z. Manna; R. Waldinger","Dept. of Comput. Sci., Stanford Univ., Palo Alto, CA, USA; Dept. of Comput. Sci., Stanford Univ., Palo Alto, CA, USA","IEEE Transactions on Software Engineering","","1992","18","8","674","704","An informal tutorial for program synthesis is presented, with an emphasis on deductive methods. According to this approach, to construct a program meeting a given specification, the authors prove the existence of an object meeting the specified conditions. The proof is restricted to be sufficiently constructive, in the sense that, in establishing the existence of the desired output, the proof is forced to indicate a computational method for finding it. That method becomes the basis for a program that can be extracted from the proof. The exposition is based on the deductive-tableau system, a theorem-proving framework particularly suitable for program synthesis. The system includes a nonclausal resolution rule, facilities for reasoning about equality, and a well-founded induction rule.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.153379","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=153379","","Computer science;Military computing;Computer languages;Contracts;Logic functions;Algebra;Artificial intelligence;Programming;Sorting","artificial intelligence;formal specification;inference mechanisms;program testing;theorem proving","deductive program synthesis;specification;proof;deductive-tableau system;theorem-proving framework;nonclausal resolution rule;reasoning;induction rule","","54","","47","","","","","","IEEE","IEEE Journals & Magazines"
"The formal specification of a small bookshop information system","D. Gray","Dept. of Comput. Sci., Queen's Univ., Belfast, UK","IEEE Transactions on Software Engineering","","1988","14","2","263","272","A specification, and its development, for a small bookshop information system are discussed. the specification is presented using mathematics and the scheme calculus of C. Morgan and B. Sufrin (see ibid., vol.SE-10, no.2, p.128-142, 1984). An insight is given into how the specification was developed and why a formal specification is appropriate.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4644","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4644","","Formal specifications;Information systems;Calculus;Mathematics;Set theory;Books;Computer science;Computational geometry;Terminology","programming theory;software engineering","set theory;formal specification;small bookshop information system;scheme calculus","","1","","10","","","","","","IEEE","IEEE Journals & Magazines"
"An Infornation-Theoretic Analysis of Relational DatabasesPart I: Data Dependencies and Information Metric","T. T. Lee","Bell Communications Research","IEEE Transactions on Software Engineering","","1987","SE-13","10","1049","1061","Database design is based on the concept of data dependency, which is the interrelationship between data contained in various sets of attributes. In particular, functional, multivalued and acyclic join, dependencies play an essential role in the design of database schemas. The basic definition of an information metric and how this notion can be used in relational database are discussed in this paper. We use Shannon entropy as an information metric to quantify the information associated with a set of attributes. Thus, we prove that data dependencies can be formulated in terms of entropies. These formulas make the numerical computation and testing of data dependencies feasible. Among the different types of data dependencies, the acyclic join dependency is most important to the design of a relational database schema. The acyclic join dependency, with multivalued dependency as a special case, impose a constraint on the information-preserving decomposition of a relation. It is interesting that this constraint on a relation is similar to Gibbs' condition for separating physical systems in statistical mechanics. They both assert that entropy is preserved during the decomposition process. That is, the entropies of the corresponding set of attributes must satisfy the inclusionexclusion identity.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232847","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702145","Acyclic join dependency;entropy;functional dependency;information-preserving decomposition;multivalued dependency","Data analysis;Information analysis;Relational databases;Entropy;Data models;Testing;Set theory;Sufficient conditions;Next generation networking","","Acyclic join dependency;entropy;functional dependency;information-preserving decomposition;multivalued dependency","","9","","23","","","","","","IEEE","IEEE Journals & Magazines"
"The Design for a Secure System Based on Program Analysis","G. H. MacEwen","Department of Computing and Information Science, Queen's University","IEEE Transactions on Software Engineering","","1983","SE-9","3","289","299","This paper describes the design of a prototype experimental secure operating system kernel called xsl that supports compile-time enforcement of an information flow policy. The security model chosen is an extension of Feiertag's model modified to state requirements in terms of program analysis functions. A prototype flow analyzer for Pascal programs, based on Denning's model, has been designed and implemented for incorporation into xs1. In addition, a flow analyzer, based on London's model, has also been designed and implemented. Both kinds of enforcement are supported in xsl. Both program anallyzers use an intermediate code program representation, originally designed for code optimization. Implementation of the flow analyzers is in Euclid with the remainder of xsl in PascaL","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236864","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703056","Access control;information flow;modularization;operating systems;security;software engineering;system design","Information security;Operating systems;Kernel;Design methodology;Information analysis;Prototypes;Design optimization;Control systems;Computer security;Protection","","Access control;information flow;modularization;operating systems;security;software engineering;system design","","","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Performance Analysis of Disk Modulo Allocation Method for Cartesian Product Files","Y. Y. Sung","School of Electrical Engineering and Computer Science, University of Oklahoma","IEEE Transactions on Software Engineering","","1987","SE-13","9","1018","1026","Cartesian product files have been shown to exhibit attractive properties for partial match queries. The Disk Modulo (DM) allocation method is shown to have good performance on the distribution of Cartesian product files into an m-disk system. However, there was no explicit expression made before to represent the DM method's response time to a given partial match query. In this paper, based upon discrete Fourier transform, we derive one formula for such a computation. After obtaining this representation, the performance characteristics of the DM method can now be given an analytic interpretation. Some theoretical results are derived from this formula. We also use our formula to analyze the performance of several popular Disk Modulo algorithms.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233524","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702324","Cartesian product files;discrete Fourier transform;disk modulo methods;partial match queries;performance","Performance analysis;Delta modulation;Delay;Discrete Fourier transforms;Algorithm design and analysis;File systems;Information retrieval;Concurrent computing;Computer science","","Cartesian product files;discrete Fourier transform;disk modulo methods;partial match queries;performance","","3","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Scheduling processes with release times, deadlines, precedence and exclusion relations","J. Xu; D. L. Parnas","Dept. of Comput. Sci., York Univ., North York, Ont., Canada; NA","IEEE Transactions on Software Engineering","","1990","16","3","360","369","An algorithm that finds an optimal schedule on a single processor for a given set of processes is presented. Each process starts executing after its release time and completes its computation before its deadline and a given set of precedence relations and exclusion relations defined on ordered pairs of process segments are satisfied. This algorithm can be applied to the important and previously unsolved problem of automated pre-run-time scheduling of processes with arbitrary precedence and exclusion in hard-real-time systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.48943","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=48943","","Optimal scheduling;Scheduling algorithm;Processor scheduling;Real time systems;Algorithm design and analysis;Councils;Timing;Runtime","optimisation;scheduling;search problems","optimal schedule;single processor;release time;precedence relations;exclusion relations;ordered pairs;process segments;automated pre-run-time scheduling;arbitrary precedence;hard-real-time systems","","192","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Privilege transfer and revocation in a port-based system","K. Ramamritham; D. Stemple; D. A. Briggs; S. Vinter","Department of Computer and Information Science, University of Massachusetts, Amherst, MA 01003; Department of Computer and Information Science, University of Massachusetts, Amherst, MA 01003; Department of Mathematics and Computer Science, University of Southern Maine, Portland, ME 04104; BBN Laboratories, Cambridge, MA 02238","IEEE Transactions on Software Engineering","","1986","SE-12","5","635","648","Gutenberg is a port-based operating system being designed to study protection issues in distributed systems. All shared resources are viewed as protected objects and hence can be assessed only via specific operations defined on them. Processes communicate and access objects through the use of ports. Each port is associated with an abstract data type operation and can be created by a process only if the process has the capability to execute the operation on the type. Thus, a port represents the privilege of the port's client process to request a service. Capabilities to create ports for requesting operations are contained in a capability directory, which is navigated by processes to gain these capabilities. Privilege transfer is a means of providing servers access to the resources they need to perform their services. In Gutenberg, privilege transfer is accomplished by allowing access to subdirectories of the capability directory and by passing capabilities, including port access capabilities, to processes via ports. It should be possible to revoke transferred privileges when breaches of trust are detected or suspected, when a period of time has passed beyond which the distributor of a privilege does not want the privilege shared, or when an error has been detected.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312959","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312959","Interprocess communication;operating systems;privilege transfer;protection;revocation","Kernel;Servers;Bibliographies;Transient analysis;Abstracts","distributed processing;operating systems (computers);security of data","port-based system;Gutenberg;operating system;protection issues;distributed systems;abstract data type operation;capability directory;privilege transfer;port access","","2","","","","","","","","IEEE","IEEE Journals & Magazines"
"Dynamic scheduling of hard real-time tasks and real-time threads","K. Schwan; H. Zhou","Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA; Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA","IEEE Transactions on Software Engineering","","1992","18","8","736","748","The authors investigate the dynamic scheduling of tasks with well-defined timing constraints. They present a dynamic uniprocessor scheduling algorithm with an O(n log n) worst-case complexity. The preemptive scheduling performed by the algorithm is shown to be of higher efficiency than that of other known algorithms. Furthermore, tasks may be related by precedence constraints, and they may have arbitrary deadlines and start times (which need not equal their arrival times). An experimental evaluation of the algorithm compares its average case behavior to the worst case. An analytic model used for explanation of the experimental results is validated with actual system measurements. The dynamic scheduling algorithm is the basis of a real-time multiprocessor operating system kernel developed in conjunction with this research. Specifically, this algorithm is used at the lowest, threads-based layer of the kernel whenever threads are created.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.153383","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=153383","","Dynamic scheduling;Real time systems;Scheduling algorithm;Timing;Operating systems;Performance analysis;Kernel;Algorithm design and analysis;Switches","computational complexity;network operating systems;real-time systems;scheduling","hard real-time tasks;real-time threads;dynamic scheduling;timing constraints;worst-case complexity;preemptive scheduling;precedence constraints;real-time multiprocessor operating system kernel","","55","","33","","","","","","IEEE","IEEE Journals & Magazines"
"Rapid application of lightweight formal methods for consistency analyses","M. S. Feather","Jet Propulsion Lab., California Inst. of Technol., Pasadena, CA, USA","IEEE Transactions on Software Engineering","","1998","24","11","949","959","Lightweight formal methods promise to yield modest analysis results in an extremely rapid manner. To fulfil this promise, they must be able to work with existing information sources, be able to analyze for manifestly desirable properties, be highly automated (especially if dealing with voluminous amounts of information), and be readily customizable and flexible in the face of emerging needs and understanding. Two pilot studies investigate the feasibility of lightweight formal methods that employ a database as the underlying reasoning engine to perform the analyses. The first study concerns aspects of software module interfaces, while the second concerns test logs' adherence to required and expected conditions.","0098-5589;1939-3520;2326-3881","","10.1109/32.730544","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=730544","","Information analysis;Performance analysis;Engines;Software testing;Application software;Failure analysis;Transaction databases;Feathers;System testing;Data analysis","formal verification;inference mechanisms;subroutines;database management systems","lightweight formal methods;consistency analyses;information sources;manifestly desirable properties;highly automated methods;customizable methods;flexible methods;emerging needs;reasoning engine;software module interfaces;required conditions;expected conditions;consistency checking;interface checking;test-log checking;database-based analysis;NASA","","21","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Stochastic automata network of modeling parallel systems","B. Plateau; K. Atif","IMAG-Groupe Calcul Parallele, Grenoble, France; IMAG-Groupe Calcul Parallele, Grenoble, France","IEEE Transactions on Software Engineering","","1991","17","10","1093","1108","A methodology for modeling a system composed of parallel activities with synchronization points is proposed. Specifically, an approach based on a modular state-transition representation of a parallel system called the stochastic automata network (SAN) is developed. The state-space explosion is handled by a decomposition technique. The dynamic behavior of the algorithm is analyzed under Markovian assumptions. The transition matrix of the chain is automatically derived using tensor algebra operators, under a format which involves a very limited storage cost.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.99196","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=99196","","Stochastic systems;Automata;Storage area networks;Explosions;Algorithm design and analysis;Matrix decomposition;Tensile stress;Algebra;Storage automation;Costs","parallel algorithms;parallel architectures;performance evaluation;stochastic automata","parallel activities;synchronization points;modular state-transition representation;parallel system;stochastic automata network;SAN;state-space explosion;decomposition technique;Markovian assumptions;transition matrix;tensor algebra operators;storage cost","","125","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Defining and validating measures for object-based high-level design","L. C. Briand; S. Morasca; V. R. Basili","Fraunhofer-Inst. for Exp. Software Eng., Kaiserslautern, Germany; NA; NA","IEEE Transactions on Software Engineering","","1999","25","5","722","743","The availability of significant measures in the early phases of the software development life-cycle allows for better management of the later phases, and more effective quality assessment when quality can be more easily affected by preventive or corrective actions. We introduce and compare various high-level design measures for object-based software systems. The measures are derived based on an experimental goal, identifying fault-prone software parts, and several experimental hypotheses arising from the development of Ada systems for Flight Dynamics Software at the NASA Goddard Space Flight Center (NASA/GSFC). Specifically, we define a set of measures for cohesion and coupling, which satisfy a previously published set of mathematical properties that are necessary for any such measures to be valid. We then investigate the measures' relationship to fault-proneness on three large scale projects, to provide empirical support for their practical significance and usefulness.","0098-5589;1939-3520;2326-3881","","10.1109/32.815329","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=815329","","Software measurement;NASA;Phase measurement;Programming;Quality management;Software development management;Quality assessment;Software systems;Fault diagnosis;Large-scale systems","object-oriented programming;object-oriented languages;Ada;software quality;software fault tolerance;aerospace computing","object-based high-level design;software development life-cycle;software quality assessment;high-level design;fault-prone software;Ada systems;Flight Dynamics Software;NASA Goddard Space Flight Center","","90","","44","","","","","","IEEE","IEEE Journals & Magazines"
"Some Empirical Observations on Program Behavior with Applications to Program Restructuring","J. B. Peachey; R. B. Bunt; C. J. Colbourn","Department of Agricultural Economics, University of Saskatchewan; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","2","188","193","The dynamic behavior of executing programs is a significant factor in the performance of virtual memory computer systems. Program restructuring attempts to improve the behavior of programs by reorganizing their object code to account for the characteristics of the virtual memory environment. A significant component of the restructuring process involves a restructuring graph. An analysis of restructuring graphs of typical programs found edge weights to be distributed in a BradfordZipf fashion, implying that a large fraction of total edge weight is concentrated in relatively few edges. This empirical observation can be used to improve the clustering phase of program restructuring, by limiting consideration to edges of large weight. We consider the effect of this improved clustering in the restructuring process by examining various means of restructuring some typical programs. In our experiments, 95 percent of the total edge value is typically accounted for by 5060 percent of the edges. For naive clustering algorithms, clustering time is therefore typically halved; for more sophisticated methods, more substantial savings result. Finally, clustering with 95 percent of total edge value typically results in only a small decay in performance measures such as number of page faults and average working set size.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232193","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701986","BradfordZipf distribution;clustering;paging;program behavior;program restructuring","Application software;Clustering algorithms;Size measurement;Guidelines;Programming profession;Agricultural engineering;Councils;Economic forecasting;Environmental economics","","BradfordZipf distribution;clustering;paging;program behavior;program restructuring","","3","","42","","","","","","IEEE","IEEE Journals & Magazines"
"Communication metrics for software development","A. H. Dutoit; B. Bruegge","Inst. fur Inf., Tech. Univ. Munchen, Germany; NA","IEEE Transactions on Software Engineering","","1998","24","8","615","628","Presents empirical evidence that metrics on communication artifacts generated by groupware tools can be used to gain significant insight into the development process that produced them. We describe a test-bed for developing and testing communication metrics, a senior-level software engineering project course at Carnegie Mellon University, in which we conducted several studies and experiments from 1991-1996 with more than 400 participants. Such a test-bed is an ideal environment for empirical software engineering, providing sufficient realism while allowing for controlled observation of important project parameters. We describe three proof-of-concept experiments to illustrate the value of communication metrics in software development projects. Finally, we propose a statistical framework based on structural equations for validating these communication metrics.","0098-5589;1939-3520;2326-3881","","10.1109/32.707697","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=707697","","Programming;Software testing;Software engineering;Equations;Collaborative software;Collaborative work;Communication system control;Software tools;Context;Computer Society","software metrics;groupware;statistics;equations;educational courses;computer science education","communication metrics;software development;communication artifacts;groupware tools;senior-level software engineering project course;Carnegie Mellon University;empirical software engineering;project parameter controlled observation;statistical framework;structural equations;validation","","15","","31","","","","","","IEEE","IEEE Journals & Magazines"
"On the File Design Problem for Partial Match Retrieval","Hung-Chang Du","Department of Computer Science, University of Minnesota","IEEE Transactions on Software Engineering","","1985","SE-11","2","213","222","In the past two decades, the increasing usage of databases and integrated information systems has encouraged the development of file structures suited for partial match retrieval. A partial match query is a query with some number of attributes specified and the rest of them unspecified. One interesting file structure proposed and heavily studied recently is called a multikey hashing scheme, but most of the previous results on designing optimal multikey hashing schemes ignored the record distribution of a file. In this paper we show that the problem of designing an optimal multikey hashing scheme taking into consideration the record distribution is computationally intractable (NP-hard). Therefore, a heuristic approach is necessary. In a multikey hashing scheme, although the directory is space efficient and the search algorithm is fast, due to the insufficient information in the directory some accessed buckets may not contain any record satisfying the given query. Thus, certain retrieval effort is wasted. A new class of file structures which combine a multikey hashing scheme and an indexed descriptor technique is introduced in this paper. By adding some extra information (either record descriptors or bucket descriptors) into the directory of a multikey hashing scheme, either only those buckets which contain at least one record satisfying the given query need to be accessed or the number of accessed buckets which do not contain any record satisfying the query is reduced.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232197","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701990","Database design;file structures;multikey hashing;NP-hard;partial match retrieval","Information retrieval;Database systems;Information systems;Distributed computing;Magnetic devices;Computer science;Terminology","","Database design;file structures;multikey hashing;NP-hard;partial match retrieval","","","","32","","","","","","IEEE","IEEE Journals & Magazines"
"Measuring Errors in Operational Analysis Assumptions","N. M. Bengtson","Department of Computer Science, North Carolina State University","IEEE Transactions on Software Engineering","","1987","SE-13","7","767","776","Operational analysis, an area of study first defined in the computer science field, has been used in the analysis of systems performance. System performance measures for a specific set of output data are obtained using operational analysis formulas derived from assumptions which are verifiable by the observed data. This paper gives relationships which may be used to quantify the errors in these assumptions. Additionally, basic propositions are given which help in understanding operational analysis assumptions. These propositions are used in developing correction terms which can be used to adjust performance measures so that their values are exact for a set of data no matter how much the assumptions used in deriving the performance measure relations are violated.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233488","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702288","Operational analysis;performance measure assumptions;performance measures;system performance","Error analysis;Performance analysis;Equations;System performance;Computer errors;Computer science;Delay;Time measurement;Computational modeling;Computer simulation","","Operational analysis;performance measure assumptions;performance measures;system performance","","2","","6","","","","","","IEEE","IEEE Journals & Magazines"
"Domain-specific languages: from design to implementation application to video device drivers generation","S. A. Thibault; R. Marlet; C. Consel","Rennes I Univ., France; NA; NA","IEEE Transactions on Software Engineering","","1999","25","3","363","377","Domain-specific languages (DSL) have many potential advantages in terms of software engineering, ranging from increased productivity to the application of formal methods. Although they have been used in practice for decades, there has been little study of methodology or implementation tools for the DSL approach. We present our DSL approach and its application to a realistic domain: the generation of video display device drivers. The article focuses on the validation of our proposed framework for domain-specific languages, from design to implementation. The framework leads to a flexible design and structure, and provides automatic generation of efficient implementations of DSL programs. Additionally, we describe an example of a complete DSL for video display adaptors and the benefits of the DSL approach for this application. This demonstrates some of the generally claimed benefits of using DSLs: increased productivity, higher-level abstraction, and easier verification. This DSL has been fully implemented with our approach and is available. Compose project URL: http://www.irisa.fr/compose/gal.","0098-5589;1939-3520;2326-3881","","10.1109/32.798325","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=798325","","Domain specific languages;DSL;Application software;Productivity;Software engineering;Displays;Graphics;Uniform resource locators;Telephony;Switching systems","high level languages;application generators;device drivers;video equipment","domain-specific languages;implementation application;video device driver generation;software engineering;formal methods;DSL approach;video display device drivers;automatic program generation;video display adaptors;higher-level abstraction","","39","","","","","","","","IEEE","IEEE Journals & Magazines"
"The cache assignment problem and its application to database buffer management","H. Levy; T. G. Messinger; R. J. T. Morris","Dept. of Comput. Sci., Tel Aviv Univ., Israel; NA; NA","IEEE Transactions on Software Engineering","","1996","22","11","827","838","Given N request streams and L/spl les/N LRU caches, the cache assignment problem asks to which cache each stream should be assigned in order to minimize the overall miss rate. An efficient solution to this problem is provided, based on characterizing each stream using the stack reference model and characterizing the interaction of the streams using a bursty stream model. It is shown that for Bernoulli (purely random) mixing of streams, the optimal cache assignment is to have one cache per stream. In practice streams are mixed in a way that is much ""burstier"" than can be represented by the Bernoulli model. Therefore a method is presented for superposition of bursty streams. The performance of the methods developed for bursty stream superposition and cache assignment are tested using trace data obtained from the database system DB2. The resulting cache assignment recommendations are then applied to the DB2 system, and considerable performance improvement is found to result.","0098-5589;1939-3520;2326-3881","","10.1109/32.553701","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=553701","","Database systems;Memory management;Indexes;Transaction databases;System testing;Pervasive computing;Aging;Cache memory;Computer science;Engineering management","storage allocation;cache storage;relational databases;software performance evaluation;storage management","cache assignment problem;database buffer management;request streams;miss rate;stack reference model;bursty stream model;Bernoulli model;random mixing;bursty stream superposition;performance;trace data;DB2","","1","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Evaluation of Error Recovery Blocks Used for Cooperating Processes","K. G. Shin; Y. Lee","Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI 48109.; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI 48109.","IEEE Transactions on Software Engineering","","1984","SE-10","6","692","700","Three alternatives for implementing recovery blocks (RB's) are conceivable for backward error recovery in concurrent processing. These are the asynchronous, synchronous, and the pseudorecovery point implementations. Asynchronous RB's are based on the concept of maximum autonomy in each of concurrent processes. Consequently, establishment of RB's in a process is made independently of others and unbounded rollback propagations become a serious problem. In order to completely avoid unbounded rollback propagations, it is necessary to synchronize the establishment of recovery blocks in all cooperating processes. Process autonomy is sacrificed and processes are forced to wait for commitments from others to establish a recovery line, leading to inefficiency in time utilization. As a compromise between asynchronous and synchronous RB's we propose to insert pseudorecovery points (PRP's) so that unbounded rollback propagations may be avoided while maintaining process autonomy. We developed probabilistic models for analyzing these three methods under standard assumptions in computer performance analysis, i.e., exponential distributions for related random variables. With these models we have estimated 1) the interval between two successive recovery lines for asynchronous RB's, 2) mean loss in computation power for the synchronized method, and 3) additional overhead and rollback distance in case PRP's are used.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010298","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010298","Backward error recovery;conversation scheme;domino effect;pseudorecovery points and lines(s);recovery block(s);recovery line(s);rollback propagations","Testing;Distributed computing;Performance analysis;Propagation losses;Sequential analysis;Standards development;Computer performance;Fault tolerant systems;Exponential distribution;Random variables","","","","22","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Software Science Applied to APL","A. H. Konstam; D. E. Wood","Department of Computing and Information Sciences, Trinity University; NA","IEEE Transactions on Software Engineering","","1985","SE-11","10","994","1000","Previous attempts to apply Halstead's software metrics to APL have led to inconsistent and counter-intuitive results. This work is a further investigation into the application of software metrics to APL to try to resolve some of the inconsistency. The effect of variations in the counting rules on values calculated for the software metrics was studied. These rules were used to analyze a set of programs from a previous study. In addition, a large number of APL programs from a university environment were analyzed. Evidence is presented that verifies that APL has a higher language level than any other common programming language previously studied. Counting monadic and dyadic uses of the same APL symbol as an instance of a different operator was found to have a significant effect on the language level calculated for APL. However, decomposing derived APL functions into separate operators did not seem to have a significant effect on language level.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231546","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701914","APL;language level;software metrics;software science","Software metrics;Application software;Computer languages;Software measurement;Assembly;Analysis of variance;Costs;Road transportation;Impurities;Vocabulary","","APL;language level;software metrics;software science","","3","","8","","","","","","IEEE","IEEE Journals & Magazines"
"The performance of flow graph locking","M. H. Eich; S. M. Garard","Dept. of Comput. Sci. & Eng., Southern Methodist Univ., Dallas, TX, USA; Dept. of Comput. Sci. & Eng., Southern Methodist Univ., Dallas, TX, USA","IEEE Transactions on Software Engineering","","1990","16","4","477","483","The performance of flow graph locking (FGL) is compared with that of two-phase locking (2PL). As the data sharing level increases, FGL has a better response time than 2PL. Regardless of the data sharing or multiprogramming levels, FGL usually facilitates a better throughput rate than 2PL.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.54301","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=54301","","Flow graphs;Concurrency control;Transaction databases;Protocols;Authorization;System recovery;Concurrent computing;Delay;Throughput;Computer science","concurrency control;distributed databases","performance;flow graph locking;two-phase locking;response time;data sharing;multiprogramming levels","","8","","7","","","","","","IEEE","IEEE Journals & Magazines"
"A Method for the Syntax Directed Design of Multiprograms","D. Coleman; J. W. Hughes; M. S. Powell","Department of Computation, University of Manchester Institute of Science and Technology; NA; NA","IEEE Transactions on Software Engineering","","1981","SE-7","2","189","196","A method of program design is described which leads naturally to the expression of a program as a pipeline network of simple processes. Starting from the problem statement the valid inputs and outputs are specified by grammars, which can be combined to define the requisite translation. A notation for translation grammars is described informally which allows a translation to take into account semantic as well as syntactic information. Terminal symbols may be attributed by data types and may be qualified by Boolean expressions. The notation is capable of direct compilation but in this paper we show how it may be used to derive a program in a conventional high level language such as Pascal or Cobol. It is shown that more complex problems can be solved by simple pipeline structures of simple translations. Provided that nonbacktracking grammars are used to specify translations, the pipeline structure is well-suited to concurrent execution on a multiprocessor. The method is illustrated by examples from data processing.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234516","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702825","Attributed translations;multiprocessing;pipeline programs;programming methodology;software engineering","Pipelines;Hardware;Design methodology;Data processing;Production;Software engineering;Writing;Councils;Distributed computing;Marketing and sales","","Attributed translations;multiprocessing;pipeline programs;programming methodology;software engineering","","8","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Construction of Universal Instances for Loop-Free Network Databases Using a Join-Like Operation","S. Jajodia; F. N. Springsteel","Computer Science and Systems Branch, Naval Research Laboratory; NA","IEEE Transactions on Software Engineering","","1987","SE-13","7","811","819","In this paper, we give a polynomial-time method to construct effectively the unique universal instance, using as few nulls as possible, from any loop-free network database, via a ""minimal information"" extension of natural join. Our results can be seen as concretely and quickly implementing the universal relation view for databases which are not pairwise consistent.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233492","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702292","Bachman diagram;extended join;-acyclic relational schema;loop-free network database;natural join;relational database;universal instance;unmarked null value","Relational databases;Polynomials;Computer science;Null value;Laboratories;Terminology;Transaction databases","","Bachman diagram;extended join;-acyclic relational schema;loop-free network database;natural join;relational database;universal instance;unmarked null value","","","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Invariants, frames and postconditions: a comparison of the VDM and B notations","J. Bicarregui; B. Ritchie","Dept. of Inf., Rutherford Appleton Lab., Chilton, UK; Dept. of Inf., Rutherford Appleton Lab., Chilton, UK","IEEE Transactions on Software Engineering","","1995","21","2","79","89","VDM and B are two ""model-oriented"" formal methods. Each gives a notation for the specification of systems as state machines in terms of a set of states with operations defined as relations on that set. Each has a notion of refinement of data and operations based on the principles of reduction of nondeterminism and increase in definedness. The paper makes a comparison of the two notations through an example of a communications protocol previously formalized by G. Bruns and S. Anderson (1994). Two abstractions and two reifications of the original specification are given. Particular attention is paid to three areas where the notations differ: the use of postconditions that assume the invariant as opposed to postconditions that enforce it; the explicit ""framing"" of operations as opposed to the ""minimal frame"" approach; and the use of relational postconditions as opposed to generalized substitutions.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.345824","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=345824","","Protocols;Data models;Carbon capture and storage;Informatics;Formal specifications;Microprocessors;Safety;Embedded software;Design engineering","Vienna development method;formal specification;specification languages;protocols","VDM;B notations;model-oriented formal methods;state machines;communications protocol;specification;invariant;explicit framing;minimal frame;relational postconditions","","5","","9","","","","","","IEEE","IEEE Journals & Magazines"
"A Compiler for an Array and Vector Processing Language","R. H. Perrott; D. Crookes; P. Milligan; W. R. M. Purdy","Department of Computer Science, Queen's University of Belfast; NA; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","5","471","478","A compiler for a Pascal-based language Actus is described. The language is suitable for the expression of the type of parallelism offered by both array and vector processors. The implementation described is for the Cray-1 computer. An objective of the implementation has been to construct an optimizing compiler which can be readily adapted for a range of array and vector processors. As a result the machine-dependent sections of the compiler have been clearly identified.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232486","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702037","Abstract representation;array processors;graph transformations;optimization;vector processors","Parallel processing;Vector processors;Hardware;Optimizing compilers;Computer languages;Programming profession;Computer science;Adaptive arrays;Program processors;Algorithms","","Abstract representation;array processors;graph transformations;optimization;vector processors","","3","","9","","","","","","IEEE","IEEE Journals & Magazines"
"A study of the applicability of complexity measures","J. S. Davis; R. J. LeBlanc","Dept. of Manage., Clemson Univ., SC, USA; NA","IEEE Transactions on Software Engineering","","1988","14","9","1366","1372","A study of the predictive value of a variety of syntax-based problem complexity measures is reported. Experimentation with variants of chunk-oriented measures showed that one should judiciously select measurable software attributes as proper indicators of what one wishes to predict, rather than hoping for a single, all-purpose complexity measure. The authors have shown that it is possible for particular complexity measures or other factors to serve as good predictors of some properties of program but not for others. For example, a good predictor of construction time will not necessarily correlate well with the number of error occurrences. M.H. Halstead's (1977) efforts measure (E) was found to be a better predictor that the two nonchunk measures evaluated, namely, T.J. McCabe's (1976) V(G) and lines of code, but at least one chunk measure predicted better than E in every case.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6179","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6179","","Software measurement;Psychology;Computer science;Terminology;Computer errors;Programming profession","software engineering","software engineering;complexity measures;predictive value;chunk-oriented measures;software attributes;construction time;error occurrences;efforts measure","","49","","42","","","","","","IEEE","IEEE Journals & Magazines"
"Region analysis: a parallel elimination method for data flow analysis","Yong-Fong Lee; B. G. Ryder; M. E. Fiuczynski","Intel Corp., Santa Clara, CA, USA; NA; NA","IEEE Transactions on Software Engineering","","1995","21","11","913","926","Parallel data flow analysis methods offer the promise of calculating detailed semantic information about a program at compile-time more efficiently than sequential techniques. Previous work on parallel elimination methods (Zobel, 1990) has been hampered by the lack of control over interval size; this can prohibit effective parallel execution of these methods. To overcome this problem, we have designed the region analysis method, a new elimination method for data flow analysis. Region analysis emphasizes flow graph partitioning to enable better load balancing in a more effective parallel algorithm. We present the design of region analysis and the empirical results we have obtained that indicate: the prevalence of large intervals in flow graphs derived from real programs; and the performance improvement of region analysis over parallel Allen-Cocke interval analysis. Our implementation analyzed programs from the Perfect Benchmarks and netlib running on a Sequent Symmetry S81.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.473220","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=473220","","Data analysis;Flow graphs;Algorithm design and analysis;Information analysis;Parallel algorithms;Performance analysis;Size control;Load flow analysis;Software tools;Computer science","data flow analysis;data flow graphs;program compilers;parallel algorithms;resource allocation;parallel programming;software performance evaluation","region analysis;parallel elimination method;parallel data flow analysis methods;semantic information;compile-time;interval size;parallel execution;flow graph partitioning;load balancing;parallel algorithm;performance improvement;interval analysis;Perfect Benchmarks;netlib;Sequent Symmetry S81;program optimization","","7","","33","","","","","","IEEE","IEEE Journals & Magazines"
"The State of Software Maintenance","N. F. Schneidewind","Naval Postgraduate School","IEEE Transactions on Software Engineering","","1987","SE-13","3","303","310","A state of software maintenance survey is presented, indicating the incongruity of the simultaneous existence of importance and neglect in this field. An overview is given of selected developments and activities covering the following topics:  The ""Maintenance Problem.""  Models.  Methods for improving maintenance.  Metrics.  Maintenance information management.  Standards.  Maintenance of existing code.  Surveys.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233161","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702216","Metrics;models;software maintenance","Software maintenance;Data processing;Information management;Code standards;Standards development;History;Computer science;Software performance;Software systems;Error correction","","Metrics;models;software maintenance","","54","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Environment evolution: the Prism model of changes","N. H. Madhavji","Sch. of Comput. Sci., McGill Univ., Montreal, Que., Canada","IEEE Transactions on Software Engineering","","1992","18","5","380","392","A software development environment supports a complex network of items of at least the following major types: people, policies, laws, resources, processes and results. Such items may need to be changed on an on-going basis. The authors have designed in the Prism project a model of changes and two supporting change-related environment infrastructures with the following key features: separation of changes to the described items from the changes to the environmental facilities encapsulating these items; a facility, called the dependency structure, for describing various items and their interdependencies, and for identifying the items affected by a given change; a facility, called the change structure for classifying, recording, and analyzing change-related data and for making qualitative judgments of the consequences of a change; identification of the many distinct properties of a change; and a built-in mechanism for providing feedback. The author's approach to the problem of change and its rationale is described.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.135771","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=135771","","Programming;Environmental management;Complex networks;Data analysis;Mechanical factors;Feedback;Project management;Engineering management;Councils;Computer science","data structures;programming environments;software tools","Prism model;software development environment;complex network;people;policies;laws;resources;processes;Prism project;change-related environment infrastructures;environmental facilities;dependency structure;change structure;change-related data;qualitative judgments;built-in mechanism;feedback","","39","","41","","","","","","IEEE","IEEE Journals & Magazines"
"A case study of software process improvement during development","I. Bhandari; M. Halliday; E. Tarver; D. Brown; J. Chaar; R. Chillarege","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1993","19","12","1157","1170","We present a case study of the use of a software process improvement method which is based on the analysis of defect data. The first step of the method is the classification of software defects using attributes which relate defects to specific process activities. Such classification captures the semantics of the defects in a fashion which is useful for process correction. The second step utilizes a machine-assisted approach to data exploration which allows a project team to discover such knowledge from defect data as is useful for process correction. We show that such analysis of defect data can readily lead a project team to improve their process during development.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.249661","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=249661","","Computer aided software engineering;Data analysis;Software systems;Production systems;Software engineering;Laboratories;Programming;Feedback","data handling;project management;software engineering;software metrics","case study;software process improvement;defect data analysis;software defects;attributes;process activities;semantics;process correction;machine-assisted approach;data exploration;project team;software engineering;defect-based process improvement;in-process metrics;knowledge discovery","","33","","25","","","","","","IEEE","IEEE Journals & Magazines"
"An analysis of some problems in managing virtual memory systems with fast secondary storage devices","S. J. Hartley","Dept. of Comput. Sci., Virginia Univ., Charlottesville, VA, USA","IEEE Transactions on Software Engineering","","1988","14","8","1176","1187","Some of the problems that are expected to be encountered in managing virtual memory systems using the newer-technology secondary storage devices are address. The difficulties that two proposed policies have in choosing the most economical program localities of reference to assign to primary memory are analyzed. K. Koh's (1981) criterion for examining the cyclic locality interval (CLI) hierarchy of a program and choosing the least-cost pathway is examined. Koh's criterion is designed for the case of a CLI containing a single inner CLI. The decision to descend the hierarchy is based on the cycle time of the outer CLI. If the outer CLI has two or more inner CLIs, it is possible for Koh's criterion to indicate that it is more economical to descend to one of the inner CLIs without that actually being the case. Choosing which CLI to descend to requires knowledge of its duration, and this is not generally available to the memory management system. An attempt to use Koh's criterion with the loop structure of a program in order to reduce space-time execution cost was not successful.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.7627","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=7627","","Memory management;Costs;Algorithm design and analysis;Computer science;Central Processing Unit;Semiconductor memory;Solid state circuits;Technology management;Space technology","storage allocation;storage management;virtual storage","storage allocation;virtual memory;secondary storage;cyclic locality interval;least-cost pathway;memory management;loop structure;space-time execution cost","","2","","32","","","","","","IEEE","IEEE Journals & Magazines"
"A Controlled Expeniment on the Impact of Software Structure on Maintainability","H. D. Rombach","Department of Computer Science, University of Maryland","IEEE Transactions on Software Engineering","","1987","SE-13","3","344","354","This paper describes a study on the impact of software structure on maintainability aspects such as comprehensibility, locality, modifiability, and reusability in a distributed system environment. The study was part of a project at the University of Kaiserslautern, West Germany, to design and implement LADY, a LAnguage for Distributed systems. The study addressed the impact of software structure from two perspectives. The language designer's perspective was to evaluate the general impact of the set of structural concepts chosen for LADY on the maintainability of software systems implemented in LADY. The language user's perspective was to derive structural criteria (metrics), measurable from LADY systems, that allow the explanation or prediction of the software maintenance behavior. A controlled maintenance experiment was conducted involving twelve medium-size distributed software systems; six of these systems were implemented in LADY, the other six systems in an extended version of sequential Pascal. The benefits of the structural LADY concepts were judged based on a comparison of the average maintenance behavior of the LADY systems and the Pascal systems; the maintenance metrics were derived by analyzing the interdependence between structure and maintenance behavior of each individual LADY system.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233165","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702220","Complexity metrics;comprehensibility;controlled experiments;distributed systems;language comparisons;locality;maintainability lity;modifiability;reusability;software structure","Software maintenance;Software systems;Software reusability;Computer science;Software measurement;Control systems;Space technology;Distributed control;Costs","","Complexity metrics;comprehensibility;controlled experiments;distributed systems;language comparisons;locality;maintainability lity;modifiability;reusability;software structure","","72","","29","","","","","","IEEE","IEEE Journals & Magazines"
"A pre-run-time scheduling algorithm for hard real-time systems","T. Shepard; J. A. M. Gagne","Dept. of Electr. & Comput. Eng., R. Mil. Coll. of Canada, Kingston, Ont., Canada; NA","IEEE Transactions on Software Engineering","","1991","17","7","669","677","Process scheduling, an important issue in the design and maintenance of hard real-time systems, is discussed. A pre-run-time scheduling algorithm that addresses the problem of process sequencing is presented. The algorithm is designed for multiprocessor applications with preemptable processes having release times, computation times, deadlines and arbitrary precedence and exclusion constraints. The algorithm uses a branch-and-bound implicit enumeration technique to generate a feasible schedule for each processor. The set of feasible schedules ensures that the timing specifications of the processes are observed and that all the precedence and exclusion constraints between pairs of processes are satisfied. the algorithm was tested using a model derived from the F-18 mission computer operational flight program.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.83903","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=83903","","Scheduling algorithm;Real time systems;Processor scheduling;Timing;Application software;Runtime;Software algorithms;Software maintenance;Senior members;Algorithm design and analysis","aerospace computing;multiprocessing systems;real-time systems;scheduling","hard real-time systems;pre-run-time scheduling algorithm;process sequencing;multiprocessor applications;preemptable processes;release times;computation times;deadlines;arbitrary precedence;exclusion constraints;branch-and-bound implicit enumeration technique;feasible schedule;timing specifications;F-18 mission computer operational flight program","","24","","9","","","","","","IEEE","IEEE Journals & Magazines"
"A Simple Separate Compilation Mechanism for Block-Structured Languages","R. J. Le Blanc; C. N. Fischer","School of Information and Computer Science, Georgia Institute of Technology, Atlanta, GA 30332.; Department of Computer Science, University of Wisconsin, Madison, WI 53706.","IEEE Transactions on Software Engineering","","1984","SE-10","3","221","227","A very simple and efficient technique for the introduction of separate compilation facilities into compilers for block-structured languages is presented. Using this technique, programs may be compiled in parts while the compile-time checking advantages of compilation as a whole are retained. These features are simple for a programmer to understand and are easy to implement. Experience has shown this separate compilation mechanism to be a useful tool in the development of large programs in block-structured languages.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010230","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010230","Block-structured languages;compilers;Pascal;programming languages;separate compilation","Program processors;Runtime;Programming profession;Proposals;Algorithms;Computer languages;Data structures;Couplings;Costs","","","","1","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Proving Consistency of Database Transactions Written in Extended Pascal","G. Gardarin; M. Melkanoff","Institut de Programmation and IRIA-SIRIUS; NA","IEEE Transactions on Software Engineering","","1982","SE-8","4","440","446","The purpose of this correspondence is to present an approach for verifying that explicitly stated integrity constraints are not violated by certain transactions. We utilize a relational model wherein constraints are given in a language based on the first-order predicate calculus. Transactions are written in terms of a Pascal-like host language with embedded first-order predicate calculus capabilities allowing queries and updates.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235580","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702968","Consistency;correctness proof;integrity constraint;predicate calculus;relational database;transaction","Transaction databases;Relational databases;Calculus;Computer languages;Programming profession;Testing;Database systems;High level languages;Data visualization;Visual databases","","Consistency;correctness proof;integrity constraint;predicate calculus;relational database;transaction","","","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Control and definition modularization: an improved software design technique for organizing programs","S. B. Yadav","Dept. of Inf. Syst. & Quantitative Sci., Texas Tech. Univ., Lubbock, TX, USA","IEEE Transactions on Software Engineering","","1990","16","1","92","99","The author proposes a technique called control and definition modularization (CDM), which derives a systematic program layout from a given structure chart using the concepts of 'control' and 'definition' modules. A control module includes processes for handling a conceptual data object not directly implementable. A definition module defines operations associated with a concrete data object implementable using a primitive or derived data type of a programming language. Grouping the operations available for each concrete data object, and keeping them separated from execution flow, improves programs maintainability. This technique extends the structured design methodology and provides designers with a systematic way of deriving informational strength modules as well as a structured physical layout from the structure chart. A program based on the CDM technique is easier to understand and maintain. This research makes a significant contribution toward bridging the gap between structured design and object-oriented concepts.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44367","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44367","","Software design;Organizing;Design methodology;Software maintenance;Concrete;Programming profession;Control systems;Process control;Computer languages;Costs","software engineering","definition modularization;software design technique;organizing programs;control and definition modularization;systematic program layout;conceptual data object;execution flow;programs maintainability;structured design methodology","","","","22","","","","","","IEEE","IEEE Journals & Magazines"
"A Methodology for Structured Database Decomposition","Shi-Kuo Chang; Wu-Haung Cheng","Knowledge Systems Laboratory, University of Illinois; NA","IEEE Transactions on Software Engineering","","1980","SE-6","2","205","218","We present a methodology for structured database decomposition based on the relational data model. It is argued that in the distributed database environment, structured database decomposition is attractive both for efficiency and for database security considerations. Techniques for parallel processing and hashed access of structurally decomposed database are presented. Techniques for structured database decomposition to support multiple user views are also described. Structured database decomposition is most advantageous in a query only database environment with stable user views, although dynamic updates can also be handled using techniques described in this paper.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230471","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702717","Database decompostion;distributed database system;distributed information system;relational database","Relational databases;Distributed databases;Spatial databases;Transaction databases;Database systems;Parallel processing;Stacking;Rain;Knowledge based systems;Laboratories","","Database decompostion;distributed database system;distributed information system;relational database","","8","","36","","","","","","IEEE","IEEE Journals & Magazines"
"The Performance of Alternative Strategies for Dealing with Deadlocks in Database Management Systems","R. Agrawal; M. J. Carey; L. W. Mcvoy","AT&amp;T Bell Laboratories; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","12","1348","1363","There is growing evidence that, for a fairly wide variety of database workloads and system configurations, locking is the concurrency control strategy of choice. With locking, of course, comes the possibility of deadlocks. Although the database literature is full of algorithms for dealing with deadlocks, very little in the way of practical performance information is available to a database system designer faced with the decision of choosing a good deadlock resolution strategy. This paper is an attempt to bridge this gap in our understanding of the behavior and performance of alternative deadlock resolution strategies. We employ a simulation model of a database environment to study the relative performance of several strategies based on deadlock detection, several strategies based on deadlock prevention, and a strategy based on timeouts. We show that the choice of the best deadlock resolution strategy depends upon the level of data contention, the resource utilization levels, and the types of transactions. We provide guidelines for selecting a deadlock resolution strategy for different operating regions.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233145","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702184","Concurrency control;database systems;deadlock;modeling and simulation;transaction processing","System recovery;Database systems;Concurrency control;Bridges;Transaction databases;Algorithm design and analysis;Resource management;Guidelines;Control system synthesis;Hardware","","Concurrency control;database systems;deadlock;modeling and simulation;transaction processing","","23","","42","","","","","","IEEE","IEEE Journals & Magazines"
"Cyclomatic complexity density and software maintenance productivity","G. K. Gill; C. F. Kemerer","Sloan Sch. of Manage., MIT, Cambridge, MA, USA; Sloan Sch. of Manage., MIT, Cambridge, MA, USA","IEEE Transactions on Software Engineering","","1991","17","12","1284","1288","A study of the relationship between the cyclomatic complexity metric (T. McCabe, 1976) and software maintenance productivity, given that a metric that measures complexity should prove to be a useful predictor of maintenance costs, is reported. The cyclomatic complexity metric is a measure of the maximum number of linearly independent circuits in a program control graph. The current research validates previously raised concerns about the metric on a new data set. However, a simple transformation of the metric is investigated whereby the cyclomatic complexity is divided by the size of the system in source statements. thereby determining a complexity density ratio. This complexity density ratio is demonstrated to be a useful predictor of software maintenance productivity on a small pilot sample of maintenance projects.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.106988","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=106988","","Software maintenance;Productivity;Circuits;Software measurement;Software performance;Software engineering;Programming;Control systems;Software metrics;Software quality","software maintenance;software metrics","cyclomatic complexity metric;software maintenance productivity;linearly independent circuits;program control graph;data set;complexity density ratio","","66","","23","","","","","","IEEE","IEEE Journals & Magazines"
"A Survey of Software Engineering Practice: Tools, Methods, and Results","L. L. Beck; T. E. Perkins","Department of Mathematical Sciences, San Diego State University; NA","IEEE Transactions on Software Engineering","","1983","SE-9","5","541","561","The results of a survey of software development practice are reported and analyzed. The problems encountered in various phases of the software life cycle are measured and correlated with characteristics of the responding installations. The use and acceptance of the term ""software engineer"" is investigated, and the functions and background of persons identified as software engineers are reported. The usage of a wide variety of software engineerilng tools and methods is measured; conclusions are drawn concerning the usefulness of these techniques.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.235114","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703095","Software development;software engineering;software engineers;software life cycle;system development","Software engineering;Software measurement;Educational institutions;Phase measurement;Software tools;Software systems;Programming profession;Software maintenance","","Software development;software engineering;software engineers;software life cycle;system development","","25","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Software Development Management Planning","J. Cooper","CACI, Inc., 1815 North Fort Meyer Drive, Arlington, VA 22209.","IEEE Transactions on Software Engineering","","1984","SE-10","1","22","26","The lack of comprehensive planning prior to the initiation of a software development project is a very pervasive failing. This paper walks through a sample software development plan discussing the various areas that a software development manager should address in preparing his project's plan. Various considerations and suggestions are presented for each of the management subject areas. How the user/customer can use the developer's plan to aid in monitoring of his software's evolution is also presented. Detailed planning of a software development project is necessary to the successful completion of the project.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010194","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010194","Project management;project planning;software acquisition management;software development plan;software engineering management","Software development management;Project management;Programming;Scheduling;Software quality;Engineering management;Quality management;Contracts;Software engineering;Costs","","","","4","","","","","","","","IEEE","IEEE Journals & Magazines"
"Automated Software Quality Assurance","H. M. Sneed; A. Merey","Software Engineering Service; NA","IEEE Transactions on Software Engineering","","1985","SE-11","9","909","916","This paper describes a family of tools which not only supports software development, but also assures the quality of each software product from the requirements definition to the integrated system. It is based upon an explicit definition of the design objectives and includes specification verification, design evaluation, static program analysis, dynamic program analysis, integration test auditing, and configuration management.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232548","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702108","Dynamic analysis;review techniques;software metrics;software quality assurance;static analysis","Software quality;Documentation;Costs;Programming;Testing;Project management;Software tools;Environmental economics;Quality assurance;Software engineering","","Dynamic analysis;review techniques;software metrics;software quality assurance;static analysis","","16","","22","","","","","","IEEE","IEEE Journals & Magazines"
"The Programmer's Apprentice: Knowledge Based Program Editing","R. C. Waters","Artificial Intelligence Laboratory, Massachusetts Institute of Technology","IEEE Transactions on Software Engineering","","1982","SE-8","1","1","12","An initial implementation of an interactive programming assistant system called the programmer's apprentice (PA) is described. The PA is designed to be midway between an improved programming methodology and an automatic programming system. The intention is that the programmer will do the hard parts of design and implementation while the PA will assist him wherever possible. One of the major underpinnings of the PA is a representation (called a plan) for programs which abstracts away from the inessential features of a program, and represents the basic logical properties of the algorithm explicitly.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.234769","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702900","Computer-aided design;editing;Lisp;plans;program analysis;programmer's apprentice;program modification;program synthesis;program understanding;transformations","Programming profession;Libraries;Automatic programming;Programming environments;Computer languages;Abstracts;Algorithm design and analysis;Program processors;Documentation;Debugging","","Computer-aided design;editing;Lisp;plans;program analysis;programmer's apprentice;program modification;program synthesis;program understanding;transformations","","48","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Using test oracles generated from program documentation","D. K. Peters; D. L. Parnas","Dept. of Electr. & Comput. Eng., McMaster Univ., Hamilton, Ont., Canada; NA","IEEE Transactions on Software Engineering","","1998","24","3","161","173","The paper illustrates how software can be described precisely using LD-relations, how these descriptions can be presented in a readable manner using tabular notations, and one way such descriptions can be used to test programs. The authors describe an algorithm that can be used to generate a test oracle from program documentation, and present the results of using a tool based on it to help test part of a commercial network management application. The results demonstrate that these methods can be effective at detecting errors and greatly increase the speed and accuracy of test evaluation when compared with manual evaluation. Such oracles can be used for unit testing, in situ testing, constructing self-checking software, and ensuring consistency between code and documentation.","0098-5589;1939-3520;2326-3881","","10.1109/32.667877","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=667877","","Documentation;Software testing;Automatic testing;System testing;Application software;Formal specifications;Automata;Software engineering;Software maintenance","system documentation;program testing;formal specification;finite state machines","test oracles;program documentation;LD-relations;tabular notations;algorithm;commercial network management application;error detection;test evaluation speed;test evaluation accuracy;in situ testing;unit testing;self-checking software construction;code","","88","","37","","","","","","IEEE","IEEE Journals & Magazines"
"RUBRIC: A System for Rule-Based Information Retrieval","B. P. Mc Cune; R. M. Tong; J. S. Dean; D. G. Shapiro","Advanced Information &amp; Decision Systems; NA; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","9","939","945","A research prototype software system for conceptual information retrieval has been developed. The goal of the system, called RUBRIC, is to provide more automated and relevant access to unformatted textual databases. The approach is to use production rules from artificial intelligence to define a hierarchy of retrieval subtopics, with fuzzy context expressions and specific word phrases at the bottom. RUBRIC allows the definition of detailed queries starting at a conceptual level, partial matching of a query and a document, selection of only the highest ranked documents for presentation to the user, and detailed explanation of how and why a particular document was selected. Initial experiments indicate that a RUBRIC rule set better matches human retrieval judgment than a standard Boolean keyword expression, given equal amounts of effort in defining each. The techniques presented may be useful in stand-alone retrieval systems, front-ends to existing information retrieval systems, or real-time document filtering and routing.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232827","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702112","Artificial intelligence;evidential reasoning;expert systems;information retrieval","Information retrieval;Software prototyping;Software systems;Databases;Production;Artificial intelligence;Humans;Real time systems;Information filtering;Information filters","","Artificial intelligence;evidential reasoning;expert systems;information retrieval","","10","","6","","","","","","IEEE","IEEE Journals & Magazines"
"FINE: A fault injection and monitoring environment for tracing the UNIX system behavior under faults","W. -. Kao; R. K. Iyer; D. Tang","Center for Reliable & High Performance Comput., Illinois Univ., Urbana, IL, USA; Center for Reliable & High Performance Comput., Illinois Univ., Urbana, IL, USA; Center for Reliable & High Performance Comput., Illinois Univ., Urbana, IL, USA","IEEE Transactions on Software Engineering","","1993","19","11","1105","1118","The authors present a fault injection and monitoring environment (FINE) as a tool to study fault propagation in the UNIX kernel. FINE injects hardware-induced software errors and software faults into the UNIX kernel and traces the execution flow and key variables of the kernel. FINE consists of a fault injector, a software monitor, a workload generator, a controller, and several analysis utilities. Experiments on SunOS 4.1.2 are conducted by applying FINE to investigate fault propagation and to evaluate the impact of various types of faults. Fault propagation models are built for both hardware and software faults. Transient Markov reward analysis is performed to evaluate the loss of performance due to an injected fault. Experimental results show that memory and software faults usually have a very long latency, while bus and CPU faults tend to crash the system immediately. About half of the detected errors are data faults, which are detected when the system is tries to access an unauthorized memory location. Only about 8% of faults propagate to other UNIX subsystems. Markov reward analysis shows that the performance loss incurred by bus faults and CPU faults is much higher than that incurred by software and memory faults. Among software faults, the impact of pointer faults is higher than that of nonpointer faults.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.256857","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=256857","","Monitoring;Kernel;Transient analysis;Performance analysis;Performance loss;Fault detection;Hardware;Performance evaluation;Delay;Computer crashes","program testing;software tools;system monitoring;Unix","FINE;fault injection and monitoring environment;UNIX system behavior;hardware-induced software errors;software faults;fault injector;software monitor;workload generator;analysis utilities;SunOS 4.1.2;transient Markov reward analysis;bus faults;CPU faults;pointer faults","","85","","33","","","","","","IEEE","IEEE Journals & Magazines"
"Specification directed module testing","I. J. Hayes","Programming Research Group, Oxford University Computing Laboratory, Oxford OX1 3QD, England; Department of Computer Science, University of Queensland, St. Lucia, Queensland 4067, Australia","IEEE Transactions on Software Engineering","","1986","SE-12","1","124","133","If a program is developed from a specification in a mathematically rigorous manner, work done in the development can be utilized in the testing of the program. The better understanding afforded by these methods provides a more thorough check on the correct operation of the program under test. This should lead to earlier detection of faults (making it easier to determine their causes), more useful debugging information, and a greater confidence in the correctness of the final product. Overall, a more systematic approach should expedite the task of the program tester and improve software reliability. The testing techniques described here apply to the testing of abstract data types (modulus, packages). The techniques utilize information generated during refinement of a data type, such as the data type invariant and the relationship between the specification and implementation states; this information is used to specify parts of the code to be written for testing.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312926","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312926","Abstract data types;data type invariant;modules;module testing;packages;pre- and postconditions;retrieval function;software reliability;specification language-Z","Testing;Abstracts;Computational modeling;Debugging;Software;Software reliability;Vegetation","program debugging;program testing;software reliability","module testing;specification;faults;debugging information;correctness;program tester;software reliability","","19","","","","","","","","IEEE","IEEE Journals & Magazines"
"A Methodology for Collecting Valid Software Engineering Data","V. R. Basili; D. M. Weiss","Department of Computer Science, University of Maryland, College Park, MD 20742.; Naval Research Laboratory, Washington, DC 20375.","IEEE Transactions on Software Engineering","","1984","SE-10","6","728","738","An effective data collection method for evaluating software development methodologies and for studying the software development process is described. The method uses goal-directed data collection to evaluate methodologies with respect to the claims made for them. Such claims are used as a basis for defining the goals of the data collection, establishing a list of questions of interest to be answered by data analysis, defining a set of data categorization schemes, and designing a data collection form. The data to be collected are based on the changes made to the software during development, and are obtained when the changes are made. To ensure accuracy of the data, validation is performed concurrently with software development and data collection. Validation is based on interviews with those people supplying the data. Results from using the methodology show that data validation is a necessary part of change data collection. Without it, as much as 50 percent of the data may be erroneous. Feasibility of the data collection methodology was demonstrated by applying it to five different projects in two different environments. The application showed that the methodology was both feasible and useful.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010301","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010301","Data collection;data collection methodology;error analysis;error classification;software engineering experimentation","Software engineering;Programming;Application software;Error correction;Laboratories;Control systems;Error correction codes;Software maintenance;Software testing;Data engineering","","","","429","","42","","","","","","IEEE","IEEE Journals & Magazines"
"Architecture-based performance analysis applied to a telecommunication system","D. Petriu; C. Shousha; A. Jalnapurkar","Dept. of Syst. & Comput. Eng., Carleton Univ., Ottawa, Ont., Canada; NA; NA","IEEE Transactions on Software Engineering","","2000","26","11","1049","1065","Software architecture plays an important role in determining software quality characteristics, such as maintainability, reliability, reusability, and performance. Performance effects of architectural decisions can be evaluated at an early stage by constructing and analyzing quantitative performance models, which capture the interactions between the main components of the system as well as the performance attributes of the components themselves. The paper proposes a systematic approach to building layered queueing network (LQN) performance models from a UML description of the high-level architecture of a system and more exactly from the architectural patterns used for the system. The performance model structure retains a clear relationship with the system architecture, which simplifies the task of converting performance analysis results into conclusions and recommendations related to the software architecture. The proposed approach is applied to a telecommunication product for which an LQN model is built and analyzed. The analysis shows how the performance bottleneck is moving from component to component (hardware or software) under different loads and configurations and exposes some weaknesses in the original software architecture, which prevent the system from using the available processing power at full capacity due to excessive serialization.","0098-5589;1939-3520;2326-3881","","10.1109/32.881717","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=881717","","Performance analysis;Software architecture;Computer architecture;Software quality;Maintenance;Buildings;Unified modeling language;Power system modeling;Hardware;Software performance","software performance evaluation;software architecture;software quality;queueing theory;telecommunication computing;specification languages;object-oriented programming","architecture based performance analysis;telecommunication system;software architecture;software quality characteristics;maintainability;reliability;reusability;performance effects;architectural decisions;quantitative performance models;performance attributes;systematic approach;layered queueing network;LQN performance models;UML description;high-level architecture;architectural patterns;performance model structure;system architecture;performance analysis results;telecommunication product;LQN model;performance bottleneck;processing power;serialization","","34","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Automatic generation of path covers based on the control flow analysis of computer programs","A. Bertolino; M. Marre","Istituto di Elaborazione dell'Inf., CNR, Pisa, Italy; NA","IEEE Transactions on Software Engineering","","1994","20","12","885","899","Branch testing a program involves generating a set of paths that will cover every arc in the program flowgraph, called a path cover, and finding a set of program inputs that will execute every path in the path cover. This paper presents a generalized algorithm that finds a path cover for a given program flowgraph. The analysis is conducted on a reduced flowgraph, called a ddgraph, and uses graph theoretic principles differently than previous approaches. In particular, the relations of dominance and implication which form two trees of the arcs of the ddgraph are exploited. These relations make it possible to identify a subset of ddgraph arcs, called unconstrained arcs, having the property that a set of paths exercising all the unconstrained arcs also cover all the arcs in the ddgraph. In fact, the algorithm has been designed to cover all the unconstrained arcs of a given ddgraph: the paths are derived one at a time, each path covering at least one as yet uncovered unconstrained arc. The greatest merits of the algorithm are its simplicity and its flexibility. It consists in just visiting recursively in combination the dominator and the implied trees, and is flexible in the sense that it can derive a path cover to satisfy different requirements, according to the strategy adopted for the selection of the unconstrained arc to be covered at each recursive iteration. This feature of the algorithm can be employed to address the problem of infeasible paths, by adopting the most suitable selection strategy for the problem at hand. Embedding of the algorithm into a software analysis and testing tool is recommended.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.368137","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=368137","","Automatic generation control;Software testing;Performance analysis;Algorithm design and analysis;Tree graphs;Software algorithms;Embedded software;Software tools;Councils;Costs","program testing;software tools;trees (mathematics);program diagnostics;flow graphs;program control structures","path covers;control flow analysis;program branch testing;program flowgraph;program inputs;ddgraph;graph theoretic principles;dominance;implication;arc trees;unconstrained arcs;dominator tree;implied tree;flexibility;simplicity;recursive iteration;infeasible paths;selection strategy;software analysis tool;software testing tool;automated testing tool","","57","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Domain-Specific Automatic Programming","D. R. Barstow","Schlumberger-Doll Research","IEEE Transactions on Software Engineering","","1985","SE-11","11","1321","1336","Domain knowledge is crucial to an automatic programming system and the interaction between domain knowledge and programming at the current time. The NIX project at Schlumberger-Doll Research has been investigating this issue in the context of two application domains related to oil well logging. Based on these experiments we have developed a framework for domain-specific automatic programming. Within the framework, programming is modeled in terms of two activities, formalization and implementation, each of which transforms descriptions of the program as it proceeds through intermediate states of development. The activities and transformations may be used to characterize the interaction of programming knowledge and domain knowledge in an automatic programming system.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231881","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701949","Automatic programming;programming knowledge;program transformations","Automatic programming;Petroleum;Well logging;Runtime","","Automatic programming;programming knowledge;program transformations","","89","","44","","","","","","IEEE","IEEE Journals & Magazines"
"Using automatic process clustering for design recovery and distributed debugging","T. Kunz; J. P. Black","Dept. of Comput. Sci., Waterloo Univ., Ont., Canada; Dept. of Comput. Sci., Waterloo Univ., Ont., Canada","IEEE Transactions on Software Engineering","","1995","21","6","515","527","Distributed applications written in Hermes typically consist of a large number of sequential processes. The use of a hierarchy of process clusters can facilitate the debugging of such applications. Ideally, such a hierarchy should be derived automatically. This paper discusses two approaches to automatic process clustering, one analyzing runtime information with a statistical approach and one utilizing additional semantic information. Tools realizing these approaches were developed and a quantitative measure to evaluate process clusters is proposed. The results obtained under both approaches are compared, and indicate that the additional semantic information improves the cluster hierarchies derived. We demonstrate the value of automatic process clustering with an example. It is shown how appropriate process clusters reduce the complexity of the understanding process, facilitating program maintenance activities such as debugging.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.391378","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=391378","","Process design;Debugging;Programming profession;Application software;Information analysis;Electronic switching systems;Runtime;Reverse engineering;Costs;Visualization","program debugging;software maintenance;reverse engineering;parallel languages;parallel programming;software tools;computer aided software engineering","automatic process clustering;design recovery;distributed debugging;Hermes;sequential processes;runtime information analysis;statistical approach;semantic information;cluster hierarchies;understanding process;program maintenance activities;reverse engineering","","16","","35","","","","","","IEEE","IEEE Journals & Magazines"
"Real-Time Euclid: A language for reliable real-time systems","E. Kligerman; A. D. Stoyenko","Department of Computer Science, University of Toronto, Toronto, Ont. M5S 1A4, Canada; Department of Computer Science, University of Toronto, Toronto, Ont. M5S 1A4, Canada","IEEE Transactions on Software Engineering","","1986","SE-12","9","941","949","Real-Time Euclid, a language designed specifically to address reliability and guaranteed schedulability issues in real-time systems, is introduced. Real-Time Euclid uses exception handlers and import/export lists to provide comprehensive error detection, isolation, and recovery. The philosophy of the language is that every exception detectable by the hardware or the software must have an exception-handler clause associated with it. Moreover, the language definition forces every construct in the language to be time- and space-bounded. Consequently, Real-Time Euclid programs can always be analyzed for guaranteed schedulability of their processes. Thus, it is felt that Real-Time Euclid is well-suited for writing reliable real-time software.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313049","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313049","Compiler;exception handling;guaranteed response time;real-time systems;run-time system;schedulability;software reliability;system programming languages","Real-time systems;Reactive power;Arrays;Monitoring;Syntactics;Software reliability","programming languages;real-time systems","Real-Time Euclid;reliable real-time systems;address reliability;schedulability issues;real-time systems;exception handlers;import/export lists;error detection;isolation;recovery;exception-handler clause;real-time software","","86","","","","","","","","IEEE","IEEE Journals & Magazines"
"Generation and consistency checking of design and program structures","Z. L. Lichtman","Department of Computer Research and Development, Armament Development Authority, P.O. Box 2250, Haifa, Israel","IEEE Transactions on Software Engineering","","1986","SE-12","1","172","181","The author describes a mini methodology for generation and representation of design and program structures and for structural consistency checking between two successive designs or between a design and a program. This methodology comprises a tool (Program Design Language), a representation, and consistency criteria. The Program Design Language (PDL) extracts structure information, in a controlled way, from the top level program design, through layers of detailed designs, down to the source code itself. It generates an actual, complete, concise, and easily comparable structure representation. Structural consistency between levels can be checked, both at the development phase and at the operation and maintenance phase, ensuring continued structural consistency between the design(s) and the program.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312930","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312930","Consistency checking;Program Design Language (PDL);program structure;software development;software quality assurance;software tools","Customer relationship management;Computer languages;Aerospace electronics;Nickel;Data mining;Program processors","software reliability;specification languages","software reliability;consistency checking;program structures;structural consistency checking;Program Design Language;structure information;program design;source code;development phase;maintenance phase","","4","","","","","","","","IEEE","IEEE Journals & Magazines"
"The Roles of Execution and Analysis in Algorthm Design","D. M. Steier; E. Kant","Department of Computer Science, Carnegie-Mellon University; NA","IEEE Transactions on Software Engineering","","1985","SE-11","11","1375","1386","The analysis and execution of partial algorithm descriptions is an important part of the algorithm design process (as is borne out by studying the behavior of human algorithm designers). In this paper, we describe a language for representing partially designed algorithms and a process, developmental evaluation, that can discover useful knowledge to guide design. Using these and other results from our research in artificial intelligence, we are building a system, DESIGNER, that automatically designs algorithms. This paper also compares developmental evaluation to execution and analysis techniques used for testing complete programs and for validation of abstract specifications; concepts similar to those found in developmental evaluation are thus shown to apply to all stages of the software life cycle.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231885","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701953","Algorithm design;automatic programming;developmental evaluation;meta-evaluation;symbolic execution","Algorithm design and analysis;Computer science;Concrete;Testing;Process design;Artificial intelligence;Production;Cognitive science;Humans;Buildings","","Algorithm design;automatic programming;developmental evaluation;meta-evaluation;symbolic execution","","5","","42","","","","","","IEEE","IEEE Journals & Magazines"
"Structuring Distributed Systems for Recoverability and Crash Resistance","S. K. Shrivastava","Computing Laboratory, University of Newcastle-upon-Tyne","IEEE Transactions on Software Engineering","","1981","SE-7","4","436","447","An object-oriented multilevel model of computation is used to discuss recoverability and crash resistance issues in distributed systems. Of particular importance are the issues that are raised when recoverability and crash resistance properties are desired from objects whose concrete representations are distributed over several nodes. The execution of a program at a node of the system can give rise to a hierarchy of processes executing various parts of the program at different nodes. Recoverability and crash resistance properties are needed to ensure that such a group of processes leave the system state consistent despite faults in the system.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230846","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702864","Atomic actions;backward error recovery;commitment;concurrency;consistency;crash resistance;distributed systems;exception handling;message passing;recoverability;secure storage","Computer crashes;Concrete;Message passing;Computational modeling;Object oriented modeling;Distributed computing;Computer errors;Concurrent computing;Secure storage;Printing","","Atomic actions;backward error recovery;commitment;concurrency;consistency;crash resistance;distributed systems;exception handling;message passing;recoverability;secure storage","","14","","19","","","","","","IEEE","IEEE Journals & Magazines"
"The application of formal methods to the assessment of high integrity software","R. E. Bloomfield; P. K. D. Froome","Department of Scientific Services, Central Electricity Generating Board, Gravesend, Kent DA 12 2RS, England; Department of Scientific Services, Central Electricity Generating Board, Gravesend, Kent DA 12 2RS, England","IEEE Transactions on Software Engineering","","1986","SE-12","9","988","993","A case study is presented in which the Vienna development method (VDM), a formal specification and development methodology, was used during the analysis phase of the assessment of a prototype nuclear reactor protection system. The VDM specification was also translated into the logic language Prolog to animate the specification and to provide a diverse implementation for use in back-to-back testing. It is claimed that this technique provides a visible and effective method of analysis which is superior to the informal alternatives.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313053","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313053","","History;Animation;Software;Formal specifications;Abstracts;Data structures;Prototypes","formal logic;specification languages","high integrity software;Vienna development method;VDM;formal specification;development methodology;prototype nuclear reactor protection system;logic language Prolog;diverse implementation;informal alternatives","","9","","","","","","","","IEEE","IEEE Journals & Magazines"
"Abstraction mechanisms for event control in program debugging","B. Lazzerini; L. Lopriore","Inst. de Elettronica e Telecomunicazioni, Pisa Univ., Italy; NA","IEEE Transactions on Software Engineering","","1989","15","7","890","901","In the event-action model of interactions between the debugging system and the program being debugged, an event will occur on the evaluation of a conditional defined in terms of the program activity if the evaluation yields the value true, and an action is an operation performed by the debugging system on the occurrence of an event. This paper presents a set of mechanisms for expressing conditionals at different levels of abstraction. At the lowest level, the authors have the simple conditionals, which can be expressed in terms of the values of the program entities and of the execution of the program statements. Simple conditionals can be grouped to form higher-level compound conditionals, which can be expressed in terms of the state and flow histories. The paper shows that the proposed abstraction mechanisms are powerful tools for monitoring program activity. They adequately support different debugging techniques, and offer the user a considerable degree of control over the debugging experiment.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.29488","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=29488","","Debugging;History;Programming profession;Performance evaluation;Target tracking","data structures;program debugging","abstraction mechanisms;event control;program debugging;conditionals;program entities;program statements;monitoring","","4","","42","","","","","","IEEE","IEEE Journals & Magazines"
"A classification and comparison framework for software architecture description languages","N. Medvidovic; R. N. Taylor","Dept. of Comput. Sci., Univ. of Southern California, Los Angeles, CA, USA; NA","IEEE Transactions on Software Engineering","","2000","26","1","70","93","Software architectures shift the focus of developers from lines-of-code to coarser-grained architectural elements and their overall interconnection structure. Architecture description languages (ADLs) have been proposed as modeling notations to support architecture-based development. There is, however, little consensus in the research community on what is an ADL, what aspects of an architecture should be modeled in an ADL, and which of several possible ADLs is best suited for a particular problem. Furthermore, the distinction is rarely made between ADLs on one hand and formal specification, module interconnection, simulation and programming languages on the other. This paper attempts to provide an answer to these questions. It motivates and presents a definition and a classification framework for ADLs. The utility of the definition is demonstrated by using it to differentiate ADLs from other modeling notations. The framework is used to classify and compare several existing ADLs, enabling us, in the process, to identify key properties of ADLs. The comparison highlights areas where existing ADLs provide extensive support and those in which they are deficient, suggesting a research agenda for the future.","0098-5589;1939-3520;2326-3881","","10.1109/32.825767","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=825767","","Software architecture;Computer architecture;LAN interconnection;Architecture description languages;Application software;Formal specifications;Computer languages;Connectors;Computer science;Computer Society","software architecture;formal specification;specification languages","software architecture description languages;interconnection structure;modeling notations;architecture-based development;formal specification;module interconnection;simulation;programming languages;classification framework","","801","","74","","","","","","IEEE","IEEE Journals & Magazines"
"Analysis and Design in MSG.84: Formalizing Functional Specifications","V. Berzins; M. Gray","Department of Computer Science, University of Minnesota; NA","IEEE Transactions on Software Engineering","","1985","SE-11","8","657","670","Model building is identified as the most important part of the analysis and design process for software systems. A set of primitives to support this process is presented, along with a formal language, MSG.84, for recording the results of analysis and design. The semantics of the notation is defined in terms of the actor formalism, which is based on a message passing paradigm. The automatic derivation of a graphical form of the specification for user review is discussed. Potentials for computer-aided design based on MSG.84 are indicated.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232516","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702076","Actor formalism;concurrency;data abstraction;diagrams;formal language;functional specification;modeling;modularity;user review","Software systems;Formal languages;Programming;Specification languages;Prototypes;Formal specifications;Power system modeling;Buildings;Software design;Process design","","Actor formalism;concurrency;data abstraction;diagrams;formal language;functional specification;modeling;modularity;user review","","14","","34","","","","","","IEEE","IEEE Journals & Magazines"
"On the Implementation and Use of Ada on Fault-Tolerant Distributed Systems","J. C. Knight; J. I. A. Urquhart","Department of Computer Science, University of Virginia; NA","IEEE Transactions on Software Engineering","","1987","SE-13","5","553","563","In this paper, we discuss the use of Ada on distributed systems in which failure of processors has to be tolerated. We assume that tasks are the primary object of distribution, and that communication between tasks on separate processors will take place using the facilities of the Ada language. It would be possible to build a separate set of facilities for communication between processors, and to treat the software on each machine as a separate program. This is unnecessary and undesirable. In addition, the Ada language Reference Manual states specifically that a system consisting of communicating processors with private memories is suitable for executing an Ada program.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233200","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702255","Ada;distributed systems;fault tolerance;highly reliable systems;tolerance of processor failure","Fault tolerant systems;Hardware;Application software;Protocols;Embedded software;Aerospace electronics;Costs;Computer displays;Actuators;Microprocessors","","Ada;distributed systems;fault tolerance;highly reliable systems;tolerance of processor failure","","4","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Supporting scenario-based requirements engineering","A. G. Sutcliffe; N. A. M. Maiden; S. Minocha; D. Manuel","Centre for HCI Design, City Univ., London, UK; NA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","12","1072","1088","Scenarios have been advocated as a means of improving requirements engineering yet few methods or tools exist to support scenario based RE. The paper reports a method and software assistant tool for scenario based RE that integrates with use case approaches to object oriented development. The method and operation of the tool are illustrated with a financial system case study. Scenarios are used to represent paths of possible behavior through a use case, and these are investigated to elaborate requirements. The method commences by acquisition and modeling of a use case. The use case is then compared with a library of abstract models that represent different application classes. Each model is associated with a set of generic requirements for its class, hence, by identifying the class(es) to which the use case belongs, generic requirements can be reused. Scenario paths are automatically generated from use cases, then exception types are applied to normal event sequences to suggest possible abnormal events resulting from human error. Generic requirements are also attached to exceptions to suggest possible ways of dealing with human error and other types of system failure. Scenarios are validated by rule based frames which detect problematic event patterns. The tool suggests appropriate generic requirements to deal with the problems encountered. The paper concludes with a review of related work and a discussion of the prospects for scenario based RE methods and tools.","0098-5589;1939-3520;2326-3881","","10.1109/32.738340","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=738340","","Object oriented modeling;Humans;Software tools;Software engineering;Libraries;Event detection;Sociotechnical systems;Concrete;Animation;Inspection","formal specification;systems analysis;software tools;object-oriented programming;financial data processing;software reusability;software performance evaluation;bibliographies","scenario based requirements engineering;scenario based RE;software assistant tool;use case approaches;object oriented development;financial system case study;abstract models;application classes;exception types;generic requirements reuse;scenario paths;normal event sequences;abnormal events;human error;system failure;rule based frames;problematic event patterns","","168","","54","","","","","","IEEE","IEEE Journals & Magazines"
"Regeneration with virtual copies for distributed computing systems","N. R. Adam; R. Tewari","MS/CIS Dept., Rutgers Univ., Newark, NJ, USA; NA","IEEE Transactions on Software Engineering","","1993","19","6","594","602","The authors consider the consistency control problem for replicated data in a distributed computing system (DCS) and propose a new algorithm to dynamically regenerate copies of data objects in response to node failures and network partitioning in the system. The DCS is assumed to have strict consistency constraints for data object copies. The algorithm combines the advantages of voting-based algorithms and regeneration mechanisms to maintain mutual consistency of replicated data objects in the case of node failures and network partitioning. The algorithm extends the feasibility of regeneration to DCS on wide area networks and is able to satisfy user queries as long as there is one current partition in the system. A stochastic availability analysis of the algorithm shows that it provides improved availability as compared to previously proposed dynamic voting algorithms.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.232024","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=232024","","Distributed computing;Partitioning algorithms;Distributed control;Heuristic algorithms;Availability;Control systems;Wide area networks;Stochastic processes;Algorithm design and analysis;Voting","distributed databases;query processing","distributed databases;virtual copies;consistency control problem;replicated data;distributed computing system;node failures;network partitioning;consistency constraints;data object copies;voting-based algorithms;regeneration mechanisms;wide area networks;user queries;stochastic availability analysis;dynamic voting algorithms","","6","","24","","","","","","IEEE","IEEE Journals & Magazines"
"PECAN: Program Development Systems that Support Multiple Views","S. P. Reiss","Department of Computer Science, Brown University","IEEE Transactions on Software Engineering","","1985","SE-11","3","276","285","This paper describes the PECAN family of program development systems. PECAN supports multiple views of the user's program. The views can be representations of the program or of the corresponding semantics. The primary program view is a syntax-directed editor. The current semantic views include expression trees, data type diagrams, flow graphs, and the symbol table. PECAN is designed to make effective use of powerful personal machines with high-resolution graphics displays and is currently implemented on APOLLO workstations.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232211","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702004","Incremental compilation;multiple views;program development systems;programming environments;syntax-directed editors","Tree graphs;Data structures;Computer displays;Workstations;Programming environments;Programming profession;Feedback;Flowcharts;Tree data structures;Flow graphs","","Incremental compilation;multiple views;program development systems;programming environments;syntax-directed editors","","89","","27","","","","","","IEEE","IEEE Journals & Magazines"
"An object-oriented knowledge representation for spatial information","L. Mohan; R. L. Kashyap","Sch. of Electr. Eng., Purdue Univ., West Lafayette, IN, USA; Sch. of Electr. Eng., Purdue Univ., West Lafayette, IN, USA","IEEE Transactions on Software Engineering","","1988","14","5","675","681","An abstract formalism for the representation of spatial knowledge is suggested. The focus is on the development of a comprehensive representation scheme for pictorial information in which the knowledge model of the given world has a high degree of perceptual similarity to a typical user's view of the same world. The model that has been developed uses the object-oriented method of knowledge representation. The intention is that with this model any user of the system will be equipped to depict pictorial information easily and will be able to portray spatial as well as conceptual abstractions, generalizations, and rules at various levels.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6146","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6146","","Knowledge representation;Object oriented modeling;Spatial resolution;Relational databases;Data models;Automatic logic units;Engines;Pattern matching;Object oriented databases;Spatial databases","data structures;knowledge engineering","object-oriented knowledge representation;spatial information;abstract formalism;pictorial information;knowledge model;object-oriented method;conceptual abstractions","","36","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Estimating the probability of failure when testing reveals no failures","K. W. Miller; L. J. Morell; R. E. Noonan; S. K. Park; D. M. Nicol; B. W. Murrill; M. Voas","Dept. of Comput. Sci., Coll. of William & Mary, Williamsburg, VA, USA; NA; NA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1992","18","1","33","43","Formulas for estimating the probability of failure when testing reveals no errors are introduced. These formulas incorporate random testing results, information about the input distribution; and prior assumptions about the probability of failure of the software. The formulas are not restricted to equally likely input distributions, and the probability of failure estimate can be adjusted when assumptions about the input distribution change. The formulas are based on a discrete sample space statistical model of software and include Bayesian prior assumptions. Reusable software and software in life-critical applications are particularly appropriate candidates for this type of analysis.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.120314","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=120314","","Software testing;Bayesian methods;Software reusability;Software reliability;Computer errors;Application software;Probability density function;System testing;NASA;Computer science","Bayes methods;probability;program testing","failure probability estimation;formulas;random testing results;input distribution;prior assumptions;failure estimate;discrete sample space statistical model;Bayesian prior assumptions;life-critical applications","","153","","25","","","","","","IEEE","IEEE Journals & Magazines"
"An improved algorithm based on subset closures for synthesizing a relational database scheme","C. -. Yang; G. Li; P. A. -. Ng","North Texas State Univ., Denton, TX, USA; North Texas State Univ., Denton, TX, USA; North Texas State Univ., Denton, TX, USA","IEEE Transactions on Software Engineering","","1988","14","11","1731","1738","An algorithm for synthesizing a better relational database scheme in elementary key normal form (EKNF) is developed. This algorithm eliminates not only extraneous attributes and other redundancies, but also superfluities from a given set of functional dependences (FDs), based primarily on subset closures, Hamiltonian cycles of FDs, and equivalent subsets of attributes. Following this algorithm, a better LR-minimum FD covering is obtained. A more practical and efficient method for designing a relational database scheme in EKNF is then provided. The time complexity of the algorithm is polynomial.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9058","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9058","","Relational databases;Inference algorithms;Art;Design methodology;Software algorithms;Chaos;Polynomials;Algorithm design and analysis;Information science","computational complexity;database theory;relational databases;set theory","subset closures;relational database scheme;elementary key normal form;functional dependences;subset closures;Hamiltonian cycles;time complexity","","3","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Qualitative methods in empirical studies of software engineering","C. B. Seaman","Dept. of Inf. Syst., Maryland Univ., Baltimore, MD, USA","IEEE Transactions on Software Engineering","","1999","25","4","557","572","While empirical studies in software engineering are beginning to gain recognition in the research community, this subarea is also entering a new level of maturity by beginning to address the human aspects of software development. This added focus has added a new layer of complexity to an already challenging area of research. Along with new research questions, new research methods are needed to study nontechnical aspects of software engineering. In many other disciplines, qualitative research methods have been developed and are commonly used to handle the complexity of issues involving human behaviour. The paper presents several qualitative methods for data collection and analysis and describes them in terms of how they might be incorporated into empirical studies of software engineering, in particular how they might be combined with quantitative methods. To illustrate this use of qualitative methods, examples from real software engineering studies are used throughout.","0098-5589;1939-3520;2326-3881","","10.1109/32.799955","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=799955","","Software engineering;Humans;Programming;Data analysis;Design for experiments;Laboratories;Computer industry;Software development management;Design methodology","user interfaces;human factors;software development management;project management","qualitative methods;empirical studies;software engineering;research community;human aspects;software development;research questions;research methods;nontechnical aspects;qualitative research methods;human behaviour;data collection;quantitative methods;real software engineering studies","","422","","21","","","","","","IEEE","IEEE Journals & Magazines"
"A metrics suite for object oriented design","S. R. Chidamber; C. F. Kemerer","MIT, Cambridge, MA, USA; MIT, Cambridge, MA, USA","IEEE Transactions on Software Engineering","","1994","20","6","476","493","Given the central role that software development plays in the delivery and application of information technology, managers are increasingly focusing on process improvement in the software development area. This demand has spurred the provision of a number of new and/or improved approaches to software development, with perhaps the most prominent being object-orientation (OO). In addition, the focus on process improvement has increased the demand for software measures, or metrics with which to manage the process. The need for such metrics is particularly acute when an organization is adopting a new technology for which established practices have yet to be developed. This research addresses these needs through the development and implementation of a new suite of metrics for OO design. Metrics developed in previous research, while contributing to the field's understanding of software development processes, have generally been subject to serious criticisms, including the lack of a theoretical base. Following Wand and Weber (1989), the theoretical base chosen for the metrics was the ontology of Bunge (1977). Six design metrics are developed, and then analytically evaluated against Weyuker's (1988) proposed set of measurement principles. An automated data collection tool was then developed and implemented to collect an empirical sample of these metrics at two field sites in order to demonstrate their feasibility and suggest ways in which managers may use these metrics for process improvement.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.295895","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=295895","","Programming;Information management;Software measurement;Engineering management;Application software;Information technology;Software development management;Technology management;Ontologies;Software engineering","object-oriented programming;object-oriented methods;software metrics","object oriented design;metrics suite;software development;process improvement;software measures;organization;automated data collection tool;measurement principles;object oriented programming","","2155","","50","","","","","","IEEE","IEEE Journals & Magazines"
"ABE: an environment for engineering intelligent systems","L. D. Erman; J. S. Lark; F. Hayes-Roth","Teknowledge Inc., Palo Alto, CA, USA; Teknowledge Inc., Palo Alto, CA, USA; Teknowledge Inc., Palo Alto, CA, USA","IEEE Transactions on Software Engineering","","1988","14","12","1758","1770","The ABE multilevel architecture for developing intelligent systems addresses the key problems of intelligent systems engineering: large-scale applications and the reuse and integration of software components. ABE defines a virtual machine for module-oriented programming and a cooperative operating system that provides access to the capabilities of that virtual machine. On top of the virtual machine, ABE provides a number of system design and development frameworks, which embody such programming metaphors as control flow, blackboards, and dataflow. These frameworks support the construction of capabilities, including knowledge processing tools, which span a range from primitive modules to skeletal systems. Finally, applications can be built on skeletal systems. In addition, ABE supports the importation of existing software, including both conventional and knowledge processing tools.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9062","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9062","","Systems engineering and theory;Intelligent systems;Machine intelligence;Virtual machining;Application software;Computer architecture;Large scale integration;Operating systems;Control systems;Modular construction","knowledge engineering;operating systems (computers);programming environments;software reusability;software tools;virtual machines","software reusability;programming environments;knowledge engineering;ABE;intelligent systems;multilevel architecture;large-scale applications;virtual machine;module-oriented programming;cooperative operating system;control flow;blackboards;dataflow;knowledge processing tools;skeletal systems","","18","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Data Element Security and Its Effects on File Segmentation","Y. M. Babad; J. A. Hoffer","Arthur Andersen and Company; NA","IEEE Transactions on Software Engineering","","1980","SE-6","5","402","410","The literature on physical database design in general, and on file segmentation in particular, typically ignores any consideration of data security and the cost to enforce it. If records can be physically designed so that all data elements in a given record type have identical security restrictions for a given user, then data element level security enforcement can be transformed into the less costly file level security enforcement for that user and rie. Similarly, if all record types have identical security restrictions, file based security might be sufficient. This paper extends an earlier model for file segmentation to include security considerations. The extended model embeds the security measures into the logical file structure and exploits a four category taxonomy of security restriction types. The model is used to generalize the interaction between element level selective security and physical database design.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230488","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702756","Database design;database security;file segmentation;logical file structure;physical file structure;selective security","Data security;Databases;Taxonomy;Memory;Protection;Costs;Current measurement;Companies","","Database design;database security;file segmentation;logical file structure;physical file structure;selective security","","","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Using partial-order methods in the formal validation of industrial concurrent programs","P. Godefroid; D. Peled; M. Staskauskas","Bell Labs., Lucent Technol. Inc., Naperville, IL, USA; NA; NA","IEEE Transactions on Software Engineering","","1996","22","7","496","507","Formal validation is a powerful technique for automatically checking that a collection of communicating processes is free from concurrency-related errors. Although validation tools invariably find subtle errors that were missed during thorough simulation and testing, the brute-force search they perform can result in excessive memory usage and extremely long running times. Recently, a number of researchers have been investigating techniques known as partial-order methods that can significantly reduce the computational resources needed for formal validation by avoiding redundant exploration of execution scenarios. This paper investigates the behavior of partial-order methods in an industrial setting. We describe the design of a partial-order algorithm or a formal validation tool that has been used on several projects that are developing software for the Lucent Technologies 5ESS/sup (R/) telephone switching system. We demonstrate the effectiveness of the algorithm by presenting the results of experiments with actual industrial examples drawn from a variety of 5ESS application domains.","0098-5589;1939-3520;2326-3881","","10.1109/32.538606","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=538606","","Error correction;Testing;Application software;Electronic switching systems;Communication industry;Computational modeling;Performance evaluation;Algorithm design and analysis;Software algorithms;Software tools","multiprocessing programs;program verification;reachability analysis;parallel programming;electronic switching systems;telecommunication computing;software tools","partial-order methods;formal validation tool;industrial concurrent programs;automatic error checking;communicating processes;concurrency-related errors;computational resources;redundant exploration;execution scenarios;Lucent Technologies 5ESS telephone switching system;automatic verification;reachability analysis","","15","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Approaches to Mechanization of the Conversation Scheme Based on Monitors","K. H. Kim","Department of Computer Science and Engineering, University of South Florida","IEEE Transactions on Software Engineering","","1982","SE-8","3","189","197","A basic problem in designing error detection and backward recovery capabilities into concurrent programs is to coordinate the detection and recovery activities of cooperating processes. As an aid to such design Randell proposed a language construct called conversation in an abstract form. Practical mechanization of the conversation scheme, i.e., selection of a well-structured syntax and associated semantics, is the issue dealt with in this paper. Four different mechanizations based on the monitor approach to interprocess communication are presented. They are presented as feasible extensions of Concurrent Pascal in order to enable visualization of their full implementation details in at least one type of concurrent programming environment. They are presented in the increasing order of the amount of efforts that they require for extending Concurrent Pascal. They offer different degrees of assistance to the programmer in proper structuring of recoverable process interactions.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235106","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702935","Concurrent program;conversation;domino effect;error detection;error recovery;monitor;process initiation","Databases;Concurrent computing;Programming profession;Computer science;Software systems;Fault tolerance;Machinery;Computer science education;Educational programs;Project management","","Concurrent program;conversation;domino effect;error detection;error recovery;monitor;process initiation","","71","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Lower bound on the number of processors and time for scheduling precedence graphs with communication costs","M. A. Al-Mouhamed","Dept. of Comput. Eng., King Fahd Univ. of Pet. & Miner., Dharhran, Saudi Arabia","IEEE Transactions on Software Engineering","","1990","16","12","1390","1401","A lower bound on the number of processors and finish time for the problem of scheduling precedence graphs with communication costs is presented. The notion of the earliest starting time of a task is formulated for the context of lower bounds. A lower bound on the completion time is proposed. A task delay which does not increase the earliest completion time of a schedule is defined. Each task can then be scheduled within a time interval without affecting the lower bound performance on the finish time. This leads to definition of a new lower bound on the number of processors required to process the task graph. A derivation of the minimum time increase over the earliest completion time is also proposed for the case of a smaller number of processors. A lower bound on the minimum number of interprocessor communication links required to achieve optimum performance is proposed. Evaluation had been carried out by using a set of 360 small graphs. The bound on the finish time deviates at most by 5% from the optimum solution in 96% of the cases and performs well with respect to the minimum number of processors and communication links.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.62447","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=62447","","Processor scheduling;Optimal scheduling;Scheduling algorithm;Costs;Approximation algorithms;Context;Delay effects;Parallel processing;Operating systems","graph theory;scheduling","scheduling;precedence graphs;communication costs;earliest starting time;lower bounds;completion time;task delay;time interval;finish time;task graph;minimum time increase;interprocessor communication links;optimum performance;small graphs","","68","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Performance Evaluation of Asynchronous Concurrent Systems Using Petri Nets","C. V. Ramamoorthy; G. S. Ho","Department of Electrical Engineering and Computer Sciences, University of California; NA","IEEE Transactions on Software Engineering","","1980","SE-6","5","440","449","Some analysis techniques for real-time asynchronous concurrent systems are presented. In order to model clearly the synchronization involved in these systems, an extended timed Petri net model is used. The system to be studied is first modeled by a Petri net. Based on the Petri net model, a system is classified into either: 1) a consistent system; or 2) an inconsistent system. Most real-world systems fall into the first class which is further subclassified into i) decision-free systems; ii) safe persistent systems; and iii) general systems. Procedures for predicting and verifying the system performance of all three types are presented. It is found that the computational complexity involved increases in the same order as they are listed above.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230492","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702760","Asynchronous;concurrent;performance;Petri net;real time","Petri nets;Real time systems;Performance analysis;System performance;Isolation technology;Military computing;Costs;Microprocessors;Computational complexity;Solid state circuits","","Asynchronous;concurrent;performance;Petri net;real time","","351","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Towards a General Concurrency Control Algorithm for Database Systems","A. A. Farrag; M. T. Ozsu","Department of Mathematics and Computing Science, Dalhousie University; NA","IEEE Transactions on Software Engineering","","1987","SE-13","10","1073","1079","The concurrency control problem in database systems has been examined by many people and several concurrency control algorithms have been proposed. The most popular algorithms are two-phase locking and timestamp ordering. This paper shows that two-phase locking and timestamp ordering are special cases of a more general concurrency control algorithm. This general algorithm is described in detail and is proven to work correctly. We show that two-phase locking and timestamp ordering represent the two end points of a series of concurrency control algorithms. Each of them is a special case of the general algorithm proposed in this paper. Moreover, each of these special cases can be selected in advance, and can even be changed dynamically during execution.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232849","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702147","Concurrency control;database;deadlock;strictness level;timestamp ordering;two-phase locking","Concurrency control;Database systems;Transaction databases;Processor scheduling;System recovery;Scholarships;Councils;Mathematics;Concurrent computing;Writing","","Concurrency control;database;deadlock;strictness level;timestamp ordering;two-phase locking","","2","","15","","","","","","IEEE","IEEE Journals & Magazines"
"The Study of a New Perfect Hash Scheme","M. W. Du; T. M. Hsieh; K. F. Jea; D. W. Shieh","Institute of Computer Engineering, National Chiao Tung University; NA; NA; NA","IEEE Transactions on Software Engineering","","1983","SE-9","3","305","313","A new approach is proposed for the design of perfect hash functions. The algorithms developed can be effectively applied to key sets of large size. The basic ideas employed in the construction are rehash and segmentation. Analytic results are given which are applicable when problem sizes are small. Extensive experiments have been performed to test the approach for problems of larger size.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236866","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703058","Hashing;perfect hash functions;rehash;segmentation","Performance evaluation;Testing;Performance analysis;Information retrieval;Databases;Program processors;Councils;Computer science;Design methodology;Algorithm design and analysis","","Hashing;perfect hash functions;rehash;segmentation","","15","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Very High Level Concurrent Programming","Y. Shi; N. Prywes; B. Szymanski; A. Pnueli","Department of Computer and Information Science, Temple University; NA; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","9","1038","1046","Concurrent systems are typically large and complex, requiring long, development time and much labor. They are, therefore, prime candidates for simplification and automation of the design and programming process. Their major application areas include real time systems, operating systems and cooperative computation. New applications are emerging with the trends towards wide usage of personal computers connected in a network and towards use of parallel processing in supercomputer architectures.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233791","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702326","Automatic program generation;concurrent programming;nonprocedural languages;specification languages","Application software;Design automation;Process design;Automatic programming;Real time systems;Operating systems;Microcomputers;Parallel processing;Supercomputers;Computer architecture","","Automatic program generation;concurrent programming;nonprocedural languages;specification languages","","2","","46","","","","","","IEEE","IEEE Journals & Magazines"
"Automated protocol implementation with RTAG","D. P. Anderson","Dept. of Electr. Eng. & Comput. Sci., California Univ., Berkeley, CA, USA","IEEE Transactions on Software Engineering","","1988","14","3","291","300","The RTAG (real-time asynchronous grammars) programming language is discussed. The language is based on an attribute grammar notation for specifying protocols. Its main design goals are: (1) to support concise and easily understood expression of complex real-world protocols; and (2) to serve as the basis of a portable software system for automated protocol implementation. The algorithms used in generating implementations from given specifications are sketched, and a Unix-based automated implementation system for RTAG is described.<<ETX>></ETX>","0098-5589;1939-3520;2326-3881","","10.1109/32.4650","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4650","","Protocols;Operating systems;Software systems;Network interfaces;Hardware;Software engineering;Debugging;Communication standards;Software standards","grammars;protocols","automated protocol implementation;RTAG;real-time asynchronous grammars;programming language;attribute grammar notation;portable software system;Unix-based automated implementation","","16","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Automated Analysis of Discrete Communication Behavior","K. Rea; R. De B. Johnston","Bell Northern Research, 3 Place du Commerce; NA","IEEE Transactions on Software Engineering","","1987","SE-13","10","1115","1126","An objective methodology for the specification and analysis of communicating processes is presented. It is based on an algebraic theory that is a formalization of a particular state machine model. The approach recognizes the fact that the complexity of system interactions is such that computer aid is not only appropriate but necessary for any practical design methodology.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232853","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702151","Algebraic models;analysis;communicating processes;communication protocols;concurrent process specification;distributed systems;verification","Computer languages;Formal specifications;Design methodology;Calculus;Carbon capture and storage;Algebra;Application software;Protocols;Distributed computing;Local area networks","","Algebraic models;analysis;communicating processes;communication protocols;concurrent process specification;distributed systems;verification","","3","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Tolerating deviations in process support systems via flexible enactment of process models","G. Cugola","Dipt. di Elettronica e Inf., Politecnico di Milano, Italy","IEEE Transactions on Software Engineering","","1998","24","11","982","1001","Process support systems (PSSs) support business organizations in modeling, improving and automating their business processes. Thanks to their ability in enacting process models, they can be used to guide people in performing their daily work and to automate the repetitive tasks that do not require human intervention. Given these potential benefits, it is surprising to observe that PSSs are not widely adopted. This is especially true in case of highly flexible and human-intensive processes, such as design processes in general and software processes in particular. This fact can be explained by observing that currently available PSSs do not fulfil some crucial needs of modern business organizations. One of their major drawbacks is that they do not offer adequate mechanisms to cope with unforeseen situations. They are good at supporting business processes if all proceeds as expected, but if an unexpected situation is met, which would require one to deviate from the process model, they often become more an obstacle than a help. This paper deals with the problem of managing unforeseen situations that require deviations from the process model during enactment in the context of the PROSYT (PROcess Support sYstem capable of Tolerating deviations) PSS. During process model enactment, PROSYT is capable of tolerating deviations from the process model by supporting users even when unexpected situations arise. Furthermore, it supports users in reconciling the process model with the process actually followed, if necessary.","0098-5589;1939-3520;2326-3881","","10.1109/32.730546","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=730546","","Organizational aspects;Humans;Workflow management software;Software engineering;Costs;Process design;Context modeling;Standardization;Page description languages","project support environments;workflow management software;computer aided software engineering;business data processing","deviation tolerance;process support systems;flexible process model enactment;business organizations;business processes;repetitive tasks;human-intensive processes;design processes;software processes;unforeseen situations;PROSYT;user support;unexpected situations;workflow management system;process-centered software engineering environment;inconsistencies;event-based components integration","","63","","39","","","","","","IEEE","IEEE Journals & Magazines"
"Automatic derivation of formal software specifications from informal descriptions","K. Miriyala; M. T. Harandi","Dept. of Comput. Sci., Illinois Univ., Urbana, IL, USA; Dept. of Comput. Sci., Illinois Univ., Urbana, IL, USA","IEEE Transactions on Software Engineering","","1991","17","10","1126","1142","SPECIFIER, an interactive system which derives formal specifications of data types and programs from their informal descriptions, is described. The process of deriving formal specifications is viewed as a problem-solving process. The system uses common problem-solving techniques such as schemas, analogy, and difference-based reasoning to derive formal specifications. If an informal description is a commonly occurring operation for which the system has a schema, then the formal specification is derived by instantiating the schema. If there is a no such schema, SPECIFIER tries to find a previously solved problem which is analogous to the current problem. If the problem found is directly analogous to the current problem, it applies an analogy mapping to obtain a formal specification. On the other hand, if the analogy found is only approximate, it solves the directly analogous part of the problem by analogy and performs difference-based reasoning using the remaining (unmatched) parts to transform the formal specification obtained by analogy to a formal specification for the entire original problem.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.99198","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=99198","","Formal specifications;Problem-solving;Computer science;Feathers;Interactive systems;Programming profession;Contracts;Software measurement;Writing;NASA","automatic programming;data structures;formal specification;software tools","formal software specifications;interactive system;data types;problem-solving process;common problem-solving techniques;schemas;analogy;difference-based reasoning;informal description;SPECIFIER;previously solved problem;analogy mapping","","39","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Testing for Perturbations of Program Statements","S. J. Zeil","Department of Computer and Information Science, University of Massachusetts","IEEE Transactions on Software Engineering","","1983","SE-9","3","335","346","Many testing methods require the selection of a set of paths on which tests are to be conducted. Errors in arithmetic expressions within program statements can be represented as perturbing functions added to the correct expression. It is then possible to derive the set of errors in a chosen functional class which cannot possibly be detected using a given test path. For example, test paths which pass through an assignment statement ""X := f(Y)"" are incapable of revealing if the expression ""X -f( Y)"" has been added to later statements. In general, there are an infinite number of such undetectable error perturbations for any test path. However, when the chosen functional class of error expressions is a vector space, a finite characterization of all undetectable expressions can be found for one test path, or for combined testing along several paths. An analysis of the undetected perturbations for sequential programs operating on integers and real numbers is presented which permits the detection of multinomial error terms. The reduction of the space of (potential undetected errors is proposed as a criterion for test path selection.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236870","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703062","Mutation testing;path analysis testing;perturbation testing;program testing;program validation","Testing;Computer errors;Error correction;Arithmetic;Military computing;Information science;Computer languages;Design methodology;Sequential analysis","","Mutation testing;path analysis testing;perturbation testing;program testing;program validation","","22","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Considerations on the insularity of performance evaluation","D. Ferrari","Computer Science Division, Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA 94720","IEEE Transactions on Software Engineering","","1986","SE-12","6","678","683","It is argued that systems performance evaluation, in the first 20 years of its existence, has developed in substantial isolation from such disciplines as computer architecture, system organization, operating systems, and software engineering. The possible causes for this phenomenon, which seems to be unique in the history of engineering, are explored. Its positive and negative effects on computer science and technology, as well as on performance evaluation itself, are discussed. The drawbacks of isolated development outweigh its advantages. Thus, instructional and research initiatives to foster the rapid integration of the performance evaluation viewpoint into the mainstream of computer science and engineering are proposed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312965","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312965","Computer engineering;computer science;evaluation techniques;measurement of system performance;modeling of system performance;performance evaluation;system performance","Computers;Performance evaluation;Computational modeling;Computer science;Communities;System performance;Analytical models","computer science;performance evaluation","performance evaluation;systems performance evaluation;computer architecture;system organization;operating systems;software engineering;computer science;technology;isolated development;research initiatives","","7","","","","","","","","IEEE","IEEE Journals & Magazines"
"Evaluation of the File Redundancy in Distributed Database Systems","S. Muro; T. Ibaraki; H. Miyajima; T. Hasegawa","Department of Applied Mathematics and Physics, Faculty of Engineering, Kyoto University; NA; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","2","199","205","This paper treats the file redundancy issue in distributed database systems, asking what is the optimal number of file copies, given the ratio r of the frequency of update requests to the frequency of all file access requests (i.e., queries and updates). Formulations of this type of problem, including optimal file allocation, have been attempted by a number of authors, and some algorithms have been proposed. Although such algorithms can be used to solve particular problems, it seems difficult to draw general conclusions applicable to a wide variety of practical distributed database systems. To probe into this hard to formulate but interesting problem, our paper constructs simplified network models of distributed database systems, and computes the optimal number of file copies, as well as their locations, to minimize the communication cost. For several network types, we plot the optimal number of file copies as a function of the ratio r.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232195","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701988","Communication cost;distributed database systems;file allocation problem;file redundancy;simple plant location problem","Database systems;Costs;Frequency;Mathematics;System performance;Probes;Physics education;Automation;Laboratories;Computer networks","","Communication cost;distributed database systems;file allocation problem;file redundancy;simple plant location problem","","5","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Interface compilation: steps toward compiling program interfaces as languages","D. R. Engler","Stanford Univ., CA, USA","IEEE Transactions on Software Engineering","","1999","25","3","387","400","Interfaces-the collection of procedures and data structures that define a library, a subsystem, a module-are syntactically poor programming languages. They have state (defined both by the interface's data structures and internally), operations on this state (defined by the interface's procedures), and semantics associated with these operations. Given a way to incorporate interface semantics into compilation, interfaces can be compiled in the same manner as traditional languages such as ANSI C or FORTRAN. The article makes two contributions. First, it proposes and explores the metaphor of interface compilation, and provides the beginnings of a programming methodology for exploiting it. Second, it presents MAGIK, a system built to support interface compilation. Using MAGIK, software developers can build optimizers and checkers for their interface languages, and have these extensions incorporated into compilation, with a corresponding gain in efficiency and safety. This organization contrasts with traditional compilation, which relegates programmers to the role of passive consumers, rather than active exploiters of a compiler's transformational abilities.","0098-5589;1939-3520;2326-3881","","10.1109/32.798327","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=798327","","Programming profession;Optimizing compilers;Program processors;Data structures;Libraries;Computer languages;Software safety;File systems;High level languages;Control systems","program compilers;application program interfaces;data structures;programming language semantics","interface compilation;program interface compilation;data structures;programming languages;programming methodology;interface semantics;MAGIK;software developers;language optimizers;transformational abilities","","7","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Interfacing UNIX to Data Communications Networks","F. Panzieri; B. Randell","Suma-Sistemi vomo Macchina; NA","IEEE Transactions on Software Engineering","","1985","SE-11","10","1016","1032","We propose an interface for use from within UNIX1 user programs for communicating over multiple and varied local and wide area networks. This interface aids the design of a distributed application program by hiding the actual communications protocols used over each network, and providing instead simple primitives for sending and receiving (possibly large) datagrams, using a simple standardized network addressing scheme based on a &lt;host number, port number&gt; pair.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231548","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701916","Datagram;network protocols;networks;Newcastle Connection;UNIX","Data communication;Protocols;Network interfaces;Wide area networks;Application software;Computer architecture;Sockets;Intelligent networks;LAN interconnection;Packet switching","","Datagram;network protocols;networks;Newcastle Connection;UNIX","","1","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Experience with Charlotte: simplicity and function in a distributed operating system","R. A. Finkel; M. L. Scott; Y. Artsy; H. -. Chang","Dept. of Comput. Sci., Kentucky Univ., Lexington, KY, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1989","15","6","676","685","A retrospective view is presented of the Charlotte distributed operating system, a testbed for developing techniques and tools to solve computation-intensive problems with large-grain parallelism. The final version of Charlotte runs on the Crystal multicomputer, a collection of VAX-11/750 computers connected by a local area network. The kernel/process interface is unique in its support for symmetric, bidirectional communication paths (called links), and synchronous nonblocking communications. Several lessons were learned in implementing Charlotte. Links have proven to be a useful abstraction, but the primitives do not seem to be at quite the right level of abstraction. The implementation uses finite-state machines and a multitask kernel, both of which work well. It also maintains absolute distributed information which is more expensive that using hints. The development of high-level tools, particularly the Lynx distributed programming language, has simplified the use of kernal primitives and helps to manage concurrency at the process level.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24721","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24721","","Concurrent computing;Kernel;Operating systems;System testing;Distributed computing;Parallel processing;Computer networks;Local area networks;Bidirectional control;Computer languages","computer communications software;local area networks;multiprocessing programs;operating systems (computers);software packages","Charlotte distributed operating system;computation-intensive problems;large-grain parallelism;Crystal multicomputer;VAX-11/750 computers;local area network;kernel/process interface;bidirectional communication paths;synchronous nonblocking communications;abstraction;finite-state machines;multitask kernel;absolute distributed information;high-level tools;Lynx distributed programming language;kernal primitives;concurrency","","10","","45","","","","","","IEEE","IEEE Journals & Magazines"
"Inference Rules for Program Annotation","N. Dershowitz; Z. Manna","Department of Computer Science, University of Illinois; NA","IEEE Transactions on Software Engineering","","1981","SE-7","2","207","222","Methods are presented whereby an Algol-like program given together with its specifications can be documented automatically. The program is incrementaly annotated with invariant relations that hold between program variables at intermediate points in the program text and explain the actual workings of the program regardless of whether it is correct. Thus, this documentation can be used for proving correctness of programs or may serve as an aid in debugging incorrect programs.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234518","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702827","Inference rules;invariant assertions;program annotation;program correctness;verification","Debugging;Mathematics;Computer science;Terminology;Documentation;Programming profession;Software engineering;Difference equations;Interactive systems;Runtime","","Inference rules;invariant assertions;program annotation;program correctness;verification","","2","","34","","","","","","IEEE","IEEE Journals & Magazines"
"A*: a language for implementing language processors","D. A. Ladd; J. C. Ramming","AT&T Bell Labs., Naperville, IL, USA; AT&T Bell Labs., Naperville, IL, USA","IEEE Transactions on Software Engineering","","1995","21","11","894","901","A* is an experimental language designed to facilitate the creation of language-processing tools. It is analogous either to an interpreted yacc with Awk as its statement language, or to a version of Awk which processes programs rather than records. A* offers two principal advantages over the combination of lex, yacc, and C: a high-level interpreted base language and built-in parse tree construction. A* programmers are thus able to accomplish many useful tasks with little code. This paper describes the motivation for A*, its design, and its evolution. Experience with A* is described, and then the paper concludes with an analysis of that experience.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.473218","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=473218","","Programming profession;Humans;Computer languages;Computer science;Costs;Application software;Software engineering","software tools;program processors;high level languages;program compilers;programming","A*;experimental language;language processors;language-processing tools;interpreted yacc;Awk;statement language;lex;yacc;C;high-level interpreted base language;parse tree construction","","20","","13","","","","","","IEEE","IEEE Journals & Magazines"
"A functional approach to program testing and analysis","W. E. Howden","Department of Electrical Engineering and Computer Science, University of California, San Diego, CA 92093","IEEE Transactions on Software Engineering","","1986","SE-12","10","997","1005","An integrated approach to testing is described which includes both static and dynamic analysis methods and which is based on theoretical results that prove both its effectiveness and efficiency. Programs are viewed as consisting of collections of functions that are joined together using elementary functional forms or complex functional structures. Functional testing is identified as the input-output analysis of functional forms. Classes of faults are defined for these forms, and results are presented which prove the fault-revealing effectiveness of well defined sets of tests. Functional analysis is identified as the analysis of the sequences of operators, functions, and data type transformations which occur in functional structures. Theoretical results are presented which prove that it is only necessary to look at interfaces between pairs of operators and data type transformations in order to detect the presence of operator or data type sequencing errors. The results depend on the definition of normal forms for operator and data type sequencing diagrams.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313016","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313016","Analysis;dynamic analysis;functions;input-output;interfaces;operators;sequence analysis;static analysis;testing;theory;validation","Testing;Measurement;Functional analysis;Data structures;Availability;Fault detection;Systematics","program testing","program analysis;static analysis;functional testing;functional approach;program testing;dynamic analysis;elementary functional forms;complex functional structures;input-output analysis","","20","","","","","","","","IEEE","IEEE Journals & Magazines"
"Generation of interactive parsers with error handling","E. Steegmans; J. Lewi; I. van Horebeek","Dept. of Comput. Sci., Katholieke Univ. Leuven, Heverlee, Belgium; Dept. of Comput. Sci., Katholieke Univ. Leuven, Heverlee, Belgium; Dept. of Comput. Sci., Katholieke Univ. Leuven, Heverlee, Belgium","IEEE Transactions on Software Engineering","","1992","18","5","357","367","The generation scheme discussed, produces interactive transducers in the form of Ada programs, with an underlying parser that is of type ELL(1). The emphasis is on error recovery in interactive parsers. A generation scheme is proposed containing powerful error-recovery generation capabilities. The interaction between syntactic and semantic error recovery is also discussed. The generation scheme has been implemented as part of the MIRA transducer writing system. With MIRA, a number of industrial case studies have been worked out, from which considerable feedback has been obtained to test and improve the adopted error-recovery strategy. One of the case studies worked out with MIRA consists of the design and implementation of an interactive software package called ABACUS. A subset called MINI-ABACUS is used as an illustration of the error-recovery principles discussed throughout this work.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.135769","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=135769","","Transducers;Power generation;Computer errors;Writing;Error correction;Software engineering;Batch production systems;Feedback;Testing;Software packages","Ada;grammars;interactive systems;program compilers;system recovery","ELL 1;interactive parsers;interactive transducers;Ada programs;underlying parser;generation scheme;error-recovery generation capabilities;semantic error recovery;MIRA transducer writing system;industrial case studies;adopted error-recovery strategy;interactive software package;MINI-ABACUS;error-recovery principles","","1","","30","","","","","","IEEE","IEEE Journals & Magazines"
"A Conceptual Analysis of the Draco Approach to Constructing Software Systems","P. Freeman","Department of Information and Computer Science, University of California, Irvine","IEEE Transactions on Software Engineering","","1987","SE-13","7","830","844","This paper analyzes the concepts of software construction embodied in the Draco approach. The analysis relates specific aspects of Draco to particular software engineering (SE) principles and suggests future research needed to extend the approach. The purpose of this analysis is to help researchers understand Draco better and thus to enhance future research.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233494","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702294","Domain-based development;reusability;SE principles;transformational development","Software systems;Software engineering;Costs;Computer science;Software reusability;Software prototyping;Prototypes;Programming;Information analysis;Software testing","","Domain-based development;reusability;SE principles;transformational development","","16","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Specifying a safety-critical control system in Z","J. Jacky","Dept. of Radiat. Oncology, Washington Univ., Seattle, WA, USA","IEEE Transactions on Software Engineering","","1995","21","2","99","106","The paper presents a formal specification in the Z notation for a safety-critical control system. It describes a particular medical device but is quite generic and should be widely applicable. The specification emphasizes safety interlocking and other discontinuous features that are not considered in classical control theory. A method for calculating interlock conditions for particular operations from system safety assertions is proposed; it is similar to ordinary Z precondition calculation, but usually results in stronger preconditions. The specification is presented as a partially complete framework that can be edited and filled in with the specific features of a particular control system. Our system is large but the specification is concise. It is built up from components, subsystems, conditions and modes that are developed separately, but also accounts for behaviors that emerge at the system level. The specification illustrates several useful idioms of the Z notation, and demonstrates that an object-oriented specification style can be expressed in ordinary Z.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.345826","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=345826","","Control systems;Medical control systems;Formal specifications;Safety;Cyclotrons;Medical treatment;Control theory;Process control;Application software;Programming","safety-critical software;computerised control;biomedical equipment;safety;formal specification;specification languages","safety-critical control system;Z notation;formal specification;medical device;safety interlocking;interlock conditions;system safety assertions;Z precondition calculation;partially complete framework;object-oriented specification style","","17","","17","","","","","","IEEE","IEEE Journals & Magazines"
"A Two-Person Inspection Method to Improve Prog ramming Productivity","D. B. Bisant; J. R. Lyle","Department of Natural Sciences, George Washington University, Washhgton, DC 20057.; NA","IEEE Transactions on Software Engineering","","1989","15","10","1294","1304","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1989.559782","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=559782","","Inspection;Productivity;Programming profession;Software quality;Logic testing;Error correction codes;Analysis of variance;Application software;Computer industry;Costs","","Fatal detection;inspections;programmer productivity;watkthrough","","64","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Software process model evolution in the SPADE environment","S. C. Bandinelli; A. Fuggetta; C. Ghezzi","Dipartimento di Elettronica e Inf., Politecnico di Milano, Italy; Dipartimento di Elettronica e Inf., Politecnico di Milano, Italy; Dipartimento di Elettronica e Inf., Politecnico di Milano, Italy","IEEE Transactions on Software Engineering","","1993","19","12","1128","1144","Software processes are long-lived entities. Careful design and thorough validation of software process models are necessary to ensure the quality of the process. They do not prevent, however, process models from undergoing change. Change requests may occur in the context of reuse, i.e. statically, in order to support software process model customization. They can also occur dynamically, while software process models are being executed, in order to support timely reaction as data are gathered from the field during process enactment. We discuss the mechanisms a process language should possess in order to support changes. We illustrate the solution adopted in the context of the SPADE environment and discuss how the proposed mechanisms can be used to model different policies for changing a software process model.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.249659","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=249659","","Object oriented modeling;Humans;Context modeling;Software engineering;Automation;Programming;Computer architecture;Software quality;Vents;Object oriented databases","formal languages;Petri nets;software engineering","software process model evolution;SPADE environment;long-lived entities;change requests;reuse;software process model customization;timely reaction;process enactment;process language;SLANG;high-level Petri nets","","130","","34","","","","","","IEEE","IEEE Journals & Magazines"
"An Availability Model for Distributed Transaction Systems","G. Martella; B. Pernici; F. A. Schreiber","Dipartimento di Elettronica, Politecnico di Milano; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","5","483","491","A method is proposed for quantitatively evaluating the availability of a distributed transaction system (DTS). The DTS dynamics can be modeled as a Markov process. The problem of formulating the set of linear homogeneous equations is considered, obtaining the related coefficient matrix, that is, the transition rate matrices of the DTS elements. Such operations can be performed according to the rules of Kronecker algebra. The transition rate matrices are used to calculate the probabilities of the different possible states of the DTS. The availability with respect to a transaction T is computed through its representation by means of a structure graph and a structure vector related to the probabilistic state of the DTS element relevant to the transaction T itself.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232488","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702039","Availability;distributed databases;Markov models;performability;reliability","Testing;Yield estimation;Software reliability;Computer bugs;Availability;Error analysis;Decision theory;Computer errors;Software measurement;Computer performance","","Availability;distributed databases;Markov models;performability;reliability","","4","","33","","","","","","IEEE","IEEE Journals & Magazines"
"Data Compression in Scientific and Statistical Databases","M. A. Bassiouni","Department of Computer Science, University of Central Florida","IEEE Transactions on Software Engineering","","1985","SE-11","10","1047","1058","Scientific and statistical database systems heavily depend on data compression techniques to make possible the management and storage of their large databases. The efficiency of data compression methods has a signficant impact on the overall performance of these systems. The purpose of this paper is to show the importance of data compression to scientific/statistical databases, to discuss the pros and cons of data compression, and to survey data compression techniques relevant to scientific/statistical databases. The emphasis is on the basic idea, motivation, and tradeoffs of each approach. Both software and hardware methods are covered. The paper is concluded by a discussion of several points of research that seem worthy of further investigation.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231852","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701920","Coding techniques;data compression;data storage;data transmission;scientific/statistical databases","Data compression;Database systems;Economic forecasting;Memory;Data communication;Computer science;Transaction databases;Costs;Information retrieval;Demography","","Coding techniques;data compression;data storage;data transmission;scientific/statistical databases","","52","","51","","","","","","IEEE","IEEE Journals & Magazines"
"Performance Analyses of Paging Algorithms for Compilation of a Highly Modularized Program","T. Chusho; T. Hayashi","Systems Development Laboratory; NA","IEEE Transactions on Software Engineering","","1981","SE-7","2","248","254","Previous works on paging behavior have mainly concentrated on procedures, not on data. This paper is an attempt to clarify the paging behavior of data referenced by a newly developed language processor, and theoretically analyze the performance of several page replacement algorithms with no loss of generality.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234522","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702831","Compilation;fault rate;locality;LRU;modular programming;optimum page size;paging behavior of data;relative difference in performance;replacement algorithm","Performance analysis;Algorithm design and analysis;Performance loss;Information analysis;Laboratories;Timing;Relational databases;Database systems;Mathematical analysis;Hardware","","Compilation;fault rate;locality;LRU;modular programming;optimum page size;paging behavior of data;relative difference in performance;replacement algorithm","","1","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Maintaining Configurations of Evolving Software Systems","K. Narayanaswamy; W. Scacchi","the USC/Information Sciences Institute; NA","IEEE Transactions on Software Engineering","","1987","SE-13","3","324","334","Software configuration management ( SCM) is an emerging discipline. An important aspect of realizing SCM is the task of maintaining the configurations of evolving software systems. In this paper, we provide an approach to resolving some of the conceptual and technical problems in maintaining configurations of evolving software systems. The approach provides a formal basis for existing notions of system architecture. The formal properties of this view of configurations provide the underpinnings for a rigorous notion of system integrity, and mechanisms to control the evolution of configurations. This approach is embodied in a language, NuMIL, to describe software system configurations, and a prototype environment to maintain software system configurations. We believe that the approach and the prototype environment offer a firm base to maintain software system configurations and, therefore, to implement SCM.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233163","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702218","Configuration;module and subsystem families;module and subsystem interfaces;software configuration maintenance system;upward compatibility","Software systems;Software maintenance;Software prototyping;Control systems;Computer science;Computer architecture;Mechanical factors;Large-scale systems;Application software;Information systems","","Configuration;module and subsystem families;module and subsystem interfaces;software configuration maintenance system;upward compatibility","","18","","38","","","","","","IEEE","IEEE Journals & Magazines"
"Controllability of computer performance tradeoffs obtained using controlled-share queue schedulers","C. M. Woodside","Department of Systems and Computer Engineering, Carleton University, Ottawa, Ont. K1S 5B6, Canada","IEEE Transactions on Software Engineering","","1986","SE-12","10","1041","1048","Adjustable feedback schedulers control the relative performance obtained from a computer system by different classes of users. This work examines the control of relative throughputs (or related measures) by feedback of departure counts. Counts from key resources in the system are used to dynamically adjust the priorities of the different classes at certain queues in an attempt to achieve preset values of the ratios of the class throughputs. An iterative mean-value algorithm is given which approximates the throughputs actually achieved by this scheduler within a few percent of error. Limits of controllability are observed beyond which the achieved throughput ratios cannot follow the preset values. A characterization is given for this `controllable performance set'. It is also shown how, using this set, the scheduler can be tuned to have approximately optimal set points for the ratios.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313020","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313020","Adjustable priorities;computer scheduling;control of queue networks;dynamic properties;fair sharing;queue networks","Throughput;Time factors;Controllability;Approximation algorithms;Indexes;Approximation methods;Computers","controllability;performance evaluation;queueing theory","controllability;adjustable feedback schedulers;computer performance tradeoffs;controlled-share queue schedulers;key resources;iterative mean-value algorithm","","5","","","","","","","","IEEE","IEEE Journals & Magazines"
"Analysis of a virtual memory model for maintaining database views","K. C. Kinsley; C. E. Hughes","Datawise Inc., Orlando, FL, USA; NA","IEEE Transactions on Software Engineering","","1992","18","5","402","409","An analytical model is given for predicting the performance of a new support strategy for database views. This strategy, called the virtual method, is compared with traditional methods for supporting views. The analytical model's predictions of improved performance by the virtual method are then validated by comparing these results with those achieved in an experimental implementation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.135773","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=135773","","Analytical models;Performance analysis;Relational databases;Queueing analysis;Computer science;Predictive models;Costs;NASA;Space technology;Memory management","database management systems;database theory;virtual storage","virtual memory model;analytical model;support strategy;database views;virtual method;traditional methods;experimental implementation","","","","16","","","","","","IEEE","IEEE Journals & Magazines"
"A model for software product quality","R. G. Dromey","Software Quality Inst., Griffith Univ., Brisbane, Qld., Australia","IEEE Transactions on Software Engineering","","1995","21","2","146","162","A model for software product quality is defined, it has been formulated by associating a set of quality-carrying properties with each of the structural forms that are used to define the statements and statement components of a programming language. These quality-carrying properties are in turn linked to the high-level quality attributes of the International Standard for Software Product Evaluation ISO-9126. The model supports building quality into software, definition of language-specific coding standards, systematically classifying quality defects, and the development of automated code auditors for detecting defects in software.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.345830","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=345830","","Software quality;Software standards;Software maintenance;Buildings;Refining;Computer languages;Code standards;Standards development;Australia;Knowledge management","software quality;software standards;ISO standards;program debugging;software tools","software product quality;quality-carrying properties;structural forms;programming language;high-level quality attributes;International Standard for Software Product Evaluation;ISO-9126;language-specific coding standards;quality defects;automated code auditors;software defect detection","","164","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Program translation via abstraction and reimplementation","R. C. Waters","Artificial Intelligence Lab., MIT, Cambridge, MA, USA","IEEE Transactions on Software Engineering","","1988","14","8","1207","1228","An abstraction-and-reimplementation paradigm is presented in which the source program is first analyzed in order to obtain a programming-language-independent abstract understanding of the computation performed by the program as a whole. The program is then reimplemented in the target language based on this understanding. The key to this approach is the abstract understanding obtained. It allows the translator to benefit from an appreciation of the global features of the source program without being distracted by what are considered irrelevant details. Knowledge-based translation via abstraction and reimplementation is described as one of the goals of the Programmer's Apprentice project. A translator which translates Cobol programs into Hibol (a very-high-level business data processing language) has been constructed. A computer which generates extremely efficient PDP-11 object code for Pascal programs has been designed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.7629","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=7629","","Program processors;Artificial intelligence;Performance analysis;Data processing;Prototypes;Writing","COBOL;data structures;expert systems;Pascal;program compilers;program interpreters","compilers;knowledge based system;data structures;abstract understanding;reimplementation;Programmer's Apprentice;translator;Cobol;Hibol;business data processing language;PDP-11 object code;Pascal programs","","56","","38","","","","","","IEEE","IEEE Journals & Magazines"
"Applying synthesis principles to create responsive software systems","C. U. Smith","L&S Comput. Technol. Inc., Austin, TX, USA","IEEE Transactions on Software Engineering","","1988","14","10","1394","1408","The general principles for formulating software requirements and designs that meet response-time goals are reviewed. The principles are related to the system performance parameters that they improve, and thus their application may not be obvious to those whose speciality is system architecture and design. The author addresses the designer's perspective and illustrates how these principles apply to typical design problems. The examples illustrate requirements and design of: communication, user interfaces, information storage, retrieval and update, information hiding, and data availability. Strategies for effective use of the principles are described.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6185","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6185","","Software systems;Delay;Software performance;Software design;Design engineering;Information retrieval;Maintenance engineering;Application software;User interfaces;Systems engineering and theory","systems analysis;user interfaces","systems analysis;synthesis principles;responsive software systems;software requirements;system performance parameters;system architecture;user interfaces;information storage","","6","","38","","","","","","IEEE","IEEE Journals & Magazines"
"Completeness and consistency in hierarchical state-based requirements","M. P. E. Heimdahl; N. G. Leveson","Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA; NA","IEEE Transactions on Software Engineering","","1996","22","6","363","377","This paper describes methods for automatically analyzing formal, state-based requirements specifications for some aspects of completeness and consistency. The approach uses a low-level functional formalism, simplifying the analysis process. State-space explosion problems are eliminated by applying the analysis at a high level of abstraction; i.e., instead of generating a reachability graph for analysis, the analysis is performed directly on the model. The method scales up to large systems by decomposing the specification into smaller, analyzable parts and then using functional composition rules to ensure that verified properties hold for the entire specification. The analysis algorithms and tools have been validated on TCAS II, a complex, airborne, collision-avoidance system required on all commercial aircraft with more than 30 passengers that fly in U.S. Airspace.","0098-5589;1939-3520;2326-3881","","10.1109/32.508311","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=508311","","Performance analysis;Error correction;Robustness;Aircraft;Software safety;Computer science;Explosions;Algorithm design and analysis;Software systems;Timing","formal specification;reachability analysis;program diagnostics","hierarchical state-based requirements;formal state-based requirements specifications;completeness;consistency;low-level functional formalism;state-space explosion problems;abstraction;reachability graph;TCAS II;complex airborne collision-avoidance system;static analysis;reactive systems;state-based requirements;formal semantics;formal methods","","131","","29","","","","","","IEEE","IEEE Journals & Magazines"
"An experimental evaluation of software redundancy as a strategy for improving reliability","D. E. Eckhardt; A. K. Caglayan; J. C. Knight; L. D. Lee; D. F. McAllister; M. A. Vouk; J. P. J. Kelly","NASA Langley Res. Center, Hampton, VA, USA; NA; NA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1991","17","7","692","702","The strategy of using multiple versions of independently developed software as a means to tolerate residual software design faults is discussed. The effectiveness of multiversion software is studied by comparing estimates of the failure probabilities of these systems with the failure probabilities of single versions. The estimates are obtained under a model of dependent failures and compared with estimates obtained when failures are assumed to be independent. The experimental results are based on 20 versions of an aerospace application developed and independently validated by 60 programmers from 4 universities. Descriptions of the application and development process are given, together with an analysis of the 20 versions.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.83905","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=83905","","Redundancy;Hardware;Application software;Educational institutions;Software reliability;Software measurement;Fault tolerance;Reliability engineering;Design engineering;Software design","fault tolerant computing;program testing;redundancy;software reliability","experimental evaluation;software redundancy;multiple versions;independently developed software;residual software design faults;multiversion software;failure probabilities;dependent failures;experimental results;aerospace application;programmers;development process","","64","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Multiaccess in a Nonqueueing Mailbox Environment","M. J. Ferguson","INRS Tlcommunications, Montreal, P.Q., Canada.","IEEE Transactions on Software Engineering","","1984","SE-10","3","237","243","A new and flexible solution to the problem of multiple users accessing a single resource, such as communication bandwidth or composite object in memory, is derived. The means of communication consists of sending and receiving messages in known locations (or equivalently, mailboxes without queueing). Any particular user is able to deposit, and hence destroy, previous messages in a mailbox. It is assumed that exclusive access to a mailbox is supplied by an underlying system. The major results of this paper are: 1) a simple tree-based algorithm that guarantees  no user or group of users can conspire to prevent access by some other user to the resource;  only one user accesses the resource at a time;  if there are N users, an individual user is guaranteed access, when requested, to the resource in no more than N-1 turns; Knuth's solution [6] can delay a user up to 2** (N-1)-1 turns; 2) an extension of Dekker's algorithm (2 users) [2] that allows the relative rates of reservations for access to the resource to be proportional to a set of N integers. When a reservation is not being used by its ``owner,'' it will be assigned to another contending request. The assignment is optimal for periodic requests.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010232","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010232","Access reservation priorities;extension of Dekker's algorithm;mailbox communication environment;many user exclusive access;single resource multiaccess;single resource mutually exclusive access;tree-based multiaccess","Bandwidth;Broadcasting;Multiprocessing systems;System testing;Timing;Delay;Time of arrival estimation;Software testing","","","","2","","6","","","","","","IEEE","IEEE Journals & Magazines"
"Measuring design-level cohesion","J. M. Bieman; Byung-Kyoo Kang","Dept. of Comput. Sci., Colorado State Univ., Fort Collins, CO, USA; NA","IEEE Transactions on Software Engineering","","1998","24","2","111","124","Cohesion was first introduced as a software attribute that, when measured, could be used to predict properties of implementations that would be created from a given design. Unfortunately, cohesion, as originally defined, could not be objectively assessed, while more recently developed objective cohesion measures depend on code-level information. We show that association-based and slice-based approaches can be used to measure cohesion using only design-level information. An analytical and empirical analysis shows that the design-level measures correspond closely with code-level cohesion measures. They can be used as predictors of or surrogates for the code-level measures. The design-level cohesion measures are formally defined, have been implemented, and can support software design, maintenance and restructuring.","0098-5589;1939-3520;2326-3881","","10.1109/32.666825","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=666825","","Software measurement;Software maintenance;Software design;Sliding mode control;Visualization;Debugging;Guidelines;Software quality;Packaging;Information analysis","software metrics;software maintenance;software reusability;systems re-engineering","design-level cohesion measurement;software attribute;implementation properties prediction;objective assessment;code-level information;association-based approaches;slice-based approaches;design-level measures;code-level measures;software design;software maintenance;software restructuring;software reengineering;software visualization;software reuse;software metrics","","41","","20","","","","","","IEEE","IEEE Journals & Magazines"
"A Framework for Discipline in Programming","Pei Hsia; F. E. Petry","Department of Computer Science, University of Alabama; NA","IEEE Transactions on Software Engineering","","1980","SE-6","2","226","232","Programmers, even in well-organized software environments which utilize some modern software engineering practices, are often lacking of a discipline in their individual programming effort. There has not been an emphasis on discipline in progamming practice, as is traditional in other engineering and scientific fields' instruction. A framework organized to be suitable for early presentation and developing usage is presented and evaluated. It integrates the notions of top-down design, stepwise refinement, structured flowcharting, test case description, and analysis in the context of a framework for systematically developing and concurrently documenting programs. The framework was evaluated in actual usage during introductory programming instruction by comparing it to a typical conventional approach. A comparison of programming effort showed only a 16 percent increase in time required in the disciplined approach, which certainly makes it feasible for introductory instruction. Program quality comparisons were carried out by a comprehensive testing for logic errors in the completed projects. The results were impressively favorable for the disciplined approach.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234479","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702719","Comparative evaluation;concurrent documentation;programming discipline;project notebook;test case description;test planning","Programming profession;Software engineering;System testing;Software testing;Project management;Production;Documentation;Process planning;Software development management;Functional programming","","Comparative evaluation;concurrent documentation;programming discipline;project notebook;test case description;test planning","","6","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Analyzing Software Safety","N. G. Leveson; P. R. Harvey","Department of Information and Computer Science, University of California; NA","IEEE Transactions on Software Engineering","","1983","SE-9","5","569","579","With the increased use of software controls in critical realtime applications, a new dimension has been introduced into software reliabilitythe ""cost"" of errors. The problems of safety have become critical as these applcations have increasingly included areas where the consequences of failure are serious and may involve grave dangers to human life and property. This paper defines software safety and describes a technique called software fault tree analysis which can be used to analyze a design as to its safety. The technique has been applied to a program which controls the flight and telemetry for a University of California spacecraft. A critical failure scenario was detected by the technique which had not been revealed during substantial testing of the program. Parts of this analysis are presented as an example of the use of the technique and the results are discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.235116","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703097","Fail-safe software;fault tree;real-time software;safety verification;software reliability;software safety;software validation;system safety","Software safety;Humans;Application software;Error correction;Software systems;Fault tolerance;Runtime;Fault trees;Aircraft;Military computing","","Fail-safe software;fault tree;real-time software;safety verification;software reliability;software safety;software validation;system safety","","122","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Software Quality Assurance","F. J. Buckley; R. Poston","RCA, Moorestown, NJ 08057.; Programming Environments, Inc., Way Side, NJ 07764.","IEEE Transactions on Software Engineering","","1984","SE-10","1","36","41","This paper describes the status of software quality assurance as a relatively new and autonomous field. The history of its development from hardware quality assurance programs is discussed, current methods are reviewed, and future directions are indicated.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010196","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010196","Development of software quality assurance programs;evaluation procedure;quality assurance;software quality criteria","Software quality;Hardware;Quality assurance;Application software;Computer aided manufacturing;Costs;Quality control;Inspection;Manufacturing automation;Manufacturing processes","","","","20","","46","","","","","","IEEE","IEEE Journals & Magazines"
"Prediction of software reliability using connectionist models","N. Karunanithi; D. Whitley; Y. K. Malaiya","Dept. of Comput. Sci., Colorado State Univ., Fort Collins, CO, USA; Dept. of Comput. Sci., Colorado State Univ., Fort Collins, CO, USA; Dept. of Comput. Sci., Colorado State Univ., Fort Collins, CO, USA","IEEE Transactions on Software Engineering","","1992","18","7","563","574","The usefulness of connectionist models for software reliability growth prediction is illustrated. The applicability of the connectionist approach is explored using various network models, training regimes, and data representation methods. An empirical comparison is made between this approach and five well-known software reliability growth models using actual data sets from several different software projects. The results presented suggest that connectionist models may adapt well across different data sets and exhibit a better predictive accuracy. The analysis shows that the connectionist approach is capable of developing models of varying complexity.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.148475","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=148475","","Software reliability;Predictive models;Parametric statistics;Educational institutions;Artificial neural networks;Senior members;Analytical models;Testing;Accuracy;Application software","neural nets;software reliability","software reliability;connectionist models;network models;training regimes;data representation methods;complexity","","122","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Commitment-based software development","W. Mark; S. Tyler; J. McGuire; J. Schlossberg","Lockheed Palo Alto Res. Labs., CA, USA; Lockheed Palo Alto Res. Labs., CA, USA; Lockheed Palo Alto Res. Labs., CA, USA; Lockheed Palo Alto Res. Labs., CA, USA","IEEE Transactions on Software Engineering","","1992","18","10","870","885","During the development of a system, software modules can be viewed in terms of their commitments: the constraints imposed by their own structure and behavior, and by their relationships with other modules (in terms of resource consumption, data requirements. etc.). The Comet system uses explicit representation and reasoning with commitments to aid the software design and development process-in particular, to lead software developers to make decisions that result in reuse. Developers can examine the commitments that must be met in order to include an existing module, and can explore how commitments change when modules are modified. Comet has been applied to the domain of sensor-based tracker software.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.163604","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=163604","","Programming;Software design;Software systems;Feedback;Design automation;Control systems;Ontologies;Couplings","artificial intelligence;knowledge representation;software engineering;software reusability","software development;software modules;constraints;resource consumption;data requirements;Comet system;explicit representation;reasoning;commitments;reuse;sensor-based tracker software","","12","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Using Annotations to Make Recursion Equations Behave","J. Schwarz","Bell Laboratories","IEEE Transactions on Software Engineering","","1982","SE-8","1","21","33","The use of annotated recursion equations as a programming technique is investigated by considering the ""telegram problem."" The annotations are used to select alternative strategies for evaluating the applicative expressions contained in the recursion equations, while the equations serve as an abstract specification of the desired results. This method has the advantage that the annotations explicitly display certain kinds of decision that would otherwise be implicit.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.234771","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702902","Annotations;applicative programming languages;functional programming languages;recursion equations","Equations;Program processors;Proposals;Displays;Computer languages;Functional programming;Concrete;Process design;Algorithm design and analysis;Transforms","","Annotations;applicative programming languages;functional programming languages;recursion equations","","5","","20","","","","","","IEEE","IEEE Journals & Magazines"
"A model for software development effort and cost estimation","K. Pillai; V. S. Sukumaran Nair","Dept. of Comput. Sci. & Eng., Southern Methodist Univ., Dallas, TX, USA; NA","IEEE Transactions on Software Engineering","","1997","23","8","485","497","Several algorithmic models have been proposed to estimate software costs and other management parameters. Early prediction of completion time is absolutely essential for proper advance planning and aversion of the possible ruin of a project. L.H. Putnam's (1978) SLIM (Software LIfecycle Management) model offers a fairly reliable method that is used extensively to predict project completion times and manpower requirements as the project evolves. However, the nature of the Norden/Rayleigh curve used by Putnam renders it unreliable during the initial phases of the project, especially in projects involving a fast manpower buildup, as is the case with most software projects. In this paper, we propose the use of a model that improves early prediction considerably over the Putnam model. An analytic proof of the model's improved performance is also demonstrated on simulated data.","0098-5589;1939-3520;2326-3881","","10.1109/32.624305","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=624305","","Programming;Mathematical model;Predictive models;Cost function;Software algorithms;Hardware;Performance analysis;Analytical models;Art;Data analysis","software development management;software cost estimation;project management","software development effort;software cost estimation;algorithmic models;project completion time prediction;advance planning;SLIM model;software lifecycle management model;manpower requirements;Norden/Rayleigh curve;initial project phases;fast manpower buildup;model performance;software development time;Gamma model","","83","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Design of flexible static program analyzers with PQL","S. Jarzabek","Dept. of Inf. Syst. & Comput. Sci., Nat. Univ. of Singapore, Singapore","IEEE Transactions on Software Engineering","","1998","24","3","197","215","Static program analyzers (SPA) are interactive tools that enhance program understanding during maintenance by answering queries about programs. Depending on the maintenance task in hand, SPAs must process different source programs and answer different types of program queries. Flexibility is, therefore, a desirable property of SPAs. The author describes a program query language, called PQL, that facilitates the design of flexible SPAs. PQL is a conceptual level, source language-independent notation to specify program queries and program views. In PQL, one can query global program design as well as search for detail code patterns. PQL queries are answered automatically by a query evaluation mechanism built into an SPA. Program design models and POL form the core of an SPA conceptual model. He based the SPA's architecture on this conceptual model. By separating the conceptual model from the implementation decisions, one can design SPAs that are customizable to the needs of the maintenance project at hand. Depending on criteria such as efficiency of query evaluation or simplicity of the SPA design, one can implement the same functional specifications of an SPA on a variety of program representations to meet the required criteria. Apart from its role in the design of SPAs, the conceptual model also allows one to rigorously study SPA functionality in the context of the underlying maintenance process and programmer behavior models, in isolation from tool implementation details.","0098-5589;1939-3520;2326-3881","","10.1109/32.667879","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=667879","","Programming profession;Database languages;Query processing;Context modeling;User interfaces;Computer Society;Reverse engineering;Software maintenance;Cost function;Information systems","system monitoring;reverse engineering;software maintenance;query languages;query processing;software tools;relational databases","flexible static program analyzer design;PQL;interactive tools;program understanding;maintenance;query answering;source programs;program query language;conceptual level source language-independent notation;program views;query global program design;code pattern searching;query evaluation mechanism;maintenance project;functional specifications;programmer behavior models","","12","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Time and Cost Evaluation Schemes of Multiple Copies of Data in Distributed Database Systems","M. Yoshida; K. Mizumachi; A. Wakino; I. Oyake; Y. Matsushita","OKI Electric Industry Company, Limited; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","9","954","959","In comparison to centralized database systems, distributed database systems have certain advantages depending on the manner in which data are redundantly distributed. These advantages are improvement in response time, better data availability, reduction in transmission cost, etc.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232829","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702114","Application environments;concurrency control;consistency;data allocation;distributed database;simulation model;transaction","Costs;Database systems;Delay;Availability;Concurrency control;Distributed databases;System recovery;Communication system control;Transaction databases;Control systems","","Application environments;concurrency control;consistency;data allocation;distributed database;simulation model;transaction","","3","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Asynchronous parallel simulation of parallel programs","S. Prakash; E. Deelman; R. Bagrodia","TIBCO Software Inc., Palo Alto, CA, USA; NA; NA","IEEE Transactions on Software Engineering","","2000","26","5","385","400","Parallel simulation of parallel programs for large datasets has been shown to offer significant reduction in the execution time of many discrete event models. The paper describes the design and implementation of MPI-SIM, a library for the execution driven parallel simulation of task and data parallel programs. MPI-SIM can be used to predict the performance of existing programs written using MPI for message passing, or written in UC, a data parallel language, compiled to use message passing. The simulation models can be executed sequentially or in parallel. Parallel execution of the models are synchronized using a set of asynchronous conservative protocols. The paper demonstrates how protocol performance is improved by the use of application-level, runtime analysis. The analysis targets the communication patterns of the application. We show the application-level analysis for message passing and data parallel languages. We present the validation and performance results for the simulator for a set of applications that include the NAS Parallel Benchmark suite. The application-level optimization described in the paper yielded significant performance improvements in the simulation of parallel programs, and in some cases completely eliminated the synchronizations in the parallel execution of the simulation model.","0098-5589;1939-3520;2326-3881","","10.1109/32.846297","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=846297","","Discrete event simulation;Protocols;Frequency synchronization;Parallel languages;Runtime;Hardware;Program processors;Computational modeling;Libraries;Performance analysis","parallel programming;parallel languages;virtual machines;message passing;application program interfaces;synchronisation;discrete event simulation","asynchronous parallel simulation;parallel programs;large datasets;execution time;discrete event models;MPI-SIM;execution driven parallel simulation;data parallel programs;MPI;message passing;UC;data parallel language;simulation models;parallel execution;asynchronous conservative protocols;protocol performance;application-level runtime analysis;communication patterns;NAS Parallel Benchmark suite;application-level optimization;simulation model","","25","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Building reliable interactive information systems","A. I. Wasserman; P. A. Pircher; D. T. Shewmake","Section of Medical Information Science, University of California, San Francisco, San Francisco, CA 94143; Section of Medical Information Science, University of California, San Francisco, San Francisco, CA 94143; Section of Medical Information Science, University of California, San Francisco, San Francisco, CA 94143","IEEE Transactions on Software Engineering","","1986","SE-12","1","147","156","User software engineering (USE) is a methodology, with supporting tools, for the specification, design, and implementation of interactive information systems. With the USE approach, the user interface is formally specified with augmented state transition diagrams, and the operations may be formally specified with preconditions and postconditions. The USE state transition diagrams may be directly executed with the application development tool RAPID/USE. RAPID/USE and its associated tool RAPSUM create and analyze logging information that is useful for system testing, and for evaluation and modification of the user interface. The authors briefly describe the USE transition diagrams and the formal specification approach, and show how these tools and techniques aid in the creation of reliable interactive information systems.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312928","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312928","Interactive information systems;RAPID/USE;software development methodology;software reliability;transition diagrams;User Software Engineering","Libraries;Information systems;User interfaces;Testing;Databases;Software reliability","software engineering;software reliability;software tools;specification languages;user interfaces","user software engineering;reliable interactive information systems;software engineering;specification;design;implementation;interactive information systems;USE;user interface;state transition diagrams;application development tool;RAPID/USE;RAPSUM;logging information;system testing","","1","","","","","","","","IEEE","IEEE Journals & Magazines"
"Simulation and comparison of Albrecht's function point and DeMarco's function bang metrics in a CASE environment","R. Rask; P. Laamanen; K. Lyyttinen","Dept. of Comput. Sci., Joensuu Univ., Finland; Dept. of Comput. Sci., Joensuu Univ., Finland; NA","IEEE Transactions on Software Engineering","","1993","19","7","661","671","Software size estimates provide a basis for software cost estimation during software development. Hence, it is important to measure the system size reliably as early as possible. Two of the best known specification level metrics, Albrecht's function points (A.J. Albrecht, 1979) and DeMarco's function bang metrics (T. DeMarco, 1982) are compared by a simulation study in which automatically generated randomized dataflow diagrams (DFDs) were used as a statistical sample to automatically count function points and function bang in a built CASE environment. These value counts were correlated statistically using correlation coefficients and regression analysis. The simulation study permits sufficient variation in the base material to cover most types of system specifications. Moreover, it allows sufficient sampling sizes to make statistical analysis of data. The obtained results show that in certain cases there is a relatively good statistical correlation between these metrics.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.238567","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=238567","","Computer aided software engineering;Cost function;Computer science;Programming;Size measurement;Regression analysis;Sampling methods;Statistical analysis;Software metrics;Software measurement","software cost estimation;software metrics;software tools","software size estimates;software cost estimation;software development;specification level metrics;function points;function bang metrics;simulation study;automatically generated randomized dataflow diagrams;DFDs;statistical sample;built CASE environment;system specifications;statistical correlation","","13","","26","","","","","","IEEE","IEEE Journals & Magazines"
"An Industrial Software Engineering Retraining Course: Development Considerations and Lessons Learned","A. Ben-David; M. I. Ben-Porath; J. Z. Loeb; M. Rich","Israel Aircraft Industries, Ben Gurion Airport, Israel.; Israel Aircraft Industries, Ben Gurion Airport, Israel.; Israel Aircraft Industries, Ben Gurion Airport, Israel.; Israel Aircraft Industries, Ben Gurion Airport, Israel; Department of Mathematics, Temple University, Philadelphia, PA 19122.","IEEE Transactions on Software Engineering","","1984","SE-10","6","748","755","Israel Aircraft Industries has recently been conducting a novel six-month intensive course to retrain practicing engineers to become software engineers working on embedded computer systems. The first course was concluded in January 1982 and the second course began in November 1982. This paper describes the objectives, educational philosophy, course content, and practical experience of the first course. It also describes how the second course was modified as a result of the lessons learned from the successes and failures of the first course.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010303","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010303","Embedded computer systems;retraining;software education","Computer industry;Software engineering;Aerospace engineering;Embedded computing;Aircraft propulsion;Aerospace industry;Embedded software;Software systems;Writing;Computer science education","","","","4","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Layout appropriateness: a metric for evaluating user interface widget layout","A. Sears","Dept. of Computer Sci., Maryland Univ., College Park, MD, USA","IEEE Transactions on Software Engineering","","1993","19","7","707","719","Numerous methods for evaluating user interfaces have been investigated to develop a metric that incorporates simple task descriptions which can assist designers in organizing their user interface. The metric, Layout Appropriateness (LA), requires a description of the sequences of actions users perform and how frequently each sequence is used. This task description can either be from observations of an existing system or from a simplified task analysis. The appropriateness of a given layout is computed by weighting the cost of each sequence of actions by how frequently the sequence is performed, which emphasizes frequent methods of accomplishing tasks while incorporating less frequent methods in the design. In addition to providing a comparison of proposed or existing layouts, an LA-optimal layout can be presented to the designer. The designer can compare the LA-optimal and existing layouts or start with the LA-optimal layout and modify it to take additional factors into consideration.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.238571","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=238571","","User interfaces;Performance analysis;Design engineering;Computer science;Performance evaluation;Organizing;Design methodology;NASA;Cost function;Data mining","human factors;performance evaluation;software metrics;user interfaces","layout appropriateness;user interface widget layout;simple task descriptions;Layout Appropriateness;simplified task analysis;weighting;LA-optimal layout","","37","","33","","","","","","IEEE","IEEE Journals & Magazines"
"The ""Software Engineering"" of Expert Systems: Is Prolog Appropriate?","P. A. Subrahmanyam","AT&amp;T Bell Laboratories","IEEE Transactions on Software Engineering","","1985","SE-11","11","1391","1400","This paper is a preliminary assessment of the viability of Prolog as a basis for the design of expert systems, where the major competition is assumed to be from Lisp and Lisp-based systems. We critically examine the basic features of Prolog from various perspectives to see to what extent they support (or hinder) expert system development. Our conclusion is that while Prolog has significant assets along several dimensions, Prolog as it exists today needs to be modified and appropriately enhanced to make it competitive to extant Lisp-based systems; we suggest the nature of some of these modifications.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231887","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701955","Expert systems;Lisp;logic programming;programming environments;Prolog","Software engineering;Expert systems;Logic programming;Programming environments;Prototypes;Subspace constraints;Computational modeling;Hardware;Costs;Sections","","Expert systems;Lisp;logic programming;programming environments;Prolog","","19","","55","","","","","","IEEE","IEEE Journals & Magazines"
"Abstract Data Type Specification in the Affirm System","D. R. Musser","Research and Development Center, General Electric Company","IEEE Transactions on Software Engineering","","1980","SE-6","1","24","32","This paper describes the data type definition facilities of the AFFIRM system for program specification and verification. Following an overview of the system, we review the rewrite rule concepts that form the theoretical basis for its data type facilities. The main emphasis is on methods of ensuring convergence (finite and unique termination) of sets of rewrite rules and on the relation of this property to the equational and inductive proof theories of data types.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230459","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702691","Abstract data types;algebraic specifications;automatic theorem proving;equational theories;program verification;rewrite rules","Equations;Intersymbol interference;Specification languages;System testing;Convergence;Interactive systems;Formal specifications;Message systems;Contracts","","Abstract data types;algebraic specifications;automatic theorem proving;equational theories;program verification;rewrite rules","","52","","45","","","","","","IEEE","IEEE Journals & Magazines"
"An Approach to User Specification of Interactive Display Interfaces","L. J. Bass","Department of Computer Science and Statistics, University of Rhode Island","IEEE Transactions on Software Engineering","","1985","SE-11","8","686","698","Forms have become widely used as a user interface for database systems. By analyzing the components of forms, a unified treatment of aggregation operators, headings, subheadings, and internal logic of a form is possible. In this paper we present a theory and a system based on that theory which allows users to easily specify displays. Displays are composed of components and the user can specify geometry of the components and grouping relationships between the components which allow for the generation of the desired display.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232518","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702078","Display system;form managers;report writer;screen management;user dialog;user interface","Database systems;Logic;User interfaces;Computer displays;Writing;Geometry;Computer peripherals;Data analysis;Computer science;Statistics","","Display system;form managers;report writer;screen management;user dialog;user interface","","6","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Transformation and Verification of Office Procedures","Shi-Kuo Chang; Wu-Lung Chan","Information Systems Laboratory, Department of Electrical and Computer Engineering, Illinois Institute of Technology; NA","IEEE Transactions on Software Engineering","","1985","SE-11","8","724","734","An office procedure is a structured set of office activities for accomplishing a specific office task. A unified model, called office procedure model (OPM), is presented to model office procedures. The OPM describes the relationships among messages, databases, alerters, and activities. The OPM can be used to coordinate and integrate the activities of an office procedure. The OPM also allows the specification of office protocols in an office information system. A methodology for the verification of office procedures is presented. With this methodology, potential problems in office procedure specification, such as deadlock, unspecified message reception, etc., can be analyzed effectively.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232522","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702082","Message exchange theory;office automation;office information system;office procedure model;Petri net;protocol analysis","Office automation;Protocols;Information systems;Databases;Information retrieval;Costs;Management information systems;System recovery;Information analysis;Computer science","","Message exchange theory;office automation;office information system;office procedure model;Petri net;protocol analysis","","3","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Performance characterization of quorum-consensus algorithms for replicated data","M. Ahamad; M. H. Ammar","Sch. of Inf. & Comput. Sci., Georgia Inst. of Technol., Atlanta, GA, USA; Sch. of Inf. & Comput. Sci., Georgia Inst. of Technol., Atlanta, GA, USA","IEEE Transactions on Software Engineering","","1989","15","4","492","496","The authors develop a model and define performance measures for a replicated data system that makes use of a quorum-consensus algorithm to maintain consistency. They consider two measures: the proportion of successfully completed transactions in systems where a transaction aborts if data is not available, and the mean response time in systems where a transaction waits until data becomes available. Based on the model, the authors show that for some quorum assignment there is an optimal degree of replication beyond which performance degrades. There exist other quorum assignments which have no optimal degree of replication. The authors also derive optimal read and write quorums which maximize the proportion of successful transactions.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.16608","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=16608","","Voting;Availability;Delay;Data systems;Time measurement;Degradation;Database systems;Hardware;Application software;Industrial control","concurrency control;distributed databases;performance evaluation;transaction processing","quorum-consensus algorithms;replicated data;performance measures;quorum-consensus algorithm;consistency;successfully completed transactions;transaction waits;quorum assignment","","66","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Reusability in Programming: A Survey of the State of the Art","T. C. Jones","Nolan, Norton &amp; Company, Lexington, MA 02173.","IEEE Transactions on Software Engineering","","1984","SE-10","5","488","494","As programming passes the 30 year mark as a professional occupation, an increasingly large number of programs are in application areas that have been automated for many years. This fact is changing the technology base of commercial programming, and is opening up new markets for standard functions, reusable common systems, modules, and the tools and support needed to facilitate searching out and incorporating existing code segments. This report addresses the 1984 state of the art in the domains of reusable data, reusable architectures, reusable design, common systems, reusable programs, and reusable modules or subroutines. If current trends toward reusability continue, the amount of reused logic and reused code in commercial programming systems may approach 50 percent by 1990. However, major efforts will be needed in the areas of reusable data, reusable architectures, and reusable design before reusable code becomes a sound basic technology.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010271","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010271","Common systems;programming productivity;reusable architecture;reusable code;reusable design;reusable documentation;reusable modules;reusable software","Programming profession;Application software;Automatic programming;Functional programming;Code standards;Logic programming;Computer industry;Retirement;Aging;Steady-state","","","","81","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Accessing files in an Internet: the Jade file system","H. C. Rao; L. L. Peterson","AT&T Bell Lab., Murray Hill, NJ, USA; NA","IEEE Transactions on Software Engineering","","1993","19","6","613","624","The Jade file system, which provides a uniform way to name and access files in an Internet environment, is introduced. Jade is a logical system that integrates a heterogeneous collection of existing file systems in which underlying file systems support different file access protocols. Because of autonomy, Jade is designed under the restriction that the underlying file systems may not be modified. In order to avoid the complexity of maintaining an Internet-wide, global name space, Jade permits each user to define a private name space. Jade's name space supports two features: it allows multiple file systems to be mounted under one directory, and it permits one logical name space to mount other logical name spaces. A prototype of Jade has been implemented to examine and validate its design. The prototype consists of interfaces to the Unix File System, the Sun Network File System, and the File Transfer Protocol. An overview of Jade's design is reported, and the authors' experiences in designing and implementing a large scale file system are reviewed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.232026","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=232026","","Internet;File systems;Access protocols;Prototypes;Computer networks;Scalability;File servers;Sun;Large-scale systems;Availability","distributed processing;file organisation;information services","Jade file system;Internet;file access protocols;global name space;multiple file systems;logical name space;Unix File System;Sun Network File System;File Transfer Protocol;large scale file system","","16","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Steps to an Advanced Ada<sup>1</sup>Programming Environment","R. N. Taylor; T. A. Standish","Programming Environment Project, Department of Information and Computer Science, University of California; NA","IEEE Transactions on Software Engineering","","1985","SE-11","3","302","310","Conceptual simplicity, tight coupling of tools, and effective support of host-target software development will characterize advanced Ada programming support environments. Several important principles have been demonstrated in the Arcturus system, including template-assisted Ada editing, command completion using Ada as a command language, and combining the advantages of interpretation and compilation. Other principles, relating to analysis, testing, and debugging of concurrent Ada programs, have appeared in other contexts. This paper discusses several of these topics, considers how they can be integrated, and argues for their inclusion in an environment appropriate for software development in the late 1980's.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232213","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702006","Ada;concurrency;debugging;programming environments;static analysis","Programming environments;Debugging;Prototypes;Software maintenance;Testing;Software prototyping;Software tools;Page description languages;Command languages;Concurrent computing","","Ada;concurrency;debugging;programming environments;static analysis","","11","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Performance evaluation of parallel systems by using unbounded generalized stochastic Petri nets","M. Granda; J. M. Drake; J. A. Gregorio","Dept. of Electron., Cantabria Univ., Santander, Spain; Dept. of Electron., Cantabria Univ., Santander, Spain; Dept. of Electron., Cantabria Univ., Santander, Spain","IEEE Transactions on Software Engineering","","1992","18","1","55","71","Methods of calculating efficiently the performance measures of parallel systems by using unbounded generalized stochastic Petri nets are presented. An explosion in the number of states to be analyzed occurs when unbounded places appear in the model. The state space of such nets is infinite, but it is possible to take advantage of the natural symmetries of the system to aggregate the states of the net and construct a finite graph of lumped states which can easily be analyzed. With the methods developed, the unbounded places introduce a complexity similar to that of safe places of the net. These methods can be used to evaluate models of open parallel systems in which unbounded places appear; systems which are k-bounded but are complex and have large values of k can also be evaluated in an appropriate way. From the steady-state solution of the model, it is possible to obtain automatically the performance measures of parallel systems represented by this type of net.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.120316","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=120316","","Stochastic systems;Petri nets;Performance analysis;State-space methods;Steady-state;Parallel processing;Markov processes;Explosions;Aggregates;Time measurement","parallel machines;parallel programming;performance evaluation;Petri nets;stochastic processes","performance measures;parallel systems;unbounded generalized stochastic Petri nets;unbounded places;state space;natural symmetries;finite graph;lumped states;unbounded places;open parallel systems;k-bounded;steady-state solution","","4","","36","","","","","","IEEE","IEEE Journals & Magazines"
"The Cactis project: database support for software environments","S. E. Hudson; R. King","Dept. of Comput. Sci., Arizona Univ., Tucson, AZ, USA; NA","IEEE Transactions on Software Engineering","","1988","14","6","709","719","The Cactis project is an on-going effort oriented toward extending database support from traditional business-oriented applications to software environments. The main goals of the project are to construct an appropriate model, and develop new techniques to support the unusual data management needs of software environments, including program compilations, software configurations, load modules, project schedules, software versions, nested and long transactions, and program transformations. The ability to manage derived information is common to many of these data needs, and the Cactis database management system has the ability to represent and maintain derived data in a time- and space-efficient fashion. A central contribution of Cactis is its integration of the type constructors of semantic models and the localized behavior capabilities of object-oriented database management systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6152","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6152","","Database systems;Object oriented databases;Application software;Data models;Environmental management;Object oriented modeling;Software development management;Information management;Computer science;Project management","database management systems;program compilers;programming environments","database support;software environments;Cactis;program compilations;software configurations;load modules;project schedules;software versions;program transformations;database management system;semantic models;object-oriented","","28","","50","","","","","","IEEE","IEEE Journals & Magazines"
"Optimal partitioning of random programs across two processors","D. M. Nicol","Dept. of Comput. Sci., Coll. of William & Mary, Williamsburg, VA, USA","IEEE Transactions on Software Engineering","","1989","15","2","134","141","B. Indurkhya et al. (1986) concluded that the optimal partitioning of a homogeneous random program over a homogeneous distributed system either assigns all modules to a single processor or distributes the modules as evenly as possible among all processors. Their analysis rests heavily on the approximation that equates the expected maximum of a set of independent random variables with the set's maximum expectation. The author strengthens this result by providing an approximation-free proof of this result for two processors under general conditions on the module execution time distribution. It is found that additional rigor leads to a different characterization of the optimality points. The author also shows that under a rigorous analysis one is led to different conclusions in the general P-processor case than those reached using B. Indurkhya et al.'s approximation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21740","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21740","","Cost function;Error analysis;Random variables;NASA;Parallel processing;Delay;Time measurement;Postal services;Computer science;Statistical analysis","distributed processing;parallel programming;programming theory","random programs;optimal partitioning;homogeneous distributed system;expected maximum;maximum expectation;approximation-free proof;module execution time distribution","","17","","5","","","","","","IEEE","IEEE Journals & Magazines"
"Timing Requirements for Time-Driven Systems Using Augmented Petri Nets","J. E. Coolahan; N. Roussopoulos","Applied Physics Laboratory, Johns Hopkins University; NA","IEEE Transactions on Software Engineering","","1983","SE-9","5","603","616","A methodology for the statement of timing requirements is presented for a class of embedded computer systems. The notion of a ""time-driven"" system is introduced which is formalized using a Petri net model augmented with timing information. Several subclasses of time-driven systems are defined with increasing levels of complexity. By deriving the conditions under which the Petri net model can be proven to be safe in the presence of time, timing requirements for modules in the system can be obtained. Analytical techniques are developed for proving safeness in the presence of time for the net constructions used in the defined subclasses of time-driven systems.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.235261","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703100","Modeling methodology;performance specifications;Petri nets;real-time systems;timing requirements","Timing;Petri nets;Embedded system;Power system modeling;Embedded computing;Control systems;Real time systems;Concurrent computing;Application software","","Modeling methodology;performance specifications;Petri nets;real-time systems;timing requirements","","106","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Two-state self-stabilizing algorithms for token rings","M. Flatebo; A. K. Datta","Dept. of Comput. Sci., Nevada Univ., Las Vegas, NV, USA; Dept. of Comput. Sci., Nevada Univ., Las Vegas, NV, USA","IEEE Transactions on Software Engineering","","1994","20","6","500","504","A self-stabilizing system is a network of processors, which, when started from an arbitrary (and possibly illegal) initial state, always returns to a legal state in a finite number of steps. This implies that the system can automatically deal with infrequent errors. One issue in designing self-stabilizing algorithms is the number of states required by each machine. This paper presents mutual exclusion algorithms which will be self-stabilizing while only requiring each machine in the network to have two states. The concept of a randomized central demon is also introduced in this paper. The first algorithm is a starting point where no randomization is needed (the randomized central demon is not necessary). The other two algorithms require randomization. The second algorithm builds on the first algorithm and reduces the number of network connections required. Finally, the number of necessary connections is again reduced yielding the final two-state, probabilistic algorithm for an asynchronous, unidirectional ring of processes.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.295897","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=295897","","Law;Legal factors;Algorithm design and analysis;Distributed algorithms;Propagation delay;Error correction;Automata;Computer science;System recovery","distributed algorithms;token networks;local area networks;probability;fault tolerant computing;reliability","two-state self-stabilizing algorithms;token rings;legal state;illegal state;infrequent errors;mutual exclusion algorithms;randomized central demon;network connections;probabilistic algorithm;asynchronous unidirectional ring;binary state machines;distributed algorithms;distributed system","","19","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Supporting cooperation in the SPADE-1 environment","S. Bandinelli; E. Di Nitto; A. Fuggetta","Eur. Software Inst., Bizkaia, Spain; NA; NA","IEEE Transactions on Software Engineering","","1996","22","12","841","865","Software development is a cooperative activity that relies heavily on the quality and effectiveness of the communication channels established within the development team and with the end-user. Process-centered software engineering environments (PSEEs) support the definition and the execution of various phases of the software process. This is achieved by explicitly defining cooperation procedures, and by supporting synchronization and data sharing among its users. PSEE and CSCW technologies have been developed rather independently from each other, leading to a large amount of research results, tools and environments, and practical experiences. We have reached a stage in technology development where it is necessary to assess and evaluate the effectiveness of the research efforts carried out so far. Moreover, it is important to understand how to integrate and exploit the results of these different efforts. The goal of the paper is to understand which kind of basic functionalities PSEEs can and should offer, and how these environments can be integrated with other tools to effectively support cooperation in software development. In particular, the paper introduces a process model we have built to support a cooperative activity related to anomaly management in an industrial software factory. The core of the paper presents and discusses the experiences and results that we have derived from this modeling activity, and how they related to the general problem of supporting cooperation in software development. The project was carried out using the SPADE (Software Process Analysis, Design and Enactment) PSEE and the ImagineDesk CSCW toolkit.","0098-5589;1939-3520;2326-3881","","10.1109/32.553634","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=553634","","Programming;Computer Society;Software engineering;Collaborative work;Communication channels;Research initiatives;Computer industry;Production facilities;Application software","groupware;computer aided software engineering;project support environments;synchronisation","computer-supported cooperative work;SPADE-1 environment;communication channels;process-centered software engineering environments;software process;cooperation procedures;synchronization;data sharing;technology development;research efforts;basic functionalities;software development;process model;cooperative activity;anomaly management;industrial software factory;ImagineDesk CSCW toolkit","","70","","53","","","","","","IEEE","IEEE Journals & Magazines"
"PARLOG and its applications","K. L. Clark","Dept. of Comput., Imperial Coll., London, UK","IEEE Transactions on Software Engineering","","1988","14","12","1792","1804","The key concepts of the parallel logic programming language PARLOG are introduced by comparing the language with Prolog. Some familiarity with Prolog and with the concepts of logic programming is assumed. Two major application areas of PARLOG, systems programming and object-oriented programming, are illustrated. Other applications are briefly surveyed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9064","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9064","","Logic programming;Testing;Object oriented programming;Parallel programming","high level languages;logic programming;object-oriented programming;parallel programming;PROLOG","PARLOG;parallel logic programming language;PARLOG;Prolog;systems programming;object-oriented programming","","7","","48","","","","","","IEEE","IEEE Journals & Magazines"
"Software Design Representation Using Abstract Process Networks","L. J. Mekly; S. S. Yau","Teletype Corporation; NA","IEEE Transactions on Software Engineering","","1980","SE-6","5","420","435","An approach to software design representation which is consistent with the concept of engineering blueprints is presented. The main criteria for software engineering blueprints are defined and a network scheme of graphical representation is considered through an overview of Petri net techniques. The concept of an abstract process (AP) is introduced as the basic element of system representation. An abstract process network schema of software design representation is developed and supported by an algebraic system of notation. Methods of AP-net construction are presented and illustrated by examples. The advantages of using the proposed approach in different phases of software engineering are pointed out and the main directions for further research have been identified.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230490","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702758","Abstract process;AP-net;engineering blueprint;finite state machines;Petri net;process expression;software design representation","Software design;Design engineering;Software engineering;Programming;Automata;Terminology;Process design;Buildings;Instruments","","Abstract process;AP-net;engineering blueprint;finite state machines;Petri net;process expression;software design representation","","16","","89","","","","","","IEEE","IEEE Journals & Magazines"
"On Linguistic Support for Distributed Programs","B. Liskov","Laboratory for Computer Science, Massachusetts Institute of Technology","IEEE Transactions on Software Engineering","","1982","SE-8","3","203","210","Technological advances have made it possible to construct systems from collections of computers connected by a network. At present, however, there is little support for the construction and execution of software to run on such a system. Our research concerns the development of an integrated language/system whose goal is to provide the needed support. This paper discusses a number of issues that must be addressed in such a language. The major focus of our work and this paper is support for the construction of robust software that survives node, network, and media failures.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235250","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702937","Atomicity;distributed programs;distributed systems;programming languages;reliability;transactions","Robustness;Computer networks;Computer languages;Computer errors;Computer network reliability;Application software;Programming profession;Telecommunication network reliability;Object oriented databases;Banking","","Atomicity;distributed programs;distributed systems;programming languages;reliability;transactions","","38","","29","","","","","","IEEE","IEEE Journals & Magazines"
"On the specification and synthesis of communicating processes","M. H. Erdogmus; R. Johnston","INRS-Telecommun., Quebec Univ., Verdun, Que., Canada; INRS-Telecommun., Quebec Univ., Verdun, Que., Canada","IEEE Transactions on Software Engineering","","1990","16","12","1412","1426","An objective methodology for the specification and synthesis of communicating processes is presented. It is demonstrated that algebraic operators can be used to formulate communicating processes in terms of behavioral constraints and that the corresponding state-machine-type process descriptions can be derived automatically or synthesized from these formulations. The behavioral constraints serve as high-level specifications for communicating processes. These constraints indicate the desired behavior of a process, possibly embedded in a system, by defining its range. The proposed approach is shown to be applicable to a common problem which concerns the synthesis of the central module serving a number of clients in a specific distributed system configuration.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.62449","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=62449","","Formal specifications;Protocols;Business;High level languages;Context modeling","automatic programming;formal specification;parallel programming","objective methodology;communicating processes;algebraic operators;behavioral constraints;state-machine-type process descriptions;behavioral constraints;high-level specifications;common problem;central module;specific distributed system configuration","","2","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Orthogonal defect classification-a concept for in-process measurements","R. Chillarege; I. S. Bhandari; J. K. Chaar; M. J. Halliday; D. S. Moebus; B. K. Ray; M. -. Wong","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1992","18","11","943","956","Orthogonal defect classification (ODC), a concept that enables in-process feedback to software developers by extracting signatures on the development process from defects, is described. The ideas are evolved from an earlier finding that demonstrates the use of semantic information from defects to extract cause-effect relationships in the development process. This finding is leveraged to develop a systematic framework for building measurement and analysis methods. The authors define ODC and discuss the necessary and sufficient conditions required to provide feedback to a developer; illustrate the use of the defect type distribution to measure the progress of a product through a process; illustrate the use of the defect trigger distribution to evaluate the effectiveness and eventually the completeness of verification processes such as inspection or testing; provides sample results from pilot projects using ODC; and open the doors to a wide variety of analysis techniques for providing effective and fast feedback based on the concepts of ODC.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.177364","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=177364","","Feedback;Software quality;Software measurement;Area measurement;Data mining;Predictive models;Sufficient conditions;Inspection;Testing;Computer industry","software quality;software reliability","orthogonal defect classification;software development;in-process measurements;feedback;semantic information;cause-effect relationships;measurement and analysis methods;necessary and sufficient conditions;defect trigger distribution;completeness;verification processes;inspection;testing","","358","","25","","","","","","IEEE","IEEE Journals & Magazines"
"A Comparison of the Axiomatic and Functional Models of Structured Programming","V. R. Basili; R. E. Noonan","Department of Computer Science, University of Maryland; NA","IEEE Transactions on Software Engineering","","1980","SE-6","5","454","465","This paper discusses axiomatic and functional models of the semantics of structured programming. The models are presented together with their respective methodologies for proving program correctness and for deriving correct programs. Examples using these methodologies are given. Finally, the models are compared and contrasted.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230494","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702762","Axiomatic correctness;functional correctness;program derivation;structured programming","Functional programming;Milling machines;Computer languages;Computer science;Programming profession;Guidelines;Flowcharts;Mathematics;Mathematical model","","Axiomatic correctness;functional correctness;program derivation;structured programming","","3","","12","","","","","","IEEE","IEEE Journals & Magazines"
"A Comprehensive Model for the Design of Distributed Computer Systems","H. K. Jain","School of Business Administration, the University of Wisconsin","IEEE Transactions on Software Engineering","","1987","SE-13","10","1092","1104","The availability of micro-, mini-, and supercomputers has complicated the laws governing the economies of scale in computers. A recent study by Ein-Dor [7] concludes that it is most effective to accomplish any task on the least powerful type of computer capable of performing it. This change in cost/performance, and the promise of increased reliability, modularity, and better response time has resulted in an increased tendency to decentralize and distribute computing power. But some economic factors, such as the communication expenses incurred and increased storage with distributed systems are working against the tendency to decentralize. It is clear that in many instances the optimal solution will be an integration of computers of varying power.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232851","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702149","Distributed data management;distributed system;file allocation;file availability;goal programming;processing cost;software path length","Distributed computing;Power system modeling;Availability;Supercomputers;Economies of scale;Costs;Power system reliability;Delay;Power system economics;Power generation economics","","Distributed data management;distributed system;file allocation;file availability;goal programming;processing cost;software path length","","14","","27","","","","","","IEEE","IEEE Journals & Magazines"
"An Operational Approach to Requirements Specification for Embedded Systems","P. Zave","Bell Laboratories","IEEE Transactions on Software Engineering","","1982","SE-8","3","250","269","The approach to requirements specification for embedded systems described in this paper is called ""operational"" because a requirements specification is an executable model of the proposed system interacting with its environment. The approach is embodied by the language PAISLey, which is motivated and defined herein. Embedded systems are characterized by asynchronous parallelism, even at the requirements level; PAISLey specifications are constructed by interacting processes so that this can be represented directly. Embedded systems are also characterized by urgent performance requirements, and PAISLey offers a formal, but intuitive, treatment of performance.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235254","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702941","Applicative programming;distributed processing;embedded (real-time) systems;requirements analysis and specification;simulation models;system design and specification","Embedded system;Costs;Software engineering;Project management;Parallel processing;Distributed processing;Analytical models;System analysis and design;Quality management;Real time systems","","Applicative programming;distributed processing;embedded (real-time) systems;requirements analysis and specification;simulation models;system design and specification","","148","","55","","","","","","IEEE","IEEE Journals & Magazines"
"The IC* model of parallel computation and programming environment","E. J. Cameron; D. M. Cohen; B. Gopinath; W. M. Keese; L. Ness; P. Uppaluru; J. R. Vollaro","Bell Commun. Res., Morristown, NJ, USA; Bell Commun. Res., Morristown, NJ, USA; Bell Commun. Res., Morristown, NJ, USA; Bell Commun. Res., Morristown, NJ, USA; Bell Commun. Res., Morristown, NJ, USA; Bell Commun. Res., Morristown, NJ, USA; Bell Commun. Res., Morristown, NJ, USA","IEEE Transactions on Software Engineering","","1988","14","3","317","326","The IC* project is an effort to create an environment for the design, specification, and development of complex systems such as communication protocols, parallel machines, and distributed systems. The basis of the project is the IC* model of parallel computation, in which a system is specified by a set of invariant expressions which describe its behavior in time. The features of this model include temporal and structural constraints, inherent parallelism, explicit modeling of time, nondeterministic evolution, and dynamic activation. The project also includes the construction of a parallel computer specifically designed to support the model of computation. The authors discuss the IC* model and the current user language, and describe the architecture and hardware of the prototype supercomputer built to execute IC* programs.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4652","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4652","","Integrated circuit modeling;Computational modeling;Concurrent computing;Programming environments;Protocols;Parallel machines;Parallel processing;Computer architecture;Hardware;Prototypes","parallel processing;programming environments;protocols","temporal constraints;parallel computation;programming environment;IC* project;design;specification;communication protocols;parallel machines;distributed systems;structural constraints;explicit modeling;nondeterministic evolution;dynamic activation;parallel computer","","17","","24","","","","","","IEEE","IEEE Journals & Magazines"
"On the Reliability of the IBM MVS/XA Operating System","S. Mourad; D. Andrews","Center for Reliable Computing, Computer Systems Laboratory, Departments of Electrical Engineering and Computer Science, Stanford University, Stanford, CA 94305, and Santa Clara University; NA","IEEE Transactions on Software Engineering","","1987","SE-13","10","1135","1139","This paper describes an analysis of system-detected errors on the MVS operating system under the eXtended Architecture (XA) for two IBM 3081 systems. The analysis classifies the errors in categories and examines the effectiveness of the recovery system of the MVS/XA. Comparison of the results for the two IBM 3081's confirm the dependence of the error distribution on the type of system utilization. The results for one of the machines are compared to those obtained for the same system when operating under MVS/SP. The comparison of the MVS/XA to the MVS/SP reveals the following: more addressing errors, a better error recording system and improved reliability and fault tolerance.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232855","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702153","Fault tolerance;IBM 3081;large computing systems;MVS/XA;operating system;recovery;reliability;workload","Operating systems;Military computing;Error analysis;Computer errors;Fault tolerant systems;Hardware;Laboratories;Large-scale systems;Fault detection;Frequency","","Fault tolerance;IBM 3081;large computing systems;MVS/XA;operating system;recovery;reliability;workload","","26","","17","","","","","","IEEE","IEEE Journals & Magazines"
"A Framework for Software Fault Tolerance in Real-Time Systems","T. Anderson; J. C. Knight","Computing Laboratory, University of New-castle-upon-Tyne; NA","IEEE Transactions on Software Engineering","","1983","SE-9","3","355","364","Real-time systems often have very high reliability requirements and are therefore prime candidates for the inclusion of fault tolerance techniques. In order to provide tolerance to software faults, some form of state restoration is usually advocated as a means of recovery. State restoration can be expensive and the cost is exacerbated for systems which utilize concurrent processes. The concurrency present in most real-time systems and the further difficulties introduced by timing constraints suggest that providing tolerance for software faults may be inordinately expensive or complex. We believe that this need not be the case, and propose a straightforward pragmatic approach to software fault tolerance'which is believed to be applicable to many real-time systems. The approach takes advantage of the structure of real-time systems to simplify error recovery, and a classification scheme for errors is introduced. Responses to each type of error are proposed which allow service to be maintained.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.237017","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703064","Concurrency;error classification;real-time systems;software fault tolerance;software reliability","Fault tolerant systems;Real time systems;NASA;Aerospace electronics;Delay;Costs;Concurrent computing;Timing;Maintenance;Software systems","","Concurrency;error classification;real-time systems;software fault tolerance;software reliability","","61","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Proving properties of real-time systems through logical specifications and Petri net models","M. Felder; D. Mandrioli; A. Morzenti","Dipartimento di Elettronica e Inf., Politecnico di Milano, Italy; Dipartimento di Elettronica e Inf., Politecnico di Milano, Italy; Dipartimento di Elettronica e Inf., Politecnico di Milano, Italy","IEEE Transactions on Software Engineering","","1994","20","2","127","141","Addresses the problem of formally analyzing the properties of real-time systems. We propose a method based on modeling the system as a timed Petri net and on specifying its properties in TRIO, an extension of temporal logic suitable for dealing explicitly with time and for measuring it. Timed Petri nets are axiomatized in terms of TRIO, so that their properties can be derived as theorems in the same spirit as the classical Hoare method allows one to prove properties of programs coded in a Pascal-like language. The method is also illustrated through an example.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.265634","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=265634","","Real time systems;Petri nets;Logic programming;Formal specifications;Automata;Time measurement;Embedded system;Resource management;Timing;Control systems","real-time systems;temporal logic;Petri nets;formal specification;theorem proving","real-time systems;property proving;logical specifications;TRIO;formal analysis;timed Petri net;temporal logic;axiomatization;Hoare method;embedded systems;first-order logic;formal specification;dual language","","49","","51","","","","","","IEEE","IEEE Journals & Magazines"
"Performance properties of vertically partitioned object-oriented systems","S. P. Hufnagel; J. C. Browne","Dept. of Comput Sci. Eng., Texas Univ., Arlington, TX, USA; NA","IEEE Transactions on Software Engineering","","1989","15","8","935","946","A vertically partitioned structure for the design and implementation of object-oriented systems is proposed, and their performance is demonstrated. It is shown that the application-independent portion of the execution overheads in object-oriented systems can be less than the application-independent overheads in conventionally organized systems built on layered structures. Vertical partitioning implements objects through extended type managers. Two key design concepts result in performance improvement: object semantics can be used in the state management functions of an object type and atomicity is maintained at the type manager boundaries providing efficient recovery points. The performance evaluation is based on a case study of a simple but nontrivial distributed real-time system application.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.31351","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=31351","","Application software;Costs;Access control;Concurrency control;Error correction;Fault detection;Control systems;Operating systems;Software performance;Software systems","object-oriented programming;performance evaluation;software engineering","object-oriented system design;object-oriented system implementation;vertical partitioning;vertically partitioned structure;object-oriented systems;application-independent overheads;conventionally organized systems;layered structures;extended type managers;design concepts;performance improvement;object semantics;state management functions;object type;atomicity;type manager boundaries;recovery points;performance evaluation;distributed real-time system application","","5","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Operational survivability in gracefully degrading distributed processing systems","E. W. Martin; R. A. De Millo","Boeing Electronics Company, Seattle, WA 98124; Department of Information and Computer Science, Georgia Institute of Technology, Atlanta, GA 30332","IEEE Transactions on Software Engineering","","1986","SE-12","6","693","704","The use of experimental methods and statistical analysis techniques to study factors influencing operational survivability in gracefully degrading systems is investigated. Survivability data are generated using a statistically designed experiment in conjunction with a simulation model of network survivability. Thirty two factors having stable regression coefficients are used to identify ten regression models explaining survivability. Influential factors include the distributed system network, the application system, and the distribution policy. Nine factors are found in all models: the number of nodes in the distribution system, distributed system connectivity, module memory requirements, module-to-module interaction frequency, distribution policy, percent of nodes lost, initial assignment results, available processing capacity at the end of the subcase, and the interaction of all application-related variables. Models that are acceptable from both an estimation and prediction viewpoint are developed. Possible commercial and military applications are suggested.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312967","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312967","Distributed processing system;graceful degradation;operational survivability","Topology;Network topology;Degradation;Memory management;Distributed processing;Analytical models;Computational modeling","distributed processing","operational survivability;distributed processing system degrading;experimental methods;statistical analysis;degrading systems;simulation model;network survivability;stable regression coefficients;distributed system network;application system;distribution policy;distribution system;distributed system connectivity;module memory requirements;module-to-module interaction frequency;distribution policy;initial assignment results","","6","","","","","","","","IEEE","IEEE Journals & Magazines"
"Automatic distribution of reactive systems for asynchronous networks of processors","P. Caspi; A. Girault; D. Pilaud","Lab. VERIMAG, Gieres, France; NA; NA","IEEE Transactions on Software Engineering","","1999","25","3","416","427","The paper addresses the problem of automatically distributing reactive systems. We first show that the use of synchronous languages allows a natural parallel description of such systems, regardless of any distribution problems. Then, a desired distribution can be easily specified, and achieved with the algorithm presented here. This distribution technique provides distributed programs with the same safety, test, and debug facilities as ordinary sequential programs. Finally, the implementation of such distributed programs only requires a very simple communication protocol (""first in first out"" queues), thereby reducing the need for large distributed real time executives.","0098-5589;1939-3520;2326-3881","","10.1109/32.798329","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=798329","","Parallel processing;Debugging;Interleaved codes;Safety;Sequential analysis;Protocols;Distributed processing;Program processors;Interactive systems;Operating systems","distributed programming;real-time systems;distributed algorithms;program compilers","automatic distribution;reactive systems;asynchronous networks of processors;synchronous languages;natural parallel description;distribution problems;distribution technique;distributed programs;debug facilities;communication protocol;first in first out queues;asynchronous communications","","33","","26","","","","","","IEEE","IEEE Journals & Magazines"
"On distributing JASMIN's optimistic multiversioning page manager","M. -. Lai; W. K. Wilkinson; V. Lanin","Bell Commun. Res., Morristown, NJ, USA; Bell Commun. Res., Morristown, NJ, USA; Bell Commun. Res., Morristown, NJ, USA","IEEE Transactions on Software Engineering","","1989","15","6","696","704","JASMIN is a functionally distributed database system running on multiple microcomputers that communicate with each other by message passing. The software modules in JASMIN can be cloned and distributed across computer boundaries. One important module is the intelligent store, a page manager that includes transaction-management facilities. It provides an optimistic, multiversioning concurrency control scheme. This scheme allows read-only transactions to run almost without conflict checking; this is important in some real-time database applications like telephone switching and routing services. The initial implementation of the intelligent store deals with centralized database only. Experiences in modifying the JASMIN intelligent store module to handle distributed databases are described. Design principles and system implementation techniques in the following areas are explored; process structure, data structures and synchronization on data structures. The process structure is aimed to provide high throughput and the data structures are designed to facilitate fast response time.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24723","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24723","","Transaction databases;Data structures;Deductive databases;Database systems;Microcomputers;Message passing;Distributed computing;Concurrency control;Application software;Telephony","concurrency control;data structures;distributed databases;microcomputer applications;software packages;transaction processing","optimistic multiversioning page manager;functionally distributed database system;multiple microcomputers;message passing;software modules;page manager;transaction-management facilities;multiversioning concurrency control scheme;read-only transactions;conflict checking;real-time database applications;telephone switching;routing services;centralized database;JASMIN intelligent store module;system implementation techniques;process structure;data structures;synchronization;high throughput;fast response time","","2","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Formal Grammar and Human Factors Design of an Interactive Graphics System","P. Reisner","IBM Research Laboratory","IEEE Transactions on Software Engineering","","1981","SE-7","2","229","240","Formal grammatical description has not generally been applied in the human factors area, which traditionally draws on behavioral science for its methodology. This paper illustrates, by means of a detailed example, how formal grammatical description can be used as a predictive tool to compare alternative designs for ease of use and to identify design choices which could cause users to make mistakes.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234520","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702829","Action languages;analytic tools;comparison of design alternatives;ease-of-use measurement;ease-of-use prediction;formal description;human factors;man-machine interface;user errors;user-oriented design","Human factors;Graphics;Testing;Program processors;Behavioral science;Computer science;Natural languages;Computer languages;Production;User interfaces","","Action languages;analytic tools;comparison of design alternatives;ease-of-use measurement;ease-of-use prediction;formal description;human factors;man-machine interface;user errors;user-oriented design","","131","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Time-Sensitive Cost Models in the Commercial MIS Environment","D. R. Jeffery","Department of Information Systems, University of New South Wales","IEEE Transactions on Software Engineering","","1987","SE-13","7","852","859","Current time-sensitive cost models suggest a significant impact on project effort if elapsed time compression or expansion is implemented. This paper reports an empirical study into the applicability of these models in the management information systems environment. It is found that elapsed time variation does not consistently affect project effort. This result is analyzed in terms of the theory supporting such a relationship, and an alternate relationship is suggested.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233496","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702296","Cost models;productivity;Putnam model;software project management;transformation of variables","Costs;Management information systems;Project management;Productivity;Predictive models;Time factors;Software engineering;Environmental management;Databases;Business","","Cost models;productivity;Putnam model;software project management;transformation of variables","","18","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Machine learning approaches to estimating software development effort","K. Srinivasan; D. Fisher","Personal Comput. Consultants Inc., Washington, DC, USA; NA","IEEE Transactions on Software Engineering","","1995","21","2","126","137","Accurate estimation of software development effort is critical in software engineering. Underestimates lead to time pressures that may compromise full functional development and thorough testing of software. In contrast, overestimates can result in noncompetitive contract bids and/or over allocation of development resources and personnel. As a result, many models for estimating software development effort have been proposed. This article describes two methods of machine learning, which we use to build estimators of software development effort from historical data. Our experiments indicate that these techniques are competitive with traditional estimators on one dataset, but also illustrate that these methods are sensitive to the data on which they are trained. This cautionary note applies to any model-construction strategy that relies on historical data. All such models for software effort estimation should be evaluated by exploring model sensitivity on a variety of historical data.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.345828","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=345828","","Machine learning;Programming;Contracts;Integrated circuit modeling;Software testing;Personnel;Regression tree analysis;Software development management;Costs;Machine learning algorithms","learning (artificial intelligence);software development management;contracts;human resource management","machine learning;software development effort estimation;software engineering;time pressures;software testing;contract bids;personnel;development resources;historical data;model-construction strategy","","223","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Formal verification of algorithms for critical systems","J. M. Rushby; F. von Henke","SRI Int., Menlo Park, CA, USA; NA","IEEE Transactions on Software Engineering","","1993","19","1","13","23","The authors describe their experience with formal, machine-checked verification of algorithms for critical applications, concentrating on a Byzantine fault-tolerant algorithm for synchronizing the clocks in the replicated computers of a digital flight control system. The problems encountered in unsynchronized systems and the necessity, and criticality, of fault-tolerant synchronization are described. An overview of one such algorithm and of the arguments for its correctness are given. A verification of the algorithm performed using the authors' EHDM system for formal specification and verification is described. The errors found in the published analysis of the algorithm and benefits derived from the verification are indicated. Based on their experience, the authors derive some key requirements for a formal specification and verification system adequate to the task of verifying algorithms of the type considered. The conclusions regarding the benefits of formal verification in this domain and the capabilities required of verification systems in order to realize those benefits are summarized.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.210304","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=210304","","Formal verification;Aerospace control;Synchronization;Fault tolerant systems;Clocks;Formal specifications;Control systems;Fault tolerance;Aircraft;Application software","fault tolerant computing;formal specification;formal verification;safety;software reliability;synchronisation","critical systems;machine-checked verification;Byzantine fault-tolerant algorithm;digital flight control system;fault-tolerant synchronization;EHDM system;formal specification","","47","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Central Server Models with Multiple Job Classes, State Dependent Routing, and Rejection Blocking","I. F. Akyildiz; H. Von Brand","School of Information and Computer Science, Georgia Institute of Technology, Atlanta, GA 30332.; NA","IEEE Transactions on Software Engineering","","1989","15","10","1305","1312","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1989.559784","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=559784","","Routing;Network servers;Throughput;Job shop scheduling;Capacity planning;Flexible manufacturing systems;Virtual manufacturing;Computer science","","Blocking;finite station capacities;performance evaluation;performance measures;queueing network models","","7","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Statistical Database Query Languages","G. Ozsoyoglu; Z. M. Ozsoyoglu","Department of Computer Engineering and Science, Case Institute of Technology, Case Western Reserve University; NA","IEEE Transactions on Software Engineering","","1985","SE-11","10","1071","1081","Databases that are mainly used for statistical analysis are called statistical databases (SDB). A statistical database management system (SDBMS) may be defined as a database management system that provides capabilities 1) to model, store, and manipulate data in a manner suitable for the needs of SDB users, and 2) to apply statistical data analysis techniques that range from simple summary statistics to advanced procedures. This paper surveys the existing and proposed SDB data definition and data manipulation (i.e., query) languages.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231854","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701922","Database systems;data definition;data manipulation;query languages;statistical databases","Database languages;Statistical analysis;Database systems;Packaging;Data analysis;Software packages;Application software;Taxonomy;Medical services;Power generation economics","","Database systems;data definition;data manipulation;query languages;statistical databases","","10","","64","","","","","","IEEE","IEEE Journals & Magazines"
"The detection of fault-prone programs","J. C. Munson; T. M. Khoshgoftaar","Div. of Comput. Sci., Univ. of West Florida, Pensacola, FL, USA; NA","IEEE Transactions on Software Engineering","","1992","18","5","423","433","The use of the statistical technique of discriminant analysis as a tool for the detection of fault-prone programs is explored. A principal-components procedure was employed to reduce simple multicollinear complexity metrics to uncorrelated measures on orthogonal complexity domains. These uncorrelated measures were then used to classify programs into alternate groups, depending on the metric values of the program. The criterion variable for group determination was a quality measure of faults or changes made to the programs. The discriminant analysis was conducted on two distinct data sets from large commercial systems. The basic discriminant model was constructed from deliberately biased data to magnify differences in metric values between the discriminant groups. The technique was successful in classifying programs with a relatively low error rate. While the use of linear regression models has produced models of limited value, this procedure shows great promise for use in the detection of program modules with potential for faults.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.135775","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=135775","","Fault detection;Software quality;Software measurement;Computer errors;Predictive models;Software metrics;Time measurement;Computer science;Error analysis;Linear regression","computational complexity;program testing;quality control;software metrics;software reliability","statistical technique;discriminant analysis;fault-prone programs;principal-components procedure;simple multicollinear complexity metrics;uncorrelated measures;orthogonal complexity domains;group determination;quality measure;large commercial systems;deliberately biased data;metric values;relatively low error rate;linear regression models;program modules","","253","","17","","","","","","IEEE","IEEE Journals & Magazines"
"PHILAN: a LAN providing a reliable message service for distributed processing","J. L. W. Kessels","Philips Res. Lab., Eindhoven, Netherlands","IEEE Transactions on Software Engineering","","1988","14","10","1424","1431","A local area network (LAN) design based on a ring topology is presented which can support both packet-switched and circuit-switched traffic. The packet-switching service is reliable in that the LAN controllers deal with all protocol problems, i.e., medium arbitrations as well as flow and error control. The service can meet real-time constraints, since the performance is stable under high load conditions and the arbitration delays are bounded. Moreover, the processing speed of the LAN controller is independent of the transmission speed, and the speed requirements are such that they can be met by a microprocessor (no need for dedicated hardware to process the information on the fly). Before the design of PHILAN is presented, an analysis is given of the protocol problems that have to be dealt with when establishing a reliable packet-switching service on a LAN.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6187","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6187","","Local area networks;Message service;Protocols;Network topology;Circuit topology;Communication system traffic control;Error correction;Delay;Microprocessors;Hardware","local area networks;packet switching;protocols","reliable message service;distributed processing;local area network;LAN;ring topology;packet-switched;circuit-switched;packet-switching;protocol;real-time constraints;processing speed;PHILAN","","","","11","","","","","","IEEE","IEEE Journals & Magazines"
"A component- and message-based architectural style for GUI software","R. N. Taylor; N. Medvidovic; K. M. Anderson; E. J. Whitehead; J. E. Robbins; K. A. Nies; P. Oreizy; D. L. Dubrow","California Univ., Irvine, CA, USA; California Univ., Irvine, CA, USA; California Univ., Irvine, CA, USA; California Univ., Irvine, CA, USA; California Univ., Irvine, CA, USA; California Univ., Irvine, CA, USA; California Univ., Irvine, CA, USA; NA","IEEE Transactions on Software Engineering","","1996","22","6","390","406","While a large fraction of application code is devoted to graphical user interface (GUI) functions, support for reuse in this domain has largely been confined to the creation of GUI toolkits (""widgets""). We present a novel architectural style directed at supporting larger grain reuse and flexible system composition. Moreover, the style supports design of distributed, concurrent applications. Asynchronous notification messages and asynchronous request messages are the sole basis for intercomponent communication. A key aspect of the style is that components are not built with any dependencies on what typically would be considered lower-level components, such as user interface toolkits. Indeed, all components are oblivious to the existence of any components to which notification messages are sent. While our focus has been on applications involving graphical user interfaces, the style has the potential for broader applicability. Several trial applications using the style are described.","0098-5589;1939-3520;2326-3881","","10.1109/32.508313","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=508313","","Graphical user interfaces;User interfaces;Application software;Computer architecture;Runtime;Concurrent computing;Artificial intelligence;Software tools;Graphics;Computer languages","graphical user interfaces;user interface management systems;software reusability;message passing;parallel programming","message-based architectural style;component-based architectural style;graphical user interface;reuse;widgets;flexible system composition;distributed concurrent applications;asynchronous notification messages;asynchronous request messages;intercomponent communication;user interface toolkits;message-based architectures;heterogeneity;concurrency","","188","","38","","","","","","IEEE","IEEE Journals & Magazines"
"Cycle Time Properties Of The FDDI Token Ring Protocol","K. C. Sevick; M. J. Johnson","Computer Systems Research Institute, University of Toronto; NA","IEEE Transactions on Software Engineering","","1987","SE-13","3","376","385","The FDDI Token Ring Protocol controls communication over fiber optic rings with transmission rates in the range of 100 megabits per second. It is intended to give guaranteed response to time-critical messages by using a ""timed token"" protocol, in which non-critical messages may be transmitted only if recent movement of the token among stations has been sufficiently fast relative to a ""target"" token rotation time (TTRT).","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233169","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702224","FDDI protocol;performance;token ring","FDDI;Token networks;Protocols;Optical fibers;Data communication;Optical fiber LAN;NASA;Optical control;Communication system control;Communications technology","","FDDI protocol;performance;token ring","","134","","22","","","","","","IEEE","IEEE Journals & Magazines"
"An optimistic locking technique for concurrency control in distributed databases","U. Halici; A. Dogac","Middle East Tech. Univ., Ankara, Turkey; Middle East Tech. Univ., Ankara, Turkey","IEEE Transactions on Software Engineering","","1991","17","7","712","724","A method called optimistic method with dummy locks (ODL) is suggested for concurrency control in distributed databases. It is shown that by using long-term dummy locks, the need for the information about the write sets of validated transactions is eliminated and, during the validation test, only the related sites are checked. The transactions to be aborted are immediately recognized before the validation test, reducing the costs of restarts. Usual read and write locks are used as short-term locks during the validation test. The use of short-term locks in the optimistic approach eliminates the need for the system-wide critical section and results in a distributed and parallel validation test. The performance of ODL is compared with strict two-phase locking (2PL) through simulation, and it is found out that for the low conflict cases they perform almost the same, but for the high conflicting cases, ODL performs better than strict 2PL.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.83907","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=83907","","Concurrency control;Distributed databases;System recovery;System testing;Costs;Optimization methods;Transaction databases;Database systems;Certification;Protocols","concurrency control;distributed databases;system recovery;transaction processing","optimistic locking technique;concurrency control;distributed databases;optimistic method;dummy locks;write sets;validated transactions;validation test;short-term locks;ODL;strict two-phase locking;low conflict cases;strict 2PL","","5","","39","","","","","","IEEE","IEEE Journals & Magazines"
"Resilient Distributed Computing","L. Svobodova","Institut National de Recherche en Informatique et an Automatique, Rocquencourt, France.; IBM Zrich Research Laboratory, 8803 Rschlikon, Switzerland.","IEEE Transactions on Software Engineering","","1984","SE-10","3","257","268","A control abstraction called atomic action is a powerful general mechanism for ensuring consistent behavior of a system in spite of failures of individual computations running in the system, and in spite of system crashes. However, because of the ``all-or-nothing'' property of atomic actions, an important amount of work might be abandoned needlessly when an internal error is encountered. This paper discusses how implementation of resilient distributed systems can be supported using a combination of nested atomic actions and stable checkpoints. Nested atomic actions form a tree structure. When an internal atomic action terminates, its results are not made permanent until the outermost atomic action commits, but they survive local node failures. Each subtree of atomic actions is recoverable individually. A checkpoint is established in stable storage as part of a remote request so that results of such a request can be reclaimed if the requesting node fails in the meantime, The paper shows how remote procedure call primitives with ``at-most-once'' semantics and recovery blocks can be built with these mechanisms.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010234","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010234","Atomic actions;checkpoints;consistency;crash resistance;distributed programs;distributed systems;recoverability;remote procedure calls","Distributed computing;Computer crashes;Hardware;Uncertainty;Power system modeling;Tree data structures;Distributed processing;Permission;Fault tolerant systems","","","","22","","40","","","","","","IEEE","IEEE Journals & Magazines"
"Understanding and controlling software costs","B. W. Boehm; P. N. Papaccio","TRW Inc., Redondo Beach, CA, USA; TRW Inc., Redondo Beach, CA, USA","IEEE Transactions on Software Engineering","","1988","14","10","1462","1477","A discussion is presented of the two primary ways of understanding software costs. The black-box or influence-function approach provides useful experimental and observational insights on the relative software productivity and quality leverage of various management, technical, environmental, and personnel options. The glass-box or cost distribution approach helps identify strategies for integrated software productivity and quality improvement programs using such structures as the value chain and the software productivity opportunity tree. The individual strategies for improving software productivity are identified. Issues related to software costs and controlling them are examined and discussed. It is pointed out that a good framework of techniques exists for controlling software budgets, schedules, and work completed, but that a great deal of further progress is needed to provide an overall set of planning and control techniques covering software product qualities and end-user system objectives.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6191","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6191","","Costs;Software quality;Productivity;Personnel;Programming profession;Control systems;Environmental management;Quality management;Writing;Software engineering","DP management;software engineering","software costs;black-box;influence-function;software productivity;glass-box;cost distribution;integrated software productivity;quality improvement;value chain;software productivity opportunity tree;software budgets;end-user system objectives","","246","","129","","","","","","IEEE","IEEE Journals & Magazines"
"A causal model for software cost estimating error","A. L. Lederer; J. Prasad","Kentucky Univ., Lexington, KY, USA; NA","IEEE Transactions on Software Engineering","","1998","24","2","137","148","Software cost estimation is an important concern for software managers and other software professionals. The hypothesized model in this research suggests that an organization's use of an estimate influences its estimating practices which influence both the basis of the estimating process and the accuracy of the estimate. The model also suggests that the estimating basis directly influences the accuracy of the estimate. A study of business information systems managers and professionals at 112 different organizations using causal analysis with the Equations Modeling System (EQS) refined the model. The refined model shows that no managerial practice in this study discourages the use of intuition, guessing and personal memory in cost estimating. Although user commitment and accountability appear to foster algorithm-based estimating, such an algorithmic basis does not portend greater accuracy. Only one managerial practice-the use of the estimate in performance evaluations of software managers and professionals-presages greater accuracy. By implication, the research suggests somewhat ironically that the most effective approach to improve estimating accuracy may be to make estimators, developers and managers more accountable for the estimate even though it may be impossible to direct them explicitly on how to produce a more accurate one.","0098-5589;1939-3520;2326-3881","","10.1109/32.666827","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=666827","","Costs;Management information systems;Programming;Software tools;Information management;Differential equations;Software reusability;Information analysis;Memory management;Software performance","software cost estimation;error analysis;software management;management information systems","causal model;software cost estimation error;software managers;accuracy;business information systems managers;causal analysis;Equations Modeling System;refined model;managerial practice;intuition;guessing;personal memory;user commitment;user accountability;algorithm-based estimating;performance evaluation;accountability;software development","","27","","69","","","","","","IEEE","IEEE Journals & Magazines"
"Analyzing hard-real-time programs for guaranteed schedulability","A. D. Stoyenko; V. C. Hamacher; R. C. Holt","Dept. of Comput. & Inf. Sci., New Jersey Inst. of Technol., Newark, NJ, USA; NA; NA","IEEE Transactions on Software Engineering","","1991","17","8","737","750","A set of language-independent schedulability analysis techniques is presented. Utilizing knowledge of implementation- and hardware-dependent information in a table-driven fashion, these techniques provide accurate worst-case time bounds and other schedulability information. A prototype schedulability analyzer has been developed to demonstrate the effectiveness of these techniques. The analyzer consists of a partially language-dependent front-end, targeted at real-time Euclid, a real-time language specifically designed with a set of schedulability analysis provisions built-in, and a language-dependent back-end. The analyzer has been used on a number of realistic real-time programs run on a multiple-microprocessor system. Predicted program performance differs only marginally from the actual performance.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.83911","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=83911","","Scheduling;Real time systems;Program processors;Process control;Timing;Chemical processes;Software performance;Programming profession;Performance analysis;Failure analysis","high level languages;program verification;real-time systems;scheduling;systems analysis","language-independent schedulability analysis;hardware-dependent information;table-driven fashion;worst-case time bounds;prototype schedulability analyzer;partially language-dependent front-end;real-time Euclid;real-time language;schedulability analysis provisions;language-dependent back-end;realistic real-time programs;multiple-microprocessor system;program performance","","42","","56","","","","","","IEEE","IEEE Journals & Magazines"
"Transformational Implementation: An Example","R. Balzer","Information Sciences Institute, University of Southern California","IEEE Transactions on Software Engineering","","1981","SE-7","1","3","14","A system for mechanically transforming formal program specifications into efficient implementations under interactive user control is described and illustrated through a detailed example. The potential benefits and problems of this approach to software implementation are discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230814","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702797","Optimization;program manipulation system;program reliability;programming techniques;program transformation","Documentation;Control systems;Process design;Computer languages;Performance analysis;Performance evaluation;Design optimization;Instruments;Automatic testing;Magnetic heads","","Optimization;program manipulation system;program reliability;programming techniques;program transformation","","85","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Performance analysis of dynamic locking with the no-waiting policy","I. K. Ryu; A. Thomasian","Digital Equipment Corp., Mountain View, CA, USA; NA","IEEE Transactions on Software Engineering","","1990","16","7","684","698","A transaction processing system with two-phase dynamic locking with the no waiting policy (DLNW) for concurrency control is considered. In this method, transactions making conflicting lock requests are aborted and restarted rather than blocked, thereby eliminating blocking delays (and deadlocks), but making it susceptible to cyclic restarts. Cyclic restarts are dealt with by delaying the restart of a transaction encountering a lock conflict or replacing it with a new transaction. Analytic solution methods for evaluating the performance of the variants of the DLNW method are described. The analytic methods, validated against simulation and shown to be acceptably accurate, are used to study the effect of the following parameters on system performance: transaction size and its distribution, degree of concurrency, the throughput characteristic of the computer system, and the mixture of read-only query and update transactions. A comparison of the DLNW and dynamic locking with waiting (DLW) methods shows that DLW provides higher throughput than DLNW, except when there is no hardware resource contention and conflicted transactions can be replaced by new transactions. The DLNW method outperforms the time-stamp ordering method, as observed from simulation results as well as case by case analyses of possible scenarios.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.56095","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=56095","","Performance analysis;Delay;Analytical models;Throughput;Concurrency control;System recovery;Computational modeling;Computer simulation;System performance;Concurrent computing","concurrency control;performance evaluation;transaction processing","performance analysis;dynamic locking;no-waiting policy;transaction processing system;concurrency control;blocking delays;deadlocks;cyclic restarts;throughput characteristic;read-only query;update transactions;time-stamp ordering method","","14","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Specification and Verification of Communication Protocols in AFFIRM Using State Transition Models","C. A. Sunshine; D. H. Thompson; R. W. Erickson; S. L. Gerhart; D. Schwabe","Information Sciences Institute, University of Southern California; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1982","SE-8","5","460","489","It is becoming increasingly important that communication protocols be formally specified and verified. This paper describes a particular approachthe state transition modelusing a collection of mechanically supported specification and verification tools incorporated in a running system called AFFIRM. Although developed for the specification of abstract data types and the verification of their properties, the formalism embodied in AFFIRM can also express the concepts underlying state transition machines. Such models easily express most of the events occurring in protocol systems, including those of the users, their agent processes, and the communication channels. The paper reviews the basic concepts of state transition models and the AFFIRM formalism and methodology and describes their union. A detailed example, the alternating bit protocol, illustrates varous properties of interest for specification and verification. Other examples explored using this formalism are briefly described and the accumulated experience is discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235736","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702976","Abstract data types;algebraic axiomatic specifications;alternating bit protocol;natural-deduction theorem-proving;protocols;specification;state transition models;verification","Protocols;Safety;Intersymbol interference;Communication channels;Electronic mail;Internet;Computer science;Specification languages;Computer languages;Concrete","","Abstract data types;algebraic axiomatic specifications;alternating bit protocol;natural-deduction theorem-proving;protocols;specification;state transition models;verification","","24","","57","","","","","","IEEE","IEEE Journals & Magazines"
"Maintenance support for object-oriented programs","N. Wilde; R. Huitt","Dept. of Comput. Sci., University of West Florida; NA","IEEE Transactions on Software Engineering","","1992","18","12","1038","1044","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1992.1263033","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1263033","","Software maintenance;Documentation;Communication system control;Data encapsulation;Costs;Software engineering;Collaborative software;Collaborative work;Councils","","","","104","","32","","","","","","IEEE","IEEE Journals & Magazines"
"Experimental evaluation of a reusability-oriented parallel programming environment","J. C. Browne; T. Lee; J. Werth","Dept. of Comput. Sci., Texas Univ., Austin, TX, USA; Dept. of Comput. Sci., Texas Univ., Austin, TX, USA; Dept. of Comput. Sci., Texas Univ., Austin, TX, USA","IEEE Transactions on Software Engineering","","1990","16","2","111","120","Reports on the initial experimental evaluation of ROPE (reusability-oriented parallel programming environment), a software component reuse system. ROPE helps the designer find and understand components by using a new classification method called structured relational classification. ROPE is part of a development environment for parallel programs which uses a declarative/hierarchical graphical programming interface. This interface allows use of components with different levels of abstraction, ranging from design units to actual code modules. ROPE supports reuse of all the component types defined in the development environment. Programs developed with the aid of ROPE were found to have error rates far less than those developed without ROPE.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44375","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44375","","Parallel programming;Error analysis;Software engineering;Software measurement;Computer displays;Concurrent computing;Software reusability;Software systems;Design for experiments;Libraries","computer graphics;parallel programming;performance evaluation;programming environments;software reusability;user interfaces","reusability-oriented parallel programming environment;experimental evaluation;ROPE;software component reuse system;structured relational classification;development environment;declarative/hierarchical graphical programming interface;design","","21","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Casting Petri Nets into Programs","R. A. Nelson; L. M. Haibt; P. B. Sheridan","IBM Thomas J. Watson Research Center; NA; NA","IEEE Transactions on Software Engineering","","1983","SE-9","5","590","602","A programming system has been implemented in which annotated Petri nets are used as machine-processable high-evel design representations. The nets can be used to express the parallelism and the dynamic sequential dependencies found in complex software. They can then be interactively fired to facilitate debugging of the design. The nets are processed into a procedure language, called XL/1, to which a variety of transformations are applied in order to produce more efficient programs. These programs are generated for either a serial or a parallel processing environment. Finally, the XL/1 programs may be translated into PL/I or PL/S. The serial processing versions have been compiled and run successfully, but the parallel processing versions have not yet been run in a parallel processing environment.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.235118","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703099","Asynchronous processes;concurrency;high-level design;high-level specification;modeling;parallel processing;Petri nets;process control;software development","Casting;Petri nets;Parallel processing;Process control;Programming;Hardware;Debugging;Concurrent computing;Process design","","Asynchronous processes;concurrency;high-level design;high-level specification;modeling;parallel processing;Petri nets;process control;software development","","45","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Managing Software Engineering Projects: A Social Analysis","W. Scacchi","Department of Computer Science, University of Southern California, Los Angeles, CA 90089.","IEEE Transactions on Software Engineering","","1984","SE-10","1","49","59","Managing software engineering projects requires an ability to comprehend and balance the technological, economic, and social bases through which large software systems are developed. It requires people who can formulate strategies for developing systems in the presence of ill-defined requirements, new computing technologies, and recurring dilemmas with existing computing arrangements. This necessarily assumes skill in acquiring adequate computing resources, controlling projects, coordinating development schedules, and employing and directing competent staff. It also requires people who can organize the process for developing and evolving software products with locally available resources. Managing software engineering projects is as much a job of social interaction as it is one of technical direction. This paper examines the social arrangements that a software manager must deal with in developing and using new computing systems, evaluating the appropriateness of software engineering tools or techniques, directing the evolution of a system through its life cycle, organizing and staffing software engineering projects, and assessing the distributed costs and benefits of local software engineering practices. Ths purpose is to underscore the role of social analysis of software engineering practices as a cornerstone in understanding what it takes to productively manage software projects.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010198","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010198","History of software engineering;organizational Impact;social analysis;software engineering project management;software life cycle","Project management;Engineering management;Software engineering;Software development management;Technology management;Software systems;Computers;Processor scheduling;Software tools;Distributed computing","","","","39","","45","","","","","","IEEE","IEEE Journals & Magazines"
"Pictorial information retrieval using the random neural network","A. Stafylopatis; A. Likas","Dept. of Electr. & Comput. Eng., Nat. Tech. Univ. of Athens, Greece; Dept. of Electr. & Comput. Eng., Nat. Tech. Univ. of Athens, Greece","IEEE Transactions on Software Engineering","","1992","18","7","590","600","A technique is developed based on the use of a neural network model for performing information retrieval in a pictorial information system. The neural network provides autoassociative memory operation and allows the retrieval of stored symbolic images using erroneous or incomplete information as input. The network used is based on an adaptation of the random neural network model featuring positive and negative nodes and symmetrical behavior of positive and negative signals. The network architecture considered has hierarchical structure and allows two-level operation during learning and recall. An experimental software prototype, including an efficient graphical interface, has been implemented and tested. The performance of the system has been investigated through experiments under several schemes concerning storage and reconstruction of patterns. These schemes are either based on properties of the random network or constitute adaptations of known neural network techniques.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.148477","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=148477","","Information retrieval;Neural networks;Information systems;Image processing;Image databases;Management information systems;Image retrieval;Data mining;Image storage;Relational databases","computerised picture processing;content-addressable storage;graphical user interfaces;information retrieval;neural nets;software prototyping","pictorial information retrieval;random neural network;autoassociative memory operation;stored symbolic images;hierarchical structure;learning;recall;software prototype;graphical interface;performance;random network","","8","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Determining an optimal time interval for testing and debugging software","N. D. Singpurwalla","Sch. of Eng. & Appl. Sci., George Washington Univ., Washington, DC, USA","IEEE Transactions on Software Engineering","","1991","17","4","313","319","A decision-theoretic procedure for determining an optimal time interval for testing software prior to its release is proposed. The approach is based on the principles of decision-making under uncertainty and involves a maximization of expected utility. Two plausible forms for the utility function, one based on costs and the other involving the realized reliability of the software, are described. Using previous results on probabilistic models for software failure, the ensuing optimization problem (which can be addressed using numerical techniques) is outlined for the case of single-state testing. The sensitivity of the results to the various input parameters is discussed, and some directions for future research are outlined.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.90431","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=90431","","Software testing;Software debugging;Cost function;Bayesian methods;Certification;Computer bugs;Decision making;Uncertainty;Utility theory;Computer science","decision theory;program debugging;program testing;programming theory","software testing;software debugging;decision theory;software reliability;optimal time interval;decision-making;uncertainty;maximization;expected utility;utility function;costs;probabilistic models;software failure;optimization problem;single-state testing","","45","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Maisie: a language for the design of efficient discrete-event simulations","R. L. Bagrodia; Wen-Toh Liao","Dept. of Comput. Sci., California Univ., Los Angeles, CA, USA; Dept. of Comput. Sci., California Univ., Los Angeles, CA, USA","IEEE Transactions on Software Engineering","","1994","20","4","225","238","Maisie is a C-based discrete-event simulation language that was designed to cleanly separate a simulation model from the underlying algorithm (sequential or parallel) used for the execution of the model. With few modifications, a Maisie program may be executed by using a sequential simulation algorithm, a parallel conservative algorithm or a parallel optimistic algorithm. The language constructs allow the run-time system to implement optimizations that reduce recomputation and state saving overheads for optimistic simulations and synchronization overheads for conservative implementations. This paper presents the Maisie simulation language, describes a set of optimizations, and illustrates the use of the language in the design of efficient parallel simulations.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.277572","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=277572","","Computational modeling;Discrete event simulation;Computer simulation;Algorithm design and analysis;Parallel architectures;Protocols;Design optimization;Concurrent computing;Distributed computing;Computer science","discrete event simulation;simulation languages;optimisation;synchronisation;parallel algorithms;C language","Maisie;C-based discrete-event simulation language;simulation model/algorithm separation;sequential simulation algorithm;parallel conservative algorithm;parallel optimistic algorithm;language constructs;run-time system;optimizations;recomputation overheads;state saving overheads;synchronization overheads;distributed simulation;semantic rollback;lookahead optimization;interrogative simulation","","85","","35","","","","","","IEEE","IEEE Journals & Magazines"
"Theories of Program Testing and the Application of Revealing Subdomains","E. J. Weyuker; T. J. Ostrand","Courant Institute of Mathematical Sciences, New York University; NA","IEEE Transactions on Software Engineering","","1980","SE-6","3","236","246","The theory of test data selection proposed by Goodenough and Gerhart is examined. In order to extend and refine this theory, the concepts of a revealing test criterion and a revealing subdomain are proposed. These notions are then used to provide a basis for constructing program tests.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234485","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702725","Program testing;revealing subdomain;software error detection;software reliability;test data generation;theory of testing","Software testing;Software reliability","","Program testing;revealing subdomain;software error detection;software reliability;test data generation;theory of testing","","101","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Analysis of concurrency-coherency control protocols for distributed transaction processing systems with regional locality","B. Ciciani; D. M. Dias; P. S. Yu","Dept. of Comput. Sci., Rome Univ., Italy; NA; NA","IEEE Transactions on Software Engineering","","1992","18","10","899","914","A system structure and protocols for improving the performance of a distributed transaction processing system when there is some regional locality of data reference are presented. A distributed computer system is maintained at each region, and a central computer system with a replication of all databases at the distributed sites is introduced. It provides the advantage of distributed systems principally for local transactions, and has the advantage of centralized systems for transactions accessing nonlocal data. Specialized protocols keep the copies at the distributed and centralized systems consistent without incurring the overhead and delay of generalized protocols for fully replicated databases. The advantages achievable through this system structure and the tradeoffs between protocols for concurrency and coherency control of the duplicate copies of the databases are studied. An approximate analytic model is used to estimate the system performance. It is found that the performance is sensitive to the protocol and that substantial performance improvement can be obtained as compared with distributed systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.163606","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=163606","","Distributed control;Access protocols;Distributed computing;Distributed databases;Transaction databases;Delay;Concurrent computing;Control systems;Performance analysis;System performance","concurrency control;distributed databases;distributed processing;performance evaluation;protocols;transaction processing","concurrency-coherency control protocols;distributed transaction processing systems;performance;databases;delay;fully replicated databases;duplicate copies;approximate analytic model","","16","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Formal Program Verification Using Symbolic Execution","R. B. Dannenberg; G. W. Ernst","Department of Computer Science, Carnegie-Mellon University; NA","IEEE Transactions on Software Engineering","","1982","SE-8","1","43","52","Symbolic execution provides a mechanism for formally proving programs correct. A notation is introduced which allows a concise presentation of rules of inference based on symbolic execution. Using this notation, rules of inference are developed to handle a number of language features, including loops and procedures with multiple exits. An attribute grammar is used to formally describe symbolic expression evaluation, and the treatment of function calls with side effects is shown to be straightforward. Because symbolic execution is related to program interpretation, it is an easy-to-comprehend, yet powerful technique. The rules of inference are useful in expressing the semantics of a language and form the basis of a mechanical verification condition generator.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.234773","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702904","Control constructs;program proving;program verification;rules of inference;side effects;symbolic execution;verification conditions","Logic;Calculus;Computer science;Computer languages","","Control constructs;program proving;program verification;rules of inference;side effects;symbolic execution;verification conditions","","5","","12","","","","","","IEEE","IEEE Journals & Magazines"
"On parallelization of static scheduling algorithms","M. -. Wu; W. Shu","Dept. of Electr. & Comput. Eng., Central Florida Univ., Orlando, FL, USA; NA","IEEE Transactions on Software Engineering","","1997","23","8","517","528","Most static algorithms that schedule parallel programs represented by macro dataflow graphs are sequential. This paper discusses the essential issues pertaining to parallelization of static scheduling and presents two efficient parallel scheduling algorithms. The proposed algorithms have been implemented on an Intel Paragon machine and their performances have been evaluated. These algorithms produce high-quality scheduling and are much faster than existing sequential and parallel algorithms.","0098-5589;1939-3520;2326-3881","","10.1109/32.624307","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=624307","","Scheduling algorithm;Processor scheduling;Parallel algorithms;Concurrent computing;Performance evaluation;NP-complete problem;Scalability;Costs;Computational efficiency","processor scheduling;parallel algorithms;parallel programming;data flow graphs;software performance evaluation","static scheduling algorithms;algorithm parallelization;parallel program scheduling;macro dataflow graphs;parallel scheduling algorithms;Intel Paragon machine;performance evaluation;modified critical-path algorithm","","4","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Persistent caching: an implementation technique for complex objects with object identity","K. Kato; T. Masuda","Dept. of Inf. Sci., Tokyo Univ., Japan; Dept. of Inf. Sci., Tokyo Univ., Japan","IEEE Transactions on Software Engineering","","1992","18","7","631","645","Many recent complex object database systems support the concepts of object identity and object identifier. Following an object identifier to access the referenced object is called navigation operation and is an essential operation in dealing with complex objects. Navigation operation is a difficult operation to implement efficiently since every navigation operation inherently causes one disk access operation. A scheme to notably accelerate the navigation operation among a sea of complex objects, by increasing the effective number of objects in one disk page is proposed. The main concept of the presented technique is threefold. The first idea is to store a cached value within a complex object that is referencing another complex object. The second is that when the referenced object is to be updated the update propagation is delayed until the time when the cached value is referenced. The third is to utilize a hashed table on main memory to efficiently validate the consistency between the cached values and the original values.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.148481","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=148481","","Navigation;Data models;Knowledge management;Office automation;Computer aided manufacturing;CADCAM;Computer aided software engineering;Computer languages;Knowledge engineering;Identity management systems","buffer storage;database management systems;file organisation","persistent caching;implementation technique;complex objects;object identity;complex object database systems;object identifier;navigation operation;update propagation;hashed table","","9","","40","","","","","","IEEE","IEEE Journals & Magazines"
"Data dependency graphs for Ada programs","L. E. Moser","Dept. of Electr. & Comput. Eng., California Univ., Santa Barbara, CA, USA","IEEE Transactions on Software Engineering","","1990","16","5","498","509","A compositional method of constructing data dependency graphs for Ada programs is presented. These graphs are useful in a program development environment for analyzing data dependencies and tracking information flow within a program. Graphs for primitive program statements are combined together to form graphs for larger program units. Composition rules are described for iteration, recursion, exception handling, and tasking, as well as for simpler Ada constructs. The correctness of the construction and the practicality of the technique are discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.52773","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=52773","","Data analysis;Information analysis;Software reliability;Data security;Information security;Modems;Computer languages;Data structures;Performance analysis;National security","Ada;data structures;programming","composition rules;Ada programs;data dependency graphs;program development environment;tracking;information flow;primitive program statements;iteration;recursion;exception handling;tasking;correctness","","9","","19","","","","","","IEEE","IEEE Journals & Magazines"
"On some reliability estimation problems in random and partition testing","M. Z. Tsoukalas; J. W. Duran; S. C. Ntafos","Comput. Sci. Program, Univ. of Texas at Dallas, Richardson, TX, USA; NA; NA","IEEE Transactions on Software Engineering","","1993","19","7","687","697","Studies have shown that random testing can be an effective testing strategy. One of the goals of testing is to estimate the reliability of the program from the test outcomes. The authors extend the Thayer-Lipow-Nelson reliability model (R. Thayer et al., 1978) to account for the cost of errors. They also compare random testing with partition testing by examining upper confidence bounds for the cost weighted performance of the two strategies.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.238569","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=238569","","Costs;Automatic testing;Software testing;Input variables;Documentation;Design methodology;Software performance;Programming;Computer science;Runtime","program testing;software reliability","random testing;effective testing strategy;test outcomes;Thayer-Lipow-Nelson reliability model;partition testing;upper confidence bounds;cost weighted performance","","48","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Monitoring for Deadlock and Blocking in Ada Tasking","S. M. German","Computer Science Laboratory, GTE Laboratories, Waltham, MA 02254.","IEEE Transactions on Software Engineering","","1984","SE-10","6","764","777","We present a deadlock monitoring algodrithm for Ada tasking programs which is based on transforming the source program. The transformations introduce a new task called the monitor, which receives information from all other tasks about their tasking activities. The monitor detects deadlocks consisting of circular entry calls as well as some noncircular blocking situations. The correctness of the program transformations is formulated and proved using an operational state graph model of tasking. The main issue in the correctness proof is to show that the deadlock monitor algorithm works correctly without having simultaneous information about the state of the program. In the course of this work, we have developed some useful techniques for programming tasking applications, such as a method for uniformly introducing task identifiers. We argue that the ease of finding and justifying program transformations is a good test of the generality and uniformity of a programming language. The complexity of the full Ada language makes it difficult to safely apply transformational methods to arbitrary programs. We discuss several problems with the current semantics of Ada's tasks.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010305","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010305","Concurrent algorithms;concurrent programming languages;correctness proofs of concurrent programs;deadlock detection;exceptions;program transformations;semantics of Ada tasking;state graph models;task identifiers","Monitoring;System recovery;Signal processing;Testing;Debugging;Computer science;Detection algorithms;Multitasking","","","","22","","11","","","","","","IEEE","IEEE Journals & Magazines"
"A model for secure protocols and their compositions","N. Heintze; J. D. Tygar","AT&T Bell Labs., Murray Hill, NJ, USA; NA","IEEE Transactions on Software Engineering","","1996","22","1","16","30","The paper develops a foundation for reasoning about protocol security. We adopt a model-based approach for defining protocol security properties. This allows us to describe security properties in greater detail and precision than previous frameworks. Our model allows us to reason about the security of protocols, and considers issues of beliefs of agents, time, and secrecy. We prove a composition theorem which allows us to state sufficient conditions on two secure protocols A and B such that they may be combined to form a new secure protocol C. Moreover, we give counter-examples to show that when the conditions are not met, the protocol C may not be secure.","0098-5589;1939-3520;2326-3881","","10.1109/32.481514","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=481514","","Cryptographic protocols;Sufficient conditions;Computer security;Logic;Authentication;Clocks;Cryptography;Concrete;Concatenated codes;Computer science","protocols;inference mechanisms;software agents;knowledge based systems;belief maintenance;theorem proving;message authentication;cryptography;distributed processing","protocol security reasoning;secure protocol compositions;secure protocol model;protocol security properties;agent beliefs;time;secrecy;composition theorem proving","","26","","24","","","","","","IEEE","IEEE Journals & Magazines"
"MIKE: A Network Operating System for the Distributed Double-Loop Computer Network","Duen-Ping Tsay; M. T. Liu","Wang Laboratories, Inc.; NA","IEEE Transactions on Software Engineering","","1983","SE-9","2","143","154","This paper presents the framework and model of a network operating system (NOS) called MIKE for use in distributed systems in general and for use in the Distributed Double-Loop Computer Network (DDLCN) in particular. MIKE, which stands for Multicomputer Integrator KErnel, provides system-transparent operation for users and maintains cooperative autonomy among local hosts.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236459","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703031","Computer networks;distributed computing systems;interprocess communication;network operating systems;network protocols;protection;resource sharing;synchronization","Network operating systems;Computer networks;Protocols;Resource management;Kernel;Protection;Distributed computing;Information science;Read-write memory;Message passing","","Computer networks;distributed computing systems;interprocess communication;network operating systems;network protocols;protection;resource sharing;synchronization","","16","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Guest editors' prologue special issue on software design methods","G. D. Bergland; P. Zave","Department of Digital Systems Research in Murray Hill, NJ; SIGSOFT and ACM Computing Surveys","IEEE Transactions on Software Engineering","","1986","SE-12","2","185","191","We describe why these papers were chosen, and categorize them in terms of major contribution, underlying model of the software life-cycle, and applicability to various types of system.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312934","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312934","","Object oriented modeling;Documentation;Software engineering;Software design;Tutorials;Computers","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"Clarifying some fundamental concepts in software testing","A. S. Parrish; S. H. Zweben","Dept. of Comput. Sci., Alabama Univ., Tuscaloosa, AL, USA; NA","IEEE Transactions on Software Engineering","","1993","19","7","742","746","A software test data adequacy criterion is a means for determining whether a test set is sufficient, or adequate, for testing a given program. A set of properties that useful adequacy criteria should satisfy have been previously proposed (E. Weyuker, 1986; 1988). The authors identify some additional properties of useful adequacy criteria that are appropriate under certain realistic models of testing. They discuss modifications to the formal definitions of certain popular adequacy criteria to make the criteria consistent with these additional properties.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.238573","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=238573","","Software testing;System testing;Computer science;Information science;Performance analysis","formal verification;program testing","software testing;software test data adequacy criterion;test set;useful adequacy criteria;realistic models;formal definitions","","10","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Specifying Software Requirements for Complex Systems: New Techniques and Their Application","K. L. Heninger","Naval Research Laboratory","IEEE Transactions on Software Engineering","","1980","SE-6","1","2","13","This paper concerns new techniques for making requirements specifications precise, concise, unambiguous, and easy to check for completeness and consistency. The techniques are well-suited for complex real-time software systems; they were developed to document the requirements of existing flight software for the Navy's A-7 aircraft. The paper outlines the information that belongs in a requirements document and discusses the objectives behind the techniques. Each technique is described and illustrated with examples from the A-7 document. The purpose of the paper is to introduce the A-7 document as a model of a disciplined approach to requirements specification; the document is available to anyone who wishes to see a fully worked-out example of the approach.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230208","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702689","Documentation techniques;functional specifications;real-time software;requirements;requirements definition;software requirements;specifications","Application software;Documentation;Real time systems;Software systems;Military aircraft;Software maintenance;Software engineering;Formal specifications;Laboratories;Weapons","","Documentation techniques;functional specifications;real-time software;requirements;requirements definition;software requirements;specifications","","232","","22","","","","","","IEEE","IEEE Journals & Magazines"
"ADI: Automatic Derivation of Invariants","M. Tamir","Department of Applied Mathematics, Weizmann Institute of Science","IEEE Transactions on Software Engineering","","1980","SE-6","1","40","48","Most current systems for mechanical program verification are not fully automatic, since the user himself must provide the intermediate inductive assertions. This paper describes an interactive computer program, called ADI, which automatically generates the needed inductive assertions. ADI is also able to extend partial loop assertions supplied by the user to form complete assertions. The implementation (written in QLISP and INTERLISP) is based on both the algorithmic and the heuristic approaches introduced by Katz and Manna in ""Logical Analysis of Programs"" [25]. For the algorithmic subsystem ADI includes: Difference Equations Constructor, Difference Equations Solver, and Invariants from Conditional Statements Generator. The heuristic subsystem includes: Exit Rules Package, Bounding Variables Component, Strengthening Executer, Weakening Executer, and a Heuristic Invariant Matcher-which is the actual implementation of two new heuristics, MATCHPQ and MATCHPT. ADI is a small step toward interactive, practical program verification.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230461","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702693","Assertions;invariants;partial correctness;program verification;QLISP;synthesis of invariants","Difference equations;Packaging;Counting circuits;Testing;Heuristic algorithms;Algorithm design and analysis;Flowcharts;Input variables;Mathematics;Data mining","","Assertions;invariants;partial correctness;program verification;QLISP;synthesis of invariants","","5","","40","","","","","","IEEE","IEEE Journals & Magazines"
"The Refinement Paradigm: The Interaction of Coding and Efficiency Knowledge in Program Synthesis","E. Kant; D. R. Barstow","Department of Computer Science, Carnegie-Mellon University; NA","IEEE Transactions on Software Engineering","","1981","SE-7","5","458","471","A refinement paradigm for implementing a high-level specification in a low-level target language is discussed. In this paradigm, coding and analysis knowledge work together to produce an efficient program in the target language. Since there are many possible implementations for a given specification of a program, searching knowledge is applied to increase the efficiency of the process of finding a good implementation. For example, analysis knowledge is applied to determine upper and lower cost bounds on alternate implementations, and these bounds are used to measure the potential impact of different design decisions and to decide which alternatives should be pursued. In this paper we also describe a particular implementation of this program synthesis paradigm, called PSI/SYN, that has automatically implemented a number of programs in the domain of symbolic processing.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230854","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702872","Automatic programming;program development;program efficiency;program synthesis;refinement paradigm;stepwise refinement","Costs;High level languages;Specification languages;Optimizing compilers;History;Artificial intelligence;Laboratories;Control systems;Computer science;Programming profession","","Automatic programming;program development;program efficiency;program synthesis;refinement paradigm;stepwise refinement","","19","","32","","","","","","IEEE","IEEE Journals & Magazines"
"Methodology for Business System Development","R. N. Mathur","Computer Sciences Corporation","IEEE Transactions on Software Engineering","","1987","SE-13","5","593","601","The methodology presented here is currently being used in the design of Standard Automated Financial System (STAFS), which is a large scale business system for use by the 14 Naval Laboratories across the nation. The system will be operational in 1987-1988 time-frame. The methodology presented is suitable for all transaction oriented systems. It enforces documentation of design at all levels of system development process allowing managers and users a high visibility into the design. It highlights the human engineering aspects of system design and utilizes thread definition, data designer, and structured design techniques. The methodology requires the use of system verification diagrams which specify the user requirements. The design produces an integrated database with security mechanisms to restrict unauthorized users from accessing data they are not authorized to use. The threads also serve as a useful tool for system testing.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233464","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702259","Decomposition;design;methodology;structured design;testing;threads;transaction","Transaction databases;System analysis and design;Documentation;Design methodology;Large-scale systems;Laboratories;Ergonomics;Data security;System testing","","Decomposition;design;methodology;structured design;testing;threads;transaction","","3","","2","","","","","","IEEE","IEEE Journals & Magazines"
"System Structure Analysis: Clustering with Data Bindings","D. H. Hutchens; V. R. Basili","Department of Computer Science, Clemson University; NA","IEEE Transactions on Software Engineering","","1985","SE-11","8","749","757","This paper examines the use of cluster analysis as a tool for system modularization. Several clustering techniques are discussed and used on two medium-size systems and a group of small projects. The small projects are presented because they provide examples (that will fit into a paper) of certain types of phenomena. Data bindings between the routines of the system provide the basis for the bindings. It appears that the clustering of data bindings provides a meaningful view of system modularization.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232524","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702084","Cluster;coupling;data binding;module;measurement;system structure","Data analysis;Computer science;Documentation;Military computing;Proposals;Computerized monitoring;Fluid flow measurement;Stability analysis","","Cluster;coupling;data binding;module;measurement;system structure","","160","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Requirements development in scenario-based design","J. M. Carroll; M. B. Rosson; G. Chin; J. Koenemann","Dept. of Comput. Sci., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","12","1156","1170","We describe and analyze the process of requirements development in scenario based design through consideration of a case study. In our project, a group of teachers and system developers initially set out to create a virtual physics laboratory. Our design work centered on the collaborative development of a series of scenarios describing current and future classroom activities. We observed classroom scenarios to assess needs and opportunities, and envisioned future scenarios to specify and analyze possible design moves. We employed claims analysis to evaluate design trade-offs implicit in these scenarios, to codify the specific advantages and disadvantages in achieving requirements. Through the course of this process, the nature of our project requirements has evolved, providing more information but also more kinds of information. We discuss the utility of managing requirements development through an evolving set of scenarios, and the generality of the scenario stages from this case study.","0098-5589;1939-3520;2326-3881","","10.1109/32.738344","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=738344","","Collaborative work;Physics;Laboratories;Design engineering;Writing;Humans;Vocabulary;Computer science","formal specification;systems analysis;physics computing;courseware;virtual reality;user interfaces","requirements development;scenario based design;case study;teachers;system developers;virtual physics laboratory;collaborative development;future classroom activities;classroom scenarios;future scenarios;claims analysis;design trade-offs;project requirements;evolving set;scenario stages","","42","","42","","","","","","IEEE","IEEE Journals & Magazines"
"Distributed database management model and validation","M. Tsuchiya; M. P. Mariani; J. D. Brom","TRW Defense Systems Group, Redondo Beach, CA 90278; TRW Defense Systems Group, Colorado Springs, CO 80916; TRW Defense Systems Group, Colorado Springs, CO 80916","IEEE Transactions on Software Engineering","","1986","SE-12","4","511","520","The authors describe a simple, yet effective, distributed database model that simulates database usage and buffer management in the distributed data processing environment. The model is table driven such that database access requirements, file location, and other information defining the database environment are set up internally in several tables, and linked lists represent the directory and data blocks. Each database transaction is defined and represented by a transaction flow diagram (TFD), and a sequence of TFDs representing an operational scenario is input to the model. The model `executes' input TFDs by looking up tables, and performs buffer management for directory and file data while logging history and gathering various statistics on database usage and buffer management. The performance data are used for database access overhead measurement, database workload characterization, and buffer allocation. Disk access frequency and response time are used to validate the simulation results.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312898","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312898","Buffer management;directory;disk access;distributed database management;performance;transaction flow diagram","Distributed databases;Data models;Space vehicles;Analytical models;Aerospace electronics;Time factors","database management systems;database theory;distributed processing","validation;distributed database model;database usage;buffer management;database access requirements;file location;database transaction;transaction flow diagram;database access overhead measurement;workload characterization;buffer allocation","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"The evolution support environment system","C. V. Ramamoorthy; Y. Usuda; A. Prakash; W. T. Tsai","Dept. of Electr. Eng. & Comput. Sci., California Univ., Berkeley, CA, USA; Dept. of Electr. Eng. & Comput. Sci., California Univ., Berkeley, CA, USA; Dept. of Electr. Eng. & Comput. Sci., California Univ., Berkeley, CA, USA; Dept. of Electr. Eng. & Comput. Sci., California Univ., Berkeley, CA, USA","IEEE Transactions on Software Engineering","","1990","16","11","1225","1234","The evolution support environment (ESE) system, which provides a framework for capturing and making available semantic information about software components of an evolving software system, is described. The goal in the design of the ESE system was to provide integrated support for management of software architecture configuration, life-cycle configuration, and version control. Software architecture configuration management allows tracking of interconnections among software components that make up a system. Life-cycle management allows traceability among specifications, design, code, and test cases during software development. Adding version control allows specific versions of software objects and their associated objects, such as specifications and test cases, to be retrieved. The authors' experience with the use of the system is discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.60311","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=60311","","Software systems;Software testing;Software maintenance;Life testing;Software architecture;Control systems;Software development management;Environmental management;Programming environments;Computer bugs","programming environments","evolution support environment system;semantic information;software components;evolving software system;ESE system;integrated support;management;software architecture configuration;life-cycle configuration;version control;interconnections;traceability;specifications;design;code;test cases;software development;software objects","","13","","44","","","","","","IEEE","IEEE Journals & Magazines"
"Type Transformations","D. S. Wile","Information Sciences Institute, University of Southern California","IEEE Transactions on Software Engineering","","1981","SE-7","1","32","39","Current work on data structure encapsulation and abstraction focuses attention on individual structures and permits separate local optimizations, of these structures. We extend this work by developing the beginnings of an algebra for aggregating individual data types into larger more coordinated structures which can be more effectively optimized. The present work can well be viewed as the data equivalent of cross-procedural optimization. We believe aggregations of pure abstract types are both common and essential in practical programs and that techniques for building and manipulating them must be developed before abstract specification and program transformation can become a practical programming paradigm.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230817","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702800","Abstract data types;optimization strategy;program optimization;program specification;program transformation","Computer languages;Data structures;Programming profession;Encapsulation;Algebra;Buildings;Interference;Marine technology;Aggregates;Specification languages","","Abstract data types;optimization strategy;program optimization;program specification;program transformation","","1","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Computing bounds for the performance indices of quasi-lumpable stochastic well-formed nets","G. Franceschinis; R. R. Muntz","Dept. of Comput. Sci., California Univ., Los Angeles, CA, USA; Dept. of Comput. Sci., California Univ., Los Angeles, CA, USA","IEEE Transactions on Software Engineering","","1994","20","7","516","525","Structural symmetries in stochastic well-formed colored Petri nets (SWN's) lead to behavioral symmetries that can be exploited by using the symbolic reachability graph (SRG) construction algorithm. The SRC allows one to compute an aggregated reachability graph (RG) and a ""lumped"" continuous time Markov chain (CTMC) that contain all the information needed to study the qualitative properties and the performance of the modeled system, respectively. Some models exhibit qualitative behavioral symmetries that are not completely reflected at the CTMC level. We call them quasi-lumpable SWN models. In these cases, exact performance indices can be obtained by avoiding the aggregation of those markings that are qualitatively, but not quantitatively, equivalent. An alternative approach consists of aggregating all the qualitatively equivalent states and computing approximated performance indices. In this paper, a technique is proposed to compute bounds on the performance of SWN models of this kind, using the results we have presented elsewhere. The technique is based on the Courtois and Semal bounded aggregation method.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.297940","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=297940","","Stochastic processes;Performance analysis;Petri nets;Stochastic systems;Computer science;Roentgenium;Parametric statistics;Computational efficiency;Timing","Petri nets;stochastic processes;Markov processes;performance evaluation","performance indices;quasilumpable stochastic well-formed Nets;stochastic well-formed colored Petri nets;symbolic reachability graph;aggregated reachability graph;continuous time Markov chain;qualitative properties;quasilumpable SWN models;approximated performance indices;SWN models;bounded aggregation method","","7","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Scalar memory references in pipelined multiprocessors: a performance study","R. Ganesan; S. Weiss","Bell Atlantic, Beltsville, MD, USA; NA","IEEE Transactions on Software Engineering","","1992","18","1","78","86","Interleaved memories are essential in pipelined computers to attain high memory bandwidth. As a memory bank is accessed, a reservation is placed on the bank for the duration of the memory cycle, which is often considerably longer than the processor cycle time. This additional parameter, namely, the bank reservation time or the bank busy time, adds to the complexity of the memory model. For Markov models, exact solutions are not feasible even without this additional parameter due to the very large state space of the Markov chain. The authors develop a Markov model which explicitly tracks the bank reservation time. Because only one processor and the requested bank are modeled, the transition probabilities are not known and have to be approximated. The performance predicted by the model is in close agreement with simulation results.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.120318","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=120318","","Bandwidth;Predictive models;Computational modeling;State-space methods;Supercomputers;Performance analysis;Costs;Stochastic processes;Computer science;Vector processors","Markov processes;parallel machines;performance evaluation;pipeline processing;probability;storage management","scalar memory references;pipelined multiprocessors;pipelined computers;high memory bandwidth;memory bank;memory cycle;processor cycle time;bank reservation time;bank busy time;Markov models;state space;Markov chain;transition probabilities;simulation results","","","","29","","","","","","IEEE","IEEE Journals & Magazines"
"The dynamics of software project staffing: a system dynamics based simulation approach","T. K. Abdel-Hamid","Dept. of Adm. Sci., US Naval Postgraduate Sch., Monterey, CA, USA","IEEE Transactions on Software Engineering","","1989","15","2","109","119","The author focuses on the dynamics of software project staffing throughout the software-development lifecycle. The research vehicle is a comprehensive system-dynamics model of the software-development process. A detailed discussion of the model's structure as well as its behavior is provided. The results of a case study in which the model is used to simulate the staffing practices of an actual software project are then presented. The experiment produces some interesting insights into the policies (both explicit and implicit) for managing the human resource, and their impact on project behavior. The decision-support capability of the model to answer what-if questions is also demonstrated. In particular, the model is used to test the degree of interchangeability of men and months on the particular software project.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21738","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21738","","Vehicle dynamics;Project management;Programming;Human resource management;Art;Personnel;Costs;Vehicles;Software testing;Software engineering","DP management;personnel;software engineering","software project staffing;system dynamics;simulation approach;software-development lifecycle;research vehicle;software-development process;software project;human resource;decision-support;what-if questions","","83","","38","","","","","","IEEE","IEEE Journals & Magazines"
"A Bayesian analysis of the logarithmic-Poisson execution time model based on expert opinion and failure data","S. Campodonico; N. D. Singpurwalla","Res. and Test Dept., Assoc. of American Railroads, Washington, DC, USA; NA","IEEE Transactions on Software Engineering","","1994","20","9","677","683","We propose a Bayesian approach for predicting the number of failures in a piece of software, using the logarithmic-Poisson model, a nonhomogeneous Poisson process (NHPP) commonly used for describing software failures. A similar approach can be applied to other forms of the NHPP. The key feature of the approach is that now we are able to use, in a formal manner, expert knowledge on software testing, as for example, published information on the empirical experiences of other researchers. This is accomplished by treating such information as expert opinion in the construction of a likelihood function which leads us to a joint distribution. The procedure is computationally intensive, but for the case of the logarithmic-Poisson model has been codified for use on a personal computer. We illustrate the working of the approach via some real live data on software testing. The aim is not to propose another model for software reliability assessment. Rather, we present a methodology that can be invoked with existing software reliability models.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.317426","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=317426","","Bayesian methods;Failure analysis;Software reliability;Predictive models;Software testing;Statistics;Microcomputers;Stochastic processes;Relays","software quality;software reliability;program testing;Bayes methods;maximum likelihood estimation","Bayesian analysis;logarithmic-Poisson execution time model;expert opinion;failure data;failure prediction;nonhomogeneous Poisson process;NHPP;software failures;expert knowledge;software testing;empirical experiences;likelihood function;joint distribution;personal computer;software reliability assessment;software reliability models","","21","","18","","","","","","IEEE","IEEE Journals & Magazines"
"The Common Ada Programming Support Environment (APSE) Interface Set (CAIS)","P. A. Oberndorf","US Naval Ocean Syst. Center, San Diego, CA, USA","IEEE Transactions on Software Engineering","","1988","14","6","742","748","The Common APSE Interface Set (CAIS) is discussed, along with its relationship to issues in the development of environments. The CAIS concepts and features are described, followed by a discussion of several ways in which the CAIS provides valuable capabilities for environment architectures and construction.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6154","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6154","","Computer aided instruction;Operating systems;Software tools;Government;Computer architecture;Software engineering;Kernel;Packaging;Defense industry","Ada;operating systems (computers);programming environments;software portability;software tools","operating system interfaces;software portability;Ada Programming Support Environment;Common APSE Interface Set;CAIS","","15","","7","","","","","","IEEE","IEEE Journals & Magazines"
"A development environment for complex distributed real-time applications","A. D. Stoyen; T. J. Marlowe; M. F. Younis; P. V. Petrov","Dept. of Comput. Sci., Nebraska Univ., Omaha, NE, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1999","25","1","50","74","Engineering of complex distributed real-time applications is one of the hardest tasks faced by the software profession today. All aspects of the process, from design to implementation, are made more difficult by the interaction of behavioral and platform constraints. Providing tools for this task is likewise not without major challenges. In this paper, we discuss a tool suite which supports the development of complex distributed real-time applications in a suitable high-level language (CRL). The suite's component tools include a compiler, a transformer-optimizer, an allocator-migrator, a schedulability analyzer, a debugger-monitor, a kernel, and a (simulated) network manager. The overall engineering approach supported by the suite is to provide as simple and natural an integrated development paradigm as possible. The suite tools address complexity due to distribution, scheduling, allocation and other sources in an integrated manner (largely) transparent to the developer. To reflect the needs of propagation of functional and nonfunctional requirements throughout the development process, a number of robust code transformation and communication mechanisms have been incorporated into the suite. To facilitate practical use of the suite, the developed programs compile-transform to a safe subset of C++ with appropriate libraries and runtime support. (In this safe subset (C++) the use of pointers is minimized. Aliases are not allowed.","0098-5589;1939-3520;2326-3881","","10.1109/32.748918","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=748918","","Real time systems;Application software;Runtime;Kernel;Resource management;Processor scheduling;Computer languages;Computer science;Computer Society;Process design","real-time systems;processor scheduling;software libraries;resource allocation;software tools;program compilers;distributed programming;program debugging;programming environments;object-oriented programming","complex distributed real-time application engineering;development environment;platform constraints;behavioral constraints;tool suite;high-level language;CRL;compiler;transformer optimizer;allocator migrator;schedulability analyzer;debugger monitor;kernel;network manager;integrated development paradigm;complexity;distribution;scheduling;allocation;functional requirements;nonfunctional requirements;robust code transformation mechanisms;robust code communication mechanisms;C++;libraries;runtime support","","1","","67","","","","","","IEEE","IEEE Journals & Magazines"
"Efficient database access from Prolog","S. Ceri; G. Gottlob; G. Wiederhold","Dept. of Math., Modena Univ., Italy; NA; NA","IEEE Transactions on Software Engineering","","1989","15","2","153","164","In designing the interface between a relational database and a Prolog interpreter, efficiency is a major issue. The authors present a method for loading into the memory-resident database of Prolog facts permanently stored in secondary storage. The rationale of the method is to save access to the database by never repeating the same query and by storing in main memory, in a compact and efficient way, information about the past interaction with the database. The authors discuss how to reduce subsumption rests required by the method to pattern matching in many relevant cases. They also describe a simulator of the method, which validates their approach, and they discuss the results of the simulation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21742","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21742","","Relational databases;Information retrieval;Pattern matching;Database systems;Transaction databases;Testing;Technology management;Database languages;Stress;Computer industry","logic programming;program interpreters;relational databases","Prolog;relational database;Prolog interpreter;memory-resident database;Prolog facts;secondary storage;subsumption rests;pattern matching","","16","","34","","","","","","IEEE","IEEE Journals & Magazines"
"Software Engineering Project Standards","M. Branstad; P. B. Powell","Institute for Computer Sciences and Technology, National Bureau of Standards, Washington, DC 20234.; Institute for Computer Sciences and Technology, National Bureau of Standards, Washington, DC 20234.","IEEE Transactions on Software Engineering","","1984","SE-10","1","73","78","Software Engineering Project Standards (SEPS) and their importance are presented in this paper by looking at standards in general, then progressively narrowing the view to software standards, to software engineering standards, and finally to SEPS. After defining SEPS, issues associated with the selection, support, and use of SEPS are examined and trends are discussed. A brief overview of existing software engineering standards is presented as the Appendix.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010201","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010201","Project management;software development;software engineering;software engineering standards;software management;software standards","Software engineering;Software standards;Measurement standards;Standards development;Software development management;Engineering management;Programming;ANSI standards;Code standards;Software measurement","","","","7","","32","","","","","","IEEE","IEEE Journals & Magazines"
"Representing and using nonfunctional requirements: a process-oriented approach","J. Mylopoulos; L. Chung; B. Nixon","Dept. of Comput. Sci., Toronto Univ., Ont., Canada; Dept. of Comput. Sci., Toronto Univ., Ont., Canada; Dept. of Comput. Sci., Toronto Univ., Ont., Canada","IEEE Transactions on Software Engineering","","1992","18","6","483","497","A comprehensive framework for representing and using nonfunctional requirements during the development process is proposed. The framework consists of five basic components which provide the representation of nonfunctional requirements in terms of interrelated goals. Such goals can be refined through refinement methods and can be evaluated in order to determine the degree to which a set of nonfunctional requirements is supported by a particular design. Evidence for the power of the framework is provided through the study of accuracy and performance requirements for information systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.142871","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=142871","","Software quality;Information systems;Software systems;Programming;Software engineering;Software measurement;Cost function;Power system reliability;Maintenance","formal specification;management information systems","nonfunctional requirements;process-oriented approach;development process;refinement methods;performance requirements;information systems","","391","","46","","","","","","IEEE","IEEE Journals & Magazines"
"Statistical foundations of audit trail analysis for the detection of computer misuse","P. Helman; G. Liepins","Dept. of Comput. Sci., New Mexico Univ., Albuquerque, NM, USA; NA","IEEE Transactions on Software Engineering","","1993","19","9","886","901","We model computer transactions as generated by two stationary stochastic processes, the legitimate (normal) process N and the misuse process M. We define misuse (anomaly) detection to be the identification of transactions most likely to have been generated by M. We formally demonstrate that the accuracy of misuse detectors is bounded by a function of the difference of the densities of the processes N and M over the space of transactions. In practice, detection accuracy can be far below this bound, and generally improves with increasing sample size of historical (training) data. Careful selection of transaction attributes also can improve detection accuracy; we suggest several criteria for attribute selection, including adequate sampling rate and separation between models. We demonstrate that exactly optimizing even the simplest of these criteria is NP-hard, thus motivating a heuristic approach. We further differentiate between modeling (density estimation) and nonmodeling approaches.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.241771","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=241771","","Monitoring;Laboratories;System testing;Intrusion detection;Physics computing;Computer science;Stochastic processes;Detectors;Space stations;Sampling methods","auditing;computer crime;security of data;stochastic processes;transaction processing","audit trail analysis;computer misuse;computer transactions;stationary stochastic processes;misuse detectors;detection accuracy;transaction attributes;NP-hard;heuristic approach;density estimation;modeling;statistical foundations;system security","","55","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Improving speed and productivity of software development: a global survey of software developers","J. D. Blackburn; G. D. Scudder; L. N. Van Wassenhove","Owen Graduate Sch. of Manage., Vanderbilt Univ., Nashville, TN, USA; NA; NA","IEEE Transactions on Software Engineering","","1996","22","12","875","885","Time is an essential measure of performance in software development because time delays tend to fall directly to the bottom line. To address this issue, this research seeks to distinguish time-based software development practices: those managerial actions that result in faster development speed and higher productivity. This study is based upon a survey of software management practices in Western Europe and builds upon an earlier study we carried out in the United States and Japan (Integrated Manufacturing Systems, vol. 7, no. 2, 1996). We measure the extent to which managers in the USA, Japan and Europe differ in their management of software projects and also determine the tools, technology and practices that separate fast and slow developers in Western Europe.","0098-5589;1939-3520;2326-3881","","10.1109/32.553636","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=553636","","Productivity;Programming;Software development management;Europe;Software measurement;Project management;Technology management;Time measurement;Delay effects;Research and development management","software engineering;software development management;delays;human resource management;project management","software development speed;software development productivity;global survey;software developers;performance measurement;time delays;time-based software development practices;managerial actions;Western Europe;USA;Japan;software project management;software engineering;global performance comparisons;empirical research","","69","","18","","","","","","IEEE","IEEE Journals & Magazines"
"A hierarchical knowledge based system for airplane classification","D. I. Moldovan; C. -. Wu","Dept. of Electr. Eng.-Syst., Univ. of Southern California, Los Angeles, CA, USA; NA","IEEE Transactions on Software Engineering","","1988","14","12","1829","1834","Airplane classification is used as an application domain to illustrate how hierarchical reasoning on large knowledge bases can be implemented. The knowledge base is organized as a two-dimensional hierarchy: one dimension corresponds to the levels of complexity often seen in computer vision, and the other dimension corresponds to the complexity of hypothesis used in the reasoning process. Reasoning proceeds top-down, from more abstract levels with fewer details toward levels with more details. Whenever possible, with the help of domain knowledge, decision is taken at a higher level, which significantly reduces processing time. A software package called RuBICS (Rule-Based Image Classification System) is described, and some examples of airplane classification are shown.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9066","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9066","","Knowledge based systems;Airplanes;Military aircraft;Air traffic control;Shape;Computer vision;Software packages;Image classification;Control system synthesis;Image recognition","aerospace computing;aircraft;computer vision;knowledge based systems;knowledge engineering","hierarchical knowledge based system;airplane classification;hierarchical reasoning;complexity;computer vision;reasoning process;RuBICS;Rule-Based Image Classification System","","5","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Response-time bounds of EQL rule-based programs under rule priority structure","Rwo-Hsi Wang; A. K. Mok","Dept. of Comput. Sci., Texas Univ., Austin, TX, USA; Dept. of Comput. Sci., Texas Univ., Austin, TX, USA","IEEE Transactions on Software Engineering","","1995","21","7","605","614","A key index of the performance of a rule based program used in real time monitoring and control is its response time, defined by the longest program execution time before a fixed point of the program is reached from a start state. Previous work in computing the response time bounds for rule based programs effectively assumes that all rules take the same amount of firing time. It is also assumed that if two rules are enabled, then either one of them may be scheduled first for firing. These assumptions can result in loose bounds, especially in the case programmers choose to impose a priority structure on the set of rules. We remove the uniform firing cost assumption and discuss how to get tighter bounds by taking rule priority information into account. We show that the rule suppression relation we previously introduced can be extended to incorporate rule priority information. A bound derivation algorithm for programs whose potential trigger relations satisfy an acyclicity condition is presented, followed by its correctness proof and an analysis example.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.392981","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=392981","","Delay;Monitoring;Algorithm design and analysis;Processor scheduling;Knowledge based systems;Timing;Time factors;Artificial intelligence;Equations;State-space methods","knowledge based systems;logic programming;real-time systems;software performance evaluation;program verification;decision support systems","response-time bounds;EQL rule based programs;EQL rule-based programs;rule priority structure;rule based program;real time monitoring;program execution time;response time bounds;priority structure;uniform firing cost assumption;rule priority information;rule suppression relation;bound derivation algorithm;potential trigger relations;acyclicity condition;correctness proof;real time decision systems;timing analysis;priority;equational rule based program","","2","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Enhancing the Security of Statistical Databases with a Question-Answering System and a Kernel Design","G. Ozsoyoglu; F. Y. Chin","Department of Computer and Information Science, Cleveland State University; NA","IEEE Transactions on Software Engineering","","1982","SE-8","3","223","234","The security problem of a statistical database is to limit database use so that no private information is deducible. This paper discusses the advantages of using a Question-Answering System and a security kernel to enhance the security constraints at the conceptual model level. An SDB design with the goal of helping the DBA in specifying certain security contraints is proposed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235252","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702939","Conceptual models;inference control;Question-Answering System;security;security kernel;statistical databases","Data security;Databases;Kernel;Protection;Information security;Control system synthesis;Inference mechanisms;Size control;Councils;Information science","","Conceptual models;inference control;Question-Answering System;security;security kernel;statistical databases","","2","","45","","","","","","IEEE","IEEE Journals & Magazines"
"A specificational approach to high level program monitoring and measuring","Y. Liao; D. Cohen","NEC Systems Lab., Princeton, NJ, USA; NA","IEEE Transactions on Software Engineering","","1992","18","11","969","978","Program monitoring and measuring is the activity of collecting information about the execution characteristics of a program. Although this activity is occasionally supported by special-purpose hardware, it is normally done by adding instrumentation code to the program so that it collects interesting data as it runs. Unfortunately, this alteration is itself a difficult task involving all the complexities of programming. Given some questions to be answered, the programmer must determine what data must be collected, determine where in the program those data can be collected, and add code to the program to collect that data and to process it to produce the desired results. The goal of the work described is to automate the process. A high-level program monitoring and measuring system is presented. The system provides a high-level specification language to let programmers specify what they want to know about their program's execution. It automatically generates an augmented program whose execution produces both the results of the original program and answers to the specified questions.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.177366","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=177366","","Monitoring;Instruments;Programming profession;Costs;Hardware;Specification languages;Debugging;Animation;Current measurement;Time measurement","automatic programming;formal specification;software metrics;specification languages;system monitoring","program measurement;specificational approach;high level program monitoring;execution characteristics;special-purpose hardware;instrumentation code;complexities;high-level specification language;augmented program","","15","","21","","","","","","IEEE","IEEE Journals & Magazines"
"A Markov chain model for statistical software testing","J. A. Whittaker; M. G. Thomason","Software Eng. Technol. Inc., Knoxville, TN, USA; NA","IEEE Transactions on Software Engineering","","1994","20","10","812","824","Statistical testing of software establishes a basis for statistical inference about a software system's expected field quality. This paper describes a method for statistical testing based on a Markov chain model of software usage. The significance of the Markov chain is twofold. First, it allows test input sequences to be generated from multiple probability distributions, making it more general than many existing techniques. Analytical results associated with Markov chains facilitate informative analysis of the sequences before they are generated, indicating how the test is likely to unfold. Second, the test input sequences generated from the chain and applied to the software are themselves a stochastic model and are used to create a second Markov chain to encapsulate the history of the test, including any observed failure information. The influence of the failures is assessed through analytical computations on this chain. We also derive a stopping criterion for the testing process based on a comparison of the sequence generating properties of the two chains.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.328991","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=328991","","Software testing;Statistical analysis;History;Probability distribution;Software quality;Failure analysis;Software systems;Stochastic processes;Performance evaluation","Markov processes;program testing;software quality;probability","Markov chain model;statistical software testing;statistical inference;software field quality;software usage;test input sequences;multiple probability distributions;stochastic model;software failures;testing process;sequence generating properties","","225","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Improving the reliability of function point measurement: an empirical study","C. F. Kemerer; B. S. Porter","MIT, Cambridge, MA, USA; NA","IEEE Transactions on Software Engineering","","1992","18","11","1011","1024","One measure of the size and complexity of information systems that is growing in acceptance and adoption is function points, a user-oriented, nonsource line of code metric of the systems development product. Previous research has documented the degree of reliability of function points as a metric. This research extends that work by (a) identifying the major sources of variation through a survey of current practice, and (b) estimating the magnitude of the effect of these sources of variation using detailed case study data from commercial systems. The results of this research show that a relatively small number of factors has the greatest potential for affecting reliability, and recommendations are made for using these results to improve the reliability of function point counting in organizations.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.177370","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=177370","","Productivity;Software measurement;Management information systems;Size measurement;Programming;Software maintenance;Area measurement;Costs;Information systems;Application software","software metrics;software quality;software reliability","software complexity measures;reliability;function point measurement;size;complexity;information systems;user-oriented;nonsource line of code metric;systems development product;function point counting","","43","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Development of Veda, a prototyping tool for distributed algorithms","C. Jard; J. -. Monin; R. Groz","IRISA, CNRS, Rennes, France; NA; NA","IEEE Transactions on Software Engineering","","1988","14","3","339","352","The development of a simulator, called Veda, is described. Veda is a software tool to help designers in protocol modeling and validation. It is oriented towards the rapid prototyping of distributed algorithms. Algorithms are described using an ISO (International Organisation for Standardization) formal description technique, called Estelle. The development of Veda and its internal structure is presented, emphasizing the use of Prolog as a software engineering tool. Typical uses of Veda are discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4654","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4654","","Prototypes;Distributed algorithms;Protocols;Virtual prototyping;Software prototyping;Software tools;Software engineering;Costs;Software algorithms;Hardware","distributed processing;protocols;software tools","Veda;prototyping tool;distributed algorithms;simulator;software tool;ISO;International Organisation for Standardization;Estelle;Prolog","","29","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Test selection based on communicating nondeterministic finite-state machines using a generalized Wp-method","Gang Luo; G. von Bochmann; A. Petrenko","Dept. d'Inf. et de Recherche Oper., Montreal Univ., Que., Canada; Dept. d'Inf. et de Recherche Oper., Montreal Univ., Que., Canada; Dept. d'Inf. et de Recherche Oper., Montreal Univ., Que., Canada","IEEE Transactions on Software Engineering","","1994","20","2","149","162","Presents a method of generating test sequences for concurrent programs and communication protocols that are modeled as communicating nondeterministic finite-state machines (CNFSMs). A conformance relation, called trace-equivalence, is defined within this model, serving as a guide to test generation. A test generation method for a single nondeterministic finite-state machine (NFSM) is developed, which is an improved and generalized version of the Wp-method that generates test sequences only for deterministic finite-state machines. It is applicable to both nondeterministic and deterministic finite-state machines. When applied to deterministic finite-state machines, it yields usually smaller test suites with full fault coverage than the existing methods that also provide full fault coverage, provided that the number of states in implementation NFSMs are bounded by a known integer. For a system of CNFSMs, the test sequences are generated in the following manner: a system of CNFSMs is first reduced into a single NFSM by reachability analysis; then the test sequences are generated from the resulting NFSM using the generalized Wp-method.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.265636","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=265636","","Protocols;Software testing;System testing;Concurrent computing;Communication system software;Computer science;Senior members;Reachability analysis;Software engineering","program testing;multiprocessing programs;protocols;finite state machines;conformance testing;specification languages;software engineering;programming theory","test selection;communicating nondeterministic finite-state machines;generalized Wp-method;test sequence generation;concurrent programs;communication protocols;conformance relation;trace-equivalence;deterministic finite-state machines;test suites;fault coverage;reachability analysis;protocol conformance testing;protocol engineering;SDL;software engineering;software testing","","119","","42","","","","","","IEEE","IEEE Journals & Magazines"
"Recovery point selection on a reverse binary tree task model","S. -. Chen; W. T. Tsai; M. B. Thuraisingham","Dept. of Comput. Sci., California Univ., Los Angeles, CA, USA; NA; NA","IEEE Transactions on Software Engineering","","1989","15","8","963","976","An analysis is conducted of the complexity of placing recovery points where the computation is modeled as a reverse binary tree task model. The objective is to minimize the expected computation time of a program in the presence of faults. The method can be extended to an arbitrary reverse tree model. For uniprocessor systems, an optimal placement algorithm is proposed. For multiprocessor systems, a procedure for computing their performance is described. Since no closed form solution is available, an alternative measurement is proposed that has a closed form formula. On the basis of this formula, algorithms are devised for solving the recovery point placement problem. The estimated formula can be extended to include communication delays where the algorithm devised still applies.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.31353","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=31353","","Binary trees;Testing;Computational modeling;Delay estimation;Computer science;Multiprocessing systems;Closed-form solution;Sequential analysis;Fault detection","computational complexity;fault tolerant computing;multiprocessing systems;trees (mathematics)","performance computation procedure;computation time minimization;recovery point selection;reverse binary tree task model;arbitrary reverse tree model;uniprocessor systems;optimal placement algorithm;multiprocessor systems;closed form solution;closed form formula;recovery point placement problem;communication delays","","3","","27","","","","","","IEEE","IEEE Journals & Magazines"
"A survey of software design techniques","S. S. Yau; J. J. -. Tsai","Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL 60201; Department of Electrical Engineering and Computer Science, University of Illinois at Chicago, Chicago, IL 60680","IEEE Transactions on Software Engineering","","1986","SE-12","6","713","721","Software design is the process which translates requirements into a detailed design representation of a software system. It is argued that good software design is the key to reliable and understandable software. Important techniques for software design, including architectural and detailed design stages, are surveyed. Recent advances in distributed software system design methodologies are also reviewed. To ensure software quality, various design verification and validation techniques are discussed. In addition, current software metrics and error-resistant software design methodologies are considered. Future research in software design is considered.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312969","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312969","Design methodologies;design representation;design verification and validation;distributed software system design;error-resistant software design;software design technique;software metrics","Software systems;Software design;Design methodology;Programming;Data structures;Formal specifications","software engineering","software design techniques;design representation;software system;software design;design stages;distributed software system;design methodologies;current software metrics;error-resistant software design;software design","","23","","","","","","","","IEEE","IEEE Journals & Magazines"
"An approach to experimental evaluation of real-time fault-tolerant distributed computing schemes","K. H. Kim","Dept. of Electr. Eng., California Univ., Irvine, CA, USA","IEEE Transactions on Software Engineering","","1989","15","6","715","725","A test-based approach to the evaluation of fault-tolerant distributed-computing schemes is discussed. The approach is based on experimental incorporation of system structuring and design techniques into real-time distributed computing testbeds centered around tightly coupled microcomputer networks. The effectiveness of this approach has been experimentally confirmed. Primary advantages of the testbed-based approach include the relatively high accuracy of the data obtained on timing and logical complexity, as well as the relatively high degree of assurance that can be obtained on the practical effectiveness of the scheme evaluated. Various design issues encountered in the course of establishing the basic microcomputer network testbed facilities are discussed, along with their augmentation to support some experiments. The shortcomings of the testbeds that have been recognized are also discussed together with the desired extensions of the testbeds. Some of the desired extensions are beyond the state-of-the-art in microcomputer network implementation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24725","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24725","","Fault tolerance;Distributed computing;Microcomputers;System testing;Real time systems;Costs;Workstations;Laboratories;Logic testing;Timing","computer networks;fault tolerant computing;microcomputer applications;performance evaluation;program testing;real-time systems","experimental evaluation;real-time fault-tolerant distributed computing schemes;test-based approach;system structuring;design techniques;real-time distributed computing testbeds;tightly coupled microcomputer networks;timing;logical complexity;practical effectiveness;design issues;microcomputer network testbed facilities;microcomputer network implementation","","11","","22","","","","","","IEEE","IEEE Journals & Magazines"
"State transition analysis: a rule-based intrusion detection approach","K. Ilgun; R. A. Kemmerer; P. A. Porras","Adv. Comput. Commun., Santa Barbara, CA, USA; NA; NA","IEEE Transactions on Software Engineering","","1995","21","3","181","199","The paper presents a new approach to representing and detecting computer penetrations in real time. The approach, called state transition analysis, models penetrations as a series of state changes that lead from an initial secure state to a target compromised state. State transition diagrams, the graphical representation of penetrations, identify precisely the requirements for and the compromise of a penetration and present only the critical events that must occur for the successful completion of the penetration. State transition diagrams are written to correspond to the states of an actual computer system, and these diagrams form the basis of a rule based expert system for detecting penetrations, called the state transition analysis tool (STAT). The design and implementation of a Unix specific prototype of this expert system, called USTAT, is also presented. This prototype provides a further illustration of the overall design and functionality of this intrusion detection approach. Lastly, STAT is compared to the functionality of comparable intrusion detection tools.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.372146","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=372146","","Intrusion detection;Expert systems;Data analysis;Prototypes;Data security;Computer security;Software;Computer science;Information analysis;Research and development","safety systems;security of data;authorisation;access control;expert systems;real-time systems","state transition analysis;rule-based intrusion detection approach;computer penetrations;state changes;state transition diagrams;graphical representation;critical events;rule based expert system;STAT;Unix specific prototype;USTAT;intrusion detection tools","","288","","34","","","","","","IEEE","IEEE Journals & Magazines"
"A layout algorithm for data flow diagrams","C. Batini; E. Nardelli; R. Tamassia","Dipartimento di Informatica e Sistemistica, Universit&#x00E1; di Roma &#x201C;La Sapienza,&#x201D; Via Buonarroti 12, 00185 Rome, Italy; Dipartimento di Informatica e Sistemistica, Universit&#x00E1; di Roma &#x201C;La Sapienza,&#x201D; Via Buonarroti 12, 00185 Rome, Italy; Dipartimento di Informatica e Sistemistica, Universit&#x00E1; di Roma &#x201C;La Sapienza,&#x201D; Via Buonarroti 12, 00185 Rome, Italy","IEEE Transactions on Software Engineering","","1986","SE-12","4","538","546","A layout algorithm is presented that allows the automatic drawing of data flow diagrams, a diagrammatic representation widely used in the functional analysis of information systems. A grid standard is defined for such diagrams, and aesthetics for good readability are identified. The layout algorithm receives as input an abstract graph specifying connectivity relations between the elements of the diagram, and produces as output a corresponding diagram according to the aesthetics. The basic strategy is to build incrementally the layout; first, a good topology is constructed with few crossings between edges; subsequently, the shape of the diagram is determined in terms of angles appearing along edges. and finally dimensions are given to the graph, obtaining a grid skeleton for the diagram.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312901","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312901","Database design;design tools;functional analysis;layout algorithms","Layout;Standards;Algorithm design and analysis;Shape;Planarization;Skeleton;Minimization","flowcharting;software tools;systems analysis","layout algorithm;data flow diagrams;functional analysis;information systems;readability;abstract graph;connectivity relations;aesthetics;grid skeleton","","28","","","","","","","","IEEE","IEEE Journals & Magazines"
"Specifying and verifying requirements of real-time systems","A. P. Ravn; H. Rischel; K. M. Hansen","Dept. of Comput. Sci., Tech. Univ. of Denmark, Lyngby, Denmark; Dept. of Comput. Sci., Tech. Univ. of Denmark, Lyngby, Denmark; Dept. of Comput. Sci., Tech. Univ. of Denmark, Lyngby, Denmark","IEEE Transactions on Software Engineering","","1993","19","1","41","55","An approach to specification of requirements and verification of design for real-time systems is presented. A system is defined by a conventional mathematical model for a dynamic system where application specific states denote functions of real time. Specifications are formulas in duration calculus, a real-time interval logic, where predicates define durations of states. Requirements define safety and functionality constraints on the system or a component. A top-level design is given by a control law: a predicate that defines an automation controlling the transition between phases of operation. Each phase maintains certain relations among the system states; this is analogous to the control functions known from conventional control theory. The top-level design is decomposed into an architecture for a distributed system with specifications for sensor, actuator, and program components. Programs control the distributed computation through synchronous events. Sensors and actuators relate events with system states. Verification is a deduction showing that a design implies requirements.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.210306","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=210306","","Real time systems;Automatic control;Sensor systems;Actuators;Mathematical model;Calculus;Logic;Safety;Design automation;Control systems","formal specification;formal verification;real-time systems;temporal logic","real-time systems;specification of requirements;verification of design;mathematical model;duration calculus;real-time interval logic;top-level design;control law;sensor;actuator;distributed computation;synchronous events","","91","","48","","","","","","IEEE","IEEE Journals & Magazines"
"Abstract data views: an interface specification concept to enhance design for reuse","D. D. Cowan; C. J. P. Lucena","Dept. of Comput. Sci., Waterloo Univ., Ont., Canada; NA","IEEE Transactions on Software Engineering","","1995","21","3","229","243","The abstract data view (ADV) design model was originally created to specify clearly and formally the separation of the user interface from the application component of a software system, and to provide a systematic design method that is independent of specific application environments. Such a method should lead to a high degree of reuse of designs for both interface and application components. The material presented, extends the concept of ADV's to encompass the general specification of interfaces between application components in the same or different computing environments. This approach to specifying interfaces clearly separates application components from each other, since they do not need to know how they are used, or how they obtain services from other application components. Thus, application components called abstract data objects (ADOs), are designed to minimize knowledge of the environment in which they are used and should be more amenable to reuse.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.372150","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=372150","","User interfaces;Application software;Data structures;Design methodology;File systems;Counting circuits;Knowledge engineering;Computer science;Mechanical systems;Couplings","abstract data types;user interfaces;formal specification;software reusability;data structures","abstract data view;interface specification concept;design for reuse;ADV design model;user interface;systematic design method;specific application environments;application components;interactive applications;end user programming;script languages","","45","","69","","","","","","IEEE","IEEE Journals & Magazines"
"Implementing Fault-Tolerant Distributed Objects","K. P. Birman; T. A. Joseph; T. Raeuchle; A. El Abbadi","Department of Computer Science, Cornell University; NA; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","6","502","508","This paper describes a technique for implementing k-resilient objectsdistributed objects that remain available, and whose operations are guaranteed to progress to completion, despite up to k site failures. The implementation is derived from the object specification automatically, and does not require any information beyond what would be required for a nonresilient nondistributed implementation. It is therefore unnecessary for an applications programmer to have knowledge of the complex protocols nonnally employed to implement fault-tolerant objects. Our technique is used in ISIS, a system being developed at Cornell to support resilient objects.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232242","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702047","Abstract data types;availability;checkpoint/restart;concurrency;consistency;distributed databases;distributed systems;fault-tolerance;recovery;reliability","Fault tolerance;Protocols;Intersymbol interference;Fault tolerant systems;Programming profession;Availability;Concurrent computing;Distributed databases;Software systems;Computer science","","Abstract data types;availability;checkpoint/restart;concurrency;consistency;distributed databases;distributed systems;fault-tolerance;recovery;reliability","","49","","29","","","","","","IEEE","IEEE Journals & Magazines"
"A distributed deadlock detection and resolution algorithm and its correctness proof","A. K. Elmagarmid; N. Soundararajan; M. T. Liu","Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA; NA; NA","IEEE Transactions on Software Engineering","","1988","14","10","1443","1452","The key idea of the algorithm is to let one transaction controller be in charge of all transactions in a set of interacting transactions. Two transactions are interacting if they are both interested in (accessing) the same resource. In addition, the controller is in charge of all the resources allocated to any of the transactions in the set. Having one controller in charge of all the transactions in a set of interacting transactions and all the resources allocated to them makes it easier to detect deadlocks and avoid them. The main problem dealt with is how a controller takes charge of another transaction when the transaction tries to access one of the resources currently in the control of the controller and how a controller releases a transaction back to its original controller when the transaction is no longer interested in any of the resources in which one or more of the other transactions are also interested. Communicating sequential processes (CSP) is used to code the algorithm. The correctness of the algorithm is proved in a semiformal manner.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6189","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6189","","System recovery;Resource management;Radio control;Computer science;Information science;Control systems","distributed processing;program verification;programming theory;system recovery;transaction processing","transaction processing;communicating sequential processes;distributed deadlock detection;correctness proof;transaction controller","","11","","4","","","","","","IEEE","IEEE Journals & Magazines"
"Identification of dynamic comprehension processes during large scale maintenance","A. Von Mayrhauser; A. M. Vans","Dept. of Comput. Sci., Colorado State Univ., Fort Collins, CO, USA; Dept. of Comput. Sci., Colorado State Univ., Fort Collins, CO, USA","IEEE Transactions on Software Engineering","","1996","22","6","424","437","We present results of observing professional maintenance engineers working with industrial code at actual maintenance tasks. Protocol analysis is used to explore how code understanding might differ for small versus large scale code. The experiment confirms that cognition processes work at all levels of abstraction simultaneously as programmers build a mental model of the code. Analysis focused on dynamic properties and processes of code understanding. Cognition processes emerged at three levels of aggregation representing lower and higher level strategies of understanding. They show differences in what triggers them and how they achieve their goals. Results are useful for defining information which maintenance engineers need for their work and for documentation and development standards.","0098-5589;1939-3520;2326-3881","","10.1109/32.508315","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=508315","","Large-scale systems;Cognition;Protocols;Software maintenance;Programming profession;Switches;Maintenance engineering;Cognitive science;Documentation;Standards development","software maintenance;reverse engineering","dynamic comprehension processes;large scale maintenance;professional maintenance engineers;industrial code;protocol analysis;code understanding;cognition processes;abstraction;dynamic properties;aggregation","","74","","34","","","","","","IEEE","IEEE Journals & Magazines"
"A Distributed Algorithm for Constructing Minimal Spanning Trees","Y. K. Dalal","Metaphor Computer Systems","IEEE Transactions on Software Engineering","","1987","SE-13","3","398","405","Most algorithms for constructing minimal spanning trees are sequential in operation. Distributed algorithms for constructing these trees operate both concurrently and asynchronously, and are useful in store-and-forward packet-switching computer-communication networks where there is typically no single source of control. The difficulties in designing such algorithms arise from communication and synchronization problems. This paper discusses these problems and describes the first distributed algorithm for constructing minimal spanning trees. This algorithm and the principles and techniques underlying its design will find application in large communication networks and large multiprocessor computer systems.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233171","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702226","Broadcast routing;computer-communication networks;distributed algorithms;minimal spanning tree;protocols;store-and-forward packet-switching;synchronization","Distributed algorithms;Computer networks;Costs;Algorithm design and analysis;Delay estimation;Nearest neighbor searches;Distributed computing;Application software;Communication networks;Routing","","Broadcast routing;computer-communication networks;distributed algorithms;minimal spanning tree;protocols;store-and-forward packet-switching;synchronization","","12","","25","","","","","","IEEE","IEEE Journals & Magazines"
"A Heuristic for Deriving Loop Functions","D. D. Dunlop; V. R. Basili","Department of Computer Science, University of Maryland, College Park, MD 20742.; Intermetrics, Inc., 4733 Bethesda Avenue, Bethesda, MD 20814.; Department of Computer Science, University of Maryland, College Park, MD 20742.","IEEE Transactions on Software Engineering","","1984","SE-10","3","275","285","The problem of analyzing an initialized loop and verifying that the program computes some particular function of its inputs is addressed. A heuristic technique for solving these problems is proposed that appears to work well in many commonly occurring cases. The use of the technique is illustrated with a number of applications. An attribute of initialized loops is identified that corresponds to the ``effort'' required to apply this method in a deterministic (i.e., guaranteed to succeed) manner. It is explained that in any case, the success of the proposed heuristic relies on the loop exhibiting a ``reasonable'' form of behavior.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010236","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010236","Constraints;initialized loop programs;loop functions;program verification","Genetic expression;Programming profession;Data structures;Arithmetic","","","","13","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Randomized Byzantine Agreement","K. J. Perry","I. B. M. Thomas J. Watson Research Center","IEEE Transactions on Software Engineering","","1985","SE-11","6","539","546","A randomized model of distributed computation was recently presented by Rabin [ 81. This model admits a solution to the Byzantine Agreement Problem for systems of n asynchronous processes where no more than t are faulty. The algorithm described by Rabin produces agreement in an expected number of rounds which is a small constant independent of n and t. Using the same model, we present an algorithm of similar complexity which is able to tolerate a greater portion of malicious processes. The algorithm is also applicable, with minor changes, to systems of synchronous processes.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232246","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702051","Distributed computing;distributed database systems;fault-tolerance;protocols;reliability","Protocols;Computational modeling;Distributed computing;Indexes;Database systems;Fault tolerant systems;Computer science;Application software;Fault tolerance","","Distributed computing;distributed database systems;fault-tolerance;protocols;reliability","","5","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Prolog-based meta-rules for relational database representation and manipulation","T. Niemi; K. Jarvelin","Tampere Univ., Finland; Tampere Univ., Finland","IEEE Transactions on Software Engineering","","1991","17","8","762","788","A Prolog-based experimental system for relational databases that is not defined from the viewpoint of any specific relational topic is proposed. The idea is that the experimental system can be used in many different contexts such as query optimization, data restructuring and database design. The definition is based entirely on the theoretical foundations of the relational model. The experimental system offers a well-defined environment for studying how other systems can be integrated with relational databases. The use of the experimental system in the context of different approaches to deductive databases is considered.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.83913","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=83913","","Relational databases;Deductive databases;Knowledge representation;Database languages;Logic programming;Application software;Data models;Knowledge based systems;Environmental management;Design automation","database theory;deductive databases;knowledge based systems;PROLOG;relational databases","Prolog-based meta-rules;relational database representation;Prolog-based experimental system;query optimization;data restructuring;database design;theoretical foundations;well-defined environment;deductive databases","","2","","70","","","","","","IEEE","IEEE Journals & Magazines"
"A Unifying Approach to the Design of a Secure Database Operating System","D. L. Spooner; E. Gudes","Department of Mathematical Sciences, Rensselaer Polytechnic Institute, Troy, NY 12181.; Department of Mathematics and Computer Science, Ben-Gurion University, Beer-Sheva 84120, Israel.","IEEE Transactions on Software Engineering","","1984","SE-10","3","310","319","Database management systems (DBMS's) today are usually built as subsystems on top of an operating system (OS). This design approach can lead to problems of unreliability and inefficient performance as well as forcing a duplication of functions between the DBMS and OS. A new design approach is proposed which eliminates much of this duplication by integrating the duplicated functions into independent subsystems used by both the DBMS and OS. Specifically, an I/O and file support subsystem and a security subsystem are defined. Both subsystems make use of a logical information model which models the stored information in secondary storage. The new database operating system organization and the logical information model are presented in detail. Design of the security subsystem is based on the access control model, and is extended with Boolean predicates to produce an access control model capable of enforcing content-dependent security policies. The access matrix is implemented using a combination of access lists and capabilities. Authorization models and multiple user processes are discussed in relation to the new system organization. The outline of a formal specification and proof of correctness of the security subsystem is also discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010240","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010240","Authorization models;capabilities;database management/operating system interface;database management systems;data security;objects;operating systems","Operating systems;Data security;Information security;Object oriented databases;Access control;Computer security;Computer architecture;Cities and towns;Protection","","","","2","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Measuring process consistency: implications for reducing software defects","M. S. Krishnan; M. I. Kellner","Sch. of Bus., Michigan Univ., Ann Arbor, MI, USA; NA","IEEE Transactions on Software Engineering","","1999","25","6","800","815","In this paper, an empirical study that links software process consistency with product defects is reported. Various measurement issues such as validity, reliability, and other challenges in measuring process consistency at the project level are discussed. A measurement scale for software process consistency is introduced. An empirical study that uses this scale to measure consistency in achieving the CMM goal questions in various key process areas (KPAs) in 45 projects at a leading software vendor is reported. The results of this analysis indicate that consistent adoption of practices specified in the CMM is associated with a lower number of defects. Even a relatively modest improvement in the consistency of implementing these practices is associated with a significant reduction in field defects.","0098-5589;1939-3520;2326-3881","","10.1109/32.824401","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=824401","","Software measurement;Coordinate measuring machines;Software engineering;Software maintenance;Costs;Software performance;Software development management;Software quality;Software systems;Scheduling","software process improvement;software metrics;software reliability","process consistency measurement;software defect reduction;software process consistency;product defects;software validity;software reliability;measurement scale;CMM;software vendor","","57","","53","","","","","","IEEE","IEEE Journals & Magazines"
"A Transformational Derivation of a Parsing Algorithm in a High-Level Language","E. Deak","Bell Laboratories","IEEE Transactions on Software Engineering","","1981","SE-7","1","23","31","This paper presents a detailed algorithm derivation scenario, using correctness preserving source-to-source transfonnations. The algorithm derived is the Cocke-Younger nodal spans parsing algorithm. We describe a high-level SETL-like specification language, and give a partial correctness formalism and a set of transformation rules which enable the combination of algorithms whose partial correctness has already been established.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230816","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702799","Algorithm specification;high-level language;partial correctness;source-to-source transformation;verification","High level languages;Computer languages;Specification languages;Automatic programming;Interactive systems;Error correction;Libraries;Algorithm design and analysis;Set theory","","Algorithm specification;high-level language;partial correctness;source-to-source transformation;verification","","","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Implementing remote evaluation","J. W. Stamos; D. K. Gifford","Lab. for Comput. Sci., MIT, Cambridge, MA, USA; Lab. for Comput. Sci., MIT, Cambridge, MA, USA","IEEE Transactions on Software Engineering","","1990","16","7","710","722","Remote evaluation (REV) is a construct for building distributed systems that involves sending executable code from one computer to another computer via a communication network. How REV can reduce communication and improve performance for certain classes of distributed applications is explained. Implementation issues are discussed. REV is incorporated into a high-level programming language by defining its syntax and its semantics. The compile-time and run-time support for REV is discussed in both heterogeneous and homogeneous systems and compared to that needed by a remote procedure call implementation. Sample performance measurements are included. Experience with a prototype REV implementation is summarized.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.56097","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=56097","","Network servers;Buildings;Application software;High performance computing;Laboratories;Computer science;Programming profession;Computer networks;Communication networks;Computer languages","computer networks;distributed processing;performance evaluation","remote evaluation implementation;compile time support;heterogeneous systems;distributed systems;executable code;communication network;distributed applications;high-level programming language;syntax;semantics;run-time support;homogeneous systems;remote procedure call implementation;performance measurements","","38","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Specification of Forms Processing and Business Procedures for Office Automation","N. C. Shu; V. Y. Lum; F. C. Tung; C. L. Chang","IBM Scientific Center; NA; NA; NA","IEEE Transactions on Software Engineering","","1982","SE-8","5","499","512","Business activities, in general, involve data processing (such as queries, extraction, manipulation, and restructuring of data, etc.) as well as conventional office work centered around preparation, distribution, and filing and retrieval of documents. Convinced that most of these activities can be expressed in terms of forms, we present in this paper a formal means for specification of forms processing. The underlying concept is that business functions can be decomposed into meaningfuliy connected form processes where each process either produces or modifies a form. Powerful constructs are provided so that most of the common data processing activities can be expressed in a very high level, concise, and yet compilable manner.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235738","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702978","Applications development;applications specification;data processing for non-DP professionals;forms data model;forms processing;office automation;office information systems;office/business procedure automation;programming by forms","Office automation;Data processing;Laboratories;Data mining;Information retrieval;Productivity;IEEE activities;Application software;Data models;Information systems","","Applications development;applications specification;data processing for non-DP professionals;forms data model;forms processing;office automation;office information systems;office/business procedure automation;programming by forms","","34","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Profiling an incremental data flow analysis algorithm","B. G. Ryder; W. Landi; H. D. Pande","Dept. of Comput. Sci., Rutgers Univ., New Brunswick, NJ, USA; Dept. of Comput. Sci., Rutgers Univ., New Brunswick, NJ, USA; Dept. of Comput. Sci., Rutgers Univ., New Brunswick, NJ, USA","IEEE Transactions on Software Engineering","","1990","16","2","129","140","Incremental data flow analysis algorithms have been designed to deal efficiently with change in evolving software systems. These algorithms document the current state of a software system by incorporating change effects into previously derived information describing the definition and use of data in the system. Unfortunately, the performance of these algorithms cannot, in general, be characterized by analytic predictions of their expected behavior. It is possible, however, to observe their performance empirically and predict their average behavior. The authors report on experiments on the empirical profiling of a general-purpose, incremental data flow analysis algorithm. The algorithm, dominator based and coded in C, was applied to statistically significant numbers of feasible, random software systems of moderate size. The experimental results, with quantifiable confidence limits, substantiate the claim that incremental analyses are viable and grow more valuable as a software system grows in size.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44377","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44377","","Data analysis;Algorithm design and analysis;Software systems;Software algorithms;Performance analysis;Information analysis;Application software;Computer science;Computer industry","parallel programming;program testing","incremental data flow analysis algorithm;evolving software systems;empirical profiling","","9","","49","","","","","","IEEE","IEEE Journals & Magazines"
"Algorithmic transformations for neural computing and performance of supervised learning on a dataflow machine","S. T. Kim; K. Suwunboriruksa; S. Herath; A. Jayasumana; J. Herath","Dept. of Electr. & Comput. Eng., Drexel Univ., Philadelphia, PA, USA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1992","18","7","613","623","Reprogrammable dataflow neural classifiers are proposed as an alternative to traditional implementations. In general, these classifiers are based on functional languages, neural-dataflow transformations, dataflow algorithmic transformations, and dataflow multiprocessors. An experimental approach is used to investigate the performance of a large-scale fine-grained dataflow classifier architecture. In this study, the functional descriptions of high level data dependency of a supervised learning algorithm are transformed into a machine executable low-level dataflow graph. The tagged token dataflow algorithmic transformation is applied to exploit the parallelism. Dataflow neural classifiers are used to implement the learning algorithm. No attempt is made to optimize the granularity of the high-level language programming blocks to balance the computation and communication. The proposed classifier architecture is more versatile than other existing architectures. Performance results show the effectiveness of dataflow neural classifiers.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.148479","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=148479","","Supervised learning;Large-scale systems;Sensor arrays;Hamming distance;Parallel processing;Computer architecture;Intelligent sensors;Intelligent actuators;Military computing;Neurons","computerised pattern recognition;learning systems;neural nets;parallel architectures;performance evaluation","algorithmic transformations;reprogrammable dataflow neural classifiers;neural computing;performance;supervised learning;dataflow machine;functional languages;neural-dataflow transformations;dataflow algorithmic transformations;dataflow multiprocessors;high level data dependency;machine executable low-level dataflow graph;tagged token dataflow algorithmic transformation;granularity","","3","","16","","","","","","IEEE","IEEE Journals & Magazines"
"A method for software reliability analysis and prediction application to the TROPICO-R switching system","K. Kanoun; M. R. de Bastos Martini; J. M. de Souza","LAAS-CNRS, Toulouse, France; NA; NA","IEEE Transactions on Software Engineering","","1991","17","4","334","344","An evaluation method which allows existing reliability growth models to provide better predictions of software behavior is presented. The method is primarily based on the analysis of the trend exhibited by the data collected on the program (which is determined by reliability growth tests). Reliability data are then partitioned according to the trend, and two types of reliability growth models can be applied: when the data exhibit reliability decrease followed by reliability growth, an S-shaped model can be applied, and in case of reliability growth, most of the other existing reliability growth models can be applied. The hyperexponential model is shown to allow prediction of the software residual failure rate in operation, and this failure rate is used as a qualification index for the software product. The method is illustrated through its application to the Brazilian electronic switching system TROPICO-R.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.90433","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=90433","","Software reliability;Application software;Predictive models;Testing;Maintenance;Electronic switching systems;Switching systems;Software systems;Failure analysis;Software development management","electronic switching systems;reliability theory;software reliability","software reliability;prediction application;TROPICO-R switching system;reliability growth models;software behavior;reliability decrease;reliability growth;S-shaped model;hyperexponential model;software residual failure rate;qualification index;Brazilian electronic switching system","","45","","33","","","","","","IEEE","IEEE Journals & Magazines"
"An empirical study of testing and integration strategies using artificial software systems","J. A. Solheim; J. H. Rowland","Emporia State Univ., KS, USA; NA","IEEE Transactions on Software Engineering","","1993","19","10","941","949","There has been much discussion about the merits of various testing and integration strategies. Top-down, bottom-up, big-bang, and sandwich integration strategies are advocated by various authors. Also, some authors insist that modules be unit tested, while others believe that unit testing diverts resources from more effective verification processes. This article addresses the ability of the aforementioned integration strategies to detect defects, and produce reliable systems. It also explores the efficacy of spot unit testing, and compares phased and incremental versions of top-down and bottom-up integration strategies. Relatively large artificial software systems were constructed using a code generator with ten basic module templates. These systems were seeded with known defects and tested using the above testing and integration strategies. A number of experiments were then conducted using a simulator whose validity was established by comparing results against these artificial systems. The defect detection ability and resulting system reliability were measured for each strategy. Results indicated that top-down integration strategies are generally most effective in terms of defect correction. Top-down and big-bang strategies produced the most reliable systems. Results favored neither those strategies that incorporate spot unit testing nor those that do not; also, results favored neither phased nor incremental strategies.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.245736","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=245736","","Software testing;System testing;Software systems;Software engineering;Milling machines;Software reliability;Reliability engineering;Phase measurement;Software measurement","program testing;software reliability","artificial software systems;top-down strategies;code generator;sandwich integration strategies;verification processes;reliable systems;spot unit testing;bottom-up integration;system reliability;defect correction;big-bang strategies","","10","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Using term rewriting to verify software","S. Antoy; J. Gannon","Dept. of Comput. Sci., Portland State Univ., OR, USA; NA","IEEE Transactions on Software Engineering","","1994","20","4","259","274","This paper describes a uniform approach to the automation of verification tasks associated with while statements, representation functions for abstract data types, generic program units, and abstract base classes. Program units are annotated with equations containing symbols defined by algebraic axioms. An operation's axioms are developed by using strategies that guarantee crucial properties such as convergence and sufficient completeness. Sets of axioms are developed by stepwise extensions that preserve these properties. Verifications are performed with the aid of a program that incorporates term rewriting, structural induction, and heuristics based on ideas used in the Boyer-Moore prover. The program provides valuable mechanical assistance: managing inductive arguments and providing hints for necessary lemmas, without which formal proofs would be impossible. The successes and limitations of our approaches are illustrated with examples from each domain.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.277574","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=277574","","Equations;Computer science;Concrete;Automation;Convergence;Tail;Abstracts;Turing machines","abstract data types;rewriting systems;program verification;theorem proving;software tools","term rewriting;verification tasks;while statements;representation functions;abstract data types;generic program units;abstract base classes;algebraic axioms;convergence;sufficient completeness;structural induction;Boyer-Moore prover;mechanical assistance","","8","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Error Sensitive Test Cases Analysis (ESTCA)","K. A. Foster","GTE Sylvania, Inc.","IEEE Transactions on Software Engineering","","1980","SE-6","3","258","264","A hardware failure analysis technique adapted to software yielded three rules for generating test cases sensitive to code errors. These rules, and a procedure for generating these cases, are given with examples. Areas for further study are recommended.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234487","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702727","Program correctness;progran testing;software errors;software reliability;test data generation","Computer aided software engineering;Hardware;Arithmetic;Displays;Software testing;Computer errors;Error correction;Assembly;Logic testing;Failure analysis","","Program correctness;progran testing;software errors;software reliability;test data generation","","40","","7","","","","","","IEEE","IEEE Journals & Magazines"
"Views for Multilevel Database Security","D. E. Denning; S. G. Akl; M. Heckman; T. F. Lunt; M. Morgenstern; P. G. Neumann; R. R. Schell","SRI International; NA; NA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","2","129","140","Because views on relational database systems mathematically define arbitrary sets of stored and derived data, they have been proposed as a way of handling context-and content-dependent classification, dynamic classification, inference, aggregation, and sanitization in multilevel database systems. This paper describes basic view concepts for a multilevel-secure relational database model that addresses the above issues. All data entering the database are labeled according to views called classification constraints, which specify access classes for related data. In addition, views called aggregation constraints restrict access to aggregates of information. All data accesses are confined to a third set of views called access views.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232889","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702194","Classification;multilevel security;protection;relational databases;security;views","Data security;Relational databases;Database systems;National security;Aggregates;Multilevel systems;Protection;Information security;Computer security","","Classification;multilevel security;protection;relational databases;security;views","","9","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Performance Analysis of Alternative Database Machine Architectures","P. B. Hawthorn; D. J. DeWitt","Computer Sciences and Mathematics Department, Lawrence Berkeley Laboratory; NA","IEEE Transactions on Software Engineering","","1982","SE-8","1","61","75","The rapid advances in the development of low-cost computer hardware have led to many proposals for the use of this hardware to improve the performance of database management systems. Usually the design proposals are quite vague about the performance of the system with respect to a given data management application. In this paper we predict the performance of several of the proposed database management machines with respect to several representative INGRES queries. The systems analyzed in this paper include associative disks, RAP, CASSM, DBC, DIRECT, and CAFS. We demonstrate that no one database machine is best for executing all types of queries. We will also show that for one class of queries the degree of performance improvement achieved does not warrant use of a database machine.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.234775","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702906","Associative processors;backend computers;computer architecture;database machines;database management;parallel processors;performance evaluation","Performance analysis;Database machines;Hardware;Proposals;Computer architecture;Application software;Contracts;Database systems;Concurrent computing","","Associative processors;backend computers;computer architecture;database machines;database management;parallel processors;performance evaluation","","15","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Tradeoffs in the design of efficient algorithm-based error detection schemes for hypercube multiprocessors","V. Balasubramanian; P. Banerjee","Dept. of Electr. Eng., Illinois Univ., Urbana, IL, USA; Dept. of Electr. Eng., Illinois Univ., Urbana, IL, USA","IEEE Transactions on Software Engineering","","1990","16","2","183","196","The authors provide an in-depth study of the various issues and tradeoffs available in algorithm-based error detection, as well as a general methodology for evaluating the schemes. They illustrate the approach on an extremely useful computation in the field of numerical linear algebra: QR factorization. They have implemented and investigated numerous ways of applying algorithm-based error detection using different system-level encoding strategies for QR factorization. Specifically, schemes based on the checksum and sum-of-squares (SOS) encoding techniques have been developed. The results of studies performed on a 16-processor Intel iPSC-2/D4/MX hypercube multiprocessor are reported. It is shown that, in general, the SOS approach gives much better coverage (85-100%) for QR factorization while maintaining low overheads (below 10%).<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44381","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44381","","Algorithm design and analysis;Hypercubes;Fault detection;Parallel algorithms;Hardware;Concurrent computing;Electrical fault detection;Costs;Computer errors;Computer architecture","encoding;error detection;linear algebra;multiprocessing systems;software engineering","hypercube multiprocessors;algorithm-based error detection;numerical linear algebra;QR factorization;encoding;checksum;sum-of-squares;16-processor Intel iPSC-2/D4/MX","","15","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Performance analysis of concurrency control using locking with deferred blocking","P. S. Yu; D. M. Dias","Res. Div., IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; Res. Div., IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA","IEEE Transactions on Software Engineering","","1993","19","10","982","996","The concurrency control (CC) method employed can be critical to the performance of transaction processing systems. Conventional locking suffers from the blocking phenomenon, where waiting transactions continue to hold locks and block other transactions from progressing. In a high data contention environment, as an increasing number of transactions wait, a larger number of lock requests get blocked and fewer lock requests can get through. The proposed scheme reduces the blocking probability by deferring the blocking behavior of transactions to the later stages of their execution. By properly balancing the blocking and abort effects, the proposed scheme can lead to better performance than either the conventional locking or the optimistic concurrency control (OCC) schemes at all data and resource contention levels. We consider both static and dynamic approaches to determine when to switch from the nonblocking phase to the blocking phase. An analytical model is developed to estimate the performance of this scheme and determine the optimal operating or switching point. The accuracy of the analytic model is validated through a detailed simulation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.245740","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=245740","","Performance analysis;Concurrency control;Broadcasting;Switches;Analytical models;Database systems;Throughput;Transaction databases;Control system analysis","concurrency control;distributed databases;performance evaluation;transaction processing","concurrency control;locking;deferred blocking;transaction processing systems;performance analysis;high data contention environment;blocking probability;optimistic concurrency control;resource contention;switching point;simulation","","8","","50","","","","","","IEEE","IEEE Journals & Magazines"
"An Alternative to the Rayleigh Curve Model for Software Development Effort","F. N. Parr","IBM T. J. Watson Research Center","IEEE Transactions on Software Engineering","","1980","SE-6","3","291","296","A new model of the software development process is presented and used to derive the form of the resource consumption curve of a project over its life cycle. The function obtained differs in detail from the Rayleigh curve previously used in fitting actual project data. The main advantage of the new model is that it relates the rate of progress which can be achieved in developing software to the structure of the system being developed. This leads to a more testable theory, and it also becomes possible to predict how the use of structured programming methods may alter pattems of life cycle resource consumption.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230475","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702731","Development process;empirical;life cycle;metrics;project evaluation;Rayleigh function;software","Programming;Constraint theory;Resource management;Curve fitting;Life testing;Software engineering;Project management","","Development process;empirical;life cycle;metrics;project evaluation;Rayleigh function;software","","53","","5","","","","","","IEEE","IEEE Journals & Magazines"
"Monitoring Software Development Through Dynamic Variables","C. W. Doerflinger; V. R. Basili","Texas Instruments Incorporated; NA","IEEE Transactions on Software Engineering","","1985","SE-11","9","978","985","This paper describes research conducted by the Software Engineering Laboratory (SEL) on the use of dynamic variables as a tool to monitor software development. The intent of the project is to identify project independent measures which may be used in a management tool for monitoring software development. This study examines several Fortran projects with similar profiles. The staff was experienced in developing these types of projects. The projects developed serve similar functions. Because these projects are similar we believe some underlying relationships exist that are invariant between the projects. These relationships, once well defined, may be used to compare the development of different projects to determine whether they are evolving the same way previous projects in this environment evolved.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232833","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702118","Database;management tool;measurement;monitoring software development","Programming;Project management;Aerodynamics;Software engineering;Software measurement;NASA;Laboratories;Software development management;Computerized monitoring;Computer science","","Database;management tool;measurement;monitoring software development","","5","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Locality of Reference in Hierarchical Database Systems","J. P. Kearns; S. DeFazio","Department of Computer Science, University of Pittsburgh; NA","IEEE Transactions on Software Engineering","","1983","SE-9","2","128","134","Localized information referencing is a long-known and much-exploited facet of program behavior. The existence of such behavior in the data accessing patterns produced by database management systems is not currently supported by empirical results. We present experimental results which demonstrate that in certain environments and under certain important applications, locality of reference is an undeniable characteristic of the information accessing behavior of a hierarchical database management system. Furthermore, database locality of reference is in a sense more regular, predictable, and hence, more exploitable than the localized reference activity found in programs in general. The implications of these results for the performance enhancement and workload characterization of database management systems are discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236457","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703029","Database;memory management;performance evaluation;workload characterization","Database systems;Memory management;Computer science;Vehicles;Cache memory;Intelligent networks","","Database;memory management;performance evaluation;workload characterization","","9","","18","","","","","","IEEE","IEEE Journals & Magazines"
"A protocol modeling and verification approach based on a specification language and Petri nets","T. Suzuki; S. M. Shatz; T. Murata","Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA; Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA; Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA","IEEE Transactions on Software Engineering","","1990","16","5","523","536","An approach for automated modeling and verification of communication protocols is presented. A language that specifies the input/output behavior of protocol entities is introduced as the starting point of the approach, and verification of the linguistic specifications is discussed. Rules for conversion of the specifications into a Petri net model (based on a timed Petri net) are presented and illustrated by examples. This leads to a second level of verification on the net model. The approach is illustrated by its application to a part of the LAPD protocol.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.52775","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=52775","","Protocols;Specification languages;Petri nets;Software engineering;Concurrent computing;Computer science;Automata;Time factors","Petri nets;program verification;protocols;specification languages","conversion rules;specification language;Petri nets;automated modeling;verification;communication protocols;input/output behavior;linguistic specifications;timed Petri net;LAPD protocol","","28","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Counting Paths: Nondeterminism as Linear Algebra","D. B. Benson","Department of Computer Science, Washington State University, Pullman, WA 99164-1210.","IEEE Transactions on Software Engineering","","1984","SE-10","6","785","794","Nondeterminism is considered to be ignorance about the actual state transition sequence performed during a computation. The number of distinct potential paths from state i to j forms a matrix [n<sub>ij</sub>]. The behavior of a nondeterministic program is defined to be this multiplicity matrix of the state transitions. The standard programming constructs have behaviors defined in terms of the behaviors of their constituents using matrix addition and multiplication only. The spectral radius of the matrix assigned to an iterating component characterizes its convergence. The spectral radius is shown to be either 0 or else  1. The program converges iff the spectral radius is zero, diverges deterministically iff the spectral radius is one, and has a proper nondeterministic divergence iff the spectral radius exceeds one. If the machine has an infinite number of states the characterization of convergence is given graph theoretically. The spectral radii of synchronous and interleaved parallel noncommunicating systems are easily computed in terms of the spectral radii of the components.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010307","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010307","Convergent iterative programs;deterministic divergence;nondeterministic divergence;nondeterministic programs;nonnegative matrices;semirings","Linear algebra;Operating systems;Computer errors;Distributed computing;Convergence;Control systems;Programming profession;Concurrent computing;Design engineering;Redundancy","","","","2","","17","","","","","","IEEE","IEEE Journals & Magazines"
"User-process communication performance in networks of computers","L. -. Cabrera; E. Hunter; M. J. Karels; D. A. Hosher","Dept. of Comput. Sci., IBM Almaden Res. Center, San Jose, CA, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1988","14","1","38","53","The authors present a study of the performance achieved by user processes when using the IPC mechanisms as implemented in Berkeley Unix 4.2BSD in Ethernet based environments. The authors assess not only the impact that different processors, network hardware interfaces, and Ethernets have on the communication across machines, but also the effect of the loading of the hosts and communication media that participate in the interprocess communication mechanism. The measurements highlight the ultimate bounds on performance that may be achieved by user process applications communicating across machines, and serve as a guide in designing performance-critical applications. A detailed timing analysis is presented of the dynamic behavior of the TCP/IP and the UDP/IP network communication protocols' implementation in Berkeley Unix 4.2BSD.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4621","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4621","","Intelligent networks;Computer networks;Protocols;Ethernet networks;Hardware;Telecommunication network reliability;Operating systems;Computer science;Application software;Timing","local area networks;network operating systems;protocols","network protocols;user processes;IPC mechanisms;Berkeley Unix 4.2BSD;Ethernet;network hardware interfaces;communication media;interprocess communication mechanism;performance-critical applications;timing analysis;TCP/IP;UDP/IP","","43","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Software Science and Cognitive Psychology","N. S. Coulter","Department of Computer and Information Systems, Florida Atlantic University","IEEE Transactions on Software Engineering","","1983","SE-9","2","166","171","Halstead proposed a methodology for studying the process of programming known as software science. This methodology merges theories from cognitive psychology with theories from computer science. There is evidence that some of the assumptions of software science incorrectly apply the results of cognitive psychology studies. HAlstead proposed theories relative to human memory models that appear to be without support from psychologists. Other software scientists, however, report empirical evidence that may support some of those theories. This anomaly places aspects of software science in a precarious position. The three conflicting issues discussed in this paper are 1) limitations of short-term memory and number of sub-routine parameters, 2) searches in human memory and programming effort, and 3) psychological time and programming time.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236461","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703033","Cognitive psychology;human memory models;human memory searches;long-term memory;programming effort;programming time;short-term memory;software science;Stroud number","Psychology;Humans;Software measurement;Algorithms;Vocabulary;Computer science;Differential equations;Information systems;Measurement units","","Cognitive psychology;human memory models;human memory searches;long-term memory;programming effort;programming time;short-term memory;software science;Stroud number","","9","","32","","","","","","IEEE","IEEE Journals & Magazines"
"The transformation schema: An extension of the data flow diagram to represent control and timing","P. T. Ward","Yourdon, Inc., New York, NY 10036","IEEE Transactions on Software Engineering","","1986","SE-12","2","198","210","The data flow diagram has been extensively used to model the data transformation aspects of proposed systems. However, previous definitions of the data flow diagram have not provided a comprehensive way to represent the interaction between the timing and control aspects of a system and its data transformation behavior. An extension of the data flow diagram called the transformation schema is described. This schema provides a notation and formation rules for building a comprehensive system model, and a set of execution rules to allow prediction of the behavior over time of a system modeled in this way. The notation and formation rules allow depiction of a system as a network of potentially concurrent `centers of activity' (transformations), and of data repositories (stores), linked by communication paths (flows). The execution rules provide a qualitative prediction rather than a quantitative one, describing the acceptance of inputs and the production of outputs by the transformations but not input and output values.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312936","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312936","Concurrent systems;data flow diagram;requirements modeling;software design;systems design;transformation schema","Delay;Data models;Production;Buffer storage;Transforms;Automata","flowcharting;programming","software engineering;transformation schema;data flow diagram;control;timing;notation;formation rules;system model;data repositories;communication paths","","63","","","","","","","","IEEE","IEEE Journals & Magazines"
"An Algebraic Specification of HDLC Procedures and Its Verification","T. Higashino; M. Mori; Y. Sugiyama; K. Taniguchi; T. Kasami","Department of Information and Computer Sciences, Faculty of Engineering Science, Osaka University, Toyonaka, Osaka, 560, Japan.; Faculty of Economics, Shiga University, Hikone, Shiga, 522, Japan.; Department of Information and Computer Sciences, Faculty of Engineering Science, Osaka University, Toyonaka, Osaka, 560, Japan.; Department of Information and Computer Sciences, Faculty of Engineering Science, Osaka University, Toyonaka, Osaka, 560, Japan.; Department of Information and Computer Sciences, Faculty of Engineering Science, Osaka University, Toyonaka, Osaka, 560, Japan.","IEEE Transactions on Software Engineering","","1984","SE-10","6","825","836","It is well known that algebraic specification methods are promising for specifying programs and for verifying their various properties formally. In this paper, an algebraic specification of information transfer procedures of high-level data link control (HDLC) procedures is presented and some of the main properties of the specification are shown. First, we introduce abstract states, state transition functions, and output functions corresponding to elementary notions extracted from the description of HDLC procedures in ISO 3309-1979 (E) and ISO 4335-1979 (E). Second, we show axioms which represent the relations between the values of functions before and after the state transitions. Then, it is proved that the specification is ``consistent,'' ``sufficiently complete,'' and ``nonredundant.'' Also it is shown that an implementation which realizes the specification is naturally derived. In the last section, verification of various properties of HDLC procedures is formulated in the same framework as the algebraic specification, and some verification examples are presented.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010311","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010311","Algebraic specification;Church-Rosser property;HDLC procedures;term rewriting system;verification","Protocols;Algebra;ISO standards;Arithmetic;Magnetooptic recording;Formal specifications","","","","12","","44","","","","","","IEEE","IEEE Journals & Magazines"
"A rational design process: How and why to fake it","D. L. Parnas; P. C. Clements","Department of Computer Science, University of Victoria, Victoria, B. C. V8W 2Y2, Canada; Computer Science and Systems Branch, Naval Research Laboratory, Washington, DC 20375; Computer Science and Systems Branch, Naval Research Laboratory, Washington, DC 20375","IEEE Transactions on Software Engineering","","1986","SE-12","2","251","257","Many have sought a software design process that allows a program to be derived systematically from a precise statement of requirements. It is proposed that, although designing a real product in that way will not be successful, it is possible to produce documentation that makes it appear that the software was designed by such a process. The ideal process and the documentation that it requires are described. The authors explain why one should attempt to design according to the ideal process and why one should produce the documentation that would have been produced by that process. The contents of each of the required documents are outlined.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312940","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312940","Programming methods;software design;software documentation;software engineering","Documentation;Software design;Computers;Maintenance engineering;Mathematical model;Data structures","software engineering;system documentation","rational design process;statement of requirements;documentation","","103","","","","","","","","IEEE","IEEE Journals & Magazines"
"An Automatic-Controller Description Language","H. Takahashi","Department of Mathematics, College of Science and Engineering, Nihon University","IEEE Transactions on Software Engineering","","1980","SE-6","1","53","64","This paper proposes a control-oriented Algol-like nonprocedural language called Condor. Automatic controller theory, in company with computer science, underlies many industrial fields. Sequential control is especially important. So far, sequential-controller description methods have by and large been lmited to graphic ones, which are unreadable in the case of large controllers. A higher-level linguistic approach has been considered unlikely. This paper proposes a language widely suitable for controller architecture description. A controller, in its nature, consists of many subsystems which work in a parallel manner, interacting with one another. This paper deems that a basic component is not a process, but a response. A controller is considered to be a responding system in which every reactor works together, having a relation and communication to one another. A Condor program is a role assignment list for the reactors; it is Algol-like and nonprocedural. All the statements work at all times, interacting with one another.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230463","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702695","Automatic control;automation;control system description language;hierarchy;logic system design automation;nonprocedural language;parallel action;programmable logic controller;relay circuit;sequential control","Automatic control;Control systems;Programmable control;Tree data structures;Programmable logic arrays;Programmable logic devices;Relays;Equations;Communication system control;Inductors","","Automatic control;automation;control system description language;hierarchy;logic system design automation;nonprocedural language;parallel action;programmable logic controller;relay circuit;sequential control","","1","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Software Reliability Models: Assumptions, Limitations, and Applicability","A. L. Goel","Department of Electrical and Computer Engineering and the School of Computer and Information Science, Syracuse University","IEEE Transactions on Software Engineering","","1985","SE-11","12","1411","1423","A number of analytical models have been proposed during the past 15 years for assessing the reliability of a software system. In this paper we present an overview of the key modeling approaches, provide a critical analysis of the underlying assumptions, and assess the limitations and applicability of these models during the software development cycle. We also propose a step-by-step procedure for fitting a model and illustrate it via an analysis of failure data from a medium-sized real-time command and control software system.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232177","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701963","Estimation;failure count models;fault seeding;input domain models;model fitting;NHPP;software reliability;times between failures","Software reliability;Software systems;Hardware;Programming profession;Software testing;Analytical models;Data analysis;Failure analysis;Real time systems;Command and control systems","","Estimation;failure count models;fault seeding;input domain models;model fitting;NHPP;software reliability;times between failures","","476","","49","","","","","","IEEE","IEEE Journals & Magazines"
"An Experiment in Small-Scale Application Software Engineering","B. W. Boehm","Systems Engineering and Integration Division, TRW","IEEE Transactions on Software Engineering","","1981","SE-7","5","482","493","This paper reports the results of an experiment in applying large-scale software engineering procedures to small software projects. Two USC student teams developed a small, interactive application software product to the same specification, one using Fortran and one using Pascal. Several hypotheses were tested, and extensive experimenal data collected. The major conclusions were as follows.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.231110","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702874","Programming languages;programming methodology;software engineering;software management;software project data","Application software;Software engineering;Project management;Engineering management;Product development;Software development management;Software testing;Large-scale systems;Computer languages;Programming","","Programming languages;programming methodology;software engineering;software management;software project data","","22","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Synthesizing Code for Resource Controllers","K. Ramamritham","Department of Computer and Information Science, University of Massachusetts","IEEE Transactions on Software Engineering","","1985","SE-11","8","774","783","A distributed system is viewed as a set of objects and processes utilizing the objects. If a shared object, known as a resource, is accessed concurrently, some mechanism is necessary to control use of the resource in order to satisfy the consistency and fairness requirements associated with the resource. These mechanisms are termed resource controllers.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232526","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702086","Shared resources;specification;synchronization;synthesis;temporal logic","Object oriented modeling;Control system synthesis;Logic;Safety;Network synthesis;Software systems;Computer architecture;Communication networks;Computer languages;Control systems","","Shared resources;specification;synchronization;synthesis;temporal logic","","1","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Making use of scenarios for validating analysis and design","W. Dzida; R. Freitag","Syst. Design Technol. Inst., Nat. Res. Center for Inf. Technol., St. Augustin, Germany; NA","IEEE Transactions on Software Engineering","","1998","24","12","1182","1196","Scenarios can help remedy the most serious obstacle in the design process that is a chronic lack of knowledge of the application domain. Moreover, scenarios can be employed in analysis and design to serve both illustrating the context of an envisaged usage (user's perspective) and demonstrating the design proposal in terms of the intended usage (analyst's perspective). In contrasting both perspectives by means of a dialectic process a synthesis can be achieved that incorporates a shared understanding. Validation is a process to achieve such an understanding. The semantic structure of types of scenarios is investigated thus illustrating how a context of use analysis according to ISO 9241-11 can be exploited for validation purposes. The role of scenarios in usability engineering is contrasted with traditional concepts of systems analysis as an attempt to narrow the bridge between software engineering and usability engineering.","0098-5589;1939-3520;2326-3881","","10.1109/32.738346","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=738346","","Proposals;Design engineering;Process design;Usability;Software engineering;Mirrors;ISO standards;Bridges;Software prototyping;Prototypes","systems analysis;formal verification;formal specification;ISO standards;software standards;user interfaces","scenarios;analysis validation;design validation;envisaged usage;user perspective;design proposal;intended usage;analyst perspective;dialectic process;shared understanding;semantic structure;use analysis;ISO 9241-11;usability engineering;systems analysis;software engineering","","25","","45","","","","","","IEEE","IEEE Journals & Magazines"
"Comparative analysis of different models of checkpointing and recovery","V. F. Nicola; J. M. van Spanje","Dept. of Comput. Sci., Duke Univ., Durham, NC, USA; NA","IEEE Transactions on Software Engineering","","1990","16","8","807","821","Different checkpointing strategies are combined with recovery models of different refinement levels in the database systems. The complexity of the resulting model increases with its accuracy in representing a realistic system. Three different analytic approaches are used depending on the complexity of the model: analytic, numerical and simulation. A Markovian queuing model is developed, resulting in a combined Poisson and load-dependent checkpointing strategy with stochastic recovery. A state-space analysis approach is used to derive semianalytic expressions for the performance variables in terms of a set of unknown boundary state probabilities. An efficient numerical algorithm for evaluating unknown probabilities is outlined. The validity of the numerical solution is checked against simulation results and shown to be of acceptable accuracy, particularly in the stable operating range. Simulations have shown that realistic load-dependent checkpointing results in performance close to the optimal deterministic checkpointing. Furthermore, the stochastic recovery model is an accurate representation of a realistic recovery.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.57620","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=57620","","Checkpointing;Database systems;Frequency;Stochastic processes;Analytical models;Queueing analysis;Performance analysis;Availability;Delay;Computer science","computational complexity;database management systems;database theory;probability;queueing theory;system recovery","DBMS;checkpointing strategies;recovery models;refinement levels;realistic system;analytic approaches;simulation;Markovian queuing model;Poisson;load-dependent checkpointing strategy;stochastic recovery;state-space analysis approach;semianalytic expressions;performance variables;unknown boundary state probabilities;numerical algorithm;numerical solution;stable operating range;optimal deterministic checkpointing","","37","","25","","","","","","IEEE","IEEE Journals & Magazines"
"The Unix System and Software Reusability","B. W. Kernighan","Bell Laboratories, Murray Hill, NJ 07974.","IEEE Transactions on Software Engineering","","1984","SE-10","5","513","518","The Unix system contains a variety of facilities that enhance the reuse of software. These vary from the utterly conventional, such as function libraries, to basic architectural mechanisms, such as the Unix pipe. The Unix pipe, which makes whole programs building blocks of larger computational structures, has been the primary reason for the development of a literature of useful, but specialized programs-programs that would be too costly to write in a conventional programming language such as C. It has led to high levels of program reuse both by the nature of its operation and through its effect on programming conventions (e.g., programs structured as simple filters). Another facility enhancing reuse on Unix is the on-line C source code for Unix system programs. This has led to a shared style of programming in which existing programs are used as models for new programs, allowing the reuse of ideas, algorithms and source code. Finally, the Unix system contains many other reuse enhancing facilities, such as generic facilities for screen management (curses and termcap) and program generators (lex and yacc).","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010275","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010275","Filter;generator;library;I/O redirection;pipe;Unix","Software reusability;Software libraries;Operating systems;Writing;Functional programming;Filters;Algorithms;Scholarships;Dictionaries;Computer languages","","","","21","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Extending objects to support multiple interfaces and access control","B. Hailpern; H. Ossher","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA","IEEE Transactions on Software Engineering","","1990","16","11","1247","1257","A mechanism, called views, that allows programmers to specify multiple interfaces for objects and to control explicitly access to each interface is described. This mechanism provides a simple and flexible means of specifying enforceable access restrictions at many levels of granularity. It also results in system organization that supports browsing based on a number of different criteria. Views is defined, some examples of its uses are given, the impact of views on system organization is discussed, and five approaches to implementing views are outlined.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.60313","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=60313","","Access control;Encapsulation;Senior members;Control systems;Protection;Data structures","data structures;object-oriented programming","multiple interfaces;access control;views;objects;enforceable access restrictions;granularity;system organization;browsing","","24","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Consequence Verification of Flowcharts","K. L. Clark; M. H. Van Emden","Department of Computing and Control, Imperial College of Science and Technology; NA","IEEE Transactions on Software Engineering","","1981","SE-7","1","52","60","A common basis is presented, for Floyd's method of inductive assertions and for the subgoal induction method of Morris and Wegbreit. This basis is provided by consequence verification, a method for verifying logic programs. We connect flowcharts with logic programs by giving a recursive definition of the set of all computations of a flowchart. This definition can be given in two ways: the recursion can run forward or backward. Both definitions can be expressed in logic, resulting in a logic program which is then subjected to consequence verification. Verification of the forward logic program is shown to be essentially Floyd's method; verification of the backward program corresponds similarly to subgoal induction.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234508","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702802","Consequence verification;inductive assertions;logic programming;program verification;subgoal induction","Flowcharts;Logic programming;Councils;Computer science","","Consequence verification;inductive assertions;logic programming;program verification;subgoal induction","","","","18","","","","","","IEEE","IEEE Journals & Magazines"
"A characterization of independence for competing Markov chains with applications to stochastic Petri nets","R. J. Boucherie","Dept. of Econ., Amsterdam Univ., Netherlands","IEEE Transactions on Software Engineering","","1994","20","7","536","544","This paper shows that some of the recently obtained product form results for stochastic Petri nets can be obtained as a special case of a simple exclusion mechanism for the product process of a collection of Markov chains.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.297942","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=297942","","Stochastic processes;Petri nets;Resource management;Routing;Fires;Fellows;Traffic control;Equations;Sufficient conditions","Petri nets;Markov processes","competing Markov chains;stochastic Petri nets;simple exclusion mechanism;independence;resource sharing","","31","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Specifying Ada server tasks with executable formal grammars","D. Hemmendinger","Dept. of Comput. Sci., Union Coll., Schenectady, NY, USA","IEEE Transactions on Software Engineering","","1990","16","7","741","754","The author shows how a class of concurrent programming problems can be specified with formal grammars. These grammars, more powerful than path expressions, translate readily into Ada server tasks using the rendezvous and select-statement, though they may also be applied to other synchronization constructs. The grammars may be used to clarify informal specifications, to compare different specifications, and to analyze the behavior of implementations of such specifications. They may also be easily converted into Prolog programs that can be executed to generate the strings of events accepted by a grammar or by the Ada task being modeled. The automated translation from Ada to such grammars, and from grammatical specifications to Ada is discussed. The former facilitates the analysis of Ada programs; the latter yields Ada code of high quality.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.56100","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=56100","","Formal specifications;Concurrent computing;Programming profession;Automata;Formal languages;Computer science;Delay","Ada;formal specification;grammars;parallel programming","Ada server tasks specification;executable formal grammars;concurrent programming problems;synchronization constructs;Prolog programs","","4","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Seven layers of knowledge representation and reasoning in support of software development","C. Rich; Y. A. Feldman","Mitsubishi Electr. Res. Lab., Cambridge, MA, USA; NA","IEEE Transactions on Software Engineering","","1992","18","6","451","469","The authors' experience in the Programmer's Apprentice project in applying knowledge representation and automated reasoning to support software development is summarized. A system, called Cake, is described that comprises seven layers of knowledge representation and reasoning facilities: truth maintenance, Boolean constraint propagation, equality, types, algebra, frames, and Plan Calculus. Sessions with two experimental software development tools implemented using Cake, the Requirements Apprentice and the Debugging Assistant, are also included.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.142869","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=142869","","Knowledge representation;Programming;Debugging;Calculus;Software tools;Laboratories;Knowledge engineering;Algebra;Software maintenance;Software prototyping","inference mechanisms;knowledge representation;software engineering;software tools","knowledge representation;reasoning;software development;Programmer's Apprentice;Cake;truth maintenance;Boolean constraint propagation;equality;types;algebra;frames;Plan Calculus;software development tools;Requirements Apprentice;Debugging Assistant","","33","","35","","","","","","IEEE","IEEE Journals & Magazines"
"Predicate logic for software engineering","D. L. Parnas","Dept. of Electr. & Comput. Eng., McMaster Univ., Hamilton, Ont., Canada","IEEE Transactions on Software Engineering","","1993","19","9","856","862","The interpretations of logical expressions found in most introductory textbooks are not suitable for use in software engineering applications because they do not deal with partial functions. More advanced papers and texts deal with partial functions in a variety of complex ways. This paper proposes a very simple change to the classic interpretation of predicate expressions, one that defines their value for all values of all variables, yet is almost identical to the standard definitions. It then illustrates the application of this interpretation in software documentation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.241769","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=241769","","Logic;Software engineering;Application software;Documentation;Design engineering;Mathematics;Programming profession;Calculus;Proposals;Solids","formal logic;software engineering","software engineering;logical expressions;partial functions;predicate expressions;predicate logic;software documentation;tabular expressions","","29","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Requirements specification for process-control systems","N. G. Leveson; M. P. E. Heimdahl; H. Hildreth; J. D. Reese","Dept. of Comput. Sci. & Eng., Washington Univ., Seattle, WA, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1994","20","9","684","707","The paper describes an approach to writing requirements specifications for process-control systems, a specification language that supports this approach, and an example application of the approach and the language on an industrial aircraft collision avoidance system (TCAS II). The example specification demonstrates: the practicality of writing a formal requirements specification for a complex, process-control system; and the feasibility of building a formal model of a system using a specification language that is readable and reviewable by application experts who are not computer scientists or mathematicians. Some lessons learned in the process of this work, which are applicable both to forward and reverse engineering, are also presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.317428","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=317428","","Software safety;Writing;Reverse engineering;Control systems;Costs;Software systems;Software prototyping;System testing;Computer science;Specification languages","process control;process computer control;formal specification;specification languages;position control;aerospace computing;aircraft instrumentation","requirements specification;process-control systems;specification language;example application;industrial aircraft collision avoidance system;TCAS II;example specification;formal requirements specification;formal model;reverse engineering","","252","","26","","","","","","IEEE","IEEE Journals & Magazines"
"The TAME project: towards improvement-oriented software environments","V. R. Basili; H. D. Rombach","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA","IEEE Transactions on Software Engineering","","1988","14","6","758","773","Experience from a dozen years of analyzing software engineering processes and products is summarized as a set of software engineering and measurement principles that argue for software engineering process models that integrate sound planning and analysis into the construction process. In the TAME (Tailoring A Measurement Environment) project at the University of Maryland, such an improvement-oriented software engineering process model was developed that uses the goal/question/metric paradigm to integrate the constructive and analytic aspects of software development. The model provides a mechanism for formalizing the characterization and planning tasks, controlling and improving projects based on quantitative analysis, learning in a deeper and more systematic way about the software process and product, and feeding the appropriate experience back into the current and future projects. The TAME system is an instantiation of the TAME software engineering process model as an ISEE (integrated software engineering environment). The first in a series of TAME system prototypes has been developed. An assessment of experience with this first limited prototype is presented including a reassessment of its initial architecture.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6156","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6156","","Software engineering;Software measurement;Process planning;Computer architecture;NASA;Computer science;Personnel;Programming;Software prototyping;Prototypes","programming environments;software engineering","TAME;process models;University of Maryland;improvement-oriented software engineering;ISEE;integrated software engineering environment","","599","","67","","","","","","IEEE","IEEE Journals & Magazines"
"Extending Ina Jo with temporal logic","J. M. Wing; M. R. Nixon","Dept. of Comput. Sci., Carnegie-Mellon Univ., Pittsburgh, PA, USA; NA","IEEE Transactions on Software Engineering","","1989","15","2","181","197","The authors give both informal and formal descriptions of both the current Ina Jo specification language and Ina Jo enhanced with temporal logic. They include details of a simple example to demonstrate the use of the proof system and details of an extended example to demonstrate the expressiveness of the enhanced language. The authors discuss their language design goals, decisions, and their implications.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21744","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21744","","Formal specifications;Concurrent computing;Specification languages;Security;Logic design;Programming;Software tools;Computer science;Trademarks;Logic functions","specification languages","Ina Jo;temporal logic;specification language;proof system;expressiveness;language design goals;decisions","","5","","39","","","","","","IEEE","IEEE Journals & Magazines"
"Guaranteeing real-time requirements with resource-based calibration of periodic processes","R. Gerber; Seongsoo Hong; M. Saksena","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; NA; NA","IEEE Transactions on Software Engineering","","1995","21","7","579","592","The paper presents a comprehensive design methodology for guaranteeing end to end requirements of real time systems. Applications are structured as a set of process components connected by asynchronous channels, in which the end points are the system's external inputs and outputs. Timing constraints are then postulated between these inputs and outputs; they express properties such as end to end propagation delay, temporal input sampling correlation, and allowable separation times between updated output values. The automated design method works as follows: First new tasks are created to correlate related inputs, and an optimization algorithm, whose objective is to minimize CPU utilization, transforms the end to end requirements into a set of intermediate rate constraints on the tasks. If the algorithm fails, a restructuring tool attempts to eliminate bottlenecks by transforming the application, which is then resubmitted into the assignment algorithm. The final result is a schedulable set of fully periodic tasks, which collaboratively maintain the end to end constraints.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.392979","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=392979","","Calibration;Timing;Real time systems;Design methodology;Constraint optimization;Design optimization;Temperature;Computer science;USA Councils;Performance analysis","real-time systems;formal specification;systems analysis;scheduling;operating systems (computers)","real-time requirements;resource-based calibration;periodic processes;comprehensive design methodology;end to end requirements guarantees;real time systems;process components;asynchronous channels;timing constraints;end to end propagation delay;temporal input sampling correlation;allowable separation times;updated output values;automated design method;optimization algorithm;CPU utilization;intermediate rate constraints;restructuring tool;assignment algorithm;schedulable set;fully periodic tasks;end to end constraint maintenance","","91","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Performance Analyses of Cartesian Product Files and Random Files","C. C. Chang; M. W. Du; R. C. T. Lee","Institute of Computer Engineering, National Chiao-Tung University, Hsinchu, Taiwan, Republic of China.; Institute of Computer Engineering, National Chiao-Tung University, Hsinchu, Taiwan, Republic of China.; Institute of Computer and Decision Sciences, National Tsing Hua University, Hsinchu, Taiwan, Republic of China.","IEEE Transactions on Software Engineering","","1984","SE-10","1","88","99","In this paper, we shall derive two formulas for the average number of buckets to be examined over all possible partial match queries for Cartesian product files and random files, respectively. The superiority of the Cartesian product file is established. A new multi-key file, called a partition file, is introduced. It is shown that both Cartesian product files and random files are special cases of partition files.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010203","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010203","Cartesian product files;partial match queries;partition files;random files","Performance analysis;File systems;Councils","","","","15","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Supporting software designers with integrated domain-oriented design environments","G. Fischer; A. Girgensohn; K. Nakakoji; D. Redmiles","Dept. of Comput. Sci., Colorado Univ., Boulder, CO, USA; Dept. of Comput. Sci., Colorado Univ., Boulder, CO, USA; Dept. of Comput. Sci., Colorado Univ., Boulder, CO, USA; Dept. of Comput. Sci., Colorado Univ., Boulder, CO, USA","IEEE Transactions on Software Engineering","","1992","18","6","511","522","An approach that embeds human-computer cooperative problem-solving tools into knowledge-based design environments that work in conjunction with human software designers in specific application domains is described. This human-centered approach takes advantage of peoples' ability to understand and incrementally reformulate their problems, while allowing them to contribute to the gradual improvement of the underlying knowledge base. The notion of evolution circumvents the inability of the original builders of a design environment to anticipate all future needs and knowledge for complete coverage of a domain. The access and development of knowledge is supported in a cycle of location, comprehension, and modification. Modification includes the evolution of the knowledge base and tools. A framework for building such tools and mechanisms is described and illustrated in terms of three systems: CATALOGEXPLORER, EXPLAINER, and MODIFIER. User studies of these systems demonstrate the promise and the limitations of the design environment approach.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.142873","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=142873","","Software design;Humans;Design engineering;Application software;Software tools;Knowledge engineering;Automatic programming;Problem-solving;Embedded software;Buildings","expert systems;programming environments;user interfaces","problem reformulation;software designers;domain-oriented design environments;human-computer cooperative problem-solving tools;knowledge-based design environments;location;comprehension;modification;CATALOGEXPLORER;EXPLAINER;MODIFIER","","32","","57","","","","","","IEEE","IEEE Journals & Magazines"
"More experience with data flow testing","E. J. Weyuker","Dept. of Comput. Sci., New York Univ., NY, USA","IEEE Transactions on Software Engineering","","1993","19","9","912","919","Experience is provided about the cost and effectiveness of the Rapps-Weyuker data flow testing criteria. This experience is based on studies using a suite of well-known numerical programs, and supplements an earlier study (Weyuker 1990) using different types of programs. The conclusions drawn in the earlier study involving cost are confirmed in this study. New observations about tester variability and cost assessment, as well as fault detection, are also provided.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.241773","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=241773","","Costs;Fault detection;Software testing;Guidelines;Software tools;Computer bugs;NASA;Computer science;Software systems","program testing;software cost estimation","data flow testing;Rapps-Weyuker data flow testing criteria;numerical programs;tester variability;cost assessment;fault detection;software testing;data adequacy","","52","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Function points analysis: an empirical study of its measurement processes","A. Abran; P. N. Robillard","Quebec Univ., Montreal, Que., Canada; NA","IEEE Transactions on Software Engineering","","1996","22","12","895","910","Function point analysis (FPA) was initially designed on the basis of expert judgments, without explicit reference to any theoretical foundation. From the point of view of the measurement scales used in its measurement process, FPA constitutes a potpourri of scales not admissible without the transformations imbedded in the implicit models of expert judgments. The results of this empirical study demonstrate that in a homogeneous environment not burdened with major differences in productivity factors there is a clear relationship between FPA's primary components and work-effort. This empirical study also indicates that there is such a relationship for each step of the FPA measurement process prior to the mixing of scales and the assignments of weights. Comparisons with FPA productivity models based on weights confirm, on the one hand, that the weights do not add information and, on the other, that the weights are fairly robust and can be used when little historical data is available. The full data set is provided for future studies.","0098-5589;1939-3520;2326-3881","","10.1109/32.553638","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=553638","","Size measurement;Productivity;Application software;Artificial intelligence;Software engineering;Software measurement;Robustness;Measurement standards;Standards development;Standards publication","software cost estimation;software metrics;human resource management","function points analysis;measurement processes;measurement scales;homogeneous environment;productivity factors;work-effort;weight assignments","","55","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Programmer-transparent coordination of recovering concurrent processes: philosophy and rules for efficient implementation","K. H. Kim","Dept. of Electr. Eng., California Univ., Irvine, CA, USA","IEEE Transactions on Software Engineering","","1988","14","6","810","821","An approach to coordination of cooperating concurrent processes, each capable of error direction and recovery, is presented. Error detection, rollback, and retry in a process are specified by a well-structured language construct called recovery block. Recovery points of processes must be properly coordinated to prevent a disastrous avalanche of process rollbacks. The approach relies on an intelligent processor system (that runs processes) capable of establishing and discarding the recovery points of interacting processes in a well coordinated manner such that a process never makes two consecutive rollbacks without making a retry between the two, and every process rollback becomes a minimum-distance rollback. Following a discussion of the underlying philosophy of the author's approach, basic rules of reducing storage and time overhead in such a processor system are discussed. Examples are drawn from the systems in which processes communicate through monitors.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6160","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6160","","Military computing;Computer errors;Intelligent systems;Process design","data structures;error detection;fault tolerant computing;multiprocessing programs;programming theory;supervisory programs;system recovery","programmer transparent coordination;system recovery;storage reduction;data structures;recovering concurrent processes;error direction;language construct;recovery block;intelligent processor system;process rollback;minimum-distance rollback;time overhead","","30","","19","","","","","","IEEE","IEEE Journals & Magazines"
"CSP methods for identifying atomic actions in the design of fault tolerant concurrent systems","A. M. Tyrrell; G. F. Carpenter","Dept. of Electron., York Univ., Heslington, UK; NA","IEEE Transactions on Software Engineering","","1995","21","7","629","639","Limiting the extent of error propagation when faults occur and localizing the subsequent error recovery are common concerns in the design of fault tolerant parallel processing systems. Both activities are made easier if the designer associates fault tolerance mechanisms with the underlying atomic actions of the system. With this in mind, the paper has investigated two methods for the identification of atomic actions in parallel processing systems described using CSP. Explicit trace evaluation forms the basis of the first algorithm, which enables a designer to analyze interprocess communications and thereby locate atomic action boundaries in a hierarchical fashion. The second method takes CSP descriptions of the parallel processes and uses structural arguments to infer the atomic action boundaries. This method avoids the difficulties involved with producing full trace sets, but does incur the penalty of a more complex algorithm.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.392983","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=392983","","Fault diagnosis;Fault tolerant systems;Fault tolerance;Algorithm design and analysis;Real time systems;Fault detection;Protection;Electronic switching systems;Parallel processing;Distributed processing","communicating sequential processes;parallel programming;software fault tolerance;program diagnostics","CSP methods;atomic actions;fault tolerant concurrent systems design;error propagation;error recovery;fault tolerant parallel processing systems;fault tolerance mechanisms;underlying atomic actions;explicit trace evaluation;interprocess communications;CSP descriptions;structural arguments;full trace sets;communicating sequential processes","","2","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Projecting software defects from analyzing Ada designs","W. W. Agresti; W. M. Evanco","Mitre Corp., McLean, VA, USA; Mitre Corp., McLean, VA, USA","IEEE Transactions on Software Engineering","","1992","18","11","988","997","Models for projecting software defects from analyses of Ada designs are described. The research is motivated by the need for technology to analyze designs for their likely effect on software quality. The models predict defect density based on product and process characteristics. Product characteristics are extracted from a static analysis of Ada subsystems, focusing on context coupling, visibility, and the import-export of declarations. Process characteristics provide for effects of reuse level and extent of changes. Multivariate regression analyses were conducted with empirical data from industry/government-developed projects: 16 Ada subsystems totaling 149000 source lines of code. The resulting models explain 63-74% of the variation in defect density of the subsystems. Context coupling emerged as a consistently significant variable in the models.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.177368","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=177368","","Software quality;Software design;Predictive models;Software reliability;Maintenance;Q factor;Government;Data mining;Multivariate regression;Context modeling","Ada;software metrics;software quality;software reliability;statistical analysis","software defects projection;context coupling;Ada designs;software quality;defect density;process characteristics;static analysis;visibility;import-export of declarations;reuse level;regression analyses","","50","","33","","","","","","IEEE","IEEE Journals & Magazines"
"How accurate is scientific software?","L. Hatton; A. Roberts","Programming Res. Ltd., Hersham, UK; NA","IEEE Transactions on Software Engineering","","1994","20","10","785","797","This paper describes some results of what, to the authors' knowledge, is the largest N-version programming experiment ever performed. The object of this ongoing four-year study is to attempt to determine just how consistent the results of scientific computation really are, and, from this, to estimate accuracy. The experiment is being carried out in a branch of the earth sciences known as seismic data processing, where 15 or so independently developed large commercial packages that implement mathematical algorithms from the same or similar published specifications in the same programming language (Fortran) have been developed over the last 20 years. The results of processing the same input dataset, using the same user-specified parameters, for nine of these packages is reported in this paper. Finally, feedback of obvious flaws was attempted to reduce the overall disagreement. The results are deeply disturbing. Whereas scientists like to think that their code is accurate to the precision of the arithmetic used, in this study, numerical disagreement grows at around the rate of 1% in average absolute difference per 4000 fines of implemented code, and, even worse, the nature of the disagreement is nonrandom. Furthermore, the seismic data processing industry has better than average quality standards for its software development with both identifiable quality assurance functions and substantial test datasets.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.328993","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=328993","","Data processing;Packaging;Geoscience;Computer languages;Feedback;Arithmetic;Computer industry;Software standards;Standards development;Programming","programming;seismology;geophysics computing;software packages;software quality","scientific software;N-version programming experiment;scientific computation;seismic data processing;large commercial packages;mathematical algorithms;programming language;Fortran;input dataset;seismic data processing industry;quality standards;software development;quality assurance","","58","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Theories of Software Reliability: How Good Are They and How Can They Be Improved?","B. Littlewood","Department of Mathematics, City University","IEEE Transactions on Software Engineering","","1980","SE-6","5","489","500","An examination of the assumptions used in early bug-counting models of software reliability shows them to be deficient. Suggestions are made to improve modeling assumptions and examples are given of mathematical implementations. Model verification via real-life data is discussed and minimum requirements are presented. An example shows how these requirements may be satisfied in practice. It is suggested that current theories are only the first step along what threatens to be a long road.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230790","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702766","Debugging software;program error;reliability growth;software bug count;software failure;software failure rate;software life-cycle cost;software reliability measurement","Software reliability;Software measurement;Testing;Predictive models;Hardware;Battery powered vehicles;Mathematical model;Roads;Computer errors;Costs","","Debugging software;program error;reliability growth;software bug count;software failure;software failure rate;software life-cycle cost;software reliability measurement","","108","","23","","","","","","IEEE","IEEE Journals & Magazines"
"MAP 2.1 conformance testing tools","R. S. Matthews; K. H. Muralidhar; S. Sparks","Commun. & Distributed Syst. Lab., Ind. Technol. Inst., Ann Arbor, MI, USA; Commun. & Distributed Syst. Lab., Ind. Technol. Inst., Ann Arbor, MI, USA; Commun. & Distributed Syst. Lab., Ind. Technol. Inst., Ann Arbor, MI, USA","IEEE Transactions on Software Engineering","","1988","14","3","363","374","The major components of the MAP 2.1 conformance test system are described. Protocol conformance testing and program testing are compared. The scope and process of dynamic conformance testing is reviewed. The architecture of the tests system is presented, first in terms of the developing ISO (International Organization for Standardization) framework, and then in terms of run-time components. Several specific tools which comprise the test system are described. These tools include test engines, a high-level control tool, monitoring and analysis tools, and document handling tools. Benefits and limitations of the test tools are examined. Conclusions and suggestions for future efforts are provided.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4656","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4656","","System testing;Software testing;Software tools;Open systems;Communication system control;Manufacturing automation;Access protocols;Runtime;Engines;Level control","manufacturing computer control;program testing;protocols;software tools","MAP 2.1 conformance testing tools;program testing;ISO;run-time components;test engines;high-level control tool;monitoring;document handling tools","","7","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Concurrency control in distributed databases through time intervals and short-term locks","U. Halici; A. Dogac","Dept. of Electr. & Electron. Eng., Middle East Technic. Univ., Ankara, Turkey; NA","IEEE Transactions on Software Engineering","","1989","15","8","994","1003","A method for concurrency control in distributed database management systems that increases the level of concurrent execution of transactions, called ordering by serialization numbers (OSN), is proposed. The OSN method works in the certifier model and uses time-interval techniques in conjunction with short-term locks to provide serializability and prevent deadlocks. The scheduler is distributed, and the standard transaction execution policy is assumed, that is, the read and write operations are issued continuously during transaction execution. However, the write operations are copied into the database only when the transaction commits. The amount of concurrency provided by the OSN method is demonstrated by log classification. It is shown that the OSN method provides more concurrency than basic timestamp ordering and two-phase locking methods and handles successfully some logs which cannot be handled by any of the past methods. The complexity analysis of the algorithm indicates that the method works in a reasonable amount of time.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.31355","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=31355","","Concurrency control;Distributed databases;Concurrent computing;Transaction databases;System recovery;Costs;Testing;Algorithm design and analysis;Performance analysis;Communication system control","concurrency control;distributed databases","concurrent transaction execution;distributed scheduler;distributed databases;concurrency control;distributed database management systems;ordering by serialization numbers;OSN method;certifier model;time-interval techniques;short-term locks;serializability;deadlocks;standard transaction execution policy;concurrency;log classification;timestamp ordering;two-phase locking;complexity analysis","","7","","22","","","","","","IEEE","IEEE Journals & Magazines"
"The Evolution of Wang Institute's Master of Software Engineering Program","M. A. Ardis","Software Engineering Institute, Carnegie-Mellon University","IEEE Transactions on Software Engineering","","1987","SE-13","11","1149","1155","Master of Software Engineering (MSE) programs are relatively new. Starting such a program is expensive in terms of human and capital resources. Some of the costs are: preparation of new course materials, acquisition of sophisticated equipment and software, and maintenance of a low student/faculty ratio. In addition, MSE students and faculty have special needs, such as technical background and familiarity with current industrial practices.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232863","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702161","Computer science education;Master of Software Engineering;professional-degree programs;programming methods;project management;software tools","Software engineering;Software maintenance;Educational institutions;Information technology;Buildings;Humans;Costs;Refining;Educational programs;Programming profession","","Computer science education;Master of Software Engineering;professional-degree programs;programming methods;project management;software tools","","3","","6","","","","","","IEEE","IEEE Journals & Magazines"
"A Semantic Design Method","I. T. Hawryszkiewycz","School of Information Sciences, Canberra College of Advanced Education","IEEE Transactions on Software Engineering","","1983","SE-9","4","373","384","A system design method where the computer system is adapted to user semantics is described. In the method, user semantics are defined as abstract objects using special languages. Both user data semantics and user operations are defined. A translator converts the abstract definitions into internal machine storage representation and machine instructions. Users can then include the defined operations in user programs. Execution of the user operations transforms the internal state consistently with the definition of the operations.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.237025","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703072","Abstract data types;adaptive systems;correctness;database;semantics;software design","Design methodology;Adaptive systems;Data structures;Data models;Databases;Computer interfaces;Computer architecture;Software design;Computer aided instruction;Computer science education","","Abstract data types;adaptive systems;correctness;database;semantics;software design","","","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Experimentation in software engineering","V. R. Basili; R. W. Selby; D. H. Hutchens","Department of Computer Science, University of Maryland, College Park, MD 20742; Department of Computer SCience, University of Maryland, College Park, MD 20742; Department of Information and Computer Science, University of California, Irvine, CA 92717; Department of Computer Science, Clemson University, Clemson, SC 29634","IEEE Transactions on Software Engineering","","1986","SE-12","7","733","743","A framework is presented for analyzing most of the experimental work performed in software engineering over the past several years. The framework of experimentation consists of four categories corresponding to phases of the experimentation process: definition, planning, operation, and interpretation. A variety of experiments are described within the framework and their contribution to the software engineering discipline is discussed. Some recommendations for the application of the experimental process in software engineering are included.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312975","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312975","Controlled experiment;data collection and analysis;empirical study;experimental design;software metrics;software technology measurement and evaluation","Software;Testing;Software engineering;Measurement;Educational institutions;Programming;Debugging","software engineering","software engineering;experimental process","","61","","","","","","","","IEEE","IEEE Journals & Magazines"
"Perturbation techniques for detecting domain errors","S. J. Zeil","Dept. of Comput. Sci., Old Dominion Univ., Norfolk, VA, USA","IEEE Transactions on Software Engineering","","1989","15","6","737","746","Perturbation testing is an approach to software testing which focuses on faults within arithmetic expressions appearing throughout a program. This approach is expanded to permit analysis of individual test points rather than entire paths, and to concentrate on domain errors. Faults are modeled as perturbing functions drawn from a vector space of potential faults and added to the correct form of an arithmetic expression. Sensitivity measures are derived which limit the possible size of those faults that would go undetected after the execution of a given test set. These measures open up an interesting view of testing, in which attempts are made to reduce the volume of possible faults which, were they present in the program being tested, would have escaped detection on all tests performed so far. The combination of these measures with standard optimization techniques yields a novel test-data-generation method called arithmetic fault detection.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24727","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24727","","Perturbation methods;Software testing;Error correction;Fault detection;Size measurement;Volume measurement;Measurement standards;Optimization methods;Floating-point arithmetic;Computer science","error detection;perturbation techniques;program testing","error detection;sensitivity measures;software testing;arithmetic expressions;individual test points;domain errors;perturbing functions;vector space;potential faults;test set;standard optimization techniques;novel test-data-generation method;arithmetic fault detection","","22","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Approximate analysis of reader/writer queues","T. Johnson","Dept. of Comput. & Inf. Sci., Florida Univ., Gainesville, FL, USA","IEEE Transactions on Software Engineering","","1995","21","3","209","218","We analyze the performance of queues that serve readers and writers. Readers are served concurrently, while writers require exclusive service. We approximately analyze a first-come-first-serve (FCFS) reader/writer queue, and derive simple formulae for computing waiting times and capacity under the assumption of Poisson arrivals and exponential service. We extend the analysis to handle a one writer queue, and a queue that includes write intention locks. The simple analyses that we present can be used as rules of thumb for designing concurrent systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.372148","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=372148","","Queueing analysis;Databases;Performance analysis;Concurrency control;Predictive models;Data analysis;Algorithm design and analysis;Operating systems;Concurrent computing;Delay","queueing theory;concurrency control;resource allocation","approximate analysis;reader/writer queues;exclusive service;first-come-first-serve;FCFS reader/writer queue;waiting times;Poisson arrivals;exponential service;one writer queue;write intention locks;concurrent systems design;performance analysis;queuing system;resource allocation;concurrency control algorithms","","12","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Load-leveling in fault-tolerant distributed computing systems","L. M. Patnaik; K. V. Iyer","School of Automation, Indian Institute of Science, Bangalore 560012, India; Vikram Sarabhai Space Centre, Trivandrum 695022, India","IEEE Transactions on Software Engineering","","1986","SE-12","4","554","560","Assuming a horizontally distributed computing system, formulations of the edge-failure and node-failure recovery problems from the standpoint of load-leveling are presented. The conditions for the existence of solutions to these problems are examined and simple algorithms are proposed for these problems. In connection with the node-failure recovery problem, the concept of a node-failure metric to characterize different possible solutions is introduced, exploiting the notion of the strength of processors. A possible application of the recovery methods in the context of reconfiguration of distributed database systems is suggested.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312903","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312903","Distributed computing systems;fault-recovery;horizontal distribution;load-leveling;work load allocation","Program processors;Resource management;Measurement;Context;Distributed computing;Throughput;Arrays","distributed processing;fault tolerant computing;system recovery","load leveling;fault-tolerant distributed computing systems;horizontally distributed computing system;edge-failure;node-failure recovery;recovery methods;reconfiguration","","1","","","","","","","","IEEE","IEEE Journals & Magazines"
"On satisfying timing constraints in hard-real-time systems","J. Xu; D. L. Parnas","Dept. of Comput. Sci., York Univ., North York, Ont., Canada; NA","IEEE Transactions on Software Engineering","","1993","19","1","70","84","The authors explain why pre-run-time scheduling is essential if one wishes to guarantee that timing constraints will be satisfied in a large complex hard-real-time system. They examine some of the major concerns in pre-run-time scheduling and consider what formulations of mathematical scheduling problems can be used to address those concerns. This work provides a guide to the available algorithms.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.210308","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=210308","","Timing;Processor scheduling;Application software;Military computing;Software safety;Control systems;Error correction;Scheduling algorithm;Computer applications;Degradation","operating systems (computers);real-time systems;scheduling","timing constraints;hard-real-time systems;pre-run-time scheduling;mathematical scheduling problems","","115","","59","","","","","","IEEE","IEEE Journals & Magazines"
"Concurrent Broadcast for Information Dissemination","D. M. Topkis","Graduate School of Administration, University of California","IEEE Transactions on Software Engineering","","1985","SE-11","10","1107","1112","Concurrent broadcast involves the dissemination of a database, consisting of messages initially distributed among the nodes of a network, so that a copy of the entire database eventually resides at each node. One application is the dissemination of network status information for adaptive routing in a communications network. This paper examines the time complexity and communication complexity of several distributed procedures for concurrent broadcast. The procedures do not use information depending on the network topology. The worst-case time complexity of a flooding procedure for concurrent broadcast is shown to be linear in the number of nodes plus the number of messages, and no other procedure for concurrent broadcast has a better worst-case time complexity. A variant of flooding is proposed to eliminate redundant message receipts from the flooding process by real-time signaling between neighbors concerning messages residing at each. This variant can reduce communication complexity, while having a worst-case time complexity similar in form to that of the flooding procedure. Special properties of concurrent broadcast in a tree are also given. The present time complexity results can be used to bound the time during which inconsistent databases may reside at different nodes, to evaluate and compare procedures for (or including) concurrent broadcast, and to schedule a sequence of instances of concurrent broadcast so that the instances do not overlap and there is no need for sequence numbers.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231858","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701926","Adaptive routing;broadcast;communication complexity;concurrent broadcast;distributed computation;distributed database;information dissemination;time complexity","Broadcasting;Routing;Databases;Complexity theory;Floods;Centralized control;Communication networks;Network topology;Signal processing;Concurrent computing","","Adaptive routing;broadcast;communication complexity;concurrent broadcast;distributed computation;distributed database;information dissemination;time complexity","","6","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Automatically generating test data from a Boolean specification","E. Weyuker; T. Goradia; A. Singh","AT&T Bell Labs., Murray Hill, NJ, USA; NA; NA","IEEE Transactions on Software Engineering","","1994","20","5","353","363","This paper presents a family of strategies for automatically generating test data for any implementation intended to satisfy a given specification that is a Boolean formula. The fault detection effectiveness of these strategies is investigated both analytically and empirically, and the costs, assessed in terms of test set size, are compared.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.286420","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=286420","","Automatic testing;Genetic mutations;Fault detection;Software testing;Formal specifications;System testing;Computer bugs;Costs;Aircraft;Collision avoidance","program testing;formal specification;Boolean algebra","test data generation;Boolean specification;fault detection effectiveness;costs;test set size;automatic test case generation;black-box testing;software testing","","139","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Partition strategy for distributed query processing in fast local networks","C. T. Yu; K. -. Guh; D. Brill; A. L. P. Chen","Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1989","15","6","780","793","A partition-and-replicate strategy for processing distributed queries referencing no fragmented relation is sketched. An algorithm is given to determine which relation and which copy of the relation is to be partitioned into fragments, how the relation is to be partitioned, and where the fragments are to be sent for processing. Simulation results show that the partition strategy is useful for processing queries in fast local network environments. The results also show that the number of partitions does not need to be large. The use of semijoins in the partition strategy is discussed. A necessary and sufficient condition for a semijoin to yield an improvement is provided.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24731","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24731","","Query processing;Intelligent networks;Relational databases;Partitioning algorithms;Data communication;Costs;Parallel processing;Sufficient conditions;Information science;Performance analysis","database theory;distributed databases;local area networks;query languages","simulation results;distributed query processing;partition-and-replicate strategy;fragmented relation;fast local network environments;semijoins","","22","","51","","","","","","IEEE","IEEE Journals & Magazines"
"Lessons from using Z to specify a software tool","M. Neil; G. Ostrolenk; M. Tobin; M. Southworth","Centre for Software Reliability, City Univ., London, UK; NA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","1","15","23","The authors were recently involved in the development of a COBOL parser (G. Ostrolenk et al., 1994), specified formally in Z. The type of problem tackled was well suited to a formal language. The specification process was part of a life cycle characterized by the front loading of effort in the specification stage and the inclusion of a statistical testing stage. The specification was found to be error dense and difficult to comprehend. Z was used to specify inappropriate procedural rather than declarative detail. Modularity and style problems in the Z specification made it difficult to review. In this sense, the application of formal methods was not successful. Despite these problems the estimated fault density for the product was 1.3 faults per KLOC, before delivery, which compares favorably with IBM's Cleanroom method. This was achieved, despite the low quality of the Z specification, through meticulous and effort intensive reviews. However, because the faults were in critical locations, the reliability of the product was assessed to be unacceptably low. This demonstrates the necessity of assessing reliability as well as ""correctness"" during system testing. Overall, the experiences reported in the paper suggest a range of important lessons for anyone contemplating the practical application of formal methods.","0098-5589;1939-3520;2326-3881","","10.1109/32.663995","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=663995","","Software tools;Statistical analysis;Productivity;Formal languages;Computer Society;System testing;Rail transportation;Telecommunication switching;Power generation","formal specification;specification languages;formal languages;COBOL;program compilers;software performance evaluation;software reliability","software tool specification;COBOL parser;formal language;specification process;life cycle;front loading;statistical testing stage;Z specification;fault density;critical locations;reliability;correctness;system testing;formal methods","","1","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Support for Distributed Transactions in the TABS Prototype","A. Z. Spector; J. Butcher; D. S. Daniels; D. J. Duchamp; J. L. Eppinger; C. E. Fineman; A. Heddaya; P. M. Schwarz","Department of Computer Science, Carnegie-Mellon University; NA; NA; NA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","6","520","530","The TABS prototype is an experimental facility that provides operating system-level support for distributed transactions that operate on shared abstract types. The facility is designed to simplify the construction of highly available and reliable distributed applications. This paper describes the TABS system model, the TABS prototype's structure, and certain aspects of its operation. The paper concludes with a discussion of the status of the project and a preliminary evaluation.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232244","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702049","Availability;distributed databases;distributed systems;overating systems organization;reliability;transaction-based systems;virtual memory","Prototypes;Buildings;Laboratories;Computer science;Concurrent computing;Jacobian matrices;Programming profession;Distributed databases;Transaction databases;Computerized monitoring","","Availability;distributed databases;distributed systems;overating systems organization;reliability;transaction-based systems;virtual memory","","15","","35","","","","","","IEEE","IEEE Journals & Magazines"
"Stability and Distributed Scheduling Algorithms","J. A. Stankovic","Department of Computer Science, Carnegie-Mellon University","IEEE Transactions on Software Engineering","","1985","SE-11","10","1141","1152","Many distributed scheduling algorithms have been developed and reported in the current literature. However, very few of them explicitly treat stability issues. This paper first discusses stability issues for distributed scheduling algorithms in general terms. Two very different distributed scheduling algorithms which contain explicit mechanisms for stability are then presented and evaluated with respect to individual specific stability issues. One of the agorithms is based on stochastic learning automata and the other on bidding. The results indicate how very specific the treatment of stability is to the algorithm and environnent under consideration.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231862","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701930","Bidding;distributed computing;real time;stability;stochastic learning automata","Stability;Scheduling algorithm;Learning automata;Stochastic processes;Distributed computing;Analytical models;Testing;Feedback;Algorithm design and analysis;Computational modeling","","Bidding;distributed computing;real time;stability;stochastic learning automata","","24","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Prototyping Versus Specifying: A Multiproject Experiment","B. W. Boehm; T. E. Gray; T. Seewaldt","Software and Information Systems, Division, TRW Defense Systems Group, Redondo Beach, CA 90278; University of California, Los Angeles, CA 90024.; Department of Computer Science, School of Engineering and Applied Science, University of California, Los Angeles, CA 90024.; Department of Computer Science, University of California, Los Angeles, CA 90024.; Universitact Kaiserslautern, Kaiserslautern, West Germany.","IEEE Transactions on Software Engineering","","1984","SE-10","3","290","303","In this experiment, seven software teams developed versions of the same small-size (2000-4000 source instruction) application software product. Four teams used the Specifying approach. Three teams used the Prototyping approach. The main results of the experiment were the following. 1) Prototyping yielded products with roughly equivalent performance, but with about 40 percent less code and 45 percent less effort. 2) The prototyped products rated somewhat lower on functionality and robustness, but higher on ease of use and ease of learning. 3) Specifying produced more coherent designs and software that was easier to integrate. The paper presents the experimental data supporting these and a number of additional conclusions.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010238","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010238","Prototypes;requirements analysis;software engineering;software engineering education;software management;software metrics;specifications","Prototypes;Software prototyping;Application software;Programming;Costs;Robustness;Software design;Software engineering;Educational products;Engineering management","","","","133","","13","","","","","","IEEE","IEEE Journals & Magazines"
"A Technique for Estimating Performance of Fault-Tolerant Programs","R. D. Schlichting","Department of Computer Science, University of Arizona","IEEE Transactions on Software Engineering","","1985","SE-11","6","555","563","A technique is presented for estimating the performance of programs written for execution on fail-stop processors. It is based on modeling the program as a discrete-time Markov chain and then using z-transforms to derive a probability distribution for time to completion.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232493","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702053","Fail-stop processors;fault-tolerant computing;Markov chains;performance evaluation;z-transforms","Fault tolerance;Probability distribution;Fault tolerant systems;Software performance;Distributed computing;Random variables;Writing;Computer crashes;Control theory","","Fail-stop processors;fault-tolerant computing;Markov chains;performance evaluation;z-transforms","","4","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Combining static concurrency analysis with symbolic execution","M. Young; R. N. Taylor","Dept. of Inf. & Comput. Sci., California Univ., Irvine, CA, USA; Dept. of Inf. & Comput. Sci., California Univ., Irvine, CA, USA","IEEE Transactions on Software Engineering","","1988","14","10","1499","1511","Static concurrency analysis detects anomalous synchronization patterns in concurrent programs, but may also report spurious errors involving infeasible execution paths. Integrated application of static concurrency analysis and symbolic execution sharpens the results of the former without incurring the full costs of the latter when applied in isolation. Concurrency analysis acts as a path selection mechanism for symbolic execution, while symbolic execution acts as a pruning mechanism for concurrency analysis. Methods of combining the techniques follow naturally from explicit characterization and comparison of the state spaces explored by each, suggesting a general approach for integrating state-based program analysis techniques in a software development environment.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6195","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6195","","Concurrent computing;Pattern analysis;State-space methods;History;Costs;Programming;Computer errors;Error correction;System recovery;Algorithm design and analysis","parallel programming;program testing","program testing;static concurrency analysis;symbolic execution;synchronization patterns;concurrent programs;path selection mechanism;concurrency analysis;program analysis;software development environment","","30","","36","","","","","","IEEE","IEEE Journals & Magazines"
"An information retrieval approach for automatically constructing software libraries","Y. S. Maarek; D. M. Berry; G. E. Kaiser","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; NA; NA","IEEE Transactions on Software Engineering","","1991","17","8","800","813","A technology for automatically assembling large software libraries which promote software reuse by helping the user locate the components closest to her/his needs is described. Software libraries are automatically assembled from a set of unorganized components by using information retrieval techniques. The construction of the library is done in two steps. First, attributes are automatically extracted from natural language documentation by using an indexing scheme based on the notions of lexical affinities and quantity of information. Then a hierarchy for browsing is automatically generated using a clustering technique which draws only on the information provided by the attributes. Due to the free-text indexing scheme, tools following this approach can accept free-style natural language queries.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.83915","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=83915","","Information retrieval;Software libraries;Indexing;Documentation;Programming profession;Productivity;Assembly;Natural languages;Computer science;Data mining","automatic programming;information retrieval systems;natural languages;software reusability;subroutines","information retrieval approach;large software libraries;software reuse;attributes;natural language documentation;indexing scheme;lexical affinities;browsing;clustering technique;free-text indexing scheme;free-style natural language queries","","136","","41","","","","","","IEEE","IEEE Journals & Magazines"
"Evaluating software design processes by analyzing change data over time","L. J. Chmura; A. F. Norcio; T. J. Wicinski","US Naval Res. Lab., Washington, DC, USA; US Naval Res. Lab., Washington, DC, USA; NA","IEEE Transactions on Software Engineering","","1990","16","7","729","740","An analysis is presented of early design and code change data from the software cost reduction (SCR) project, a well-reported effort conducted at the US Naval Research Laboratory from 1978 to 1988. The analyses are mostly time-based studies of the change data and relationships between the data and SCR personnel activity data. Some analyses of the change data show patterns consistent with a major goal of the SCR project: the design and development of easy-to-change software. Specifically, most changes took a day or less to uncover and resolve; the majority of changes updated at most one module. Moreover, these percentages remained fairly stable. No positive relationship appeared between error-correction effort and the number of days that an error remained in the SCR design documentation. Other analyses suggest that consistency may have been temporary. For example, the analyses suggest a stepwise growth in average change effort, and an increasing percentage of changes resulted in module interface updates. Certain specific ratios between SCR change data and personnel activity data may be possible indicators of design incompleteness.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.56099","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=56099","","Software design;Data analysis;Thyristors;Laboratories;Personnel;Electrical capacitance tomography;Software engineering;Costs;Statistical analysis;Guidelines","software engineering","software design processes evaluation;early design and code change data;software cost reduction;error-correction effort;stepwise growth;module interface updates","","6","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Lock Conversion in Non-Two-Phase Locking Protocols","C. Mohan; D. Fussell; Z. M. Kedem; A. Silberschatz","IBM Research Laboratory; NA; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","1","15","22","A locking protocol is a set of rules governing the manner in which the database entities may be accessed. Such a protocol usually employs several kinds of locks. Most of the previous work in this area has assumed that once a transaction acquires a particular kind of lock on a data item it is not allowed to convert this lock to another kind. In this paper we perform a systematic study of the consequences of allowing lock conversions in non-two-phase locking protocols, and show how this leads to increased concurrency and affects deadlock-freedom. The non-two-phase protocols that we study are the very general guard protocols defined for databases in which a directed acyclic graph structure can be superimposed on the data items. We present very natural generalizations of these protocols, including correctness proofs, and develop deadlock removal methods.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231533","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701894","Concurrency;consistency;database systems;deadlocks;locking protocols;rollbacks;serializability;transactions","System recovery;Access protocols;Transaction databases;Concurrent computing;Computer science;Database systems;Information retrieval;Concurrency control;Laboratories;Proposals","","Concurrency;consistency;database systems;deadlocks;locking protocols;rollbacks;serializability;transactions","","8","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Object-oriented software evolution","K. J. Lieberherr; C. Xiao","Coll. of Comput. Sci., Northeastern Univ., Boston, MA, USA; Coll. of Comput. Sci., Northeastern Univ., Boston, MA, USA","IEEE Transactions on Software Engineering","","1993","19","4","313","343","The authors review propagation patterns for describing object-oriented software at a higher level of abstraction than one used by today's programming languages. A propagation pattern defines a family of programs from which one can select a member by giving a class dictionary graph that details the structure of behavior through part-of and inheritance relationships between classes. Three concepts are introduced: evolution histories, growth-plans and a propagation-directive calculus. Evolution histories describe a sequence of development phases of an object-oriented program, each phase being executable and therefore testable. To keep the programs flexible and short, they are described in terms of propagation patterns. Each phase of an evolution history is tested in small steps that are constrained by class dictionary graphs belonging to a growth-plan. Propagation directives are useful for describing both propagation patterns and growth-plans and are therefore endowed with sufficient expressiveness by being given a formal calculus applicable to object-oriented programming in general. A propagation directive is a succinct description of a family of submodels for a given family of data models.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.223802","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=223802","","Object oriented programming;History;Testing;Dictionaries;Calculus;Propagation delay;Books;Computer languages;Data models;Software performance","object-oriented programming","object-oriented software evolution;propagation patterns;class dictionary graph;inheritance relationships;evolution histories;growth-plans;propagation-directive calculus;formal calculus;submodels;data models","","33","","48","","","","","","IEEE","IEEE Journals & Magazines"
"Achieving dependability throughout the development process: a distributed software experiment","J. P. J. Kelly; S. C. Murphy","Dept. of Electr. & Comput. Eng., California Univ., Santa Barbara, CA, USA; NA","IEEE Transactions on Software Engineering","","1990","16","2","153","165","Distributed software engineering techniques and methods for improving the specification and testing phases are considered. To examine these issues, an experiment was performed using the design diversity approach in the specification, design, implementation, and testing of distributed software. In the experiment, three diverse formal specifications were used to produce multiple independent implementations of a distributed communication protocol in Ada. The problems encountered in building complex concurrent processing systems in Ada were also studied. Many pitfalls were discovered in mapping the formal specifications into Ada implementations.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44379","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44379","","Software testing;Automatic testing;Fault tolerance;Software engineering;Formal specifications;Hardware;Fault detection;Software performance;Protocols;Buildings","Ada;computer communications software;data communication systems;distributed processing;formal specification;program testing;protocols","distributed software engineering;B/B testing;automated testing;software testing;dependability;multiple independent implementations;distributed communication protocol;Ada;complex concurrent processing systems","","15","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Interprocess communication dependency on network load","A. Braccini; A. Del Bimbo; E. Vicario","Dipartimento di Sistemi e Inf., Firenze Univ., Italy; Dipartimento di Sistemi e Inf., Firenze Univ., Italy; Dipartimento di Sistemi e Inf., Firenze Univ., Italy","IEEE Transactions on Software Engineering","","1991","17","4","357","369","Results of an analysis of the communication performance as perceived by the application layer in the presence of background load are presented. The analysis was carried out on two distinct protocol suites, TCP/IP and XNS, on a single Ethernet LAN with personal computer workstations. Service times for a reliable transfer and an unreliable transmission as perceived by the application layer were measured. An appropriate model of the reliable transfer process was used to derive service time analytical estimates. Owing to the close relation between measured and estimated values, the model was used to identify the major sources of delay and to evaluate the effects of possible improvements. The most important causes affecting the transport layer performance as background load increases are identified, and different strategies are examined in order to reduce their impact. The improvement margin offered by the implementation of a lightweight transport protocol specifically tailored to the requirements of a bulk data transfer over an Ethernet is addressed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.90435","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=90435","","Application software;Ethernet networks;Delay estimation;Performance analysis;Protocols;TCPIP;Local area networks;Microcomputers;Workstations;Delay effects","local area networks;performance evaluation;protocols","interprocess communication dependency;network load;communication performance;application layer;background load;protocol suites;TCP/IP;XNS;Ethernet LAN;personal computer workstations;reliable transfer;unreliable transmission;service time analytical estimates;transport protocol;bulk data transfer","","5","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Provable improvements on branch testing","P. G. Frankl; E. J. Weyuker","Dept. of Comput. Sci., Polytechnic Univ., Brooklyn, NY, USA; NA","IEEE Transactions on Software Engineering","","1993","19","10","962","975","This paper compares the fault-detecting ability of several software test data adequacy criteria. It has previously been shown that if C/sub 1/ properly covers C/sub 2/, then C/sub 1/ is guaranteed to be better at detecting faults than C/sub 2/, in the following sense: a test suite selected by independent random selection of one test case from each subdomain induced by C/sub 1/ is at least as likely to detect a fault as a test suite similarly selected using C/sub 2/. In contrast, if C/sub 1/ subsumes but does not properly cover C/sub 2/, this is not necessarily the case. These results are used to compare a number of criteria, including several that have been proposed as stronger alternatives to branch testing. We compare the relative fault-detecting ability of data flow testing, mutation testing, and the condition-coverage techniques, to branch testing, showing that most of the criteria examined are guaranteed to be better than branch testing according to two probabilistic measures. We also show that there are criteria that can sometimes be poorer at detecting faults than substantially less expensive criteria.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.245738","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=245738","","Fault detection;Software testing;Genetic mutations;Concrete;Space technology;Computer science;Fluid flow measurement;Costs;NASA;Software systems","program debugging;program testing;programming theory","branch testing;fault-detecting ability;software test data adequacy;test suite;independent random selection;data flow testing;mutation testing;condition-coverage techniques;probabilistic measure;software testing","","63","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Modular verification of data abstractions with shared realizations","G. W. Ernst; R. J. Hookway; W. F. Ogden","Dept. of Comput. Eng. & Sci., Case Western Reserve Univ., Cleveland, OH, USA; NA; NA","IEEE Transactions on Software Engineering","","1994","20","4","288","307","Presents a method for the modular specification and verification of data abstractions in which multiple abstract objects share a common realization level data structure. Such shared realizations are an important implementation technique for data abstractions, because they provide for efficient use of memory; i.e., they allow the amount of memory allocated to the realization of an abstract object to be dynamic, so that only the amount of memory needed for its realization is allocated to it at any one time. To be explicit, an example of this kind of data abstraction is given. Although a number of programming languages provide good support for shared realizations, there has been limited research on its specification and verification. An important property of The authors' method is that it allows data abstractions to be dealt with modularly; i.e., each data abstraction can be specified and verified individually. Its abstract specification is made available for use by other program modules, but all of its implementation details are hidden, which simplifies the verification of code that uses the abstraction. The authors have developed semantics for data abstractions and their method of specification, and have used it to prove that their verification method is logically sound and relatively complete in the sense of Cook (1978). The use of shared realizations impacts specification and verification in several related ways. The manipulation of one abstract object may inadvertently produce a side effect on other abstract objects. Without shared realizations, such unwanted side effects can be prevented by scoping rules, but this is not possible with shared realizations. Instead, the absence of such side effects must be explicitly proven by the verification method. This requires the specification language to provide for quantification over the currently active (allocated) instances of an abstract type that is not necessary for the specification of less advanced implementations of data abstractions.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.277576","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=277576","","Data structures;Computer languages;Specification languages;Application software;National security;Information science;Aggregates;Runtime","data structures;program verification;specification languages","modular verification;data abstractions;shared realizations;modular specification;realization level data structure;abstract specification;semantics;quantification","","7","","50","","","","","","IEEE","IEEE Journals & Magazines"
"Experience with Path Analysis and Testing of Programs","M. R. Woodward; D. Hedley; M. A. Hennell","Department of Computational and Statistical Science, University of Uverpool; NA; NA","IEEE Transactions on Software Engineering","","1980","SE-6","3","278","286","There are a number of practical difficulties in performing a path testing strategy for computer programs. One problem is in deciding which paths, out of a possible infinity, to use as test cases. A hierarchy of structural test metrics is suggested to direct the choide and to monitor the coverge of test paths. Another problem is that many of the chosen paths may be infeasible in the sense that no test data can ever execute them. Experience with the use of ""allegations"" to circumvent this problem and prevent the static generation of many infeasible paths is reported.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230473","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702729","Alegations;infeasible paths;path testing;test metrics","H infinity control;Software testing;Performance analysis;Performance evaluation;Computerized monitoring;Councils;Reliability theory;Feedback;Imaging phantoms;Linear code","","Alegations;infeasible paths;path testing;test metrics","","98","","15","","","","","","IEEE","IEEE Journals & Magazines"
"MuseA Computer Assisted Verification System","J. D. Halpern; S. Owre; N. Proctor; W. F. Wilson","Department of Government Research and Development, Sytek, Inc.; NA; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","2","151","156","Muse is a verification system which extends the collection of tools developed by SRI International for their Hierarchical Development Methodology (HDM). It enhances the SRI system by providing a capability for proving invariants and constraints for the state machine described by a specification written in SPECIAL (the specification language of HDM). In particular, it enables one to use the HDM system to meet the requirements for formal verification in a National Computer Security Center A1 evaluation of a secure operating system. In addition to the tools provided by SRI, Muse has a parser, a facility to handle multiple modules, a formula generator, and a theorem prover. The theorem prover has a number of interesting features designed to facilitate human direction of the proving process. In concept, it is open-ended. We introduce the notion of a theorem prover kernel as a device for ensuring the logical soundness of the prover in the face of continual improvements to its functionality.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.226477","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702196","Formal specification;formal verification;HDM;interactive theorem proving;Muse;National Computer Security Center;software verification;SPECIAL;theorem prover","Formal verification;Computer security;Multilevel systems;Operating systems;Specification languages;Humans;Kernel;Software;Formal specifications;NASA","","Formal specification;formal verification;HDM;interactive theorem proving;Muse;National Computer Security Center;software verification;SPECIAL;theorem prover","","2","","14","","","","","","IEEE","IEEE Journals & Magazines"
"A case study of CES: a distributed collaborative editing system implemented in Argus","I. Greif; A. Seliger; W. Weihl","Lab. for Comput. Sci., MIT, Cambridge, MA, USA; Lab. for Comput. Sci., MIT, Cambridge, MA, USA; Lab. for Comput. Sci., MIT, Cambridge, MA, USA","IEEE Transactions on Software Engineering","","1992","18","9","827","839","Experience implementing CES, a distributed collaborative editing system, is described. CES was written in Argus, a language that was designed to support the construction of reliable distributed programs, and exhibits a number of requirements typical of distributed applications. The authors' experience illustrates numerous areas in which the support provided by Argus for meeting those requirements was quite helpful, but also identifies several areas in which the support provided by Argus was inadequate. Some of the problems arise because of the distinction in Argus (and in other systems) between locally and remotely accessible data and the mechanisms provided for implementing each. Others arise because of limitations of the mechanisms for building user-defined data types. The authors discuss the problems they encountered, including the implications for other systems. They also suggest solutions to the problems, or in some cases further research directed at finding solutions.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.159831","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=159831","","Computer aided software engineering;Collaboration;Collaborative work;Computer science;Writing;Intelligent networks;Collaborative tools;Books;Computerized monitoring;Application software","data structures;groupware;parallel languages;text editing","distributed collaborative editing system;Argus;reliable distributed programs;distributed applications;remotely accessible data;user-defined data types","","18","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Measurement and analysis of workload effects on fault latency in real-time systems","M. H. Woodbury; K. G. Shin","Dept. of Electr. Eng. & Comput. Sci., Michigan Univ., Ann Arbor, MI, USA; Dept. of Electr. Eng. & Comput. Sci., Michigan Univ., Ann Arbor, MI, USA","IEEE Transactions on Software Engineering","","1990","16","2","212","216","The authors demonstrate the need to address fault latency in highly reliable real-time control computer systems. It is noted that the effectiveness of all known recovery mechanisms is greatly reduced in the presence of multiple latent faults. The presence of multiple latent faults increases the possibility of multiple errors, which could result in coverage failure. The authors present experimental evidence indicating that the duration of fault latency is dependent on workload. A synthetic work generator is used to vary the workload, and a hardware fault injector is applied to inject transient faults of varying durations. This method makes it possible to derive the distribution of fault latency duration. Experimental results obtained from the fault-tolerant multiprocessor at the NASA Airlab are presented and discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44383","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44383","","Delay;Real time systems;Computer errors;Hardware;Control systems;NASA;Laboratories;Time sharing computer systems;Fault tolerance;Physics computing","control systems;fault tolerant computing;multiprocessing systems;program testing;real-time systems;software engineering;system recovery","workload effects;fault latency;real-time systems;control computer systems;recovery mechanisms;multiple latent faults;coverage failure;synthetic work generator;hardware fault injector;fault-tolerant multiprocessor;NASA Airlab","","6","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Deadline-Oriented Servicing: Waiting-Time Distributions","B. Walke; W. Rosenbohm","AEG-TELEFUNKEN, Research Institute of Ulm; NA","IEEE Transactions on Software Engineering","","1980","SE-6","3","304","312","An infinite queue single server model is considered where requests arrive from independent Poisson streams and demand service according to arbitrary distribution functions which may be different for different requests. Associated with each request is an urgency number which, together with request's time of arrival, defines a deadline for beginning its service. This relative urgency discipline has at its two limiting case the fint-come first-serve and head of the line discipline. In [1] the mean waiting time is computed approximately and dose bounds are derived there. Here we present simulation results, derive close approximations for the tails of the waiting-time distribution functions and compare them to those of the two limiting cases.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230477","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702733","Computer performance evaluation;queuing analysis","Real time systems;Reactive power;Random variables;Distribution functions","","Computer performance evaluation;queuing analysis","","1","","6","","","","","","IEEE","IEEE Journals & Magazines"
"Systematic program development","R. G. Dromey","Dept. of Comput. Sci., Wollongong Univ., NSW, Australia","IEEE Transactions on Software Engineering","","1988","14","1","12","29","A constructive method of program development is presented. It is based on a simple strategy for problem decomposition that is claimed to be more supportive of goal-oriented programming than the Wirth-Dijkstra top-down refinement method. With the proposed method, a program is developed by making a sequence of refinements, each of which can establish the postcondition for a corresponding sequence of progressively weaker preconditions until a mechanism has been composed that will establish the postcondition for the original given precondition for the problem. The strategy can minimize case analysis, simplify constructive program proofs, and ensure a correspondence between program structure and data structure.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4619","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4619","","Data structures;Process design;Formal specifications;Pressing;Proposals;Information technology;Australia;Partitioning algorithms","programming;software engineering","program development;problem decomposition;goal-oriented programming;refinements;postcondition;case analysis;constructive program proofs;program structure;data structure","","3","","15","","","","","","IEEE","IEEE Journals & Magazines"
"The Requirements Apprentice: automated assistance for requirements acquisition","H. B. Reubenstein; R. C. Waters","Mitre Corp., Bedford, MA, USA; NA","IEEE Transactions on Software Engineering","","1991","17","3","226","240","An automated tool called the Requirements Apprentice (RA) which assists a human analyst in the creation and modification of software requirements is presented. Unlike most other requirements analysis tools, which start from a formal description language, the focus of the RA is on the transition between informal and formal specifications. The RA supports the earliest phases of creating a requirement, in which ambiguity, contradiction, and incompleteness are inevitable. From an artificial intelligence perspective, the central problem the RA faces is one of knowledge acquisition. The RA develops a coherent internal representation of a requirement from an initial set of disorganized imprecise statements. To do so, the RA relies on a variety of techniques, including dependency-directed reasoning, hybrid knowledge representations and the reuse of common forms (cliches). An annotated transcript showing an interaction with a working version of the RA is given.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.75413","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=75413","","Programming;Artificial intelligence;Knowledge acquisition;Humans;Knowledge representation;Helium;Software systems;Buildings;Knowledge engineering;Terrorism","formal specification;knowledge acquisition;knowledge representation;software tools","Requirements Apprentice;requirements acquisition;automated tool;human analyst;software requirements;formal specifications;ambiguity;contradiction;incompleteness;artificial intelligence;knowledge acquisition;coherent internal representation;disorganized imprecise statements;dependency-directed reasoning;hybrid knowledge representations","","127","","49","","","","","","IEEE","IEEE Journals & Magazines"
"A framework for the automated drawing of data structure diagrams","C. Ding; P. Mateti","Dept. of Comput. Eng. & Sci., Case Western Reserve Univ., Cleveland, OH, USA; NA","IEEE Transactions on Software Engineering","","1990","16","5","543","557","Data structure diagrams are two-dimensional figures made up of lines that aim to pictorially indicate the interrelationships of the elements of a data structure. The various rules and factors of aesthetics that go into the way data structure diagrams are drawn are collected together. The various subjective factors are formulated into computable objectives and numeric parameters. These are distilled from a large number of data structure drawings found in various textbooks. The rules used have not reached a level of acceptance comparable to that of the relevant rules in engineering graphics. The internal architecture of a (sub)system that helps draw data structure diagrams is outlined.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.52777","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=52777","","Data structures;Programming profession;Engineering drawings;Debugging;Books;Displays;Computer science;Animation;Reactive power;Data engineering","computer graphics;data structures;diagrams;software engineering","pictorial indication;automated drawing;data structure diagrams;two-dimensional figures;lines;interrelationships;rules;factors of aesthetics;computable objectives;numeric parameters","","23","","54","","","","","","IEEE","IEEE Journals & Magazines"
"A Concurrency Measure","M. G. Khayat","Department of Computer Science and Engineering, University of Petroleum &amp; Minerals, Dhahran, Saudi Arabia.","IEEE Transactions on Software Engineering","","1984","SE-10","6","804","810","With the new advents of technology and the availability of microprocessors and minicomputers, parallel and distributed processing is gaining widespread acceptability. In such systems resources are shared among a number of processes. Accesses to the resources must be synchronized in order to guarantee proper operation of a system. In this research work, a measure, called maximal compatibility, is developed to measure the degree of concurrency (parallelism) a synchronization policy achieves. A set of accesses is considered compatible if it only contains accesses that are permitted to occur simultaneously. A policy is maximally compatible if it allows every compatible set of accesses to occur simultaneously and if the maximum number of requests is always satisfied without allowing incompatible accesses to occur simultaneously.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010309","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010309","Compatibility;concurrency control;degree of concurrency;dining philosophers problem;interprocess communication;maximal compatibility;parallel processing;readers/writers problem;synchronization policies;update synchronization","Concurrent computing;Parallel processing;Distributed processing;Availability;Microprocessors;Microcomputers;Concurrency control;Interleaved codes;Petri nets","","","","","","30","","","","","","IEEE","IEEE Journals & Magazines"
"On the exact and approximate throughput analysis of closed queuing networks with blocking","I. F. Akyildiz","Sch. of Inf. & Comput. Sci., Georgia Inst. of Technol., Atlanta, GA, USA","IEEE Transactions on Software Engineering","","1988","14","1","62","70","A type of blocking is investigated in which, on completion of its service, a job attempts to enter a new station. If, at that moment, the destination station is full, the job is forced to reside in the server of the source station until a place becomes available in the destination station. The server of the source station remains blocked during this period of time. This model is known as a queuing network with transfer blocking. The state space of queuing networks with blocking is reduced by considering finite capacities of the stations. A nonblocking queuing network with the appropriate total number of jobs is derived. The state space of this network is equal to the state space of the blocking queuing network. The transformation of state space is exact for two-station networks and approximate for three-or-more station cases. The approximation has been validated by executing several examples, including stress tests. In all investigated network models, the approximate throughput results deviate, on the average, less than 3% from the simulation results.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4623","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4623","","Throughput;Queueing analysis;Network servers;State-space methods;Computer networks;Application software;Algorithm design and analysis;Occupational stress;Testing;Performance analysis","performance evaluation;queueing theory;virtual machines","exact throughput;approximate throughput analysis;closed queuing networks;blocking;source station;destination station;transfer blocking;state space;two-station networks;simulation results","","44","","20","","","","","","IEEE","IEEE Journals & Magazines"
"A Very High-Level Interactive Graphical Trace for the Pascal Heap","S. L. Getz; G. Kalligiannis; S. R. Schach","Department of Computer Science, University of Cape Town; NA; NA","IEEE Transactions on Software Engineering","","1983","SE-9","2","179","185","A very high-level trace for data structures is one which displays a data structure in the shape in which the user conceptualizes it, be it a tree, an array, or a graph. GRAPHTRACE is a system that facilitates the very high-level graphic display of interrelationships among dynamically allocated Pascal records. It offers the user a wide range of options to enable him to ""see"" the data structures on a graphics screen in a format as close as possible to that in which he visualizes it, thereby providing a useful display capability when the user's conceptual model is a directed graph or tree.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236595","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703035","Data structures;debugging;graphics;heap;interactive tracing;Pascal;portability;precompiler;tracing;very high-level trace","Data structures;High level languages;Displays;Tree data structures;Programming profession;Africa;Shape;Tree graphs;Graphics;Core dumps","","Data structures;debugging;graphics;heap;interactive tracing;Pascal;portability;precompiler;tracing;very high-level trace","","7","","10","","","","","","IEEE","IEEE Journals & Magazines"
"An overview of JSD","J. R. Cameron","Michael Jackson Systems, Limited, London WIN 5AF, England","IEEE Transactions on Software Engineering","","1986","SE-12","2","222","240","The Jackson System Development (JSD) method addresses most of the software lifecycle. JSD specifications consist mainly of a distributed network of processes that communicate by message-passing and read-only inspection of each other's data. A JSD specification is therefore directly executable, at least in principle. Specifications are developed middle-out from an initial set of `model' processes. The model processes define a set of events, which limit the scope of the system, define its semantics, and form the basis for defining data and outputs. Implementation often involves reconfiguring or transforming the network to run on a smaller number of real or virtual processors. The main phase of JSD are introduced and illustrated by a small example system. The rationale for the approach is discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312938","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312938","Design methodology;system design;systems analysis","Libraries;Films;Data models;Databases;Synchronization;Contracts;Program processors","software engineering","JSD;Jackson System Development;software lifecycle;distributed network;message-passing;read-only inspection;JSD specification;semantics","","32","","","","","","","","IEEE","IEEE Journals & Magazines"
"Existence dependency: The key to semantic integrity between structural and behavioral aspects of object types","M. Snoeck; G. Dedene","Univ. Libre de Bruxelles, Belgium; NA","IEEE Transactions on Software Engineering","","1998","24","4","233","251","In object-oriented conceptual modeling, the generalization/specialization hierarchy and the whole/part relationship are prevalent classification schemes for object types. This paper presents an object-oriented conceptual model where, in the end, object types are classified according to two relationships only. Existence dependency and generalization/specialization. Existence dependency captures some of the interesting semantics that are usually associated with the concept of aggregation (also called composition or Part Of relation), but in contrast with the latter concept, the semantics of existence dependency are very precise and its use clear cut. The key advantage of classifying object types according to existence dependency are the simplicity of the concept, its absolute unambiguity, and the fact that it enables to check conceptual schemes for semantic integrity and consistency. We will first define the notion of existence dependency and claim that it is always possible to classify objects according to this relationship, thus removing the necessity for the Part Of relation and other kinds of associations between object types. The second claim of this paper is that existence dependency is the key to semantic integrity checking to a level unknown to current object-oriented analysis methods. In other words: Existence dependency allows us to track and solve inconsistencies in an object-oriented conceptual schema.","0098-5589;1939-3520;2326-3881","","10.1109/32.677182","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=677182","","Object oriented modeling;Lattices;Automata;Quality control","object-oriented methods;software engineering","semantic integrity;object types;existence dependency;object-oriented conceptual modeling;software engineering;conceptual model;aggregation;composition;quality;consistency checking","","52","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Closed Covers: To Verify Progress for Communicating Finite State Machines","M. G. Gouda","Department of Computer Sciences, University of Texas at Austin, Austin, TX 78712.","IEEE Transactions on Software Engineering","","1984","SE-10","6","846","855","Consider communicating finite state machines which exchange messages over unbounded FIFO channels. We discuss a technique to verify that the communication between a given pair of such machines will progress indefinitely; this implies that the communication is free from deadlocks and unspecified receptions. The technique is based on finding a set of global states for the communicating pair such that the following two conditions (along with other conditions) are satisfied: 1) the initial global state is in that set; and 2) starting from any global state in that set, an ``acyclic version'' of the communicating pair must reach a global state in that set. We call such a set a closed cover, and show that the existence of a closed cover for a communicating pair is sufficient to guarantee indefinite communication progress. We also show that in many practical instances, if the communication is guaranteed to progress indefinitely, then the existence of a closed cover is necessary.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010313","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010313","Communicating finite state machines;communication progress;communication protocols;verification techniques","Automata;Protocols;System recovery;Data structures;Resource management","","","","27","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Consistency issues in distributed checkpoints","J. -. Helary; R. H. B. Netzer; M. Raynal","IRISA, Rennes, France; NA; NA","IEEE Transactions on Software Engineering","","1999","25","2","274","281","A global checkpoint is a set of local checkpoints, one per process. The traditional consistency criterion for global checkpoints states that a global checkpoint is consistent if it does not include messages received and not sent. The paper investigates other consistency criteria, transitlessness, and strong consistency. A global checkpoint is transitless if it does not exhibit messages sent and not received. Transitlessness can be seen as a dual of traditional consistency. Strong consistency is the addition of transitlessness to traditional consistency. The main result of the paper is a statement of the necessary and sufficient condition answering the following question: ""given an arbitrary set of local checkpoints, can this set be extended to a global checkpoint that satisfies P"" (where P is traditional consistency, transitlessness, or strong consistency). From a practical point of view, this condition, when applied to transitlessness, is particularly interesting as it helps characterize which messages do not need to be recorded by checkpointing protocols.","0098-5589;1939-3520;2326-3881","","10.1109/32.761450","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=761450","","Sufficient conditions;Checkpointing;Protocols;Computer Society;Fault tolerant systems;Heart;System recovery;Distributed computing;Computational modeling","distributed algorithms;program diagnostics;data integrity;software fault tolerance","consistency issues;distributed checkpoints;global checkpoint;local checkpoints;consistency criterion;transitlessness;strong consistency;sufficient condition;arbitrary set;traditional consistency;checkpointing protocols;message recording;distributed systems;fault tolerance;rollback recovery","","25","","19","","","","","","IEEE","IEEE Journals & Magazines"
"An empirical study of software design practices","D. N. Card; V. E. Church; W. W. Agresti","System Sciences Division, Computer Sciences Corporation, Silver Spring, MD 20910; System Sciences Division, Computer Sciences Corporation, Silver Spring, MD 20910; System Sciences Division, Computer Sciences Corporation, Silver Spring, MD 20910","IEEE Transactions on Software Engineering","","1986","SE-12","2","264","271","Results of an empirical study of software design practices in one specific environment are reported. The practices examined affect module size, module strength, data coupling, descendant span, unreferenced variables, and software reuse. Measures characteristic of these practices were extracted from 887 Fortran modules developed for five flight dynamics software projects monitored by the Software Engineering Laboratory. The relationship of these measures to cost and fault rate was analyzed using a contingency table procedure. The results show that some recommended design practices, despite their intuitive appeal, are ineffective in this environment, whereas others are very effective.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312942","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312942","Coupling;fault rate;module cost;reuse;size;Software Engineering Laboratory;strength;unreferenced variables","Couplings;Correlation;Software reusability;Computers;Software design;Monitoring","software engineering","software design practices;module size;module strength;data coupling;descendant span;unreferenced variables;software reuse;Fortran modules;flight dynamics software projects;Software Engineering Laboratory;cost;fault rate;contingency table","","16","","","","","","","","IEEE","IEEE Journals & Magazines"
"An experimental comparison of the effectiveness of branch testing and data flow testing","P. G. Frankl; S. N. Weiss","Dept. of Comput. Sci., Polytech. Univ., Brooklyn, NY, USA; NA","IEEE Transactions on Software Engineering","","1993","19","8","774","787","An experiment comparing the effectiveness of the all-uses and all-edges test data adequacy criteria is discussed. The experiment was designed to overcome some of the deficiencies of previous software testing experiments. A large number of test sets was randomly generated for each of nine subject programs with subtle errors. For each test set, the percentages of executable edges and definition-use associations covered were measured, and it was determined whether the test set exposed an error. Hypothesis testing was used to investigate whether all-uses adequate test sets are more likely to expose errors than are all-edges adequate test sets. Logistic regression analysis was used to investigate whether the probability that a test set exposes an error increases as the percentage of definition-use associations or edges covered by it increases. Error exposing ability was shown to be strongly positively correlated to percentage of covered definition-use associations in only four of the nine subjects. Error exposing ability was also shown to be positively correlated to the percentage of covered edges in four different subjects, but the relationship was weaker.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.238581","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=238581","","Software testing;Data analysis;Computer science;Performance evaluation;Random number generation;Logistics;Regression analysis;Genetic mutations;Acoustic testing;Error correction","errors;program testing","error exposing ability;branch testing;data flow testing;all-edges test data adequacy criteria;software testing experiments;executable edges;definition-use associations;all-uses adequate test sets;regression analysis","","145","","40","","","","","","IEEE","IEEE Journals & Magazines"
"Guaranteed Response Times in a Hard-Real-Time Environment","D. W. Leinbaugh","Department of Computer Science, University of Nebraska","IEEE Transactions on Software Engineering","","1980","SE-6","1","85","91","This paper describes a scheduling algorithm for a set of tasks that guarantees the time within which a task, once started, will complete. A task is started upon receipt of an external signal or the completion of other tasks. Each task has a rxed set of requirements in processor time, resources, and device operations needed for completion of its various segments. A worst case analysis of task performance is carried out. An algorithm is developed for determining the response times that can be guaranteed for a set of tasks. Operating system overhead is also accounted for.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234465","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702697","Guaranteed response time;hard-real-time;multiprocessing;real-time programming","Time factors;Optimal scheduling;Processor scheduling;Scheduling algorithm;Delay;Real time systems;Performance analysis;Operating systems;Process control;Multiprocessing systems","","Guaranteed response time;hard-real-time;multiprocessing;real-time programming","","105","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Software Reliability Growth Modeling: Models and Applications","S. Yamada; S. Osaki","Graduate School of Systems Science, Okayama University of Science; NA","IEEE Transactions on Software Engineering","","1985","SE-11","12","1431","1437","This paper summarizes existing software reliability growth models (SRGM's) described by nonhomogeneous Poisson processes. The SRGM's are classified in terms of the software reliability growth index of the error detection rate per error. The maximum-likelihood estimations based on the SRGM's are discussed for software reliability data analysis and software reliability evaluation. Using actual software error data observed by software testing, application examples of the existing SRGM's are illustrated.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232179","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701965","Error detection rate per error;maximum-likelihood estimation;nonhomogeneous Poisson processes;software error;software reliability analysis;software reliability growth models","Software reliability;Application software;Software testing;Software systems;Maximum likelihood estimation;Software measurement;Error correction;Data analysis;Computer errors;Programming","","Error detection rate per error;maximum-likelihood estimation;nonhomogeneous Poisson processes;software error;software reliability analysis;software reliability growth models","","208","","18","","","","","","IEEE","IEEE Journals & Magazines"
"The Soma: A Programming Construct for Distributed Processing","J. L. W. Kessels","Philips Research Laboratories","IEEE Transactions on Software Engineering","","1981","SE-7","5","502","509","A construct is proposed for parallel programming, called soma (software machine). A soma is a sequential process that can communicate with other somas by exchanging messages via mailboxes. The soma construct is well suited for implementation on conventional as well as on distributed computer architectures, the main characteristic of the latter being the absence of a common store.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.231112","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702876","Communication;concurrency;distributed programming;mailbox;message passing;send and receive operations;synchronization","Distributed processing;Parallel programming;Computer architecture;Concurrent computing;Parallel processing;Condition monitoring;Proposals;Message passing;Computerized monitoring","","Communication;concurrency;distributed programming;mailbox;message passing;send and receive operations;synchronization","","7","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Identifying extended entity-relationship object structures in relational schemas","V. M. Markowitz; J. A. Makowsky","Dept. of Comput. Sci. Res., Lawrence Berkeley Lab., CA, USA; NA","IEEE Transactions on Software Engineering","","1990","16","8","777","790","Relational schemas consisting of relation-schemes, key dependencies and key-based inclusion dependencies (referential integrity constraints) are considered. Schemas of this form are said to be entity-relationship (EER)-convertible if they can be associated with an EER schema. A procedure that determines whether a relational schema is EER-convertible is developed. A normal form is proposed for relational schemas representing EER object structures. For EER-convertible relational schemas, the corresponding normalization procedure is presented. The procedures can be used for analyzing the semantics of existing relational databases and for converting relational database schemas into object-oriented database schemas.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.57618","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=57618","","Relational databases;Erbium;Data models;Object oriented modeling;Object oriented databases;Information systems;Laboratories;Transaction databases","database management systems;database theory;object-oriented programming;relational databases","extended entity-relationship object structures;relation-schemes;key dependencies;key-based inclusion dependencies;referential integrity constraints;EER schema;EER-convertible;normal form;relational schemas;EER object structures;normalization procedure;semantics;relational database schemas;object-oriented database schemas","","78","","27","","","","","","IEEE","IEEE Journals & Magazines"
"A contingency approach to estimating record selectivities","P. -. Chu","Coll. of Bus., Ohio State Univ., Columbus, OH, USA","IEEE Transactions on Software Engineering","","1991","17","6","544","552","An approach to estimating record selectivity rooted in the theory of fitting a hierarchy of models in discrete data analysis is presented. In contrast to parametric methods, this approach does not presuppose a distribution pattern to which the actual data conform; it searches for one that fits the actual data. This approach makes use of parsimonious models wherever appropriate in order to minimize the storage requirement without sacrificing accuracy. Two-dimensional cases are used as examples to illustrate the proposed method. It is demonstrated that the technique of identifying a good-fitting and parsimonious model can drastically reduce storage space and that the implementation of this technique requires little extra processing effort. The case of perfect or near-perfect association and the idea of keeping information about salient cells of a table are discussed. A strategy to reduce storage requirement in cases in which a good-fitting and parsimonious model is not available is proposed. Hierarchical models for three-dimensional cases are presented, along with a description of the W.E. Deming and F.F. Stephan (1940) iterative proportional fitting algorithm which fits hierarchical models of any dimensions.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.87280","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=87280","","Histograms;Cost function;Data analysis;Parameter estimation;Query processing;Relational databases;Data models;Information retrieval;Database systems;Shape","information retrieval systems;relational databases;storage management","contingency approach;record selectivities;discrete data analysis;parsimonious models;storage requirement;storage space;near-perfect association;storage requirement;three-dimensional cases;iterative proportional fitting algorithm;hierarchical models","","4","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Query Processing in a Fragmented Relational Distributed System: Mermaid","C. T. Yu; C. C. Chang; M. Templeton; D. Brill; E. Lund","Department of Electrical Engineering and Computer Science, University of Illinois; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","8","795","810","This paper describes the query optimizer of the Mermaid system which provides a user with a unified view of multiple preexisting databases which may be stored under different DBMS's. The algorithm is designed for databases which may contain replicated or fragmented relations and for users who are primarily making interactive, ad hoc queries. Although the implementation of the algorithm is a front-end system, not an integrated distributed DBMS, it should be applicable to a distributed DBMS also.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232528","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702088","Algorithm;distributed query processing;dynamic estimation;semijoin","Query processing;Relational databases;Transaction databases;Algorithm design and analysis;Delay;Spatial databases;Costs;Parallel processing;Assembly;Database languages","","Algorithm;distributed query processing;dynamic estimation;semijoin","","19","","45","","","","","","IEEE","IEEE Journals & Magazines"
"Automatic Compiler Production: The Front End","S. P. Reiss","Department of Computer Science, Brown University","IEEE Transactions on Software Engineering","","1987","SE-13","6","609","627","This paper describes a system for automatically producing complete compiler front ends from simple, nonprocedural specifications of the source language. This system is based on a detailed model of a compiler front end that is presented first. The system itself is then described using a Pascal subset as an example. This work was part of a larger project aimed at producing complete compilers in a similar fashion.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233472","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702267","Compiler-compilers;compiler generation;data types;semantics;symbols","Production systems;Buildings;Robustness;Computer science","","Compiler-compilers;compiler generation;data types;semantics;symbols","","","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Starvation and critical race analyzers for Ada","G. M. Karam; R. J. A. Buhr","Dept. of Syst. & Comput. Eng., Carleton Univ., Ottawa, Ont., Canada; Dept. of Syst. & Comput. Eng., Carleton Univ., Ottawa, Ont., Canada","IEEE Transactions on Software Engineering","","1990","16","8","829","843","Starvation and critical race analysis tools for Ada designs are described. These tools are part of a temporal analysis toolset that includes an operational specification language, a language interpreter, and a deadlock analyzer for Ada. The starvation analyzer is based on a set-theoretic model of starvation. It uses a proof tree produced by the deadlock analyzer to define the possible computation space of the design. A preprocessing phase of the starvation tool optimizes the analysis so that the resulting analysis is efficient. Unlike livelock analysis in state machines, the starvation analyzer does not require a priori specification of home states to discern liveness. The critical race analysis tool provides semiautomatic proof of critical races by identifying nondeterministic rendezvous (races) from the proof tree generated by the deadlock analyzer, and then assisting the human operator in identifying which of these constitute critical races. Several design examples are used to demonstrate the capabilities of the two analysis methods.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.57622","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=57622","","System recovery;Algorithm design and analysis;Information analysis;Specification languages;Automatic testing;Delay;Software testing;Humans;System analysis and design","Ada;program interpreters;programming;software tools;specification languages;system recovery","race analyzers;critical race analysis tools;Ada designs;temporal analysis toolset;operational specification language;language interpreter;deadlock analyzer;starvation analyzer;set-theoretic model;deadlock analyzer;computation space;preprocessing phase;starvation tool;liveness;semiautomatic proof;nondeterministic rendezvous;human operator;design examples","","19","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Parameterized Programming","J. A. Goguen","SRI International, Menlo Park, CA 94025; the Center for the Study of Language and Information, Stanford University Stanford, CA 94305.","IEEE Transactions on Software Engineering","","1984","SE-10","5","528","543","Parameterized programming is a powerful technique for the reliable reuse of software. In this technique, modules are parameterized over very general interfaces that describe what properties of an environment are required for the module to work correctly. Reusability is enhanced by the flexibility of the parameterization mechanism proposed here. Reliability is further enhanced by permitting interface requirements to include more than purely syntactic information. This paper introduces three new ideas that seem especially useful in supporting parameterized programming: 1) theories, which declare global properties of program modules and interfaces; 2) views, which connect theories with program modules in an elegant way; and 3) module expressions, a kind of general structured program transformation which produces new modules by modifying and combining existing modules. Although these ideas are illustrated with some simple examples in the OBJ programming language, they should also be taken as proposals for an Ada<sup>1</sup> library system, for adding modules to Prolog, and as considerations for future language design efforts. OBJ is an ultra-high level programming language, based upon rewrite rules, that incorporates these ideas, and many others from modern programming methodology.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010277","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010277","Adaptability;interfaces;logic programming;methodology;modularization;OBJ;parameterized programming;program library;programming;program transformation;reliability;reusability","Logic programming;Computer languages;Proposals;Packaging;Writing;Debugging;Software libraries;Software packages;Costs;Functional programming","","","","92","","57","","","","","","IEEE","IEEE Journals & Magazines"
"Formal analysis of the alternating bit protocol by temporal Petri nets","I. Suzuki","Dept. of Electr. Eng. & Comput. Sci., Wisconsin Univ., Milwaukee, WI, USA","IEEE Transactions on Software Engineering","","1990","16","11","1273","1281","Temporal Petri nets are Petri nets in which certain restrictions on the firings of transitions are represented by formulas containing temporal operators. The use of temporal Petri nets for formal specification and verification of the alternating bit protocol is discussed. The temporal Petri net which models the protocol is analyzed formally using the existing theory of omega -regular expressions and Buchi-automata.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.60315","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=60315","","Protocols;Petri nets;Transmission lines;Safety;Formal specifications;Logic;Timing;Computer simulation;Transmission line theory","automata theory;formal specification;Petri nets;program verification;programming theory","formal analysis;formal verification;alternating bit protocol;temporal Petri nets;firings;transitions;formulas;temporal operators;formal specification;omega -regular expressions;Buchi-automata","","41","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Flow control for limited buffer multicast","P. B. Danzig","Dept. of Comput. Sci., Univ. of Southern California, Los Angeles, CA, USA","IEEE Transactions on Software Engineering","","1994","20","1","1","12","Analyses a multiround flow control algorithm that attempts to minimize the time required to multicast a message to a group of recipients and receive responses directly from each group member. Such a flow control algorithm may be necessary because the hurry of responses to the multicast can overflow the buffer space of the process that issued the multicast. The condition that each recipient directly respond to the multicast prevents the use of reliable multicast protocols based on software combining trees or negative-acknowledgments. The flow control analysed algorithm directs the responding processes to hold their responses for some period of time, called the backoff time, before sending them to the originator. The backoff time depends on the number of recipients that respond, the originator's available buffer space and buffer service time distribution, and the number of times that the originator is willing to retransmit its message. This paper develops an approximate analysis of the service time distribution of the limited-buffer preemptive queuing process that occurs within the protocol processing layers of a multiprogrammed operating system. It then uses this model to calculate multicast backoff times. The paper reports experimental verification of the accuracy of this service time model and discusses its application to the multicast flow control problem.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.263751","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=263751","","Multicast algorithms;Multicast protocols;Communication system control;Operating systems;Intersymbol interference;Algorithm design and analysis;Queueing analysis;Communication channels;Throughput;System recovery","telecommunications control;protocols;storage management;queueing theory;buffer storage;multiprogramming;network operating systems","multiround flow control algorithm;limited buffer multicast;buffer overflow;response holding;backoff time;recipients;available buffer space;buffer service time distribution;message retransmission;approximate analysis;service time distribution;limited-buffer preemptive queuing process;protocol processing layers;multiprogrammed operating system;accuracy","","16","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Optimization of the Number of Copies in a Distributed Data Base","E. G. Coffman; E. Gelenbe; B. Plateau","Bell Laboratories; NA; NA","IEEE Transactions on Software Engineering","","1981","SE-7","1","78","84","We consider the effect on system performance of the distribution of a data base in the form of multiple copies at distinct sites. The purpose of our analysis is to determine the gain in READ throughput that can be obtained in the presence of consistency preserving algorithms that have to be implemented when UPDATE operations are carried out on each copy. We show that READ throughput diminishes if the number of copies exceeds an optimal value. The theoretical model we develop is applied to a system in which consistency is preserved through the use of Ellis' ring algorithm.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234510","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702804","Consistency control algorithm;distributed database;performance evaluation;preemptive priority;queuing theory;read processing capacity;update","Throughput;Computer networks;Communication networks;System performance;Algorithm design and analysis;Distributed control;Distributed databases;Queueing analysis;Large scale integration;Information processing","","Consistency control algorithm;distributed database;performance evaluation;preemptive priority;queuing theory;read processing capacity;update","","52","","4","","","","","","IEEE","IEEE Journals & Magazines"
"A Message-Based Approach to Discrete-Event Simulation","R. L. Bagrodia; K. M. Chandy; J. Misra","Department of Computer Sciences, University of Texas at Austin; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","6","654","665","This paper develops a message-based approach to discrete-event simulation. Although message-based simulators have the same expressive power as traditional discrete-event simulation lanuages, they provide a more natural environment for simulating distributed systems. In message-based simulations, a physical system is modeled by a set of message-communicating processes. The events in the system are modeled by message-communications. The paper proposes the entity construct to represent a message-communicating process operating in simulated time. A general wait until construct is used for process scheduling and message-communication. Based on these two notions, the paper proposes a language fragment comprising a small set of primitives. The language fragment can be implemented in any general-purpose, sequential programming language to construct a message-based simulator. We give an example of a message-based simulation language, called MAY, developed by implementing the language fragment in Fortran. MAY is in the public domain and is available on request.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233203","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702271","Discrete-event simulation;distributed system;entity;message;message-based simulation","Discrete event simulation;Computer languages;Power system modeling;Computational modeling;Trademarks;Virtual manufacturing;Packaging machines","","Discrete-event simulation;distributed system;entity;message;message-based simulation","","35","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Program Reusability through Program Transformation","J. M. Boyle; M. N. Muralidharan","Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, IL 60439.; Department of Computer Science, University of Kentucky, Lexington, KY 40506.","IEEE Transactions on Software Engineering","","1984","SE-10","5","574","588","How can a program written in pure applicative LISP be reused in a Fortran environment? One answer is by automatically transforming it from LISP into Fortran. In this paper we discuss a practical application of this technique-one that yields an efficient Fortran program. We view this process as an example of abstract programming, in which the LISP program constitutes an abstract specification for the Fortran version. The idea of strategy-a strategy for getting from LISP to Fortran-is basic to designing and applying the transformations. One strategic insight is that the task is easier if the LISP program is converted to ``recursive'' Fortran, and then the recursive Fortran program is converted to nonrecursive standard Fortran. Another strategic insight is that much of the task can be accomplished by converting the program from one canonical form to another. Developing a strategy also involves making various implementation decisions. One advantage of program transformation methodology is that it exposes such decisions for examination and review. Another is that it enables optimizations to be detected and implemented easily. Once a strategy has been discovered, it can be implemented by means of rewrite-rule transformations using the TAMPR program transformation system. The transformational approach to program reuse based on this strategy has a measure of elegance. It is also practical-the resulting Fortran program is 25 percent faster than its compiled LISP counterpart, even without extensive optimization.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010281","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010281","","Computer science;Packaging;Contracts;Mathematics;Laboratories;Linear programming;Equations;Writing;Debugging","","","","40","","48","","","","","","IEEE","IEEE Journals & Magazines"
"Translating SQL Into Relational Algebra: Optimization, Semantics, and Equivalence of SQL Queries","S. Ceri; G. Gottlob","Dipartimento di Elettronica, Politecnico di Milano; NA","IEEE Transactions on Software Engineering","","1985","SE-11","4","324","345","In this paper, we present a translator from a relevant subset of SQL into relational algebra. The translation is syntax-directed, with translation rules associated with grammar productions; each production corresponds to a particular type of SQL subquery.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232223","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702016","Program translation;query equivalence;query languages;query optimization;relational algebra;relational database model;SQL","Algebra;Database languages;Query processing;Production;Calculus;Database systems;Relational databases;Formal languages;Proposals","","Program translation;query equivalence;query languages;query optimization;relational algebra;relational database model;SQL","","11","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Integrated environments for formally well-founded design and simulation of concurrent systems","A. Giacalone; S. A. Smolka","Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA; Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA","IEEE Transactions on Software Engineering","","1988","14","6","787","802","An ongoing project concerned with the development of environments that support the specification and design of concurrent systems is reported. The project has two key aspects: an existing and working system, Clara, that supports Milner's CCS as a specification and design language; and the development of general techniques for computer-aided generation of Clara-like environments for other concurrent languages. The Clara environment is emphasized. It has two main components: support for the usage of formal techniques in the design process, and a rich and highly interactive simulation facility. A further distinguishing feature is the environment's graphical user interface which is based on a pictorial version of CCS. The semantics of CCS is defined nonprocedurally in two phases: an operational semantics given as a set of inference rules, and an algebraic semantics represented by a set of equational rules.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6158","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6158","","Carbon capture and storage;Concurrent computing;User interfaces;Computational modeling;Calculus;Application software;Computer science;Process design;Graphical user interfaces;Equations","computer graphics;parallel programming;programming environments;programming theory;simulation languages;specification languages;user interfaces","programming environments;parallel programming;specification language;concurrent systems;Clara;CCS;concurrent languages;formal techniques;interactive simulation;graphical user interface;operational semantics;inference rules;algebraic semantics;equational rules","","8","","51","","","","","","IEEE","IEEE Journals & Magazines"
"Proof procedure and answer extraction in Petri net model of logic programs","G. Peterka; T. Murata","Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA; Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA","IEEE Transactions on Software Engineering","","1989","15","2","209","217","A proof procedure and answer extraction in a high-level Petri net model of logic programs is discussed. The logic programs are restricted to the Horn clause subset of first-order predicate logic and finite problems. The logic program is modeled by a high-level Petri net and the execution of the logic program or the answer extraction process in predicate calculus corresponds to a firing sequence which fires the goal transition in the net. For the class of the programs described above, the goal transition is potentially firable if an only if there exists a nonnegative T-invariant which includes the goal transition in its support. This is the main result proved. Three examples are given to illustrate in detail the above results.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21746","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21746","","Logic programming;Fires;Petri nets;Calculus;Computer science;Artificial intelligence;Automatic logic units;Sufficient conditions;Terminology","logic programming;Petri nets;programming theory;theorem proving","answer extraction;Petri net model;logic programs;proof procedure;Horn clause subset;first-order predicate logic;firing sequence;goal transition","","61","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Designing and prototyping data-intensive applications in the Logres and Algres programming environment","F. Cacace; S. Ceri; L. Tanca; S. Crespi-Reghizzi","Dipartimento di Elettronica e Inf., Politecnico di Milano, Italy; Dipartimento di Elettronica e Inf., Politecnico di Milano, Italy; Dipartimento di Elettronica e Inf., Politecnico di Milano, Italy; Dipartimento di Elettronica e Inf., Politecnico di Milano, Italy","IEEE Transactions on Software Engineering","","1992","18","6","534","546","The authors present an environment and a methodology for the design and rapid prototyping of data-intensive software applications, i.e., applications which perform substantial retrieval and update activity on persistent data. In the approach, the application is formally specified using Logres, a database language which combines object-oriented data modeling and rule-based programming. These specifications are translated into Algres, an extended relational algebra, thus yielding a rapid executable prototype. Algres programs embedded into a conventional programming language interface may be converted to conventional programs operating on a commercial relational system. This methodology helps automate the conversion from declarative requirements to imperative code, performing several tasks fully automatically and reducing the probability of human errors, while integrity constraints and application specifications are expressed in a declarative language, at a very high level of abstraction.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.142875","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=142875","","Prototypes;Application software;Software prototyping;Design methodology;Software performance;Information retrieval;Database languages;Object oriented modeling;Object oriented programming;Algebra","formal specification;programming environments;software prototyping","prototyping;data-intensive applications;Logres;Algres;programming environment;rapid prototyping;persistent data;database language;object-oriented data modeling;rule-based programming;relational algebra;declarative requirements;imperative code;human errors;integrity constraints;application specifications","","3","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Incremental LL(1) parsing in language-based editors","J. J. Shilling","Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA","IEEE Transactions on Software Engineering","","1993","19","9","935","940","This paper introduces an efficient incremental LL(1) parsing algorithm for use in language-based editors that use the structure recognition approach. It is designed to parse user input at intervals of very small granularity and to limit the amount of incremental parsing needed when changes are made internal to the editing buffer. The algorithm uses the editing focus as a guide in restricting parsing. It has been implemented in the Fred language-based editor.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.241775","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=241775","","Production;Programming;Feedback;Heuristic algorithms","grammars;program compilers;software tools;text editing","incremental LL(1) parsing;language-based editors;structure recognition approach;granularity;Fred language-based editor;software development environments","","1","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Software reliability trend analyses from theoretical to practical considerations","K. Kanoun; J. C. Laprie","Lab. d'Autom. et d'Anal. des Syst., CNRS, Toulouse, France; Lab. d'Autom. et d'Anal. des Syst., CNRS, Toulouse, France","IEEE Transactions on Software Engineering","","1994","20","9","740","747","This paper addresses the problem of reliability growth characterization and analysis. It is intended to show how reliability trend analyses can help the project manager in controlling the progress of the development activities and in appreciating the efficiency of the test programs. Reliability trend change may result from various reasons, some of them are desirable and expected (such as reliability growth due to fault removal) and some of them are undesirable (such as slowing down Of the testing effectiveness). Identification in time of the latter allows the project manager to take the appropriate decisions very quickly in order to avoid problems which may manifest later. The notions of reliability growth over a given interval and local reliability trend change are introduced through the subadditive property, allowing: better definition and understanding of the reliability growth phenomena; the already existing trend tests are then revisited using these concepts. Emphasis is put on the way trend tests can be used to help the management of the testing and validation process and on practical results that can be derived from their use; it is shown that, for several circumstances, trend analyses give information of prime importance to the developer.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.317434","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=317434","","Software reliability;Software testing;Project management;Software development management;Information analysis;Application software;Reliability engineering;Reliability theory;Software systems;Predictive models","software reliability;project management","software reliability trend analyses;software reliability growth characterization;reliability trend analyses;project manager;software testing;software validation","","21","","22","","","","","","IEEE","IEEE Journals & Magazines"
"An Approach to the Modeling of Software Testing with Some Applications","T. Downs","Department of Electrical Engineering, University of Queensland","IEEE Transactions on Software Engineering","","1985","SE-11","4","375","386","In this paper, an approach to the modeling of software testing is described. A major aim of this approach is to allow the assessment of the effects of different testing (and debugging) strategies in different situations. It is shown how the techniques developed can be used to estimate, prior to the commencement of testing, the optimum allocation of test effort for software which is to be nonuniformly executed in its operational phase. In addition, the question of application of statistical models in cases where the data environment undergoes changes is discussed. Finally, two models are presented for the assessment of the effects of imperfections in the debugging process.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232227","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702020","Computer performance modeling;reliability growth;software reliability;software testing;stochastic models","Software testing;Application software;Debugging;Software systems;Australia;Software reliability;Mathematical model;Software performance;Phase estimation;Telecommunications","","Computer performance modeling;reliability growth;software reliability;software testing;stochastic models","","12","","11","","","","","","IEEE","IEEE Journals & Magazines"
"An evaluation of relational join algorithms in a pipelined query processing environment","K. P. Mikkilineni; S. Y. W. Su","Honeywell Corp. Syst. Dev., Golden Valley, MN, USA; NA","IEEE Transactions on Software Engineering","","1988","14","6","838","848","A query processing strategy which is based on pipelining and data-flow techniques is presented. Timing equations are developed for calculating the performance of four join algorithms: nested block, hash, sort-merge, and pipelined sort-merge. They are used to execute the join operation in a query in distributed fashion and in pipelined fashion. Based on these equations and similar sets of equations developed for other relational algebraic operations, the performance of query execution was evaluated using the different join algorithms. The effects of varying the values of processing time, I/O time, communication time, buffer size, and join selectively on the performance of the pipelined join algorithms are investigated. The results are compared to the results obtained by employing the same algorithms for executing queries using the distributed processing approach which does not exploit the vertical concurrency of the pipelining approach. These results establish the benefits of pipelining.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6162","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6162","","Query processing;Pipeline processing;Relational databases;Timing;Differential algebraic equations;Distributed processing;Concurrent computing;Performance analysis;Algorithm design and analysis;Data models","database theory;distributed databases;merging;performance evaluation;pipeline processing;relational databases;sorting","relational databases;distributed databases;timing equations;relational join algorithms;pipelined query processing environment;nested block;hash;sort-merge;pipelined sort-merge;query execution;distributed processing","","11","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Software Function, Source Lines of Code, and Development Effort Prediction: A Software Science Validation","A. J. Albrecht; J. E. Gaffney","IBM Corporate Information Systems and Administration; NA","IEEE Transactions on Software Engineering","","1983","SE-9","6","639","648","One of the most important problems faced by software developers and users is the prediction of the size of a programming system and its development effort. As an alternative to ""size,"" one might deal with a measure of the ""function"" that the software is to perform. Albrecht [1] has developed a methodology to estimate the amount of the ""function"" the software is to perform, in terms of the data it is to use (absorb) and to generate (produce). The ""function"" is quantified as ""function points,"" essentially, a weighted sum of the numbers of ""inputs,"" ""outputs,""master files,"" and ""inquiries"" provided to, or generated by, the software. This paper demonstrates the equivalence between Albrecht's external input/output data flow representative of a program (the ""function points"" metric) and Halstead's [2] ""software science"" or ""software linguistics"" model of a program as well as the ""soft content"" variation of Halstead's model suggested by Gaffney [7].","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.235271","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703110","Cost estimating;function points;software linguistics","Application software;Software measurement;Software performance;Size measurement;Performance evaluation;State estimation;Software design;Information systems","","Cost estimating;function points;software linguistics","","678","","9","","","","","","IEEE","IEEE Journals & Magazines"
"A framework for expressing the relationships between multiple views in requirements specification","B. Nuseibeh; J. Kramer; A. Finkelstein","Dept. of Comput., Imperial Coll. of Sci., Technol. & Med., London, UK; Dept. of Comput., Imperial Coll. of Sci., Technol. & Med., London, UK; Dept. of Comput., Imperial Coll. of Sci., Technol. & Med., London, UK","IEEE Transactions on Software Engineering","","1994","20","10","760","773","Composite systems are generally comprised of heterogeneous components whose specifications are developed by many development participants. The requirements of such systems are invariably elicited from multiple perspectives that overlap, complement, and contradict each other. Furthermore, these requirements are generally developed and specified using multiple methods and notations, respectively. It is therefore necessary to express and check the relationships between the resultant specification fragments. We deploy multiple ViewPoints that hold partial requirements specifications, described and developed using different representation schemes and development strategies. We discuss the notion of inter-ViewPoint communication in the context of this ViewPoints framework, and propose a general model for ViewPoint interaction and integration. We elaborate on some of the requirements for expressing and enacting inter-ViewPoint relationships-the vehicles for consistency checking and inconsistency management. Finally, though we use simple fragments of the requirements specification method CORE to illustrate various components of our work, we also outline a number of larger case studies that we have used to validate our framework. Our computer-based ViewPoints support environment, The Viewer, is also briefly described.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.328995","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=328995","","Vehicles;Context modeling;Programming;Diffusion tensor imaging;Automotive engineering;Interconnected systems;Software engineering;Information analysis;Information processing","formal specification","multiple views;requirements specification;heterogeneous components;multiple ViewPoints;partial requirements specifications;inter-ViewPoint communication;ViewPoints framework;consistency checking;inconsistency management;requirements specification method;CORE;computer-based ViewPoints support;The Viewer","","205","","63","","","","","","IEEE","IEEE Journals & Magazines"
"The role of opportunism in the software design reuse process","A. Sen","Dept. of Bus. Anal. & Res., Texas A&M Univ., College Station, TX, USA","IEEE Transactions on Software Engineering","","1997","23","7","418","436","Software design involves translating a set of task requirements into a structured description of a computer program that will perform the task. A software designer can use design schema, collaborative design knowledge, or can reuse design artifacts. Very little has been done to include reuse of design artifacts in the software development life cycle, despite tremendous promises of reuse. As a result, this technique has not seen widespread use, possibly due to a lack of cognitive understanding of the reuse process. This research explores the role of a specific cognitive aspect, opportunism, in demand-side software reuse. We propose a cognitive model based on opportunism that describes the software design process with reuse. Protocol analysis verifies that the software design with reuse is indeed opportunistic and reveals that some software designers employ certain tasks of the reuse process frequently. Based on these findings, we propose a reuse support system that incorporates blackboard technology and existing reuse library management system.","0098-5589;1939-3520;2326-3881","","10.1109/32.605760","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=605760","","Software design;Software reusability;Software tools;Collaborative software;Programming;Software libraries;Investments;Humans;Computer aided software engineering;Process design","software reusability;software libraries;software tools;blackboard architecture","opportunism;software design reuse process;task requirements;structured description;design schema;collaborative design knowledge;software development life cycle;cognitive model;demand-side software reuse;protocol analysis;blackboard technology;reuse library management system","","27","","42","","","","","","IEEE","IEEE Journals & Magazines"
"Semiautomatic implementation of protocols using an Estelle-C compiler","S. T. Vuong; A. C. Lau; R. I. Chan","Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada; Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada; Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada","IEEE Transactions on Software Engineering","","1988","14","3","384","393","The basic ideas underlying an Estelle-C compiler, which accepts an Estelle protocol specification and produces a protocol implementation in C, are presented. The implementation of the ISO (International Organization for Standardization) class-2 transparent protocol, using the semiautomatic approach, is discussed. A manual implementation of the protocol is performed and compared to the semiautomatic implementation. The semiautomatic approach to protocol implementation offers several advantages over the conventional manual one, including correctness and modularity in protocol implementation code, conformance to the specification, and reduction in implementation time. Finally, ongoing development of a new Estelle-C compiler is presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4658","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4658","","Transport protocols;Testing;Trademarks;Research and development;Standards development;Code standards;Workstations;Sun;Ethernet networks","program compilers;protocols","protocols;Estelle-C compiler;specification;ISO;class-2 transparent protocol;modularity","","33","","25","","","","","","IEEE","IEEE Journals & Magazines"
"An efficient implementation of static string pattern matching machines","J. -. Aoe","Dept. of Inf. Sci. & Syst. Eng., Tokushima Univ., Japan","IEEE Transactions on Software Engineering","","1989","15","8","1010","1016","A technique for implementing a static transition table of a string pattern matching machine which locates all occurrences of a finite number of keywords in a string is described. The approach is based on S.C. Johnson's (1975) storage and retrieval method of the transition table of a finite-state machine. By restricting the transition table of the finite-state machine to that of the string pattern-matching machine, triple arrays of Johnsons's data structure can be reduced to two arrays. The retrieval program of the reduced data structure can be speeded up by a finite straight program without loops.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.31357","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=31357","","Pattern matching;Scanning probe microscopy;Data structures;Automata;Information retrieval;Libraries;Filtering;Frequency;Information analysis;Pattern analysis","data structures;information retrieval;subroutines","implementation technique;keyword location;static string pattern matching machines;transition table;finite-state machine;triple arrays;Johnsons's data structure;retrieval program;reduced data structure;finite straight program","","16","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Verification of concurrent control flow in distributed computer systems","S. S. Yau; W. Hong","Dept. of Electr. Eng. & Comput. Sci., Northwestern Univ., Evanston, IL, USA; Dept. of Electr. Eng. & Comput. Sci., Northwestern Univ., Evanston, IL, USA","IEEE Transactions on Software Engineering","","1988","14","4","405","417","An approach to verifying control flow in distributed computer systems (DCS) is presented. The approach is based on control flow checking among software components distributed over processors and cooperating among them. In this approach, control-flow behavior of DCS software is modeled and contained in special software components called verifiers. The verifiers are distributed over the processors and consulted to check the correctness of the control flow in DCS software during its execution. Algorithms for deriving the verifiers are presented. This technique can detect global errors including synchronization errors as well as local errors. It can be used for sequential or concurrent software at various levels of details. Experiments show that using this technique requires no significant overhead.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4662","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4662","","Distributed control;Control systems;Concurrent computing;Distributed computing;Computer errors;Software maintenance;Error correction;Fault tolerance;Software testing;Sequential analysis","distributed processing;program verification;programming theory","distributed software;program verification;program correctness;concurrent control flow;control flow checking;software components;global errors;synchronization errors;local errors;concurrent software","","3","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Exercises in Software Design","J. L. Bentley; J. A. Dallen","AT&amp;T Bell Laboratories; NA","IEEE Transactions on Software Engineering","","1987","SE-13","11","1164","1169","Typical software engineering courses teach principles in lectures and readings, then apply them in the development of a single program (requiring several months). We recently taught a software engineering class that incorporated many smaller exercises (requiring several hours). The class was successful: students were able to experiment with a broad set of ideas, and make interesting mistakes without jeopardizing the grades of their development team. This paper describes some tools and techniques we taught, and suggests how they might be incorporated into typical software engineering classes.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232865","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702163","Awk language;engineering design;prototyping;software engineering education","Software design;Software engineering;Computer science;Military computing;Pipelines;Design engineering;Software prototyping;Computer science education;Documentation;Geography","","Awk language;engineering design;prototyping;software engineering education","","1","","7","","","","","","IEEE","IEEE Journals & Magazines"
"On the Multiple Implementation of Abstract Data Types Within a Computation","J. R. White","Xerox Palo Alto Research Center","IEEE Transactions on Software Engineering","","1983","SE-9","4","395","411","A fundamental step in the software design process is the selection of a refinement (implementation) for a data abstraction. This step traditionally involves investigating the expected performance of a system under different refinements of an abstraction and then selecting a single alternative which minimizes some performance cost metric. In this paper we reformulate this design step to allow different refinements of the same data abstraction within a computation. This reformulation reflects the fact that the implementation appropriate for a data abstraction is dependent on the behavior exhibited by the objects of the abstraction. Since this behavior can vary among the objects of a computation, a single refinement is often inappropriate. Accordingly, three frameworks are presented for understanding and representing variations in the behavior of objects and, thus, the potential for multiple implementations. The three frameworks are based upon: 1) a static partitioning of objects into disjoint implementation classes; 2) static partitioning of classes into implementation regions; and 3) dynamic partitioning of classes into implementation regions. These frameworks and analytic tools useful in investigating expected performance under multiple implementations are described in detail.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.234776","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703074","Abstract data type;abstraction refinement;data abstraction;multiple implementations;performance analysis;software design;software engineering","Software design;Design methodology;Performance analysis;Costs;Software engineering;Software systems;Encapsulation;Software maintenance;Packaging;Computer science","","Abstract data type;abstraction refinement;data abstraction;multiple implementations;performance analysis;software design;software engineering","","","","39","","","","","","IEEE","IEEE Journals & Magazines"
"Knowledge-based programming: A survey of program design and construction techniques","A. T. Goldberg","Kestrel Institute, Palo Alto, CA 94304; Department of Computer and Information Sciences University of California, Santa Cruz, CA 95064","IEEE Transactions on Software Engineering","","1986","SE-12","7","752","768","An application of artificial intelligence (AI) to the development of software is presented for the construction of efficient implementations of programs from formal high-level specifications. Central to this discussion is the notion of program development by means of program transformation. Using this methodology, a formal specification is compiled (either manually or automatically) into an efficient implementation by the repeated application of correctness-preserving, source-to-source transformations. The author considers techniques for data structure selection, the procedural representation of logic assertions, store-versus-compute, finite differencing, loop fusion, and algorithm design methods presented from the point of view of algorithm design and high-level program optimization.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312977","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312977","Knowledge-based software development;program optimization;program synthesis;program transformation;very-high-level languages","Knowledge based systems;Software;Programming;Data structures;Optimization;Semantics","artificial intelligence;programming;programming theory","program design;artificial intelligence;formal high-level specifications;program development;program transformation;correctness-preserving;source-to-source transformations;data structure selection;procedural representation;logic assertions;finite differencing;loop fusion;algorithm design","","11","","","","","","","","IEEE","IEEE Journals & Magazines"
"A retrospective on the VAX VMM security kernel","P. A. Karger; M. E. Zurko; D. W. Bonin; A. H. Mason; C. E. Kahn","Open Software Found., Cambridge, MA, USA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1991","17","11","1147","1165","The development of a virtual-machine monitor (VMM) security kernel for the VAX architecture is described. The focus is on how the system's hardware, microcode, and software are aimed at meeting A1-level security requirements while maintaining the standard interfaces and applications of the VMS and ULTRIX-32 operating systems. The VAX security kernel supports multiple concurrent virtual machines on a single VAX system, providing isolation and controlled sharing of sensitive data. Rigorous engineering standards were applied during development to comply with the assurance requirements for verification and configuration management. The VAX security kernel has been developed with a heavy emphasis on performance and system management tools. The kernel performs sufficiently well that much of its development was carried out in virtual machines running on the kernel itself, rather than in a conventional time-sharing system.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.106971","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=106971","","Kernel;Data security;Virtual machining;Computer architecture;Hardware;Software maintenance;Software standards;Application software;Voice mail;Operating systems","DEC computers;security of data;supervisory programs;virtual machines","VAX VMM;security kernel;virtual-machine monitor;microcode;A1-level security requirements;standard interfaces;ULTRIX-32 operating systems;multiple concurrent virtual machines;isolation;controlled sharing;sensitive data;configuration management;system management tools","","56","","56","","","","","","IEEE","IEEE Journals & Magazines"
"Modeling and evaluating design alternatives for an on-line instrumentation system: a case study","A. Waheed; D. T. Rover; J. K. Hollingsworth","MRJ Technol. Solutions, NASA Ames Res. Center, Moffett Field, CA, USA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","6","451","470","This paper demonstrates the use of a model-based evaluation approach for instrumentation systems (ISs). The overall objective of this study is to provide early feedback to tool developers regarding IS overhead and performance; such feedback helps developers make appropriate design decisions about alternative system configurations and task scheduling policies. We consider three types of system architectures: network of workstations (NOW), symmetric multiprocessors (SMP), and massively parallel processing (MPP) systems. We develop a Resource OCCupancy (ROCC) model for an on-line IS for an existing tool and parameterize it for an IBM SP-2 platform. This model is simulated to answer several ""what if"" questions regarding two policies to schedule instrumentation data forwarding: collect-and-forward (CF) and batch-and-forward (BF). In addition, this study investigates two alternatives for forwarding the instrumentation data: direct and binary tree forwarding for an MPP system. Simulation results indicate that the BF policy can significantly reduce the overhead and that the tree forwarding configuration exhibits desirable scalability characteristics for MPP systems. Initial measurement-based testing results indicate more than 60 percent reduction in the direct IS overhead when the BF policy was added to Paradyn parallel performance measurement tool.","0098-5589;1939-3520;2326-3881","","10.1109/32.689402","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=689402","","Instruments;Computer aided software engineering;Feedback;Application software;Monitoring;Real time systems;System testing;Space technology;Workstations;Parallel processing","parallel processing;multiprocessing programs;system monitoring;software tools;software metrics","design alternatives;on-line instrumentation system;model-based evaluation approach;tool developers;design decisions;alternative system configurations;task scheduling policies;system architectures;symmetric multiprocessors;massively parallel processing;IBM SP-2 platform;collect-and-forward;batch-and-forward;tree forwarding configuration;scalability characteristics;Paradyn parallel performance measurement tool","","2","","33","","","","","","IEEE","IEEE Journals & Magazines"
"Interprocedural def-use associations for C systems with single level pointers","H. D. Pande; W. A. Landi; B. G. Ryder","Siemens Corp. Res. Inc., Princeton, NJ, USA; Siemens Corp. Res. Inc., Princeton, NJ, USA; NA","IEEE Transactions on Software Engineering","","1994","20","5","385","403","Def-use analysis links possible value-setting statements for a variable (i.e. definitions) to potential value-fetches (i.e. uses) of that value. This paper describes the first algorithm that calculates accurate interprocedural def-use associations in C software systems. Our algorithm accounts for program-point-specific pointer-induced aliases, though it is currently limited to programs using a single level of indirection. We prove the NP-hardness of the interprocedural reaching definitions problem and describe the approximations made by our polynomial-time algorithm. Initial empirical results are also presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.286418","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=286418","","Performance analysis;Polynomials;Algorithm design and analysis;Arithmetic;Software tools;Debugging;System testing;Information analysis;Software systems;Computer science","computational complexity;C language;program compilers;program diagnostics;software engineering;data structures","interprocedural def-use associations;C software systems;single level pointers;value-setting statements;value-fetches;program-point-specific pointer-induced aliases;indirection;NP-hardness;interprocedural reaching definitions problem;polynomial-time algorithm;static analysis","","37","","60","","","","","","IEEE","IEEE Journals & Magazines"
"Algorithms for constructing minimal deduction graphs","C. -. Yang; J. J. -. Chen; H. L. Chau","Dept. of Comput. Sci., Univ. of North Texas, Denton, TX, USA; NA; NA","IEEE Transactions on Software Engineering","","1989","15","6","760","770","Two algorithms for constructing minimal deduction graphs (MDG) for inferring rules and facts in an extended version of the Horn clause logic are described. A deduction graph (DG) is minimal if the number of arcs in the graph is minimized. Horn clauses (HC) are extended to Horn formulas (HF), such that the head or the body of an HF can be a conjunction of positive literals or a disjunction of the bodies of some rule instances, respectively. Each algorithm constructs an MDG from its source to its sink, whose arcs infer the HF 'if source then sink'. The construction of an MDG is based on a sound and complete set of inference rules of reflexivity, transitivity, and conjunction for HFs which proceeds by expanding a tree rooted at its sink until its source has a successful backtracking to the root. Then the MDG is extracted from the tree. The nodes being expanded in such a tree are classified into seven types, which are assigned by different priorities for their growing into subtrees or for their pruning to reduce the tree space.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24729","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24729","","Hafnium;Tree graphs;Expert systems;Relational databases;Logic;Engines;Chaos;Inference algorithms;Classification tree analysis;Knowledge based systems","expert systems;graphs;inference mechanisms;logic programming","MDG construction algorithms;Hern clauses;minimal deduction graphs;Horn clause logic;DG;arcs;Horn formulas;HF;positive literals;rule instances;sink;inference rules;reflexivity;transitivity;backtracking;subtrees;tree space","","8","","18","","","","","","IEEE","IEEE Journals & Magazines"
"NON-VON's performance on certain database benchmarks","B. K. Hillyer; D. E. Shaw; A. Nigam","Department of Computer Science, Columbia University, New York, NY 10027; Department of Computer Science, Columbia University, New York, NY 10027; IBM Thomas J. Watson Research Center, Yorktown Heights, NY 10598","IEEE Transactions on Software Engineering","","1986","SE-12","4","577","583","In a paper by P.B. Hawthorn and D.J. DeWitt (1982) the projected performance of several proposed database machines was examined for three relational database queries. The present authors investigate the performance of a massively parallel machine called NON-VON for the same queries under comparable assumptions. In the case of simple queries, a NON-VON machine of comparable size to those considered by Hawthorn and DeWitt is found to be somewhat faster than the fastest machines examined in their study; for a more complex database operation, NON-VON is shown to be five to ten times faster than the fastest of these machines.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312905","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312905","Associative processor;computer architecture;database machine;database management;parallel processor;performance analysis;SIMD machine;tree machine","Magnetic heads;Process control;Clocks;Computer architecture;Random access memory;Loading;Disk drives","database management systems;parallel processing;performance evaluation;relational databases","performance;database machines;relational database queries;parallel machine;NON-VON","","7","","","","","","","","IEEE","IEEE Journals & Magazines"
"Atomic Remote Procedure Call","Kwei-Jay Lin; J. D. Gannon","Department of Computer Science, University of Maryland; NA","IEEE Transactions on Software Engineering","","1985","SE-11","10","1126","1135","Remote procedure call (RPC) is a programming primitive that makes building distributed programs easier. Atomicity, whkh implies totality and serializability, has been recognized as an important property to assure consistency in spite of computing node crashes. We have implemented an atomk remote procedure call mechanism which provides users a simple and reliable language primitive. Concurrency is controlled by attaching a call graph path identifier to each message representing a procedure call. Procedures keep their last accepted calling message paths to compare against incoming message paths. Only calls that can be serialized are accepted. Associated states of static variables are saved in backup processors on procedure entry and restored to corresponding variables in case of procedure crash. Detailed concurrency control and recovery algorithms are given, and illustrated with examples.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231860","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701928","Atomic action;concurrency;distributed system;reliability;remote procedure call","Computer crashes;Communication channels;Concurrent computing;Concurrency control;Computer languages;Joining processes;Telecommunication network reliability;Intelligent networks;Distributed computing;Resource management","","Atomic action;concurrency;distributed system;reliability;remote procedure call","","6","","17","","","","","","IEEE","IEEE Journals & Magazines"
"An empirical evaluation of weak mutation","A. J. Offutt; S. D. Lee","Dept. of Inf. & Software Syst. Eng., George Mason Univ., Fairfax, VA, USA; NA","IEEE Transactions on Software Engineering","","1994","20","5","337","344","Mutation testing is a fault-based technique for unit-level software testing. Weak mutation was proposed as a way to reduce the expense of mutation testing. Unfortunately, weak mutation is also expected to provide a weaker test of the software than mutation testing does. This paper presents results from an implementation of weak mutation, which we used to evaluate the effectiveness versus the efficiency of weak mutation. Additionally, we examined several options in an attempt to find the most appropriate way to implement weak mutation. Our results indicate that weak mutation can be applied in a manner that is almost as effective as mutation testing, and with significant computational savings.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.286422","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=286422","","Genetic mutations;Software testing;Programming profession;Software systems;Algorithms;Automatic testing;System testing;Computer science;Systems engineering and theory;Software engineering","program testing;software engineering","weak mutation;mutation testing;fault-based technique;unit-level software testing;effectiveness;efficiency;computational savings","","84","","32","","","","","","IEEE","IEEE Journals & Magazines"
"Approximate throughput analysis of cyclic queueing networks with finite buffers","R. O. Onvural; H. G. Perros","Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA; Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA","IEEE Transactions on Software Engineering","","1989","15","6","800","808","An approximation method for obtaining the throughput of cyclic queueing networks with blocking as a function of the number of customers in it is presented. The approximation method was developed for two different blocking mechanisms. It was also extended to the case of the central server model with blocking. Validation tests show that the algorithm is fairly accurate.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24733","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24733","","Throughput;Queueing analysis;Network servers;Approximation methods;Computer science;Signal processing;Testing;System recovery;Computer networks;Bismuth","computer networks;performance evaluation;queueing theory","approximate throughput analysis;validation tests;finite buffers;approximation method;cyclic queueing networks;customers;blocking mechanisms;central server model","","31","","18","","","","","","IEEE","IEEE Journals & Magazines"
"On the Design of a Microcode Compiler for a Machine-Independent High-Level Language","P. -. R. Ma; T. G. Lewis","TRW Systems Group; NA","IEEE Transactions on Software Engineering","","1981","SE-7","3","261","274","A translator system employing a partial compiler, intermediate language, and three-pass code generator is described that produces compact microcode for a class of horizontal microinstruction machines.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230836","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702839","Code compaction;code optimization;high-level language compilers;microcode optimization;microprogramming;portability;translator writing systems","High level languages;Microprogramming;Optimizing compilers;Compaction;Application software;Hardware;Software tools;Computer science;Concurrent computing;Writing","","Code compaction;code optimization;high-level language compilers;microcode optimization;microprogramming;portability;translator writing systems","","8","","25","","","","","","IEEE","IEEE Journals & Magazines"
"A formal evaluation of data flow path selection criteria","L. A. Clarke; A. Podgurski; D. J. Richardson; S. J. Zeil","Dept. of Comput. & Inf. Sci., Massachusetts Univ., Amherst, MA, USA; Dept. of Comput. & Inf. Sci., Massachusetts Univ., Amherst, MA, USA; Dept. of Comput. & Inf. Sci., Massachusetts Univ., Amherst, MA, USA; Dept. of Comput. & Inf. Sci., Massachusetts Univ., Amherst, MA, USA","IEEE Transactions on Software Engineering","","1989","15","11","1318","1332","The authors report on the results of their evaluation of path-selection criteria based on data-flow relationships. They show how these criteria relate to each other, thereby demonstrating some of their strengths and weaknesses. A subsumption hierarchy showing their relationship is presented. It is shown that one of the major weaknesses of all the criteria is that they are based solely on syntactic information and do not consider semantic issues such as infeasible paths. The authors discuss the infeasible-path problem as well as other issues that must be considered in order to evaluate these criteria more meaningfully and to formulate a more effective path-selection criterion.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.41326","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=41326","","Software testing;Information science;Computer science;Marine vehicles;Programming profession;Contracts;Terminology","flowcharting;software engineering","formal evaluation;data flow path selection criteria;data-flow relationships;subsumption hierarchy;syntactic information;infeasible-path problem","","76","","27","","","","","","IEEE","IEEE Journals & Magazines"
"A programming methodology for dual-tier multicomputers","S. B. Baden; S. J. Fink","Dept. of Comput. Sci. & Eng., California Univ., San Diego, La Jolla, CA, USA; NA","IEEE Transactions on Software Engineering","","2000","26","3","212","226","Hierarchically organized ensembles of shared memory multiprocessors possess a richer and more complex model of locality than previous generation multicomputers with single processor nodes. These dual-tier computers introduce many new factors into the programmer's performance model. We present a methodology for implementing block-structured numerical applications on dual-tier computers and a run-time infrastructure, called KeLP2, that implements the methodology. KeLP2 supports two levels of locality and parallelism via hierarchical SPMD control flow, run-time geometric meta-data, and asynchronous collective communication. KeLP applications can effectively overlap communication with computation under conditions where nonblocking point-to-point message passing fails to do so. KeLP's abstractions hide considerable detail without sacrificing performance and dual-tier applications written in KeLP consistently outperform equivalent single-tier implementations written in MPI. We describe the KeLP2 model and show how it facilitates the implementation of five block-structured applications specially formulated to hide communication latency on dual-tiered architectures. We support our arguments with empirical data from applications running on various single- and dual-tier multicomputers. KeLP2 supports a migration path from single-tier to dual-tier platforms and we illustrate this capability with a detailed programming example.","0098-5589;1939-3520;2326-3881","","10.1109/32.842948","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=842948","","Application software;Concurrent computing;Parallel processing;Programming profession;Computer architecture;Computer applications;Runtime;Communication system control;Message passing;Delay","message passing;shared memory systems;parallel processing;parallel programming","programming methodology;dual-tier multicomputers;shared memory multiprocessors;performance model;block-structured numerical applications;run-time infrastructure;KeLP2;hierarchical SPMD control flow;run-time geometric meta-data;asynchronous collective communication;point-to-point message passing;communication latency;dual-tiered architectures","","15","","50","","","","","","IEEE","IEEE Journals & Magazines"
"An Empirical Study of Distributed Application Performance","K. A. Lantz; W. I. Nowicki; A. M. Theimer","Department of Computer Science, Stanford University; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","10","1162","1174","A major reason for the rarity of distributed applications, despite the proliferation of networks, is the sensitivity of their performance to various aspects of the network environment. We demonstrate that distributed applications can run faster than local ones, using common hardware. We also show that the primary factors affecting performance are, in approximate order of importance: speed of the user's workstation, speed of the remote host (if any), and the high-level (above the transport level) protocols used. In particular, the use of batching, pipelining, and structure in high-level protocols reduces the degradation often experienced between different bandwidth networks. Less significant, but still noticeable improvements result from proper design and implementation of the underlying transport protocols. Ultimately, with proper application of these techniques, network bandwidth is rendered virtually insignificant.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231864","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701932","Concurrency;distributed programming;distributed systems;performance evaluation;protocol design;protocol implementation","Transport protocols;Application software;Computational efficiency;Distributed computing;Bandwidth;Contracts;Computer science;Graphics;Hardware;Workstations","","Concurrency;distributed programming;distributed systems;performance evaluation;protocol design;protocol implementation","","9","","28","","","","","","IEEE","IEEE Journals & Magazines"
"On Homogeneity and On Line=Off-Line Behavior in M/G/1 Queueing Systems","R. M. Bryant","Department of Computer Sciences and the Madison Academic Computing Center, University of Wisconsin-Madison","IEEE Transactions on Software Engineering","","1981","SE-7","3","291","299","Operational analysis replaces certain classical queueing theory assumptions with the conditions of ""homogeneous service times"" and ""on-line= off-line behavior."" In this paper we explore the relationship between the operational and classical concepts for the sample paths of an M/G/1 queueing system. The primary results are that the sample paths can have these operational properties with nonzero probability if and only if the service time is exponential. We also state dual results for interarrival times in G/M/l. Additionally, we show that open, feedforward networks of single server queues can have product form solutions valid across a range of system arrival rates if and only if all of the service times are exponential. Finally, we consider the relationship between the operational quantities S(n) and the mean service time in M/G/1. This relationship is shown to depend on the form of the service time distribution. It follows that using operational analysis to predict the performance of an M/G/1 queueing system will be most successful when the service time is exponential. Simulation evidence is presented which supports this claim.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230840","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702843","Computer system modeling;decomposition;G/M/1;M/G/1;networks of queues;operational analysis;service functions","Queueing analysis;Military computing;Stochastic systems;Network servers;Performance analysis;Modeling;State estimation;Computer performance;Predictive models;Job listing service","","Computer system modeling;decomposition;G/M/1;M/G/1;networks of queues;operational analysis;service functions","","3","","17","","","","","","IEEE","IEEE Journals & Magazines"
"A set of inference rules for quantified formula handling and array handling in verification of programs over integers","D. Sarkar; S. C. De Sarkar","Dept. of Comput. Sci. & Eng., Indian Inst. of Technol., Kharagpur, India; Dept. of Comput. Sci. & Eng., Indian Inst. of Technol., Kharagpur, India","IEEE Transactions on Software Engineering","","1989","15","11","1368","1381","Because of the undecidability problem of program verification, it becomes necessary for an automated verifier to seek human assistance for proving theorems which fall beyond its capability. In order that the user be able to interact smoothly with the machine, it is desired that the theorems be maintained and processed by the prover in a form as close as possible to the popular algebraic notation. Motivated by the need of such an automated verifier, which works in an environment congenial to human participation and at the same time uses the methodologies of resolution provers of first-order logic, some inference rules have previously been proposed by the authors (ibid., vol.15, no.1, p.1-9, Jan. 1989) for integer arithmetic, and their completeness issues have been discussed. In the present work, the authors examine how these rules can be applied to quantified formulas vis-a-vis verification of programs involving arrays. An interesting situation, referred to as bound-extension, has been found to occur frequently in proving the quantified verification conditions of the paths in a program. A novel rule, called bound-extension rule, has been devised to consolidate and depict the various issues involved in a bound-extension process. It has been proved that the rule set proposed previously by the authors is adequate for handling a more general phenomenon, called bound-modification, which covers bound-extension in all its entirety.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.41330","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=41330","","Humans;Programmable logic arrays;Arithmetic;Costs;Computer science;Formal languages;Calculus;Programming profession;Virtual colonoscopy","decidability;inference mechanisms;program verification;theorem proving","inference rules;quantified formula handling;array handling;undecidability problem;program verification;automated verifier;first-order logic;integer arithmetic;quantified formulas;bound-extension rule;bound-modification","","1","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Handling timing errors in distributed programs","A. J. Gordon; R. A. Finkel","Dept. of Math. & Comput. Sci., Colorado Sch. of Mines, Golden, CO, USA; NA","IEEE Transactions on Software Engineering","","1988","14","10","1525","1535","The authors describe a tool called TAP, which is defined to aid the programmer in discovering the causes of timing errors in running programs. TAP is similar to a postmortem debugger, using the history of interprocess communication to construct a timing graph, a directed graph where an edge joins node x to node y if event x directly precedes event y in time. The programmer can then use TAP to look at the graph to find the events that occurred in an unacceptable order. Because of the nondeterministic nature of distributed programs, the authors feel a history-keeping mechanism but always be active so that bugs can be dealt with as they occur. The goal is to collect enough information at run time to construct the timing graph if needed. Since it is always active, this mechanism must be efficient. The authors also describe experiments run using TAP and report the impact that TAP's history-keeping mechanism has on the running time of various distributed programs.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6197","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6197","","Timing;Programming profession;Computer bugs;History;Debugging;Error correction;Degradation;Computer science;Computer errors;Operating systems","directed graphs;distributed processing;program testing;software tools","distributed programs;TAP;timing errors;postmortem debugger;interprocess communication;timing graph;directed graph;history-keeping mechanism","","2","","21","","","","","","IEEE","IEEE Journals & Magazines"
"An Information-Based Model for Failure-Handling in Distributed Database Systems","F. Y. Chin; K. V. S. Ramarao","Center for Computer Studies and Applications, University of Hong Kong; NA","IEEE Transactions on Software Engineering","","1987","SE-13","4","420","431","We consider the failure atomicity problem of distributed transactions in conjunction with the maximization of database availability. We propose a new information-based model for the distributed transaction-execution, which explicitly expresses the information at each stage during a protocol. In addition to rederiving certain existing results, we prove a fundamental relation among the site failures and the network partitioning. We propose a realistic model for site failures under which we show that the costs of commit and termination protocols can be greatly reduced. Finally, we explore the possible recovery strategies for a failed site and show how they are improved under our site failure model.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233179","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702234","Atomic transactions;database availability;network partitioning;nonblocking commit protocols;nontrivial termination;recovery strategies;site failures","Database systems;Transaction databases;Protocols;Distributed databases;Availability;Costs;Degradation;Councils;Computer applications;Application software","","Atomic transactions;database availability;network partitioning;nonblocking commit protocols;nontrivial termination;recovery strategies;site failures","","1","","13","","","","","","IEEE","IEEE Journals & Magazines"
"A case history analysis of software error cause-effect relationships","T. Nakajo; H. Kume","Fac. of Eng., Tokyo Univ., Japan; Fac. of Eng., Tokyo Univ., Japan","IEEE Transactions on Software Engineering","","1991","17","8","830","838","Approximately 700 errors in four commercial measuring-control software products were analyzed, and the cause-effect relationships of errors occurring during software development were identified. The analysis method used defined appropriate observation points along the path leading from cause to effect of a software error and gathered the corresponding data by analyzing each error using fault tree analysis. Each observation point's data were categorized, and the relationships between two adjoining points were summarized using a cross-indexing table. Four major error-occurrence mechanisms were identified; two are related to hardware and software interface specification misunderstandings, while the other two are related to system and module function misunderstandings. The effects of structured analysis and structured design methods on software errors were evaluated.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.83917","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=83917","","Computer aided software engineering;History;Error analysis;Cause effect analysis;Humans;Programming;Data analysis;US Department of Transportation;Computer errors;Marine vehicles","computerised control;failure analysis;software reliability;structured programming;system recovery;systems analysis","case history analysis;commercial measuring-control software products;cause-effect relationships;software development;observation points;software error;fault tree analysis;cross-indexing table;error-occurrence mechanisms;software interface specification misunderstandings;module function misunderstandings;structured analysis;structured design methods","","18","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Testing Formal Specifications to Detect Design Errors","R. A. Kemmerer","Department of Computer Science, University of California","IEEE Transactions on Software Engineering","","1985","SE-11","1","32","43","Formal specification and verification techniques are now apused to increase the reliability of software systems. However, these proaches sometimes result in specifying systems that cannot be realized or that are not usable. This paper demonstrates why it is necessary to test specifications early in the software life cycle to guarantee a system that meets its critical requirements and that also provides the desired functionality. Definitions to provide the framework for classifying the validity of a functional requirement with respect to a formal specification tion are also introduced. Finally, the design of two tools for testing formal specifications is discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231535","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701896","Design and development;formal verification;reliable software;requirements;specification;testing","Formal specifications;Formal verification;Information security;Software testing;Software systems;Life testing;System testing;Computer science","","Design and development;formal verification;reliable software;requirements;specification;testing","","87","","7","","","","","","IEEE","IEEE Journals & Magazines"
"Proof rules for flush channels","T. Camp; P. Kearns; M. Ahuja","Dept. of Comput. Sci., Coll. of William & Mary, Williamsburg, VA, USA; Dept. of Comput. Sci., Coll. of William & Mary, Williamsburg, VA, USA; NA","IEEE Transactions on Software Engineering","","1993","19","4","366","378","Flush channels generalize conventional asynchronous communication constructs such as virtual circuits and datagrams. They permit the programmer to specify receipt-order restrictions on a message-by-message basis, providing an opportunity for more concurrency in a distributed program. A Hoare-style partial correctness verification methodology for distributed systems which use flush channel communication is developed, and it is shown that it it possible to reason about such systems in a relatively natural way.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.223804","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=223804","","Asynchronous communication;Programming profession;Concurrent computing;Computer science;Data engineering;Joining processes;Protocols;Context;Switching circuits;Packet switching","distributed processing;program verification","flush channels;asynchronous communication constructs;virtual circuits;datagrams;receipt-order restrictions;message-by-message basis;concurrency;distributed program;Hoare-style partial correctness verification methodology","","6","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Implementation of the Database Machine Direct","H. Boral; D. J. Dewitt; D. Friedland; N. F. Jarrell; W. K. Wilkinson","Department of Computer Sciences, University of Wisconsin; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1982","SE-8","6","533","543","DIRECT is a multiprocessor database machine designed and implemented at the University of Wisconsin. This paper describes our experiences with the implementation of DIRECT. We start with a brief overview of the original machine proposal and how it differs from what was actually implemented. We then describe the structure of the DIRECT software. This includes software on host computers that interfaces with the database machine; software on the back-end controller of DIRECT; and software executed by the query processors. In addition to describing the structure of the software we will attempt to motivate and justify its design and implementation. We also discuss a number of implementation issues (e.g., debugging of the code across several machines). We conclude the paper with a list of the ""lessons"" we have learned from this experience.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235882","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702986","Associative processors;computer architecture;database machine;database management;parallel processors","Database machines;Hardware;Computer architecture;Relational databases;Military computing;Aggregates;Proposals;Computer interfaces;Debugging;Software design","","Associative processors;computer architecture;database machine;database management;parallel processors","","14","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Test-execution-based reliability measurement and modeling for large commercial software","J. Tian; Peng Lu; J. Palma","IBM Software Solutions Toronto Lab., New York, Ont., Canada; NA; NA","IEEE Transactions on Software Engineering","","1995","21","5","405","414","The paper studies practical reliability measurement and modeling for large commercial software systems based on test execution data collected during system testing. The application environment and the goals of reliability assessment were analyzed to identify appropriate measurement data. Various reliability growth models were used on failure data normalized by test case executions to track testing progress and provide reliability assessment. Practical problems in data collection, reliability measurement and modeling, and modeling result analysis were also examined. The results demonstrated the feasibility of reliability measurement in a large commercial software development environment and provided a practical comparison of various reliability measurements and models under such an environment.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.387470","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=387470","","Software testing;Software measurement;System testing;Software systems;Application software;Software reliability;Relational databases;Time measurement;Programming","software reliability;testing;system monitoring","large commercial software;modeling;test-execution-based reliability measurement;test execution data;system testing;application environment;measurement data;reliability growth models;normalised failure data;testing progress tracking;reliability assessment;data collection;large commercial software development environment","","27","","15","","","","","","IEEE","IEEE Journals & Magazines"
"A New Security Testing Method and Its Application to the Secure Xenix Kernel","V. D. Gligor; C. S. Chandersekaran; Wen-Der Jiang; A. Johri; G. L. Luckenbaugh; L. E. Reich","Department of Electrical Engineering, University of Maryland; NA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","2","169","183","A new security testing method is proposed that combines the advantages of both traditional ""black box"" (monolithic functional) testing and ""white box"" (functional-synthesis-based) testing. The new method allows significant coverage both for security model-based tests and for individual kernel-call tests. It eliminates redundant kernel test cases 1) by using a variant of control synthesis graphs, 2) by analyzing dependencies between descriptive kernel-call specifications, and 3) by exploiting access check separability. A higher degree of test assurance is achieved than that of other security testing methods because the new method helps eliminate cyclic dependencies among test programs for different kernel calls. The application of this method to the testing of the Secure Xenix kernel is illustrated.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232890","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702198","Access check graphs;control synthesis graphs;cyclic dependencies;data flow coverage;functional testing;kernels;security model;security testing","Kernel;Software testing;Data security;Computer security;Control system synthesis;Flow graphs;System testing;Scattering;Thumb;Trademarks","","Access check graphs;control synthesis graphs;cyclic dependencies;data flow coverage;functional testing;kernels;security model;security testing","","5","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Debugging effort estimation using software metrics","N. Gorla; A. C. Benander; B. A. Benander","Dept. of Comput. Sci., Cleveland State Univ., OH, USA; Dept. of Comput. Sci., Cleveland State Univ., OH, USA; Dept. of Comput. Sci., Cleveland State Univ., OH, USA","IEEE Transactions on Software Engineering","","1990","16","2","223","231","Measurements of 23 style characteristics, and the program metrics LOC, V(g), VARS, and PARS were collected from student Cobol programs by a program analyzer. These measurements, together with debugging time (syntax and logic) data, were analyzed using several statistical procedures of SAS (statistical analysis system), including linear, quadratic, and multiple regressions. Some of the characteristics shown to correlate significantly with debug time are GOTO usage, structuring of the IF-ELSE construct, level 88 item usage, paragraph invocation pattern, and data name length. Among the observed characteristic measures which are associated with lowest debug times are: 17% blank lines in the data division, 12% blank lines in the procedure division, and 13-character-long data items. A debugging effort estimator, DEST, was developed to estimate debug times.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44385","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44385","","Debugging;Software metrics;Lab-on-a-chip;Reactive power;Logic;Synthetic aperture sonar;Regression analysis;Statistical analysis;Programming profession;Computational Intelligence Society","program debugging;program testing;statistical analysis","debugging effort estimation;quadratic regressions;linear regressions;software metrics;style characteristics;LOC;V(g);VARS;PARS;Cobol programs;program analyzer;statistical procedures;SAS;statistical analysis system;multiple regressions;GOTO usage;IF-ELSE construct;level 88 item usage;paragraph invocation pattern;data name length;debug times;DEST","","19","","12","","","","","","IEEE","IEEE Journals & Magazines"
"The Logical Access Path Schema of a Database","N. Roussopoulos","Department of Computer Science, University of Maryland","IEEE Transactions on Software Engineering","","1982","SE-8","6","563","573","A new schema which models the usage of the logical access paths of the database is proposed. The schema models all database activities (i.e., retrievals and updates), and integrates their logical access paths by recognizing common subpaths and increasing the ""weight"" of the shared subpaths. The logical access path schema provides a comprehensive picture of the logical access paths, and the cumulative usage of the shared subpaths and/or intermediate results. The schema serves a dual purpose. Firstly, it is used as a model of the access requirements during the database design, and secondly, as the basis for optimization during the operation of the database.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235886","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702990","Aggregation hierarchy;external logical subschema;generalization hierarchy;logical access path;propositional calculus;views","Databases;Joining processes;Information retrieval;Design optimization;Calculus;Data structures;Computer science","","Aggregation hierarchy;external logical subschema;generalization hierarchy;logical access path;propositional calculus;views","","28","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Modeling and verification of time dependent systems using time Petri nets","B. Berthomieu; M. Diaz","CNRS, Toulouse, France; CNRS, Toulouse, France","IEEE Transactions on Software Engineering","","1991","17","3","259","273","A description and analysis of concurrent systems, such as communication systems, whose behavior is dependent on explicit values of time is presented. An enumerative method is proposed in order to exhaustively validate the behavior of P. Merlin's time Petri net model, (1974). This method allows formal verification of time-dependent systems. It is applied to the specification and verification of the alternating bit protocol as a simple illustrative example.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.75415","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=75415","","Petri nets;Fires;Protocols;Reachability analysis","formal specification;parallel programming;Petri nets;program verification;protocols","verification;time dependent systems;time Petri nets;concurrent systems;communication systems;explicit values;formal verification;time-dependent systems;specification;alternating bit protocol","","590","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Fragtypes: a basis for programming environments","N. H. Madhavji","Sch. of Comput. Sci., McGill Univ., Montreal, Que., Canada","IEEE Transactions on Software Engineering","","1988","14","1","85","97","The author introduces a novel basis for programming environments that encourages development of software in fragments of various types, called fragtypes. Fragtypes range from a simple expression type to a complete subsystem type. As a result, they are suited to the development of software in an enlarged scope that includes both programming in the small and programming in the large. The author shows how proposed operations on fragtypes can achieve unusual effects on the software development process. Fragtypes and their associated construction rules form the basis of the programming environment MUPE-2, which is currently under development at McGill University. The target and the implementation language of this environment is the programming language Modula-2.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4625","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4625","","Programming environments;Software engineering;Power engineering and energy;Software systems;Systems engineering and theory;Councils;Computer science;Large-scale systems;Synthesizers;Utility programs","programming environments","programming environments;fragments;fragtypes;programming in the small;programming in the large;software development process;construction rules;MUPE-2;implementation language;programming language;Modula-2","","7","","18","","","","","","IEEE","IEEE Journals & Magazines"
"An Engineering Approach to Software Test Data Design","S. T. Redwine","MITRE Corporation","IEEE Transactions on Software Engineering","","1983","SE-9","2","191","200","A systematic approach to test data design is presented based on both practical translation of theory and organization of professional lore. The approach is organized around five domains and achieving coverage (exercise) of them by the test data. The domains are processing functions, input, output, interaction among functions, and the code itself. Checklists are used to generate data for processing functions. Separate checklists have been constructed for eight common business data processing functions such as editing, updating, sorting, and reporting. Checklists or specific concrete directions also exist for input, output, interaction, and code coverage. Two global heuristics concerning all test data are also used. A limited discussion on documenting test input data, expected results, and actual results is included.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236597","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703037","Multiple domain test coverage;software testing;test coverage;test data design;test documentation;test metrics","Data engineering;Design engineering;Software testing;Software design;System testing;Guidelines;Data processing;Sorting;Concrete;Documentation","","Multiple domain test coverage;software testing;test coverage;test data design;test documentation;test metrics","","11","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Encapsulation of parallelism and architecture-independence in extensible database query execution","G. Graefe; D. L. Davison","Dept. of Comput. Sci., Portland State Univ., OR, USA; NA","IEEE Transactions on Software Engineering","","1993","19","8","749","764","Emerging database application domains demand not only high functionality, but also high performance. To satisfy these two requirements, the Volcano query execution engine combines the efficient use of parallelism on a wide variety of computer architectures with an extensible set of query processing operators that can be nested into arbitrarily complex query evaluation plans. Volcano's novel exchange operator permits designing, developing, debugging, and tuning data manipulation operators in single-process environments but executing them in various forms of parallelism. The exchange operator shields the data manipulation operators from all parallelism issues. The design and implementation of the generalized exchange operator are examined. The authors justify their decision to support hierarchical architectures and argue that the exchange operator offers a significant advantage for development and maintenance of database query processing software. They discuss the integration of bit vector filtering into the exchange operator paradigm with only minor modifications.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.238579","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=238579","","Encapsulation;Parallel processing;Query processing;Databases;Volcanoes;Computer architecture;Application software;Engines;Debugging;Software maintenance","distributed databases;parallel programming;query processing","extensible database query execution;database application domains;high functionality;high performance;Volcano query execution engine;parallelism;computer architectures;query processing operators;arbitrarily complex query evaluation plans;debugging;data manipulation operators;exchange operator;generalized exchange operator;hierarchical architectures;database query processing software;bit vector filtering","","12","","63","","","","","","IEEE","IEEE Journals & Magazines"
"Experience using Web-based shotgun measures for large-system characterization and improvement","S. McLellan; A. Roesler; Z. Fei; S. Chandran; C. Spinuzzi","Schlumberger Lab. for Comput. Sci., Austin, TX, USA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","4","268","277","This article discusses our experience in using a World Wide Web-based shotgun measurement approach for mining and characterizing large software systems. The approach recognizes that measurement information is essentially management information, that different levels and functions of the organizational hierarchy require different information to make decisions, and that a measurement program is typically a discovery process about an organization's current modes of operations. What we found was the usefulness of a measurement program that also allows managers to dynamically formulate new goals and get answers to questions not specifically related to original goals but raised nonetheless by metric data. We describe three specific cases of decisions that were made using this approach and data collected from one large system and accessed using the company's intranet over the past two years.","0098-5589;1939-3520;2326-3881","","10.1109/32.677184","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=677184","","Software measurement;Software libraries;Current measurement;Application software;Systems engineering and theory;Software development management;Software tools;Software systems;Information management;Multidimensional systems","very large databases;software metrics;configuration management","Web-based shotgun measures;large-system characterization;measurement program;intranet;software mining;characterization;improvement paradigm;software metrics;shotgun measures;software reuse;process improvement;World Wide Web","","2","","21","","","","","","IEEE","IEEE Journals & Magazines"
"A design methodology for data-parallel applications","L. S. Nyland; J. F. Prins; A. Goldberg; P. H. Mills","Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","2000","26","4","293","314","A methodology for the design and development of data-parallel applications and components is presented. Data-parallelism is a well understood form of parallel computation, yet developing simple applications can involve substantial efforts to express the problem in low level notations. We describe a process of software development for data-parallel applications starting from high level specifications, generating repeated refinements of designs to match different architectural models and performance constraints, enabling a development activity with cost benefit analysis. Primary issues are algorithm choice, correctness, and efficiency, followed by data decomposition, load balancing, and message passing coordination. Development of a data-parallel multitarget tracking application is used as a case study, showing the progression from high to low level refinements. We conclude by describing tool support for the process.","0098-5589;1939-3520;2326-3881","","10.1109/32.844491","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=844491","","Design methodology;Concurrent computing;Application software;Parallel processing;Milling machines;Parallel programming;Cost benefit analysis;Load management;Process design;Algorithm design and analysis","parallel programming;parallel algorithms;cost-benefit analysis;message passing;resource allocation","data-parallel application design;design methodology;data-parallelism;parallel computation;low level notations;high level specifications;repeated refinements;architectural models;performance constraints;development activity;cost benefit analysis;algorithm choice;data decomposition;load balancing;message passing coordination;data-parallel multitarget tracking application;case study;tool support","","8","","49","","","","","","IEEE","IEEE Journals & Magazines"
"The Gradient Model Load Balancing Method","F. C. H. Lin; R. M. Keller","ESL Inc.; NA","IEEE Transactions on Software Engineering","","1987","SE-13","1","32","38","A dynamic load balancing method is proposed for a class of large-diameter multiprocessor systems. The method is based on the ""gradient model,"" which entails transferring backlogged tasks to nearby idle processors according to a pressure gradient indirectly established by requests from idle processors. The algorithm is fully distributed and asynchronous. Global balance is achieved by successive refinements of many localized balances. The gradient model is formulated so as to be independent of system topology.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232563","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702130","Applicative systems;computer architecture;data flow;distributed systems;load balancing;multiprocessor systems;reduction architecture","Load modeling;Load management;Multiprocessing systems;Computer architecture;Throughput;Time measurement;Delay;Protocols;Expert systems;Topology","","Applicative systems;computer architecture;data flow;distributed systems;load balancing;multiprocessor systems;reduction architecture","","101","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Abstractions for software architecture and tools to support them","M. Shaw; R. DeLine; D. V. Klein; T. L. Ross; D. M. Young; G. Zelesnik","Dept. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA; Dept. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1995","21","4","314","335","Architectures for software use rich abstractions and idioms to describe system components, the nature of interactions among the components, and the patterns that guide the composition of components into systems. These abstractions are higher level than the elements usually supported by programming languages and tools. They capture packaging and interaction issues as well as computational functionality. Well-established (if informal) patterns guide the architectural design of systems. We sketch a model for defining architectures and present an implementation of the basic level of that model. Our purpose is to support the abstractions used in practice by software designers. The implementation provides a testbed for experiments with a variety of system construction mechanisms. It distinguishes among different types of components and different ways these components can interact. It supports abstract interactions such as data flow and scheduling on the same footing as simple procedure call. It can express and check appropriate compatibility restrictions and configuration constraints. It accepts existing code as components, incurring no runtime overhead after initialization. It allows easy incorporation of specifications and associated analysis tools developed elsewhere. The implementation provides a base for extending the notation and validating the model.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.385970","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=385970","","Software architecture;Computer languages;Computer architecture;Software engineering;Computer science;Software design;Software tools;Packaging;System testing;Scheduling","software engineering;specification languages;software tools;scheduling;data flow computing","software architecture;software tools;abstractions;idioms;system component descriptions;component interactions;component composition;packaging;computational functionality;informal patterns;notation;software design;system construction mechanisms;abstract interactions;data flow;scheduling;model validation;compatibility restrictions;configuration constraints;initialization;specifications;analysis tools","","328","","39","","","","","","IEEE","IEEE Journals & Magazines"
"Constrained expressions: Adding analysis capabilities to design methods for concurrent software systems","G. S. Avrunin; L. K. Dillon; J. C. Wileden; W. E. Riddle","Department of Mathematics and Statistics, University of Massachusetts, Amherst, MA 01003; Department of Computer and Information Science, University of Massachusetts, Amherst, MA 01003; Department of Computer Science, University of California, Santa Barbara, CA 93106; Department of Computer and Information Science, University of Massachusetts, Amherst, MA 01003; Software design & analysis, inc., Boulder, CO 80303","IEEE Transactions on Software Engineering","","1986","SE-12","2","278","292","An approach to the design of concurrent software systems based on the constrained expression formalism is described. This formalism provides a rigorous conceptual model for the semantics of concurrent computations, thereby supporting analysis of important system properties as part of the design process. This approach allows designers to use standard specification and design languages, rather than forcing them to deal with the formal model explicitly or directly. As a result, the approach attains the benefits of formal rigor without the associated pain of unnatural concepts or notations for its users. The conceptual model of concurrency underlying the constrained expression formalism treats the collection of possible behaviors of a concurrent system as a set of sequences of events. The constrained expression formalism provides a useful closed-form description of these sequences. Algorithms were developed for translating designs expressed in a wide variety of notations into these constrained expression descriptions. A number of powerful analysis techniques that can be applied to these descriptions have also been developed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312944","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312944","Ada-based design notation;analysis techniques;concurrent software systems;constrained expressions;design method;event-based","Design methodology;Software systems;Semantics;Concurrent computing;Educational institutions;Filtering;Computer languages","parallel processing;software engineering;specification languages","software engineering;analysis capabilities;design methods;concurrent software systems;constrained expression formalism;semantics;system properties;design process;specification;design languages;closed-form description","","18","","","","","","","","IEEE","IEEE Journals & Magazines"
"A transaction-based approach to vertical partitioning for relational database systems","W. W. Chu; I. T. Ieong","Dept. of Comput. Sci., California Univ., Los Angeles, CA, USA; Dept. of Comput. Sci., California Univ., Los Angeles, CA, USA","IEEE Transactions on Software Engineering","","1993","19","8","804","812","An approach to vertical partitioning in relational databases in which the attributes of a relation are partitioned according to a set of transactions is proposed. The objective of vertical partitioning is to minimize the number of disk accesses in the system. Since transactions have more semantic meanings than attributes, this approach allows the optimization of the partitioning based on a selected set of important transactions. An optimal binary partitioning (OBP) algorithm based on the branch and bound method is presented, with the worst case complexity of O(2/sup n/), where n is the number of transactions. To handle systems with a large number of transactions, an algorithm BPi with complexity varying from O(n) to O(2/sup n/) is also developed. The experimental results reveal that the performance of vertical partitioning is sensitive to the skewness of transaction accesses. Further, BPi converges rather rapidly to OBP. Both OBP and BPi yield results comparable with that of global optimum obtained from an exhaustive search.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.238583","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=238583","","Relational databases;Partitioning algorithms;Transaction databases;Clustering algorithms;Delay;Information retrieval;Costs;Tree graphs;Integer linear programming","computational complexity;relational databases;transaction processing","transaction-based approach;vertical partitioning;relational databases;disk accesses;semantic meanings;optimal binary partitioning;OBP;branch and bound method;BPi;complexity;transaction accesses;global optimum","","29","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Specification of fault-tolerant system issues by predicate/transition nets and regular expressions-approach and case study","F. Belli; K. -. Grosspietsch","Dept. of Electr. & Electron. Eng., Paderborn Univ., St. Augustin, Germany; Dept. of Electr. & Electron. Eng., Paderborn Univ., St. Augustin, Germany","IEEE Transactions on Software Engineering","","1991","17","6","513","526","A method to systematically integrate fault tolerance properties into the design of complex software systems is presented. The method exploits a formal specification of the system in which the amount of necessary redundancy can be determined. The system description is based on a combination of a predicate/transition net with regular expressions. The net model provides a formal overview of the system behavior in general, supporting the correct understanding of potential concurrency in the system processes. Regular expressions are used to model the sequential behavior of single-system components in detail. Both model layers provide well-defined levels of error detection; the regular expressions enable the system designer to also determine and introduce redundancy to achieve error correction. The techniques used to describe and analyze system behavior are explained using a case study that contains a stepwise-refined specification and analysis of a multistory shelving system model that has been implemented using the method presented. It is shown that the method applies to any software system which is to be protected against the considered errors.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.87278","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=87278","","Fault tolerant systems;Software systems;Fault detection;Redundancy;Error correction;Hardware;Concurrent computing;Protection;Petri nets;Testing","fault tolerant computing;formal specification;Petri nets;software reliability","fault tolerance properties;complex software systems;formal specification;redundancy;system description;predicate/transition net;regular expressions;formal overview;system behavior;sequential behavior;single-system components;model layers;error detection;stepwise-refined specification;multistory shelving system model","","20","","19","","","","","","IEEE","IEEE Journals & Magazines"
"On the identification of covert storage channels in secure systems","C. -. Tsai; V. D. Gligor; C. S. Chandersekaran","VDG Inc., Chevy Chase, MD, USA; NA; NA","IEEE Transactions on Software Engineering","","1990","16","6","569","580","A practical method for the identification of covert storage channels is presented and its application to the source code of the Secure Xenix kernel is illustrated. The method is based on the identification of all visible/alterable kernel variables by using information-flow analysis of language code. The method also requires that, after the sharing relationships among the kernel primitives and the visible/alterable variables are determined, the nondiscretionary access rules implemented by each primitive be applied to identify the potential storage channels. The method can be generalized to other implementation languages, and has the following advantages: it helps discover all potential storage channels is kernel code, thereby helping determine whether the nondiscretionary access rules are implemented correctly; it helps avoid discovery of false flow violations and their unnecessary analysis; and it helps identify the kernel locations where audit code and time-delay variables need to be placed for covert-channel handling.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.55086","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=55086","","Secure storage;Kernel;Information security;Communication channels;Information analysis;Communication system security;Timing;Control systems;Voice mail;Operating systems","operating systems (computers);security of data;software engineering","identification;covert storage channels;secure systems;source code;Secure Xenix kernel;visible/alterable kernel variables;information-flow analysis;language code;sharing relationships;nondiscretionary access rules;implementation languages;false flow violations;kernel locations;audit code;time-delay variables;covert-channel handling","","26","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Toward High Confidence Software","J. P. Cavano","Rome Air Development Center","IEEE Transactions on Software Engineering","","1985","SE-11","12","1449","1455","Moving toward high confidence software that can meet ever increasing demands for critical DOD applications will require planning, specifying, selecting, and managing the necessary development and testing activities that will ensure the success of the software project. In order to trust the decisions being made, there must be evidence (i.e., an information base of data and facts) that techniques and tools being chosen for application on critical projects will perform as expected. Today, these expectations are mostly intuitive; there is little hard evidence available to guide acquisition managers and software developers in making necessary decisions.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232181","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701967","DOD applications;high confidence software;software reliability measurement methodology","Software reliability;US Department of Defense;Software development management;Software measurement;Application software;Project management;Software testing;Engineering management;Software safety;Programming","","DOD applications;high confidence software;software reliability measurement methodology","","4","","14","","","","","","IEEE","IEEE Journals & Magazines"
"On the Development of Correct Specified Programs","A. J. Blikle","Institute of Computer Science, Polish Academy of Sciences","IEEE Transactions on Software Engineering","","1981","SE-7","5","519","527","The paper describes a method of program development which guarantees correctness. Our programs consist of an operational part, called instruction, and a specification. Both these parts are subject to the development and the refinement process. The specification consists of a pre-and postcondition called global specification and a set of assertions called local specification. A specified program is called correct if: 1) the operational part is totally correct w.r.t. the pre-and postcondition, 2) the precondition guarantees nonabortion, 3) local assertions are adequate for the proof of 1) and 2). The requirement of nonabortion leads to the use of a three-valued predicate calculus. We use McCarthy's calculus in that place. The paper contains a description of an experimental programming language PROMET-1 designed for our style of programming. The method is illustrated by the derivation of a bubblesort procedure.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.231114","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702878","Assertion-specified programs;bubblesort procedures;program correctness;program development;PROMET-1;sorting","Calculus;Measurement standards;Computer science;Computer languages;Sorting;Mathematics;Bridges;Control systems;Software tools;Software engineering","","Assertion-specified programs;bubblesort procedures;program correctness;program development;PROMET-1;sorting","","2","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Analysis and refinement of software test data adequacy properties","A. Parrish; S. H. Zweben","Dept. of Comput. Sci., Alabama Univ., Tuscaloosa, AL, USA; NA","IEEE Transactions on Software Engineering","","1991","17","6","565","581","Test data adequacy criteria are standards that can be applied to decide if enough testing has been performed. Previous research in software testing has suggested 11 fundamental properties which reasonable criteria should satisfy if the criteria make use of the structure of the program being tested. It is shown that there are several dependencies among the 11 properties making them questionable as a set of fundamental properties, and that the statements of the properties can be generalized so that they can be appropriately analyzed with respect to criteria that do not necessarily make use of the program's structure. An analysis that shows the relationships among the properties with respect to different classes of criteria which utilize the program structure and the specification in different ways is discussed. It is shown how the properties differ under the two models in order to maintain consistency that the dependencies are largely a result of five very weak existential properties, and that by modifying three of the properties, these weaknesses can be eliminated. The result is a reduced set of seven properties, each of which is strong from a mathematical perspective.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.87282","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=87282","","Software testing;Performance evaluation;Performance analysis;Software standards;Standards development;Computer science;Information science","data integrity;formal specification;program testing;standards","software test data adequacy properties;standards;software testing;program structure;specification;consistency;weak existential properties","","19","","7","","","","","","IEEE","IEEE Journals & Magazines"
"ABYSS: an architecture for software protection","S. R. White; L. Comerford","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA","IEEE Transactions on Software Engineering","","1990","16","6","619","629","ABYSS (a basic Yorktown security system) is an architecture for protecting the execution of application software. It supports a uniform security service across the range of computing systems. The use of ABYSS in solving the software protection problem, especially in the lower end of the market, is discussed. Both current and planned software distribution channels are supportable by the architecture, and the system is nearly transparent to legitimate users. A novel use-once authorization mechanism, called a token, is introduced as a solution to the problem of providing authorizations without direct communication. Software vendors may use the system to obtain technical enforcement of virtually any terms and conditions of the sale of their software, including such things as rental software. Software may be transferred between systems, and backed up to guard against loss in case of failure. The problem of protecting software on these systems is discussed, and guidelines to its solution are offered.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.55090","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=55090","","Computer architecture;Software protection;Application software;Authorization;Software systems;Data security;Public key cryptography;Marketing and sales;Guidelines;Licenses","security of data;software engineering","software protection architecture;execution protection;software transfer;software back-up;loss guarding;ABYSS;a basic Yorktown security system;application software;uniform security service;computing systems;software distribution channels;use-once authorization;token;technical enforcement;rental software","","11","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Partition Analysis: A Method Combining Testing and Verification","D. J. Richardson; L. A. Clarke","Department of Computer and Information Science, University of Massachusetts; NA","IEEE Transactions on Software Engineering","","1985","SE-11","12","1477","1490","The partition analysis method compares a procedure's implementation to its specification, both to verify consistency between the two and to derive test data. Unlike most verification methods, partition analysis is applicable to a number of different types of specification languages, including both procedural and nonprocedural languages. It is thus applicable to high-level descriptions as well as to low-level designs. Partition analysis also improves upon existing testing criteria. These criteria usually consider only the implementation, but partition analysis selects test data that exercise both a procedure's intended behavior (as described in the specifications) and the structure of its implementation. To accomplish these goals, partition analysis divides or partitions a procedure's domain into subdomains in which all elements of each subdomain are treated uniformly by the specification and processed uniformly by the implementation. This partition divides the procedure domain into more manageable units. Information related to each subdomain is used to guide in the selection of test data and to verify consistency between the specification and the implementation. Moreover, the testing and verification processes are designed to enhance each other. Initial experimentation has shown that through the integration of testing and verification, as well as through the use of information derived from both the implementation and the specification, the partition analysis method is effective for evaluating program reliability. This paper describes the partition analysis method and reports the results obtained from an evaluation of its effectiveness.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231892","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701971","Software testing;software verification;symbolic evaluation","Information analysis;Specification languages;Data analysis;Process design;Software testing;Computer errors;Information science","","Software testing;software verification;symbolic evaluation","","61","","50","","","","","","IEEE","IEEE Journals & Magazines"
"A Space-Efficient Optimization of Call-by-Need","F. W. Burton; D. Maurer; H. -. Oberhauser; R. Wilhelm","Department of Computer Science, University of Utah; NA; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","6","636","642","Call-by-need is widely regarded as an optimal (to within a constant factor) parameter passing mechanism for functional programming languages. Except for certain special cases involving higher order functions, call-by-need is optimal with respect to time. However, call-by-need is far from optimal with respect to space. We examine some of the space problems which can arise with call-by-need and other parameter passing mechanisms. A simple optimizing technique, based on work by Mycroft [1], is proposed. If it can be determined both that an expression must be evaluated eventually and that the evaluation of the expression is likely to reduce the space required by the program, then the evaluation is performed as soon as possible. This optimization does not result in optimal space performance in all cases. However, in most of the common cases where call-by-need causes a problem the proposed optimization avoids the problem. Since our technique is not always optimal, it is likely to be of greatest advantage in situations where efficiency is important but not critical. For example, functional languages with call-by-name semantics are increasingly being used as specification languages. Since such a specification is runnable, it may be used as a prototype. This makes it possible to experiment with a program and refine the specification before the implementation in the target language is started.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233474","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702269","Call-by-need;functional programming;optimization;space;strictness","Functional programming;Calculus;Performance evaluation;Specification languages;Prototypes;Parallel processing;Computer science;Cities and towns;Program processors","","Call-by-need;functional programming;optimization;space;strictness","","1","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Automated software test data generation","B. Korel","Dept. of Comput. Sci., Wayne State Univ., Detroit, MI, USA","IEEE Transactions on Software Engineering","","1990","16","8","870","879","An alternative approach to test-data generation based on actual execution of the program under test, function-minimization methods and dynamic data-flow analysis is presented. Test data are developed for the program using actual values of input variables. When the program is executed, the program execution flow is monitored. If during program execution an undesirable execution flow is observed then function-minimization search algorithms are used to automatically locate the values of input variables for which the selected path is traversed. In addition, dynamic data-flow analysis is used to determine those input variables responsible for the undesirable program behavior, significantly increasing the speed of the search process. The approach to generating test data is then extended to programs with dynamic data structures and a search method based on dynamic data-flow analysis and backtracking is presented. In the approach described, values of array indexes and pointers are known at each step of program execution; this information is used to overcome difficulties of array and pointer handling.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.57624","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=57624","","Automatic testing;Software testing;Data analysis;Input variables;Minimization methods;Costs;Monitoring;Automatic control;Data structures;Search methods","automatic programming;data structures;minimisation;program testing;search problems","automated software test data generation;function-minimization methods;dynamic data-flow analysis;input variables;program execution flow;function-minimization search algorithms;input variables;program behavior;dynamic data structures;backtracking;array indexes;pointers","","412","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Use of Very High Level Languages and Program Generation by Management Professionals","T. T. Cheng; E. D. Lock; N. S. Prywes","Faculty of Management, McGill University, Montreal, P. Q., Canada H3A 2A7.; Tymshare, Philadelphia, PA 19107.; Department of Computer Science, Moore School, University of Pennsylvania, Philadelphia, PA 19104.","IEEE Transactions on Software Engineering","","1984","SE-10","5","552","563","The introduction of very high level languages (VHLL) and automatic program generation are expected to reduce significantly the needed programming skills and considerably increase software development productivity. The paper explores the hypothesis that the preferred mode of developing management systems will be for the management professional to directly specify, generate, and debug the needed software without involvement of professional programmers. The investigation is experimental, by having an accountant develop an accounting system, using the equational type MODEL VHLL and program generator, and by monitoring carefully the times that it takes to perform certain steps or debug certain types of errors. The investigation consisted of progressive development of an accounting system in three stages: first a general ledger, extended for inventory management, and concluding with a major modification to incorporate reporting for the effects of changing prices in accordance with Financial Accounting Standard 33 (FAS 33). In this way the work pattern in modifying and maintaining a system was investigated as well. The developer was an M.B.A. candidate majoring in accounting with a limited computer background who determined the requirements of the accounting system and used MODEL to generate the programs, along with their extensions and modifications. A description of the accounting system design is presented first. Next, a sample MODEL specification is discussed in order to communicate generally the style of specifying computations in MODEL. This sample is used also to demonstrate the incorporation of FAS 33.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010279","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010279","Equational language;MODEL;nonprocedural language;program generation;software development productivity","High level languages;Programming profession;Automatic programming;Software development management;Birth disorders;Productivity;Software debugging;Equations;Monitoring;Inventory management","","","","9","","34","","","","","","IEEE","IEEE Journals & Magazines"
"The evolving philosophers problem: dynamic change management","J. Kramer; J. Magee","Imperial Coll. of Sci. Technol. & Med., London Univ., UK; Imperial Coll. of Sci. Technol. & Med., London Univ., UK","IEEE Transactions on Software Engineering","","1990","16","11","1293","1306","A model for dynamic change management which separates structural concerns from component application concerns is presented. This separation of concerns permits the formulation of general structural rules for change at the configuration level without the need to consider application state, and the specification of application component actions without prior knowledge of the actual structural changes which may be introduced. In addition, the changes can be applied in such a way so as to leave the modified system in a consistent state, and cause no disturbance to the unaffected part of the operational system. The model is applied to an example problem, 'evolving philosophers'. The principles of this model have been implemented and tested in the Conic environment for distributed systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.60317","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=60317","","Application software;Functional programming;System testing;Computer industry;Humans;Software systems","software engineering","concerns separation;evolving philosophers problem;dynamic change management;structural concerns;component application concerns;separation of concerns;structural rules;configuration level;consistent state;Conic environment;distributed systems","","373","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Automatic analysis and test case derivation for a restricted class of LOTOS expressions with data parameters","T. Higashino; G. v. Bochmann","Dept. d'Inf. et de Recherche Oper., Montreal Univ., Que., Canada; Dept. d'Inf. et de Recherche Oper., Montreal Univ., Que., Canada","IEEE Transactions on Software Engineering","","1994","20","1","29","42","We propose an automatic analysis and test case derivation method for LOTOS expressions with data values. We introduce the class of P-LOTOS expressions where the data types are restricted to Presburger arithmetic. That is, only the integer and Boolean types are used, and the operators of the integers are restricted to addition, subtraction, and comparison. For this class, we give an algorithm for deriving a set of test cases (a test suite). The algorithm is carried out by using a decision procedure for integer linear programming problems. We also give solutions for the deadlock detection problem, the detection of nonexecutable branches, and the detection of nondeterministic behaviors. We have implemented a tool for the analysis and test selection based on our techniques. The derivation of a test suite for a simplified Session protocol is described as an example.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.263753","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=263753","","Automatic testing;Computer aided software engineering;Protocols;Automata;System recovery;System testing;Open systems;Context;Software testing;Arithmetic","specification languages;formal specification;linear programming;integer programming;concurrency control","test case derivation;LOTOS expressions;data parameters;automatic analysis method;data values;P-LOTOS expressions;data types;Presburger arithmetic;integer;Boolean types;addition;subtraction;comparison;decision procedure;integer linear programming problems;deadlock detection problem;nonexecutable branch detection;nondeterministic behavior detection;test selection;simplified Session protocol;specification language","","17","","27","","","","","","IEEE","IEEE Journals & Magazines"
"A visual language compiler","S. -. Chang; M. J. Tauber; B. Yu; J. -. Yu","Dept. of Comput. Sci., Pittsburgh Univ., PA, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1989","15","5","506","525","The SIL-ICON compiler is a software system for the specification, interpretation, prototyping, and generation of icon-oriented systems. The system design of the SIL-ICON compiler is presented. The icon system G, the icon dictionary ID, the operator dictionary OD, and the extended task action grammar ETAG are described. An application example to design a text editor using the Heidelberg icon set is also presented in detail.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24700","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24700","","Dictionaries;Software systems;Software prototyping;Computer science;Silicon compiler;Application software;Programming environments;Algebra;Fuzzy set theory;Fuzzy systems","computer graphics;program compilers;user interfaces","visual language compiler;SIL-ICON compiler;software system;specification;interpretation;prototyping;generation;icon-oriented systems;system design;icon system;G;icon dictionary;ID;operator dictionary;OD;extended task action grammar;ETAG;text editor;Heidelberg icon set","","50","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Mapping Considerations in the Design of Schemas for the Relational Model","S. Al-Fedaghi; P. Scheuermann","Department of Electrical Engineering and Computer Science, Northwestern University; NA","IEEE Transactions on Software Engineering","","1981","SE-7","1","99","111","The typical design process for the relational database model develops the conceptual schema and each of the external schemas separately and independently from each other. This paper proposes a new design methodology that constructs the conceptual schema in such a way that overlappings among external schemas are reflected. If the overlappings of external schemas do not produce transitivity at the conceptual level, then with our design method, the relations in the external schemas can be realized as a join over independent components. Thus, a one-to-one function can be defined for the mapping between tuples in the external schemas to tuples in the conceptual schema. If transitivity is produced, then we show that no such function is possible and a new technique is introduced to handle this special case.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234512","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702806","Conceptual schema;external schema;functional dependencies;independent components;interferences;logical database design;mapping functions;relational database mode","Relational databases;Interference;Personnel;Design methodology;Process design;Software engineering","","Conceptual schema;external schema;functional dependencies;independent components;interferences;logical database design;mapping functions;relational database mode","","5","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Some Theory Concerning Certification of Mathematical Subroutines by Black Box Testing","R. P. Roe; J. H. Rowland","Department of Mathematics, Fort Lewis College; NA","IEEE Transactions on Software Engineering","","1987","SE-13","6","677","682","Several inequalities are derived for use in certifying function subroutines by means of black box testing. It is assumed that a function is approximated by means of a polynomial of limited degree on a closed interval. These inequalities give upper bounds on the error of the approximation over the entire interval based on the error measured over a finite sample and known properties of the function.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233205","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702273","Certification;sampling;testing","Certification;Algorithms;Testing;Polynomials;Sampling methods;Mathematics;Upper bound;Computer languages;NIST;Differential equations","","Certification;sampling;testing","","2","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Empirical Studies of Programming Knowledge","E. Soloway; K. Ehrlich","Department of Computer Science, Yale University, New Haven, CT 06520; Compu-Tech, Inc., New Haven, CT.; Honeywell Information Systems, Inc. Waltham, MA 02154.","IEEE Transactions on Software Engineering","","1984","SE-10","5","595","609","We suggest that expert programmers have and use two types of programming knowledge: 1) programming plans, which are generic program fragments that represent stereotypic action sequences in programming, and 2) rules of programming discourse, which capture the conventions in programming and govern the composition of the plans into programs. We report here on two empirical studies that attempt to evaluate the above hypothesis. Results from these studies do in fact support our claim.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010283","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010283","Cognitive models of programming;novice/expert differences;program conprehension;software psychology","Programming profession;Functional programming;Psychology;Physics;Circuits;Text processing","","","","332","","22","","","","","","IEEE","IEEE Journals & Magazines"
"A Recursive Solution Method to Analyze the Performance of Static Locking Systems","A. Thomasian; In Kyung Ryu","IBM Thomas J. Watson Researeh Center, P.O. Box 704, Yorktown Heights, NY 10598.; NA","IEEE Transactions on Software Engineering","","1989","15","10","1147","1156","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1989.559761","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=559761","","Performance analysis;Transaction databases;Concurrency control;Scheduling;System recovery;Indexes;Control systems;Database systems;Hardware","","Concurrency control;database systems;performance evaluation;queueing networks","","6","","22","","","","","","IEEE","IEEE Journals & Magazines"
"SEESA Software testing Environment Support System","N. Roussopoulos; R. T. Yeh","Department of Computer Science, University of Maryland; NA","IEEE Transactions on Software Engineering","","1985","SE-11","4","355","366","SEES is a database system to support program testing. The program database is automatically created during the compilation of the program by a compiler built using the YACC compiler-compiler.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232225","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702018","","Software testing;Programming profession;Computer architecture;Relational databases;Error correction;Database systems;Program processors;Writing;Workstations;Software tools","","","","2","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Real-time specification using Lucid","D. B. Skillicorn; J. I. Glasgow","Dept. of Comput. & Inf. Sci., Queen's Univ., Kingston, Ont., Canada; Dept. of Comput. & Inf. Sci., Queen's Univ., Kingston, Ont., Canada","IEEE Transactions on Software Engineering","","1989","15","2","221","229","A methodology is presented for transforming a functional specification written in Lucid to an equivalent specification that captures its real-time properties. The enhanced specification consists of a set of equations that can be solved for several properties, including execution time and external requirements, or may simply be checked for the existence of a solution. Lucid has a set of meaning-preserving transformations, and a proof system corresponding to a behavioral semantics has been constructed. Both of these tools can be used to reason about properties of the specification. The specification is executable and can be used as a prototype for the system being specified. It is possible to express architectural constraints within the same formal framework. Thus this type of specification can be used to guide the development of new real-time systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21748","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21748","","Life testing;Lab-on-a-chip;Software testing;Random variables;Cost function;Software systems;System testing;Computer errors;Life estimation;Lifetime estimation","formal specification;real-time systems","Lucid;functional specification;real-time properties;execution time;external requirements;meaning-preserving transformations;proof system;behavioral semantics;architectural constraints;real-time systems","","12","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Communication and Synchronization Primitives for Distributed Programs","N. Natarajan","Department of Computer Science and Engineering, University of Texas at Arlington","IEEE Transactions on Software Engineering","","1985","SE-11","4","396","416","A distributed program is a collection of several processes which execute concurrently, possibly in different nodes of a distributed system, and which cooperate with each other to realize a common goal. In this paper, we present a design of communication and synchronization primitives for distributed programs. The primitives are designed such that they can be provided by a kernel of a distributed operating system. An important feature of the design is that the configuration of a process, i.e., identities of processes with which the process communicates, is specified separately from the computation performed by the process. This permits easy configuration and reconfiguration of processes. We identify different kinds of communication failures, and provide distinct mechanisms for handling them. The communication primitives are not atomic actions. To enable the construction of atomic actions, two new program components, atomic agent and manager are introduced. These are devoid of policy decisions regarding concurrency control and atomic commitment. We introduce the notion of conflicts relation using which a designer can construct either an optimistic or a pessimistic concurrency control scheme. The design also incorporates primitives for constructing nested atomic actions.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232229","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702022","Atomic action;communication failure;computing agent;distributed operating system;distributed piogram;distributed system;kernel;port","Kernel;Operating systems;Concurrency control;Distributed computing;Design optimization;Programming;Computer science;Computer networks;Centralized control;Context","","Atomic action;communication failure;computing agent;distributed operating system;distributed piogram;distributed system;kernel;port","","4","","32","","","","","","IEEE","IEEE Journals & Magazines"
"Advanced exception handling mechanisms","P. A. Buhr; W. Y. R. Mok","Dept. of Comput. Sci., Waterloo Univ., Ont., Canada; NA","IEEE Transactions on Software Engineering","","2000","26","9","820","836","It is no longer possible to consider exception handling as a secondary issue in language design, or even worse, a mechanism added after the fact via a library approach. Exception handling is a primary feature in language design and must be integrated with other major features, including advanced control flow, objects, coroutines, concurrency, real-time, and polymorphism. Integration is crucial as there are both obvious and subtle interactions between exception handling and other language features. Unfortunately, many exception handling mechanisms work only with a subset of the features and in the sequential domain. A framework for a comprehensive, easy to use, and extensible exception handling mechanism is presented for a concurrent, object-oriented environment. The environment includes language constructs with separate execution stacks, e.g. coroutines and tasks, so the exception environment is significantly more complex than the normal single-stack situation. The pros and cons of various exception features are examined, along with feature interaction with other language mechanisms. Both exception termination and resumption models are examined in this environment, and previous criticisms of the resumption model, a feature commonly missing in modern languages, are addressed.","0098-5589;1939-3520;2326-3881","","10.1109/32.877844","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=877844","","Testing;Object oriented modeling;Libraries;Concurrent computing;Robustness;Process control;Writing;Robust control;Programming profession","exception handling;object-oriented programming;high level languages;multiprocessing programs","advanced exception handling mechanisms;language design;advanced control flow;objects;coroutines;concurrency;real-time systems;polymorphism;concurrent object-oriented environment;language constructs;execution stacks;feature interaction;exception termination model;exception resumption model","","24","","","","","","","","IEEE","IEEE Journals & Magazines"
"Multilevel data structures: models and performance","A. Moitra; S. S. Iyengar; F. B. Bastani; I. L. Yen","Dept. of Comput. Sci., Cornell Univ., Ithaca, NY, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1988","14","6","858","867","A stepwise method of deriving the high-performance implementation of a set of operations is proposed. This method is based on the ability to organize the data into a multilevel data structure to provide an efficient implementation of all the operations. Typically, for such data organization the performance may deteriorate over a period of time and that can be corrected by reorganizing the data. This data reorganization is done by the introduction of maintenance processes. For a particular example, the multilevel data organization and the different models of maintenance processes possible are considered. The various models of maintenance process provide varying amounts of concurrency by varying the degree of atomicity in different operations. Performance behavior for the different models is derived and a correctness proof for the developed implementation is outlined.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6164","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6164","","Data structures;Concurrent computing;Computer science;Processor scheduling;Binary search trees;Distributed computing;Tree data structures;Information science;Delay;Tail","data structures;program verification;programming theory;software reliability","program verification;multilevel data structure;data organization;maintenance processes;concurrency;correctness proof","","3","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Design and Implementation of Secure Xenix","V. D. Gligor; C. S. Chandersekaran; R. S. Chapman; L. J. Dotterer; M. S. Hetch; Wen-Der Jiang; A. Johri; G. L. Luckenbaugh; N. Vasudevan","Department of Electrical Engineering, University of Maryland; NA; NA; NA; NA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","2","208","221","Secure Xenix is an experimental system designed to run on IBM PC/AT workstations. Like Xenix, it is a Unix System V implementation on the PC/AT workstation; unlike Xenix, it eliminates the Unix security deficiencies and it enhances security policies. In this paper, we present the design features of Secure Xenix, their integration within Xenix, and some of the lessons learned from this experiment to date.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232893","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702201","Access control lists;auditor;model interpretation;operating system security;secure attention key;security levels;trusted path;Unix;Xenix","Workstations;Operating systems;Project management;Trademarks;US Government;Information security;Testing;Kernel","","Access control lists;auditor;model interpretation;operating system security;secure attention key;security levels;trusted path;Unix;Xenix","","16","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Software CAD: a revolutionary approach","R. J. A. Buhr; G. M. Karam; C. J. Hayes; C. M. Woodside","Dept. of Syst. & Comput. Eng., Carleton Univ., Ottowa, Ont., Canada; Dept. of Syst. & Comput. Eng., Carleton Univ., Ottowa, Ont., Canada; NA; NA","IEEE Transactions on Software Engineering","","1989","15","3","235","249","A research project is described in which an experimental software CAD environment called the Carleton embedded system design environment (CAEDE), oriented toward embedded systems and Ada, was developed to provide a demonstration of the concept and to serve as a research testbed. The major contribution of CAEDE is a demonstration of a visual paradigm which combines semantic depth and syntactic shallowness, relative to Ada, in a manner that makes it possible for the embedded-system designer to work in terms of abstract machines while still thinking Ada. A secondary contribution is the identification of Prolog as a promising approach for supporting tool development in an environment which supports the visual paradigm. Also described are experimental tools for temporal analysis, performance analysis, and the generation of skeleton Ada code.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21752","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21752","","Design automation;Embedded system;Software tools;Embedded software;Performance analysis;Skeleton;Computer graphics;Design engineering;Sun;Testing","Ada;automatic programming;CAD;programming environments;software engineering;software tools","automatic programming;research project;software CAD environment;Carleton embedded system design environment;CAEDE;embedded systems;Ada;visual paradigm;semantic depth;syntactic shallowness;abstract machines;Prolog;tool development;temporal analysis;performance analysis;skeleton Ada code","","24","","58","","","","","","IEEE","IEEE Journals & Magazines"
"Metric Analysis and Data Validation Across Fortran Projects","V. R. Basili; R. W. Selby; T. Phillips","Department of Computer Science, university of Maryland; NA; NA","IEEE Transactions on Software Engineering","","1983","SE-9","6","652","663","The desire to predict the effort in developing or explain the quality of software has led to the proposal of several metrics in the literature. As a step toward validating these metrics, the Software Engineering Laboratory has analyzed the Software Science metrics, cyclomatic complexity, and various standard program measures for their relation to 1) effort (including design through acceptance testing), 2) development errors (both discrete and weighted according to the amount of time to locate and frix), and 3) one another. The data investigated are collected from a production Fortran environment and examined across several projects at once, within individual projects and by individual programmers across projects, with three effort reporting accuracy checks demonstrating the need to validate a database. When the data come from individual programmers or certain validated projects, the metrics' correlations with actual effort seem to be strongest. For modules developed entirely by individual programmers, the validity ratios induce a statistically significant ordering of several of the metrics' correlations. When comparing the strongest correlations, neither Software Science's E metric, cyclomatic complexity nor source lines of code appears to relate convincingly better with effort than the others","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.235430","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703112","Complexity metrics;data validation;software effort and error metrics;Software Engineering Laboratory;Software Science","Data analysis;Programming profession;Software quality;Proposals;Software engineering;Laboratories;Measurement standards;Software standards;Standards development;Software measurement","","Complexity metrics;data validation;software effort and error metrics;Software Engineering Laboratory;Software Science","","66","","28","","","","","","IEEE","IEEE Journals & Magazines"
"A formal framework for ASTRAL intralevel proof obligations","A. Coen-Porisini; R. A. Kemmerer; D. Mandrioli","Dipartimento di Elettronica e Inf., Politecnico di Milano, Italy; NA; NA","IEEE Transactions on Software Engineering","","1994","20","8","548","561","ASTRAL is a formal specification language for real-time systems. It is intended to support formal software development, and therefore has been formally defined. This paper focuses on how to formally prove the mathematical correctness of ASTRAL specifications. ASTRAL is provided with structuring mechanisms that allow one to build modularized specifications of complex systems with layering. In this paper, further details of the ASTRAL environment components and the critical requirements components, which were not fully developed in previous papers, are presented. Formal proofs in ASTRAL can be divided into two categories: interlevel proofs and intralevel proofs. The former deal with proving that the specification of level i+1 is consistent with the specification of level i, and the latter deal with proving that the specification of level i is consistent and satisfies the stated critical requirements. This paper concentrates on intralevel proofs.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.310665","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=310665","","Real time systems;Formal specifications;Programming;Timing;Automata;Logic functions;Laboratories;Software;Computer science","formal specification;real-time systems;finite state machines;program verification;specification languages","intralevel proof obligations;ASTRAL;formal specification language;real-time systems;formal software development;mathematical correctness;formal methods;formal specification;verification;timing requirements;formal proof;state machines;ASLAN;TRIO","","10","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Version support for engineering database systems","K. R. Dittrich; R. A. Lorie","Forschungszentrum Inf., Karlsruhe, West Germany; NA","IEEE Transactions on Software Engineering","","1988","14","4","429","437","In engineering applications, multiple copies of object descriptions have to coexist in a single database. A scheme is proposed that enables users to explicitly deal with these object versions. After introducing a basic version model, the problem of rerouting interobject references on the creation of new versions is solved by providing generic references and user-specific environments. Logical version clusters are introduced that allow for the meaningful grouping of versions. Some remarks on implementation and a comparison with other approaches are also included.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4664","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4664","","Data engineering;Systems engineering and theory;Database systems;Design engineering;Transaction databases;Aging;Technology management;Data models;Very large scale integration","CAD;data structures;database management systems;engineering computing","version support;CAD;data structures;engineering database;object descriptions;object versions;rerouting;user-specific environments;version clusters","","67","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Software Projects in an Academic Environment","D. B. Wortman","Department of Computer Science, University of Toronto","IEEE Transactions on Software Engineering","","1987","SE-13","11","1176","1181","The ""software hut"" is a course project that is used in conjunction with a graduate-level course in software engineering. The purpose of this project is to give the students some ""real world"" experience with the design and implementation of software. This paper describes the author's experience in using such a project and presents some suggestions on how a project should be organized.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232867","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702165","Course project;education;graduate course;software engineering;software engineering education;software hut;teaching experiences","Software engineering;Software tools;Inspection;Computer science education;Educational programs;Software testing;System testing;Software systems;Uncertainty;Councils","","Course project;education;graduate course;software engineering;software engineering education;software hut;teaching experiences","","3","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Petri Net Models for the Evaluation of Applicative Programs Based on -Expressions","W. E. Kluge; H. Schlutter","Gesellschaft fr Mathematick und Datenverarbeitung GmbH; NA","IEEE Transactions on Software Engineering","","1983","SE-9","4","415","427","In applicative systems, program design is based on elementary constructs of the form apply function to argument(s), also called applications, which are to be recursively inserted into each other. Program evaluation follows a process of meaning-preserving transformations which systematically distributes argument expressions within function expressions and substitutes applications of primitive functions by their values, until a constant expression representing the result of the computation with respect to these transformations is being reached.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.234778","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703076","","Calculus;Computer applications;Concurrent computing;Computational modeling;Functional programming;Distributed computing;Concrete;Flow graphs;Petri nets;Computer languages","","","","2","","22","","","","","","IEEE","IEEE Journals & Magazines"
"A relational calculus with set operators, its safety, and equivalent graphical languages","G. Ozsoyoglu; H. Wang","Dept. of Comput. Eng. & Sci., Case Western Reserve Univ., Cleveland, OH, USA; Dept. of Comput. Eng. & Sci., Case Western Reserve Univ., Cleveland, OH, USA","IEEE Transactions on Software Engineering","","1989","15","9","1038","1052","The authors propose a relational calculus (RC/S) which uses set comparison and set manipulation operators to replace universal quantifiers and negations. It is argued that compared to the Codd relational calculus (RC), RC/S queries are easier to construct and comprehend. It is proved that the expressive power of RC is equivalent to the expressive power of RC/S, and algorithms for translating an RC query into an RC/S query and vice versa are given. A safe RC/S query is defined as one that has finite output and can be evaluated in finite time. Then a subset of RC/S queries, called RC/S* is defined, and it is proved that RC/S* is safe. RC/S* is compared to the existing largest safe subsets of RC, i.e. the evaluable formulas and the allowed formulas. Algorithms are given to transform any evaluable formula into an RC/S* query, and some RC/S* formulas that are not evaluable are given. RC/S* queries can be directly implemented using a graphical language similar to Query-by-Example (QBE). Two different graphical languages are described that are equivalent to the RC/S* in expressive power, and these languages are compared to QBE.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.31363","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=31363","","Calculus;Safety;Database languages;Intelligent systems;Automation;Relational databases;Power measurement;Prototypes;Design engineering;Data engineering","computer graphics;database theory;query languages;relational databases","algorithms;relational calculus;set operators;safety;graphical languages;set comparison;set manipulation;Codd relational calculus;RC/S queries;RC query;evaluable formulas;allowed formulas;RC/S* query;Query-by-Example;QBE","","21","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Specification of modular systems","H. Weber; H. Ehrig","Fachbereich Informatik, Universit&#x00E4;t Dortmund, Postfach 500 500, 4600 Dortmund, West Germany; Fachbereich Informatik, Technische Universit&#x00E4;t Berlin, Strasse des 17, juni 135, 1000 Berlin 10, West Germany","IEEE Transactions on Software Engineering","","1986","SE-12","7","784","798","A modularity concept for structuring large software systems is presented. The concept enforces an extreme modularity discipline that goes considerably beyond the one found in modern programming languages such as MODULA-2 or Ada. The concept is meant to be used to tightly control side effects in the execution of systems that are constructed of independently developed modules. A family of specification languages is introduced whose members are all based on the modularity concept and thus support the uniform monolinguistic specification of software systems at all development stages. The languages have been defined to enable matching informal, semiformal, and formal specifications and thus to make formal specification of modular systems practicable. The construction of large software systems as interconnections of modules is shown to lead to manageable system structures and to new degrees of freedom in the structuring of the software development process. The suitability of the modularity concept has been evaluated in a large software project for the development of a database management system. The concept and specification languages are explained with the aid of sample specifications.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312979","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312979","Data abstraction;informal;procedural;algebraic specifications;modularity;software development;software structuring","Formal specifications;Software systems;Specification languages;Database systems;Production","software engineering;specification languages","modular systems;modularity concept;structuring large software systems;independently developed modules;specification languages;monolinguistic specification;formal specification;database management system","","6","","","","","","","","IEEE","IEEE Journals & Magazines"
"Towards a framework for software measurement validation","B. Kitchenham; S. L. Pfleeger; N. Fenton","Nat. Comput. Centre, Manchester, UK; NA; NA","IEEE Transactions on Software Engineering","","1995","21","12","929","944","In this paper we propose a framework for validating software measurement. We start by defining a measurement structure model that identifies the elementary component of measures and the measurement process, and then consider five other models involved in measurement: unit definition models, instrumentation models, attribute relationship models, measurement protocols and entity population models. We consider a number of measures from the viewpoint of our measurement validation framework and identify a number of shortcomings; in particular we identify a number of problems with the construction of function points. We also compare our view of measurement validation with ideas presented by other researchers and identify a number of areas of disagreement. Finally, we suggest several rules that practitioners and researchers can use to avoid measurement problems, including the use of measurement vectors rather than artificially contrived scalars.","0098-5589;1939-3520;2326-3881","","10.1109/32.489070","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=489070","","Software measurement;Software metrics;Computer Society;Particle measurements;Object oriented modeling;Measurement units;Instruments;Protocols;Area measurement;Software engineering","software metrics;measurement theory","software measurement validation;framework;measurement structure model;measures;measurement process;measurement protocols;unit definition models;instrumentation models;attribute relationship models;entity population models;measurement vectors","","246","","21","","","","","","IEEE","IEEE Journals & Magazines"
"A uniform presentation of confidentiality properties","J. Jacob","Comput. Lab., Oxford Univ., UK","IEEE Transactions on Software Engineering","","1991","17","11","1186","1194","Security (in the sense of confidentiality) properties are properties of shared systems. A suitable model of shared systems, in which one can formally define the term security property and then proceed to catalog several security properties, is presented. The purpose is to present various information-flow properties in a manner that exposes their differences and similarities. Abstraction is the main tool, and everything that is not central to the purpose is discarded. The presentation is generic in the model of computation. The abstraction lays bare a regular structure into which many interesting information-flow properties fall. A shared system is represented by a relation. How this model lets one reason about information flow is discussed and the term information flow property is formally defined. Various information-flow properties are described. Composability and probabilistic security properties are addressed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.106973","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=106973","","Information security;Computational modeling;Jacobian matrices;Fluid flow measurement;System software;Hardware;Mathematics;Information theory;Radar","security of data","composability;confidentiality properties;security property;information-flow properties;probabilistic security properties","","4","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Interconnection of Local Computer Networks: Modeling and Optimization Problems","G. Bernard","Laboratoire ISEM, Universit&#233;Paris-Sud","IEEE Transactions on Software Engineering","","1983","SE-9","4","463","470","We study problems of optimization of the topology of interconnected local computer networks using random access to a single channel. An approach to modeling of the system by a queueing network is proposed: the analytical solution of the model allows us to obtain global performance measures, which may be used as evaluation criteria in network topology optimization problems. A heuristic is proposed for the latter aspect for one class of problems. We also derive from the model the time needed, for a new user which joins the network, to transmit its number of messages.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.234782","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703080","Decomposition method;local computer networks;queueing systems;random access;topological optimization","Computer networks;Delay;Optical fibers;Network topology;Application software;Access protocols;Joining processes;Queueing analysis;Performance analysis;Optimization methods","","Decomposition method;local computer networks;queueing systems;random access;topological optimization","","1","","8","","","","","","IEEE","IEEE Journals & Magazines"
"An evaluation of the MOOD set of object-oriented software metrics","R. Harrison; S. J. Counsell; R. V. Nithi","Dept. of Electron. & Comput. Sci., Southampton Univ., UK; NA; NA","IEEE Transactions on Software Engineering","","1998","24","6","491","496","This paper describes the results of an investigation into a set of metrics for object-oriented design, called the MOOD metrics. The merits of each of the six MOOD metrics is discussed from a measurement theory viewpoint, taking into account the recognized object-oriented features which they were intended to measure: encapsulation, inheritance, coupling, and polymorphism. Empirical data, collected from three different application domains, is then analyzed using the MOOD metrics, to support this theoretical validation. Results show that (with appropriate changes to remove existing problematic discontinuities) the metrics could be used to provide an overall assessment of a software system, which may be helpful to managers of software development projects. However, further empirical studies are needed before these results can be generalized.","0098-5589;1939-3520;2326-3881","","10.1109/32.689404","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=689404","","Mood;Software metrics;Encapsulation;Software measurement;Computer Society;Application software;Software quality;Emotion recognition;Software systems;Project management","software metrics;object-oriented programming;data encapsulation;inheritance","object-oriented software metrics;object-oriented design;MOOD metrics;measurement theory;object-oriented features;encapsulation;inheritance;coupling;polymorphism","","117","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Dynamic file structure for partial match retrieval based on overflow bucket sharing","T. Yuen; D. H. Du","Department of Computer Science, University of Minnesota, Minneapolis, MN 55455; Department of Computer Science, Pace University, New York, NY 10038; Department of Computer Science, University of Minnesota, Minneapolis, MN 55455","IEEE Transactions on Software Engineering","","1986","SE-12","8","801","810","A hashing-based dynamic file structure is introduced for partial match retrieval using overflow bucket sharing. The sharing of overflow buckets is dynamic in the sense that an overflow bucket is shared by a varying number of primary buckets according to the local conditions of the file. The use and sharing of overflow buckets defers splitting of the data buckets, thereby increasing the storage utilization. For the same reason, plus the fact that the sharing is dynamic, the growth of the directory is slowed down. Under the proposed organization, the records are stored more compactly in the data buckets, and for those partial match queries in which few attributes are specified, groups of neighboring directory entries have high probability of being referenced together, so that the retrieval costs for these types of partial match queries are reduced. This file organization is found to be space efficient and is also time efficient for queries in which the number of specified attributes is small.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312983","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312983","Database management;file organization;information storage and retrieval;physical design","Organizations;Vectors;Indexes;Computer science;Educational institutions;Manganese;Large Hadron Collider","data structures;file organisation","hashing;partial match retrieval;overflow bucket sharing;dynamic file structure;data buckets;storage utilization;neighboring directory entries;retrieval costs;file organization;space efficient","","1","","","","","","","","IEEE","IEEE Journals & Magazines"
"Designing an agent synthesis system for cross-RPC communication","Yen-Min Huang; C. V. Ravishankar","IBM Corp., Research Triangle Park, NC, USA; NA","IEEE Transactions on Software Engineering","","1994","20","3","188","198","Remote procedure call (RPC) is the most popular paradigm used today to build distributed systems and applications. As a consequence, the term ""RPC"" has grown to include a range of vastly different protocols above the transport layer. A resulting problem is that programs often use different RPC protocols, cannot be interconnected directly, and building a solution for each case in a large heterogeneous environment is prohibitively expensive. We describe the design of a system that can synthesize programs (RPC agents) to accommodate RPC heterogeneities. Because of its synthesis capability, the system also facilitates the design and implementation of new RPC protocols through rapid prototyping. We have built a prototype system to validate the design and to estimate the agent development costs and cross-RPC performance. The evaluation shows that the synthesis approach provides a more general solution than existing approaches do, and with lower software development and maintenance costs, while maintaining reasonable cross-RPC performance.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.268920","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=268920","","Transport protocols;Costs;Software maintenance;Software prototyping;Prototypes;Programming;Fault tolerance;Multicast protocols;Buildings;Runtime","remote procedure calls;protocols;software prototyping;parallel programming;telecommunications computing","agent synthesis system;cross-RPC communication;remote procedure call;distributed systems;transport layer;RPC protocols;large heterogeneous environment;RPC agents;RPC heterogeneities;rapid prototyping;agent development costs;cross-RPC performance;maintenance costs","","11","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Trace analysis for conformance and arbitration testing","G. V. Bochmann; R. Dssouli; J. R. Zhao","Montreal Univ., Que., Canada; Montreal Univ., Que., Canada; Montreal Univ., Que., Canada","IEEE Transactions on Software Engineering","","1989","15","11","1347","1356","The authors explore a testing approach where the concern for selecting the appropriate test input provided to the implementation under test (IUT) is separated as much as possible from the analysis of the observed output. Particular emphasis is placed on the analysis of the observed interactions of the IUT in order to determine whether the observed input/output trace conforms to the IUT's specification. The authors consider this aspect of testing with particular attention to testing of communication protocol implementations. Various distributed test architectures are used for this purpose, where partial input/output traces are observable by local observers at different interfaces. The error-detection power of different test configurations is determined on the basis of the partial trace visible to each local observer and their global knowledge about the applied test case. The automated construction of trace analysis modules from the formal specification of the protocol is also discussed. Different transformations of the protocol specification may be necessary to obtain the reference specification, which can be used by a local or global observer for checking the observed trace. Experience with the construction of an arbiter for the OSI (open systems interconnection) transport protocol is described.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.41328","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=41328","","System testing;Formal specifications;Modular construction;Transport protocols;Councils;Decision support systems;Fault detection;Software testing","conformance testing;open systems;program testing;protocols","conformance testing;arbitration testing;implementation under test;IUT;communication protocol implementations;distributed test architectures;partial input/output traces;local observers;error-detection power;global knowledge;automated construction;trace analysis modules;formal specification;reference specification;OSI;open systems interconnection;transport protocol","","37","","31","","","","","","IEEE","IEEE Journals & Magazines"
"On a unified framework for the evaluation of distributed quorum attainment protocols","D. A. Menasce; Y. Yesha; K. Kalpakis","Dept. of Comput. Sci., George Mason Univ., Fairfax, VA, USA; NA; NA","IEEE Transactions on Software Engineering","","1994","20","11","868","884","Quorum attainment protocols are an important part of many mutual exclusion algorithms. Assessing the performance of such protocols in terms of number of messages, as is usually done, may be less significant than being able to compute the delay in attaining the quorum. Some protocols achieve higher reliability at the expense of increased message cost or delay. A unified analytical model which takes into account the network delay and its effect on the time needed to obtain a quorum is presented. A combined performability metric, which takes into account both availability and delay, is defined, and expressions to calculate its value are derived for two different reliable quorum attainment protocols: D. Agrawal and A. El Abbadi's (1991) and Majority Consensus algorithms (R.H. Thomas, 1979). Expressions for the primary site approach are also given as upper bound on performability and lower bound on delay. A parallel version of the Agrawal and El Abbadi protocol is introduced and evaluated. This new algorithm is shown to exhibit lower delay at the expense of a negligible increase in the number of messages exchanged. Numerical results derived from the model are discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.368122","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=368122","","Availability;Delay effects;Performance analysis;Access protocols;Computer science;Time measurement;Costs;Analytical models;Upper bound;Fault tolerant systems","distributed algorithms;protocols;software performance evaluation;software fault tolerance","unified framework;distributed quorum attainment protocols;mutual exclusion algorithms;protocol performance;unified analytical model;network delay;performability metric;Majority Consensus algorithms;primary site approach;performability;parallel version;performance analysis;fault tolerance;distributed systems;delay analysis;tree-based mutual exclusion protocols","","4","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Reliability Optimization in the Design of Distributed Systems","C. S. Raghavendra; S. Hariri","Department of Electrical Engineering&#8212;Systems, University of Southern California; NA","IEEE Transactions on Software Engineering","","1985","SE-11","10","1184","1193","The reliability of a distributed system depends on the reliabilities of its communication links and computing elements, as well as on the distribution of its resources, such as programs and data files. A useful measure of reliability in distributed systems is the terminal reliability between a pair of nodes which is the probability that at least one communication path exists between these nodes. An interesting optimization problem is that of maximizing the terminal reliability between a pair of computing elements under a given budget constraint. Analytical techniques to solve this problem are applicable only to special forms of reliability expressions. In this paper, three iterative algorithms for terminal reliability maximization are presented. The first two algorithms require the computation of terminal reliability expressions, and are therefore efficient for only small networks. The third algorithm, which is developed for large distributed systems, does not require the computation of terminal reliability expressions; this algorithm maximizes approximate objective functions and gives accurate results. Several examples are presented to illustrate the approximate optimization algorithm and an estimation of the error involved is also given.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231866","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701934","Distributed systems;iterative algorithms;pattern search method;reliability optimization;terminal reliability","Design optimization;Power system reliability;Telecommunication network reliability;Iterative algorithms;Distributed computing;Computer networks;Computer network reliability;Optimization methods;Constraint optimization;Reliability engineering","","Distributed systems;iterative algorithms;pattern search method;reliability optimization;terminal reliability","","23","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Fragmenting relations horizontally using a knowledge-based approach","D. -. Shin; K. B. Irani","Dept. of Sci. & Eng., Connecticut Univ., Storrs, CT, USA; NA","IEEE Transactions on Software Engineering","","1991","17","9","872","883","In distributed DBMSs, one major issue in developing a horizontal fragmentation technique is what criteria to use to guide the fragmentation. The authors propose to use, in addition to typical user queries, particular knowledge about the data itself. Use of this knowledge allows revision of typical user queries into more precise forms. The revised query expressions produce better estimations of user reference clusters to the database than the original query expressions. The estimated user reference clusters form a basis to partition relations horizontally. In the proposed approach, an ordinary many-sorted language is extended to represent the queries and knowledge compatibly. This knowledge is identified in terms of five axiom schemata. An inference procedure is developed to apply the knowledge to the queries deductively.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.92906","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=92906","","Distributed databases;Knowledge based systems;Costs;Inference mechanisms;Logic design;Helium;Parallel processing;Query processing;Computer science","distributed databases;inference mechanisms;information retrieval systems;knowledge based systems;knowledge representation","knowledge-based approach;distributed DBMSs;horizontal fragmentation technique;typical user queries;revised query expressions;estimated user reference clusters;many-sorted language;inference procedure","","8","","20","","","","","","IEEE","IEEE Journals & Magazines"
"A Study of a Mechanism for Controlling Multiprogrammed Memory in an Interactive System","A. Brandwajn; J. -. Hernandez","Amdahl Corporation; NA","IEEE Transactions on Software Engineering","","1981","SE-7","3","321","331","This paper deals with the following mechanism for controlling the multiprogramming set in a demand paging system: processes are dynamically divided into several categories according to the number of page faults generated during their residence in main memory. A process is admitted into the multiprogramming set only if there is enough space free in the main memory to contain the number of pages corresponding to the current category of the process. Using a queueing network model of an interactive system with such a control mechanism we study the effectivenesss of the control considered, and, more particularly, its ability to partition the memory space according to the locality of processes.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230842","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702845","Classes of processes;demand paging;hybrid analytical-simulation solution method;interactive system;multiprogrammed memory;process admission and memory allocation;queueing network models","Control systems;Interactive systems;Partitioning algorithms;Automatic control;Queueing analysis;Algorithm design and analysis;Memory management;Throughput;Delay","","Classes of processes;demand paging;hybrid analytical-simulation solution method;interactive system;multiprogrammed memory;process admission and memory allocation;queueing network models","","1","","33","","","","","","IEEE","IEEE Journals & Magazines"
"A case study in structure specification: a grid description of Scribe","H. Ossher","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA","IEEE Transactions on Software Engineering","","1989","15","11","1397","1416","The author describes a case study in which the grid mechanism was used to describe the structure of Scribe, a document-processing system in widespread use. The structure description is presented and explained in some detail, and the effectiveness of the grid for specifying the important structural features of Scribe is discussed. It is shown that the grid succeeds in its objective of presenting complex structures clearly. A grid specification forms a suitable basis for a narrative explanation of system structure. It is further noted that some detailed improvements would further enhance the expressiveness of the grid, and that environment support is essential for serious use of the grid.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.41332","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=41332","","Computer aided software engineering;Programming profession;Software systems;Computer errors;Control systems","computer graphics;data structures;software engineering","structure specification;grid mechanism;Scribe;document-processing system;grid specification;environment support","","3","","35","","","","","","IEEE","IEEE Journals & Magazines"
"Constraint-based automatic test data generation","R. A. DeMilli; A. J. Offutt","Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA; NA","IEEE Transactions on Software Engineering","","1991","17","9","900","910","A novel technique for automatically generating test data is presented. The technique is based on mutation analysis and creates test data that approximate relative adequacy. It is a fault-based technique that uses algebraic constraints to describe test cases designed to find particular types of faults. A set of tools (collectively called Godzilla) that automatically generates constraints and solves them to create test cases for unit and module testing has been implemented. Godzilla has been integrated with the Mothra testing system and has been used as an effective way to generate test data that kill program mutants. The authors present an initial list of constraints and discuss some of the problems that have been solved to develop the complete implementation of the technique.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.92910","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=92910","","Automatic testing;Software testing;System testing;Genetic mutations;Algorithms;Fault detection;Costs;Software systems;Software engineering;Computer science","computational complexity;program testing","constraint-based data generation;automatic test data generation;mutation analysis;relative adequacy;fault-based technique;algebraic constraints;Godzilla;module testing;Mothra testing system","","363","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Software Bases for the Flexible Composition of Application Systems","R. T. Mittermeir; M. Oppitz","Department of Informatik, Universit&#228;t f&#252;r Bildungswissenschaften Klagenfurt; NA","IEEE Transactions on Software Engineering","","1987","SE-13","4","440","460","In various application areas, classes of computer programs can be identified such that each program belonging to a class, can be considered as a special variant of a generic program.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233181","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702236","Software base;software engineering;software generalization;software modularization;software reusability","Application software;Software systems;Databases;Software reusability;Skeleton;Control systems;Buildings;User interfaces;Software performance;Software engineering","","Software base;software engineering;software generalization;software modularization;software reusability","","11","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Protocol Verification via Projections","S. S. Lam; A. U. Shankar","Department of Computer Science, University of Texas, Austin, TX 78712.; Department of Computer Sciences, University of Texas, Austin, TX 78712.; Department of Computer Science, University of Maryland, College Park, MD 20742.","IEEE Transactions on Software Engineering","","1984","SE-10","4","325","342","The method of projections is a new approach to reduce the complexity of analyzing nontrivial communication protocols. A protocol system consists of a network of protocol entities and communication channels. Protocol entities interact by exchanging messages through channels; messages in transit may be lost, duplicated as well as reordered. Our method is intended for protocols with several distinguishable functions. We show how to construct image protocols for each function. An image protocol is specified just like a real protocol. An image protocol system is said to be faithful if it preserves all safety and liveness properties of the original protocol system concerning the projected function. An image protocol is smaller than the original protocol and can typically be more easily analyzed. Two protocol examples are employed herein to illustrate our method. An application of this method to verify a version of the high-level data link control (HDLC) protocol is described in a companion paper.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010246","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010246","Communicating processes;communication protocols;distributed systems;image protocols;message-passing networks;method of projections;protocol analysis;verification","Protocols;Image analysis;Safety;Communication system control;Transfer functions;Computer languages;Control systems","","","","120","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Gambit: An Interactive Database Design Tool for Data Structures, Integrity Constraints, and Transactions","R. P. Braegger; A. M. Dudler; J. Rebsamen; C. A. Zehnder","Federal Institute of Technology (ETH); NA; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","7","574","583","The design of a database is a rather complex and dynamic process that requires comprehensive knowledge and experience. There exist many manual design tools and techniques, but the step from a schema to an implementation is still a delicate subject. The interactive database design tool Gambit supports the whole process in an optimal way. It is based on an extended relational-entity relationship model. The designer is assisted in outlining and describing data structures and consistency preserving update transactions. The constraints are formulated using the database programming language Modula/R which is based upon first-order predicate calculus. The update transactions are generated automatically as Modula/R programs and include all defined integrity constraints. They are collected in so-called data modules that represent the only interface to the database apart from read operations. The prototype facility of Gambit allows the designer to test the design of the database. The results can be used as feedback leading to an improvement of the conceptual schema and the transactions.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232501","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702061","Data modules;database design;database programming language;entity relationship model;integrity constraints;propagation path concept","Transaction databases;Data structures;Relational databases;Database systems;Computer languages;User interfaces;Prototypes;Testing;Feedback;Satellite broadcasting","","Data modules;database design;database programming language;entity relationship model;integrity constraints;propagation path concept","","5","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Modeling Software Behavior in Terms of a Formal Life Cycle Curve: Implications for Software Maintenance","W. K. Wiener-Ehrlich; J. R. Hamrick; V. F. Rupolo","Bankers Trust Company, New York, NY 10006.; AT&amp;T Bell Laboratories, Piscataway, NJ.; Bankers Trust Company, New York, NY 10006.; Dun and Bradstreet, Berkeley Heights, NJ.","IEEE Transactions on Software Engineering","","1984","SE-10","4","376","383","In this paper, a formal model of the software manloading pattern, the Rayleigh model, is described and then applied to four Bankers Trust Company (BTCo.) new development projects possessing complete life cycle manloading data (maintenance phase included). To fit the Rayleigh curve to a project's manloading scores, (nonlinear) regression was used to obtain least squares estimates of the Rayleigh parameters, which, in turn, were used to generate the Rayleigh manloading curve. For all four projects, deviation from the Rayleigh curve was small and constant throughout the software development phases (i.e., preliminary design through implementation); however, the Rayleigh curve consistently deviated from the actual manloading during system maintenance, underestimating the amount of maneffort expended. Restricting maintenance maneffort to manpower expended on repair of system faults (``corrective'' maintenance) resulted in a single Rayleigh curve that could be applied over the entire BTCo. life cycle. Furthermore, this corrective portion of the maintenance effort could be accurately forecasted from the Rayleigh curve fit to software development. Implications of these findings for software management are discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010250","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010250","Corrective maintenance;development project;empirical;fitted curve;forecasting software maintenancce;formal model of software life cycle;projected curve;Rayleigh model;residual score","Software maintenance;Programming;Large-scale systems;Project management;Pattern analysis;Predictive models;Mathematical model;Software development management;Load forecasting;Logistics","","","","7","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Managing requirements inconsistency with development goal monitors","W. N. Robinson; S. D. Pawlowski","Dept. of Comput. Inf. Syst., Georgia State Univ., Atlanta, GA, USA; NA","IEEE Transactions on Software Engineering","","1999","25","6","816","835","Managing the development of software requirements can be a complex and difficult task. The environment is often chaotic. As analysts and customers leave the project, they are replaced by others who drive development in new directions. As a result, inconsistencies arise. Newer requirements introduce inconsistencies with older requirements. The introduction of such requirements inconsistencies may violate stated goals of development. In this article, techniques are presented that manage requirements document inconsistency by managing inconsistencies that arise between requirement development goals and requirements development enactment. A specialized development model, called a requirements dialog meta-model, is presented. This meta-model defines a conceptual framework for dialog goal definition, monitoring, and in the case of goal failure, dialog goal reestablishment. The requirements dialog meta-model is supported in an automated multiuser World Wide Web environment, called DEALSCRIBE. An exploratory case study of its use is reported. This research supports the conclusions that: an automated tool that supports the dialog meta-model can automate the monitoring and reestablishment of formal development goals; development goal monitoring can be used to determine statements of a development dialog that fail to satisfy development goals; and development goal monitoring can be used to manage inconsistencies in a developing requirements document. The application of DEALSCRIBE demonstrates that a dialog meta-model can enable a powerful environment for managing development and document inconsistencies.","0098-5589;1939-3520;2326-3881","","10.1109/32.824411","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=824411","","Computerized monitoring;Condition monitoring;Power system management;Design engineering;Power engineering and energy;Computer aided software engineering;Software development management;Student members;Chaos;Web sites","systems analysis;formal specification;software development management;information resources","requirements inconsistency management;development goal monitors;software requirements development management;requirement development goals;requirements development enactment;requirements dialog meta-model;dialog goal definition;World Wide Web;multiuser environment;DEALSCRIBE","","34","","75","","","","","","IEEE","IEEE Journals & Magazines"
"An Application of Name Based Addressing to Low Level Distributed Algorithms","M. Ahamad; A. J. Bernstein","Department of Computer Science, State University of New York at Stony Brook; NA","IEEE Transactions on Software Engineering","","1985","SE-11","1","59","67","An interprocess communication structure for a distributed language is described which provides message level communication, multicast, and a generalized naming facility. The design is oriented to the needs of low level algorithms which, for example, might be used in a distributed operating system to support resource allocation or enhance reliability. The proposal is illustrated by programming several distributed algorithms from the literature. An implementation is described that takes advantage of physical multicast technology, and reduces to more conventional schemes for common communication paradigms.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231843","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701898","Distributed algorithms;distributed languages;multicast","Distributed algorithms;Resource management;Bandwidth;Broadcasting;Multicast algorithms;Operating systems;Application software;Costs;Ethernet networks;Broadcast technology","","Distributed algorithms;distributed languages;multicast","","2","","30","","","","","","IEEE","IEEE Journals & Magazines"
"A human factors experimental comparison of SQL and QBE","M. Y. -. Yen; R. W. Scamell","Dept. of Bus. Comput. Inf. Syst., Alaska Univ., Anchorage, AK, USA; NA","IEEE Transactions on Software Engineering","","1993","19","4","390","409","SQL and QBE are compared in the same operating environment, and the effects of query language type and other variables on user performance and satisfaction are studied. The experimental design combined a factorial design and a counterbalanced design in an effort to compare SQL and QBE. The results indicated that query language type affects user performance in paper and pencil testing, with QBE users having higher scores than SQL users. In contrast, in online testing, query language type had no effect on user performance. In addition, under certain conditions, query complexity had a significant effect on user performance and user satisfaction was influenced by query language type. Moreover, order of exposure impacted user performance on the basis of interaction with query language type, query complexity, and programming experience.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.223806","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=223806","","Human factors;Database languages;Testing;ANSI standards;Standards development;Natural languages;User interfaces;Design for experiments;Laboratories;Relational databases","human factors;query languages","human factors experimental comparison;SQL;QBE;operating environment;query language type;user performance;factorial design;counterbalanced design;online testing;query complexity","","23","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Evaluating emerging software development technologies: lessons learned from assessing aspect-oriented programming","G. C. Murphy; R. J. Walker; E. L. A. Banlassad","Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada; NA; NA","IEEE Transactions on Software Engineering","","1999","25","4","438","455","Determining whether a new software development technique is useful and usable is a challenging taste. Various flavors of empirical study may be used to help with this task, including surveys, case studies, and experiments. Little guidance is available within the software engineering community to help choose among these alternatives when assessing a new and evolving software development technique within some cost bounds. We faced this challenge when assessing a new programming technique called aspect-oriented programming. To assess the technique, we chose to apply both a case study approach and a series of four experiments because we wanted to understand and characterize the kinds of information that each approach might provide. We describe and critique the evaluation methods we employed, and discuss the lessons we have learned. These lessons are applicable to other researchers attempting to assess new programming techniques that are in an early stage of development.","0098-5589;1939-3520;2326-3881","","10.1109/32.799936","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=799936","","Programming;Application software;Software engineering;Costs;Computer Society;Psychology;Management training;Software design;Computer science","programming;software engineering","emerging software development technologies;aspect-oriented programming;case study approach;evaluation methods","","13","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Understanding code mobility","A. Fuggetta; G. P. Picco; G. Vigna","Dipt. di Elettronica e Inf., Politecnico di Milano, Italy; NA; NA","IEEE Transactions on Software Engineering","","1998","24","5","342","361","The technologies, architectures, and methodologies traditionally used to develop distributed applications exhibit a variety of limitations and drawbacks when applied to large scale distributed settings (e.g., the Internet). In particular, they fail in providing the desired degree of configurability, scalability, and customizability. To address these issues, researchers are investigating a variety of innovative approaches. The most promising and intriguing ones are those based on the ability of moving code across the nodes of a network, exploiting the notion of mobile code. As an emerging research field, code mobility is generating a growing body of scientific literature and industrial developments. Nevertheless, the field is still characterized by the lack of a sound and comprehensive body of concepts and terms. As a consequence, it is rather difficult to understand, assess, and compare the existing approaches. In turn, this limits our ability to fully exploit them in practice, and to further promote the research work on mobile code. Indeed, a significant symptom of this situation is the lack of a commonly accepted and sound definition of the term mobile code itself. This paper presents a conceptual framework for understanding code mobility. The framework is centered around a classification that introduces three dimensions: technologies, design paradigms, and applications. The contribution of the paper is two-fold. First, it provides a set of terms and concepts to understand and compare the approaches based on the notion of mobile code. Second, it introduces criteria and guidelines that support the developer in the identification of the classes of applications that can leverage off of mobile code, in the design of these applications, and, finally, in the selection of the most appropriate implementation technologies. The presentation of the classification is intertwined with a review of state-of-the-art in the field. Finally, the use of the classification is exemplified in a case study.","0098-5589;1939-3520;2326-3881","","10.1109/32.685258","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=685258","","Computer networks;Pervasive computing;IP networks;Large-scale systems;Scalability;Guidelines;Appropriate technology;Mobile agents;Availability;Hardware","distributed processing;software portability;object-oriented programming","code mobility;software architecture;methodologies;distributed applications;configurability;scalability;customizability;computer network;research field;conceptual framework;design paradigms;mobile code;classification;case study;mobile agent;object oriented programming","","534","","73","","","","","","IEEE","IEEE Journals & Magazines"
"Analyzing expected time by scheduler-luck games","S. Dolev; A. Israeli; S. Moran","Dept. of Math. & Comput. Sci., Ben-Gurion Univ. of the Negev, Beer-Sheva, Israel; NA; NA","IEEE Transactions on Software Engineering","","1995","21","5","429","439","We introduce a novel technique, the scheduler luck game (in short sl-game) for analyzing the performance of randomized distributed protocols. We apply it in studying uniform self-stabilizing protocols for leader election under read/write atomicity. We present two protocols for the case where each processor in the system can communicate with all other processors and analyze their performance using the sl-game technique.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.387472","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=387472","","Protocols;Nominations and elections;Processor scheduling;Performance analysis;Tail;Computer science;Atomic measurements;Distributed algorithms;Time measurement","computational complexity;protocols;processor scheduling;scheduling;software performance evaluation;random processes;distributed processing;game theory","scheduler-luck games;expected time analysis;performance analysis;randomized distributed protocols;uniform self-stabilizing protocols;leader election;read/write atomicity;processor","","20","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Analysis of faults in an N-version software experiment","S. S. Brilliant; J. C. Knight; N. G. Leveson","Dept. of Comput. Sci., Virginia Univ., Charlottesville, VA, USA; Dept. of Comput. Sci., Virginia Univ., Charlottesville, VA, USA; NA","IEEE Transactions on Software Engineering","","1990","16","2","238","247","The authors have conducted a large-scale experiment in N-version programming. A total of 27 versions of a program were prepared independently from the same specification at two universities. The results of executing the versions revealed that the versions were individually extremely reliable but that the number of input cases in which more than one failed was substantially more than would be expected if they were statistically independent. After the versions had been executed, the failures of each version were examined and the associated faults located. It appears that minor differences in the software development environment would not have a major impact in reducing the incidence of faults that cause correlated failures.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44387","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44387","","Educational institutions;Application software;Computer science;Large-scale systems;Fault tolerance;Aircraft propulsion;Programming profession;Computer languages;Software reliability;Production","fault tolerant computing;program testing;software engineering","failure analysis;fault location;statistical correlation;N-version programming;software development environment","","78","","15","","","","","","IEEE","IEEE Journals & Magazines"
"A Mechanism for Database Protection in Cellular-Logic Devices","Yang-Chang Hong; S. Y. W. Su","Institute of Information Science, Academia Sinica, Taipei, Taiwan, and the Department of Information Engineering, National Taiwan University; NA","IEEE Transactions on Software Engineering","","1982","SE-8","6","583","596","Protection of data in a database against unauthorized disclosure, alteration, or destruction is an important aspect of a multiuser database system. In a system which uses a celiular-logic device as a means for data management applications, protection can be achieved in part by associating security windows with queries. This paper describes a mechanism for dynamically creating these windows for cellular-logic devices. The mechanism mainly benefits from the associative techniques such as content and context searches, tagging and marking data, etc. These techniques allow the windows to be created physically by simultaneously activating related access control decision procedures, which implement access control decisions employed by the system, to mask out those data to which the user does not have the right of access. Furthermore, they enable the content-dependent security decisions to be efficiently implemented, eliminating the drawbacks found in conventional systems. Thus, a query accessing to a protected database system is identical to a query accessing to its companion window. An implementation of this mechanism on the cellular-logic device CASSM is also presented.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.236019","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702992","Associative programming;cellular-logic device;content addressing;database management;database security;parallel processing;security window","Protection;Data security;Information security;Database systems;Access control;Remuneration;Parallel processing;Costs;Tagging;Parallel programming","","Associative programming;cellular-logic device;content addressing;database management;database security;parallel processing;security window","","2","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Rendezvous facilities: Concurrent C and the Ada language","N. H. Gehani; W. D. Roome","AT&T Bell Lab., Murray Hill, NJ, USA; AT&T Bell Lab., Murray Hill, NJ, USA","IEEE Transactions on Software Engineering","","1988","14","11","1546","1553","The concurrent programming facilities in both Concurrent C and the Ada language are based on the rendezvous concept. Although these facilities are similar, there are substantial differences. Facilities in Concurrent C were designed keeping in perspective the concurrent programming facilities in the Ada language and their limitations. Concurrent C facilities have also been modified as a result of experience with its initial implementations. The authors compare the concurrent programming facilities in Concurrent C and Ada and show that it is easier to write a variety of concurrent programs in Concurrent C than in Ada.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9043","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9043","","Feedback;Terminology;Resumes","Ada;C language;parallel programming","parallel programming;Concurrent C;Ada;concurrent programming;rendezvous concept","","15","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Performance analysis of two-phase locking","A. Thomasian; I. K. Ryu","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; NA","IEEE Transactions on Software Engineering","","1991","17","5","386","402","A straightforward analytic solution method is developed which takes into account the variability of transaction size (the number of lock requests). The authors first obtain analytic expressions for the probability of lock conflict, probability of deadlock, and the waiting time per lock conflict. They then develop a family of noniterative analytic solutions to evaluate the overall system performance by considering the expansion in transaction response time due to transaction blocking. The accuracy of these solutions is verified by validation against simulation results. Also introduced is a new measure for the degree of lock contention, which is a product of the mean number of lock conflicts per transaction and the mean waiting time per lock conflict (when blocked by an active transaction). It is shown that the variability in transaction size results in an increase in both measures as compared to fixed-size transactions of comparable size. The authors also provide a solution method for the case when the processing times of transaction steps are different.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.90443","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=90443","","Performance analysis;System recovery;Delay;Degradation;System performance;Costs;Concurrency control;Hardware;Throughput;Frequency estimation","concurrency control;distributed databases;system recovery;transaction processing","two-phase locking;transaction size;lock requests;probability;lock conflict;deadlock;system performance;transaction response time;transaction blocking;simulation;lock contention","","33","","25","","","","","","IEEE","IEEE Journals & Magazines"
"The Performance Evaluation of Control Implementations","J. P. Kearns; C. J. Meier; M. L. Soffa","Department of Computer Science, University of Pittsburgh; NA; NA","IEEE Transactions on Software Engineering","","1982","SE-8","2","89","96","A methodology for the experimental investigation of the implementation of control in programming languages is presented. The methodology specifies a data-collection technique, the environment for driving simulations of control implementations, and a meaningful metric for performance evaluation. The key in the methodology is the separation of activity which is affected by the control implementation from that which is not.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.234951","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702916","Coroutines;measurement;performance evaluation;spaghetti stack;storage management","Communication system control;Computer languages;Runtime;Computer science;IEL;Cost accounting;High level languages;Real time systems;Control system synthesis;Artificial intelligence","","Coroutines;measurement;performance evaluation;spaghetti stack;storage management","","4","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Models of software development environments","D. E. Perry; G. E. Kaiser","AT&T Bell Lab., Murray Hill, NJ, USA; NA","IEEE Transactions on Software Engineering","","1991","17","3","283","295","A general model of software development environments that consists of structures, mechanisms, and policies is presented. The advantage of this model is that it distinguishes intuitively those aspects of an environment that are useful in comparing and contrasting software development environments. Four classes of environments-the individual, the family, the city. and the state-are characterized by means of a sociological metaphor based on scale. The utility of the taxonomy is that it delineates the important classes of interactions among software developers and exposes the ways in which current software development environments inadequately support the development of large systems. The generality of the model is demonstrated by its application to a previously published taxonomy that categorizes environments according to how they relate to language-centered, structure-oriented, toolkit, and method-based environments.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.75417","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=75417","","Programming;Cities and towns;Taxonomy;Application software;Software tools;Software systems;Hardware;Power system modeling;Research and development","programming environments","language centered environments;structure-oriented environments;toolkit environments;software development environments;sociological metaphor;method-based environments","","31","","117","","","","","","IEEE","IEEE Journals & Magazines"
"Macro-Based Cross Assemblers","K. R. Tavernier; P. H. Notredame","Interfacultair Centrum Informatica, Laboratorium voor Electronica en Meettechniek, Rijksuniversiteit Gent; NA","IEEE Transactions on Software Engineering","","1980","SE-6","4","334","340","The problem of implementing cross assemblers by means of a macro expansion technique is addressed. Various problems caused by the implementation technique proper, as well as the target machine instruction set, are identified.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234489","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702741","Addressing modes;cross assembler;imbedded macro calls;imbedded macro definitons;macro assembler;macros;meta assembler;microprocessor","Microprocessors;Assembly systems;Hardware;Computer architecture;File systems;Design engineering;Power engineering and energy;Error correction;Memory;Counting circuits","","Addressing modes;cross assembler;imbedded macro calls;imbedded macro definitons;macro assembler;macros;meta assembler;microprocessor","","2","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Companson and Diagnosis of Large Replicated Files","W. K. Fuchs; Kun-Lung Wu; J. A. Abraham","Compiler Systems Group, Coordinated Science Laboratory, University of Illinois at Urbana-Champaign; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","1","15","22","This paper examines the problem of comparing large replicated files in a context in which communication dominates the cost of comparison. A low-cost checking matrix is proposed for comparison of these replicated files. The checking matrix is composed of check symbols generated by a divide-and-conquer encoding algorithm. The matrix allows for detection and diagnosis of disagreeing pages with very little communication overhead. In contrast to a previous O(N) proposal, the storage requirement for the checking matrix is O(log N), where N is the number of pages in the file. The matrix can be stored in main memory without the need for extra accesses to disk during normal updates of pages.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232561","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702128","Data transmission;distributed files;file comparison;replicated files","Jacobian matrices;Proposals;Costs;Software systems;Database systems;Context;Encoding;Software performance;Monitoring;Software algorithms","","Data transmission;distributed files;file comparison;replicated files","","2","","10","","","","","","IEEE","IEEE Journals & Magazines"
"The Impact of Run-Time Schema Interpretation in a Network Data Model DBMS","A. J. Baroody; D. J. DeWitt","Xerox Webster Research Center; NA","IEEE Transactions on Software Engineering","","1982","SE-8","2","123","136","This paper describes a simulation study of the effect of runtime schema interpretation in a network data model database management system. To perform database operations, programmers use a data manipulation language which supports calls to the data manipulation routines. The data manipulation routines utilize database descriptors from the schema to determine which operations on the database are to be performed for a given actual parameter to the procedure. Current database systems perform the binding of schema descriptors in the data manipulation routines at run-time by interpretation. A niumber of researchers are studying methods to precompute the information required to determine the correct function to execute rather than using run-time interpretation.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.234955","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702920","Database system;interpretation;memory hierarchy;network data model;object-oriented programming;optimization;performance evaluation;simulation","Runtime;Intelligent networks;Data models;Object oriented modeling;Database systems;Transaction databases;Programming profession;Object oriented databases;System performance;Performance evaluation","","Database system;interpretation;memory hierarchy;network data model;object-oriented programming;optimization;performance evaluation;simulation","","","","24","","","","","","IEEE","IEEE Journals & Magazines"
"A Remote Procedure Call Facility for Interconnecting Heterogeneous Computer Systems","B. N. Bershad; D. T. Ching; E. D. Lazowska; J. Sanislo; M. Schwartz","Department of Computer Science, University of Washington; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","8","880","894","Heterogeneity in hardware and software is an inevitable consequence of experimental computer research. At the University of Washington, the Heterogeneous Computer Systems (HCS) project is a major research and development effort whose goal is to simplify the interconnection of heterogeneous computer systems.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233507","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702307","Distributed computer systems;heterogeneous computer systems;remote procedure call","Hardware;Transport protocols;Application software;Workstations;Research and development;Runtime;Buildings;Performance analysis;Testing;Computer science","","Distributed computer systems;heterogeneous computer systems;remote procedure call","","36","","29","","","","","","IEEE","IEEE Journals & Magazines"
"A domain-specific software architecture for adaptive intelligent systems","B. Hayes-Roth; K. Pfleger; P. Lalanda; P. Morignot; M. Balabanovic","Knowledge Syst. Lab., Stanford Univ., Palo Alto, CA, USA; Knowledge Syst. Lab., Stanford Univ., Palo Alto, CA, USA; Knowledge Syst. Lab., Stanford Univ., Palo Alto, CA, USA; Knowledge Syst. Lab., Stanford Univ., Palo Alto, CA, USA; Knowledge Syst. Lab., Stanford Univ., Palo Alto, CA, USA","IEEE Transactions on Software Engineering","","1995","21","4","288","301","A good software architecture facilitates application system development, promotes achievement of functional requirements, and supports system reconfiguration. We present a domain-specific software architecture (DSSA) that we have developed for a large application domain of adaptive intelligent systems (AISs). The DSSA provides: (a) an AIS reference architecture designed to meet the functional requirements shared by applications in this domain, (b) principles for decomposing expertise into highly reusable components, and (c) an application configuration method for selecting relevant components from a library and automatically configuring instances of those components in an instance of the architecture. The AIS reference architecture incorporates features of layered, pipe and filter, and blackboard style architectures. We describe three studies demonstrating the utility of our architecture in the subdomain of mobile office robots and identify software engineering principles embodied in the architecture.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.385968","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=385968","","Software architecture;Computer architecture;Application software;Decision support systems;Adaptive systems;Intelligent systems;Software libraries;Filters;Teleworking;Mobile robots","adaptive systems;software engineering;mobile robots;office automation;software agents;software reusability;blackboard architecture;reconfigurable architectures","domain-specific software architecture;adaptive intelligent systems;application system development;functional requirements;system reconfiguration;reference architecture;expertise decomposition;highly reusable components;application configuration method;library components selection;automatic configuration;layered architecture;pipe and filter architecture;blackboard architecture;mobile office robots;software engineering principles;software reuse;intelligent agents","","60","","39","","","","","","IEEE","IEEE Journals & Magazines"
"A controlled experiment to assess the benefits of procedure argument type checking","L. Prechelt; W. F. Tichy","Fakultat fur Inf., Karlsruhe Univ., Germany; NA","IEEE Transactions on Software Engineering","","1998","24","4","302","312","Type checking is considered an important mechanism for detecting programming errors, especially interface errors. This report describes an experiment to assess the defect-detection capabilities of static, intermodule type checking. The experiment uses ANSI C and Kernighan & Ritchie (K&R) C. The relevant difference is that the ANSI C compiler checks module interfaces (i.e., the parameter lists calls to external functions), whereas K&R C does not. The experiment employs a counterbalanced design in which each of the 40 subjects, most of them CS PhD students, writes two nontrivial programs that interface with a complex library (Motif). Each subject writes one program in ANSI C and one in K&R C. The input to each compiler run is saved and manually analyzed for defects. Results indicate that delivered ANSI C programs contain significantly fewer interface defects than delivered K&R C programs. Furthermore, after subjects have gained some familiarity with the interface they are using, ANSI C programmers remove defects faster and are more productive (measured in both delivery time and functionality implemented).","0098-5589;1939-3520;2326-3881","","10.1109/32.677186","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=677186","","Programming profession;Computer languages;Computer errors;Productivity;Computer Society;Libraries;Gain measurement;Time measurement;Program processors","program debugging;C language","programming errors;type checking;defect-detection;intermodule type checking;ANSI C;K&R C","","19","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Caching Hints in Distributed Systems","D. B. Terry","Computer Science Laboratory, Xerox Palo Alto Research Center","IEEE Transactions on Software Engineering","","1987","SE-13","1","48","54","Caching reduces the average cost of retrieving data by amortizing the lookup cost over several references to the data. Problems with maintaining strong cache consistency in a distributed system can be avoided by treating cached information as hints. A new approach to managing caches of hints suggests maintaining a minimum level of cache accuracy, rather than maximizing the cache hit ratio, in order to guarantee performance improvements. The desired accuracy is based on the ratio of lookup costs to the costs of detecting and recovering from invalid cache entries. Cache entries are aged so that they get purged when their estimated accuracy falls below the desired level. The age thresholds are dictated solely by clients' accuracy requirements instead of being suggested by data storage servers or system administrators.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232834","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702132","Cache consistency;caching;computer-communication networks;data accuracy;database management;distributed data management;distributed systems;functional lifetimes;hints;resource location","Costs;Memory;File servers;Information retrieval;Network servers;Distributed databases;Computer network management;Resource management;Cache storage;Aging","","Cache consistency;caching;computer-communication networks;data accuracy;database management;distributed data management;distributed systems;functional lifetimes;hints;resource location","","26","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Modeling and Verification of Real-Time Protocols for Broadcast Networks","P. Jain; S. S. Lam","Department of Computer Sciences, University of Texas at Austin; NA","IEEE Transactions on Software Engineering","","1987","SE-13","8","924","937","A class of demand-assigned multiple-access (DAMA) protocols have been proposed for high-speed local area networks (LAN's) that offer integrated services for data, voice, video, and facsimile traffic. These protocols exploit the directionality of signal propagation and implement stringent real-time constraints to achieve collision-freedom. Correct implementation of DAMA protocols will require a very careful analysis of time-dependent interactions using a formal method. To date, most verification methods have been focused on asynchronous communication over point-to-point links.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233511","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702311","Broadcast channel;local area networks;multiple-access protocols;real-time constraints;verification","Broadcasting;Access protocols;Local area networks;Multimedia communication;Delay;Topology;Intserv networks;Facsimile;Telecommunication traffic;Traffic control","","Broadcast channel;local area networks;multiple-access protocols;real-time constraints;verification","","4","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Correct architecture refinement","M. Moriconi; X. Qian; R. A. Riemenschneider","Comput. Sci. Lab., SRI Int., Menlo Park, CA, USA; Comput. Sci. Lab., SRI Int., Menlo Park, CA, USA; Comput. Sci. Lab., SRI Int., Menlo Park, CA, USA","IEEE Transactions on Software Engineering","","1995","21","4","356","372","A method is presented for the stepwise refinement of an abstract architecture into a relatively correct lower-level architecture that is intended to implement it. A refinement step involves the application of a predefined refinement pattern that provides a routine solution to a standard architectural design problem. A pattern contains an abstract architecture schema and a more detailed schema intended to implement it. The two schemas usually contain very different architectural concepts (from different architectural styles). Once a refinement pattern is proven correct, instances of it can be used without proof in developing specific architectures. Individual refinements are compositional, permitting incremental development and local reasoning. A special correctness criterion is defined for the domain of software architecture, as well as an accompanying proof technique. A useful syntactic form of correct composition is defined. The main points are illustrated by means of familiar architectures for a compiler. A prototype implementation of the method has been used successfully in a real application.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.385972","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=385972","","Computer architecture;Software architecture;Concrete;Integrated circuit synthesis;Software prototyping;Prototypes;Application software;Software systems;Data engineering;Computer science","software engineering;program compilers;program verification","correct architecture refinement;stepwise refinement;abstract architecture schema;relatively correct lower-level architecture;predefined refinement pattern;standard architectural design problem;architectural styles;compositional refinements;incremental development;local reasoning;correctness criterion;software architecture;proof technique;syntactic form;correct composition;compiler;hierarchy;formal methods","","130","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Evaluating alternative software production functions","Qing Hu","Dept. of Decision & Inf. Syst., Florida Atlantic Univ., Boca Raton, FL, USA","IEEE Transactions on Software Engineering","","1997","23","6","379","387","Software development projects are notorious for cost overruns and schedule delays. While dozens of software cost models have been proposed, few of them seem to have any degree of consistent accuracy. One major factor contributing to this persistent and wide spread problem is an inadequate understanding of the real behavior of software development processes. We believe that software development could be studied as an economic production process and that established economic theories and methods could be used to develop and validate software production and cost models. We present the results of evaluating four alternative software production models using the P-test, a statistical procedure developed specifically for testing the truth of a hypothesis in the presence of alternatives in econometric studies. We found that the truth of the widely used Cobb-Douglas type of software production and cost models (e.g., COCOMO) cannot be maintained in the presence of quadratic or translog models. Overall, the quadratic software production function is shown to be the most plausible model for representing software production processes. Limitations of this study and future directions are also discussed.","0098-5589;1939-3520;2326-3881","","10.1109/32.601078","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=601078","","Programming;Cost function;Econometrics;Software maintenance;Delay;Production systems;Software systems;Software testing;Environmental economics;Size measurement","software cost estimation;economics;project management;statistical analysis","alternative software production function evaluation;software development projects;cost overruns;schedule delays;software cost models;consistent accuracy;software development processes;economic production process;economic theories;cost models;software production models;P-test;statistical procedure;hypothesis testing;econometric studies;translog models;quadratic software production function","","19","","39","","","","","","IEEE","IEEE Journals & Magazines"
"Salient features of an executable specification language and its environment","P. Zave; W. Schell","AT&T Bell Laboratories, Murray Hill, NJ 07974; AT&T Bell Laboratories, Murray Hill, NJ 07974","IEEE Transactions on Software Engineering","","1986","SE-12","2","312","325","The executable specification language PAISLey and its environment are presented as a case study in the design of computer languages. It is shown that PAISLey is unusual (and for some features unique) in having the following desirable features: (1) there is both synchronous and asynchronous parallelism free of mutual-exclusion problems, (2) all computations are encapsulated, (3) specifications in the language can be executed no matter how incomplete they are, (4) timing constraints are executable, (5) specifications are organized so that bounded resource consumption can be guaranteed, (6) almost all forms of inconsistency can be detected by automated checking, and (7) a notable degree of simplicity is maintained. Conclusions are drawn concerning the differences between executable specification languages and programming languages, and potential uses for PAISLey are given.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312946","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312946","Distributed systems;executable specifications;functional programming;interpreters;language design;operational approach to software development;parallelism;performance simulation;programming environments;real-time systems;user interfaces","Parallel processing;Monitoring;Specification languages;Functional programming;Computational modeling","specification languages","executable specification language;PAISLey;computer languages;parallelism;mutual-exclusion;timing constraints;automated checking;simplicity","","28","","","","","","","","IEEE","IEEE Journals & Magazines"
"Exception handlers in functional programming languages","R. Govindarajan","Dept. of Electr. Eng., McGill Univ., Montreal, Que., Canada","IEEE Transactions on Software Engineering","","1993","19","8","826","834","Constructs for expressing exception handling can greatly help to avoid clutter in code by allowing the programmer to separate the code to handle unusual situations from the code for the normal case. The author proposes a new approach to embed exception handlers in functional languages. The proposed approach discards the conventional view of treating exceptions, as a means of effecting a control transfer; instead, exceptions are used to change the state of an object. The two types of exceptions, terminate and resume, are treated differently. A terminate exception, when raised, is viewed as shielding the input object. On the other hand, a resume exception designates the input object as curable and requires the immediate application of a handler function. This approach enables the clean semantics of functions raising exceptions without associating any implementation restriction and without loss of the referential transparency and the commutativity properties of functions.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.238585","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=238585","","Functional programming;Resumes;Fault tolerance;Application software;Computer languages;Software standards;Programming profession;Parallel processing;Robustness;Software reliability","exception handling;functional programming;high level languages;programming theory","functional programming;exception handling;programmer;functional languages;terminate;resume;input object;implementation restriction;referential transparency;commutativity properties","","2","","11","","","","","","IEEE","IEEE Journals & Magazines"
"The SeaView security model","T. F. Lunt; D. E. Denning; R. R. Schell; M. Heckman; W. R. Shockley","SRI Int., Menlo Park, CA, USA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1990","16","6","593","607","A multilevel database is intended to provide the security needed for database systems that contain data at a variety of classifications and serve a set of users having different clearances. A formal security model for such a system is described. The model is formulated in two layers, one corresponding to a reference monitor that enforces mandatory security, and the second an extension of the standard relational model defining multilevel relations and formalizing policies for labeling new and derived data, data consistency, and discretionary security. The model also defines application-independent properties for entity integrity, referential integrity, and polyinstantiation integrity.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.55088","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=55088","","Data security;Database systems;Relational databases;Multilevel systems;Military computing;Transaction databases;Monitoring;Labeling;Protection;Authorization","relational databases;security of data;software engineering","policy formalization;new data;SeaView security model;multilevel database;classifications;users;clearances;formal security model;reference monitor;mandatory security;standard relational model;multilevel relations;labeling;derived data;data consistency;discretionary security;application-independent properties;entity integrity;referential integrity;polyinstantiation integrity","","82","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Test selection based on finite state models","S. Fujiwara; G. v. Bochmann; F. Khendek; M. Amalou; A. Ghedamsi","Dept. d'Inf. et de Recherche Oper., Montreal Univ., Que., Canada; Dept. d'Inf. et de Recherche Oper., Montreal Univ., Que., Canada; Dept. d'Inf. et de Recherche Oper., Montreal Univ., Que., Canada; Dept. d'Inf. et de Recherche Oper., Montreal Univ., Que., Canada; Dept. d'Inf. et de Recherche Oper., Montreal Univ., Que., Canada","IEEE Transactions on Software Engineering","","1991","17","6","591","603","A method for the selection of appropriate test case, an important issue for conformance testing of protocol implementations as well as software engineering, is presented. Called the partial W-method, it is shown to have general applicability, full fault-detection power, and yields shorter test suites than the W-method. Various other issues that have an impact on the selection of a suitable test suite including the consideration of interaction parameters, various test architectures for protocol testing and the fact that many specifications do not satisfy the assumptions made by most test selection methods (such as complete definition, a correctly implemented reset function, a limited number of states in the implementation, and determinism), are discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.87284","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=87284","","Protocols;Software testing;Automata;Hardware;System testing;Software engineering;Formal specifications;Councils","conformance testing;program testing;protocols","finite state models;conformance testing;protocol implementations;software engineering;partial W-method;full fault-detection power;test suites;interaction parameters;test architectures;protocol testing;reset function;determinism","","280","","24","","","","","","IEEE","IEEE Journals & Magazines"
"A transportable programming language (TPL) system. II. The bifunctional compiler system","S. Leong; S. Jodis; K. Sullivan; O. Jiang; P. A. D. de Maine","Dept. of Comput. Sci. & Eng., Auburn Univ., AL, USA; Dept. of Comput. Sci. & Eng., Auburn Univ., AL, USA; Dept. of Comput. Sci. & Eng., Auburn Univ., AL, USA; Dept. of Comput. Sci. & Eng., Auburn Univ., AL, USA; Dept. of Comput. Sci. & Eng., Auburn Univ., AL, USA","IEEE Transactions on Software Engineering","","1990","16","6","639","646","For pt.I see P.A.D. de Maine, S. Leong, and C.G. Dairs, Int. J. Comput. Inform. Sci., vol.14, p.161-82, 1985. The transportable programming language (TPL) method is a high-level-language approach that uses a bifunctional compiler to efficiently convert code among various dialects of a particular high-level language (HLL) via the hypothetical parent of the high-level language (HPHLL). The TPL compiler system that has been implemented has three parts: a rule modifier, a table generator, and a TPL compiler. A metalanguage, called the conversion rule description language (CRDL), is used to describe the conversion of a dialect to HPHLL and of the HPHLL to another dialect. The table generator translates those descriptions to tabular forms that drive the bifunctional compiler. The TPL compiler can then be used to translate programs coded in a local dialect into HPHLL and vice versa. The rule modifier alters the descriptions of a default-a synthetic 'most common'-dialect. It greatly simplifies the task of writing the conversion descriptions for a new environment or dialect. The TPL method is now being extended so that it can be used to retarget a dialect of any HLL to a standard environment such as Ada. Details of the TPL compiler system are given.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.55092","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=55092","","Computer languages;High level languages;Program processors;Computer science;Writing;Transportation;Performance evaluation;Software testing;Time to market","high level languages;program compilers","code conversion, program translation;transportable programming language;high-level-language;bifunctional compiler;hypothetical parent;rule modifier;table generator;metalanguage;conversion rule description language;tabular forms","","3","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Software Fault Tolerance: An Evaluation","T. Anderson; P. A. Barrett; D. N. Halliwell; M. R. Moulding","Centre for Software Reliability, University of Newcastle upon Tyne; NA; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","12","1502","1510","In order to assess the effectiveness of software fault tolerance techniques for enhancing the reliability of practical systems, a major experimental project has been conducted at the University of Newcastle upon Tyne. Techniques were developed for, and applied to, a realistic implementation of a real-time system (a naval command and control system). Reliability data were collected by operating this system in a simulated tactical environment for a variety of action scenarios. This paper provides an overview of the project and presents the results of three phases of experimentation. An analysis of these results shows that use of the software fault tolerance approach yielded a substantial improvement in the reliability of the command and control system.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231894","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701973","Real-time systems;software fault tolerance;software reliability","Fault tolerance;Software reliability;Fault tolerant systems;Reliability engineering;Command and control systems;Software systems;Programming;Software performance;Real time systems;Software maintenance","","Real-time systems;software fault tolerance;software reliability","","34","","27","","","","","","IEEE","IEEE Journals & Magazines"
"A noninterference monitoring and replay mechanism for real-time software testing and debugging","J. J. P. Tsai; K. -. Fang; H. -. Chen; Y. -. Bi","Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA; Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA; Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA; Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA","IEEE Transactions on Software Engineering","","1990","16","8","897","916","A noninterference monitoring and replay mechanism using the recorded execution history of a program to control the replay of the program behavior and guarantee the reproduction of its errors is presented. Based on this approach, a noninterference monitoring architecture has been developed to collect the program execution data of a target real-time software system without affecting its execution. A replay mechanism designed to control the reproduction of the program behavior as well as the examination of the states of the target system and its behavior is presented. The monitoring system has been implemented using a Motorola 68000 computer in a Unix system environment. An example is used to illustrate how the mechanism detects timing errors of real-time software systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.57626","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=57626","","Monitoring;Software testing;Real time systems;Software systems;Software debugging;Timing;System testing;History;Error correction;Computer architecture","program debugging;program testing;real-time systems","real-time software testing;recorded execution history;program behavior;noninterference monitoring architecture;program execution data;target real-time software system;replay mechanism;monitoring system;Motorola 68000 computer;Unix system environment;timing errors;real-time software systems","","76","","34","","","","","","IEEE","IEEE Journals & Magazines"
"Strategies for the prevention of communication deadlocks in distributed parallel programs","V. C. Barbosa","Programa de Engenharia de Sistemas e Computacao, Univ. Federal do Rio de Janeiro, Brazil","IEEE Transactions on Software Engineering","","1990","16","11","1311","1316","The occurrence of communication deadlocks caused by the unavailability of message buffers during the execution of distributed parallel programs is investigated. Such deadlocks can occur even if the program is designed for deadlock-freedom, since they are largely dependent on the system's ability to handle message buffering space. A class of deadlock prevention strategies which require that the programmer provide upper bounds on the buffer usage in the several communication channels involved is exploited, and it is argued that such bounds are relatively simple to obtain in many cases. The proposed strategies range from those which require a minimal amount of buffers to those which ensure a reasonable level of concurrency in process execution, although at the expense of more buffering space. It is shown that in general these strategies require the solution of NP-hard optimization problems, and an efficient heuristic to tackle the concurrency-optimal strategy is suggested. Randomly generated systems are then used to show that the heuristic tends to be very successful.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.60319","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=60319","","System recovery;Routing;Programming profession;Upper bound;Communication channels;Concurrent computing;Integrated circuit interconnections;Buffer storage;Parallel processing","computational complexity;parallel programming;programming theory","randomly generated systems;communication deadlocks;distributed parallel programs;unavailability;message buffers;message buffering space;deadlock prevention;upper bounds;buffer usage;communication channels;concurrency;process execution;NP-hard optimization problems;heuristic","","6","","18","","","","","","IEEE","IEEE Journals & Magazines"
"A theory of interfaces and modules I/spl minus/composition theorem","S. S. Lam; A. U. Shankar","Dept. of Comput. Sci., Texas Univ., Austin, TX, USA; NA","IEEE Transactions on Software Engineering","","1994","20","1","55","71","We model a system as a directed acyclic graph where nodes represent modules and arcs represent interfaces. At the heart of our theory is a definition of what it means for a module to satisfy a set of interfaces as a service provider for some and as a service consumer for others. Our definition of interface satisfaction is designed to be separable; i.e., interfaces encode adequate information such that each module in a system can be designed and verified separately, and composable; i.e., we have proved a composition theorem for the system model in general.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.263755","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=263755","","Heart;Transport protocols;Communication networks;Routing protocols;Telecommunication network reliability;Australia;Computer science;Software engineering","directed graphs;systems analysis;user interfaces;formal specification","interface theory;modules;composition theorem;system modelling;directed acyclic graph;nodes;arcs;interface satisfaction;service provider;service consumer;module design;module verification;system model;system design;specification","","18","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Comparing two functional programming systems","B. Hailpern; T. Huynh; G. Revesz","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA","IEEE Transactions on Software Engineering","","1989","15","5","532","542","A technique is presented for comparing the performance of functional languages with different evaluation strategies running on different machines. A set of small benchmarks is used, and th execution times of these programs running in the functional language and in the implementation language of the functional system are compared. The ratio of these execution times measured how well the functional system used the resources of the underlying hardware and implementation language. Also two functional programming systems are described. One system is a graph reduction interpreter for lambda calculus. The other is a DEL-style intermediate instruction set architecture for FP. The benchmarks in FP and the performances of the two systems on these benchmarks are presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24702","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24702","","Functional programming;Calculus;Workstations;Hardware;Application software;Statistical analysis;Complexity theory;Computer architecture;Software performance;Radio access networks","functional programming;high level languages;performance evaluation","performance comparison;functional programming systems;functional languages;evaluation strategies;benchmarks;execution times;implementation language;graph reduction interpreter;lambda calculus;DEL-style intermediate instruction set architecture;FP","","1","","36","","","","","","IEEE","IEEE Journals & Magazines"
"DMIN: An Algorithm for Computing the Optimal Dynamic Allocation in a Virtual Memory Computer","R. L. Budzinski; E. S. Davidson; W. Mayeda; H. S. Stone","Central Research Laboratory, Texas Instruments, Inc.; NA; NA; NA","IEEE Transactions on Software Engineering","","1981","SE-7","1","113","121","An optimal unrealizable (in real time) virtual memory allocation algorithm DMIN is developed. OMIN has the following properties. A dynamic (time-varying) size of allocation is computed by DMIN to minimize the space-time product of physical memory aliocated to a task during execution. The algorithm is a function of one parameter R, the reactivation time-the average time from the occurrence of a page fault for a task to restarting execution of the task.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234514","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702808","Dynamic memory allocation;minimum space time product;optical virtual memory allocation;page replacement algorithms;virtual memory","Heuristic algorithms;Radio spectrum management;Memory management;Physics computing;Helium;Cost function;Laboratories;Instruments;Measurement standards;Loss measurement","","Dynamic memory allocation;minimum space time product;optical virtual memory allocation;page replacement algorithms;virtual memory","","5","","20","","","","","","IEEE","IEEE Journals & Magazines"
"An Empirical Study of Software Metrics","H. F. Li; W. K. Cheung","Department of Computer Science; NA","IEEE Transactions on Software Engineering","","1987","SE-13","6","697","708","Software metrics are computed for the purpose of evaluating certain characteristics of the software developed. A Fortran static source code analyzer, FORTRANAL, was developed to study 31 metrics, including a new hybrid metric introduced in this paper, and applied to a database of 255 programs, all of which were student assignments. Comparisons among these metrics are performed. Their cross-correlation confirms the internal consistency of some of these metrics which belong to the same class. To remedy the incompleteness of most of these metrics, the proposed metric incorporates context sensitivity to structural attributes extracted from a flow graph. It is also concluded that many volume metrics have similar performance while some control metrics surprisingly correlate well with typical volume metrics in the test samples used. A flexible class of hybrid metric can incorporate both volume and control attributes in assessing software complexity.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233475","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702275","Control complexity;cross correlation;empirical study;Halstead's software science;hybrid metrics;software metric","Software metrics;Software measurement;Volume measurement;Size measurement;Software maintenance;Costs;Size control;Databases;Flow graphs;Testing","","Control complexity;cross correlation;empirical study;Halstead's software science;hybrid metrics;software metric","","30","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Distributed Checkpointing for Globally Consistent States of Databases","Sang Hyuk Son; A. K. Agrawala","Department of Computer Science, University of Virginia, Charlottesville, VA 22903.; NA","IEEE Transactions on Software Engineering","","1989","15","10","1157","1167","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1989.559763","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=559763","","Checkpointing;Distributed databases;Transaction databases;Database systems;Costs;Computer science;Algorithm design and analysis;Robustness;Interference","","Availability;checkpoint;consistency;distributed database;noninterference;recovery;transaction","","14","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Making Pointers Safe in System Programming Languages","D. B. Lomet","IBM Thomas J. Watson Research Center","IEEE Transactions on Software Engineering","","1985","SE-11","1","87","96","System programming languages usually provide pointers so as to permit efficient and understandable programs to be written. Some higher level languages either avoid pointers altogether or greatly circumscribe pointers to guarantee safety, i.e., so that programs cannot gain access to storage in an inappropriate way. By combining the ideas of 1) pointer scope front Algol 68, 2) tombstones for invalidating dangling references, and 3) freezing which permits freeable objects to have scoped pointers, we solVe the problem of providing convenient and efficient pointers while simultaneously guaranteeing safety.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231846","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701901","Efficiency;pointers;programming languages;safety","Computer languages;Safety;Data structures;Arithmetic;Protection;Aggregates;Programming profession;Delay effects","","Efficiency;pointers;programming languages;safety","","1","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Dynamic Configuration for Distributed Systems","J. Kramer; J. Magee","Department of Computing, Imperial College of Science and Technology; NA","IEEE Transactions on Software Engineering","","1985","SE-11","4","424","436","Dynamic system configuration is the ability to modify and extend a system while it is running. The facility is a requirement in large distributed systems where it may not be possible or economic to stop the entire system to allow modification to part of its hardware or software. It is also useful during production of the system to aid incremental integration of component parts, and during operation to aid system evolution. The paper introduces a model of the configuration process which permits dynamic incremental modification and extension. Using this model we determine the properties required by languages and their execution environments to support dynamic configuration. CONIC, the distributed system which has been developed at Imperial College with the specific objective of supporting dynamic configuration, is described to illustrate the feasibility of the model.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232231","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702024","Configuration;configuration process;configuration specification;distributed systems;flexibility;reusability;system evolution","Hardware;Environmental economics;Application software;Software systems;Economic forecasting;Production systems;Embedded computing;Humans;Software testing;System testing","","Configuration;configuration process;configuration specification;distributed systems;flexibility;reusability;system evolution","","179","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Analysis and testing of programs with exception handling constructs","S. Sinha; M. J. Harrold","Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA; NA","IEEE Transactions on Software Engineering","","2000","26","9","849","871","Analysis techniques, such as control flow, data flow, and control dependence, are used for a variety of software engineering tasks, including structural and regression testing, dynamic execution profiling, static and dynamic slicing, and program understanding. To be applicable to programs in languages such as Java and C++, these analysis techniques must account for the effects of exception occurrences and exception handling constructs; failure to do so can cause the analysis techniques to compute incorrect results and, thus, limit the usefulness of the applications that use them. This paper discusses the effects of exception handling constructs on several analysis techniques. The paper presents techniques to construct representations for programs with explicit exception occurrences-exceptions that are raised explicitly through throw statements-and exception handling constructs. The paper presents algorithms that use these representations to perform the desired analyses. The paper also discusses several software engineering applications that use these analyses. Finally, the paper describes empirical results pertaining to the occurrence of exception handling constructs in Java programs and their effect on some analysis tasks.","0098-5589;1939-3520;2326-3881","","10.1109/32.877846","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=877846","","Java;Performance analysis;Information analysis;Software testing;Failure analysis;Software engineering;Cause effect analysis;Data analysis;Frequency;Computer Society","program testing;exception handling;software engineering;Java;C++ language;data flow analysis;program slicing;object-oriented programming","program testing;program analysis;exception handling constructs;Java;C++;control flow analysis;data flow analysis;control dependence analysis;throw statements;software engineering","","59","","51","","","","","","IEEE","IEEE Journals & Magazines"
"Factors Affecting Distributed System Security","D. M. Nessett","Lawrence Livermore National Laboratory, University of California","IEEE Transactions on Software Engineering","","1987","SE-13","2","233","248","Recent work examining distributed system security requirements. is critiqued. A notion of trust based on distributed system topology and distributed system node evaluation levels proposed in that work is shown to be deficient. The notion fails to make allowances for the distributed system physical security environment, security factors related to the management of distributed systems by more than one jurisdictive authority, and the interactions that can occur between nodes supporting different mandatory and discretionary security mechanisms.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233148","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702203","Computer communications security;computer security;distributed systems;distributed system security;heterogeneity","Communication system security;Computer security;Network topology;Proposals;National security;Application software;Computer architecture;Environmental management;Access control;Privacy","","Computer communications security;computer security;distributed systems;distributed system security;heterogeneity","","3","","46","","","","","","IEEE","IEEE Journals & Magazines"
"Functional refinement and nested objects for object-oriented design","P. Jalote","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA","IEEE Transactions on Software Engineering","","1989","15","3","264","270","An extended object-oriented design methodology is proposed which incorporates a top-down, stepwise refinement approach in a coherent fashion. The extended object-oriented design methodology also includes a phase of progressive object refinement to support the nesting of objects, which would allow entities in real life that are composed of subentities to be modeled. A design example is included, and experiences encountered using this methodology in a course are described.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21754","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21754","","Design methodology;Object oriented modeling;Software design;Software systems;Costs;Process design;Packaging;Computer science","Ada;object-oriented programming;software engineering","Ada;nested objects;object-oriented design;stepwise refinement;progressive object refinement;nesting","","26","","16","","","","","","IEEE","IEEE Journals & Magazines"
"ToolpackAn Experimental Software Development Environment Research Project","L. J. Osterweil","Department of Computer Science, University of Colorado","IEEE Transactions on Software Engineering","","1983","SE-9","6","673","685","This paper discusses the goals and methods of the Toolpack project and in this context discusses the architecture and design of the software system being produced as the focus of the project. Toolpack is presented as an experimental activity in which a large software tool environment is being created for the purpose of general distribution and then careful study and analysis. The paper begins by explaining the motivation for building integrated tool sets. It then proceeds to explain the basic requirements that an integrated system of tools must satisfy in order to be successful and to remain useful both in practice and as an experimental object. The paper then summarizes the tool capabilities that will be incorporated into the environment. It then goes on to present a careful description of the actual architecture of the Toolpack integrated tool system. Finally the Toolpack project experimental plan is presented, and future plans and directions are summarized.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.235432","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703114","Experimentation with prototypes;Fortran;portable software;programming environments;software tools;virtual file system","Programming;Software tools;Computer architecture;Software prototyping;Software systems;Algorithm design and analysis;Transaction databases;Software design;Buildings;Virtual prototyping","","Experimentation with prototypes;Fortran;portable software;programming environments;software tools;virtual file system","","29","","24","","","","","","IEEE","IEEE Journals & Magazines"
"An automated approach to information systems decomposition","D. Paulson; Y. Wand","Fac. of Manage., Lethbridge Univ., Alta., Canada; NA","IEEE Transactions on Software Engineering","","1992","18","3","174","189","A method for automating the process of system decomposition is described. The method is based on a formal specification scheme, formal definition of good decomposition, heuristic rules governing the search for good candidate decompositions, and a measure of complexity that allows ranking of the candidate decompositions. The decomposition method has been implemented as a set of experimental computerized systems analysis tools and applied to a standard problem for which other designs already exist. The results are encouraging, in that decompositions generated using other methodologies map easily into those suggested by the computerized tools. Additionally, the use of the method indicates that when more than one 'good' decomposition is suggested by the system, the specifications might have been incomplete. That is, the computerized tools can identify areas where more information should be sought by analysis.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.126767","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=126767","","Information systems;System analysis and design;Information analysis;Electric breakdown;Formal specifications;Position measurement;Modeling;Power system management;Business","computational complexity;formal specification;software tools;systems analysis","automated approach;information systems decomposition;formal specification scheme;formal definition;heuristic rules;complexity;experimental computerized systems analysis tools;standard problem","","34","","45","","","","","","IEEE","IEEE Journals & Magazines"
"An analysis of several software defect models","T. -. Yu; V. Y. Shen; H. E. Dunsmore","AT&T Bell Labs., Naperville, IL, USA; NA; NA","IEEE Transactions on Software Engineering","","1988","14","9","1261","1270","Results are presented of an analysis of several defect models using data collected from two large commercial projects. Traditional models typically use either program matrices (i.e. measurements from software products) or testing time or combinations of these as independent variables. The limitations of such models have been well-documented. The models considered use the number of defects detected in the earlier phases of the development process as the independent variable. This number can be used to predict the number of defects to be detected later, even in modified software products. A strong correlation between the number of earlier defects and that of later ones was found. Using this relationship, a mathematical model was derived which may be used to estimate the number of defects remaining in software. This defect model may also be used to guide software developers in evaluating the effectiveness of the software development and testing processes.<<ETX>></ETX>","0098-5589;1939-3520;2326-3881","","10.1109/32.6170","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6170","","Software testing;Mathematical model;Software measurement;Predictive models;Time measurement;Phase detection;Programming;Software metrics;Resource management;Microelectronics","programming theory;software reliability","software testing;software reliability;software defect models;mathematical model;software development","","37","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Inconsistency handling in multiperspective specifications","A. C. W. Finkelstein; D. Gabbay; A. Hunter; J. Kramer; B. Nuseibeh","Dept. of Comput., London Univ., UK; Dept. of Comput., London Univ., UK; Dept. of Comput., London Univ., UK; Dept. of Comput., London Univ., UK; Dept. of Comput., London Univ., UK","IEEE Transactions on Software Engineering","","1994","20","8","569","578","The development of most large and complex systems necessarily involves many people-each with their own perspectives on the system defined by their knowledge, responsibilities, and commitments. To address this we have advocated distributed development of specifications from multiple perspectives. However, this leads to problems of identifying and handling inconsistencies between such perspectives. Maintaining absolute consistency is not always possible. Often this is not even desirable since this can unnecessarily constrain the development process, and can lead to the loss of important information. Indeed since the real-world forces us to work with inconsistencies, we should formalize some of the usually informal or extra-logical ways of responding to them. This is not necessarily done by eradicating inconsistencies but rather by supplying logical rules specifying how we should act on them. To achieve this, we combine two lines of existing research: the ViewPoints framework for perspective development, interaction and organization, and a logic-based approach to inconsistency handling. This paper presents our technique for inconsistency handling in the ViewPoints framework by using simple examples.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.310667","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=310667","","Data models;Logic;Diffusion tensor imaging;Databases","formal specification;data integrity;temporal logic;distributed processing","multiperspective specifications;inconsistency handling;complex systems;distributed development;specifications;development;logical rules;ViewPoints;multiple perspectives;specification;process modeling;first order predicate logic;temporal logic","","133","","40","","","","","","IEEE","IEEE Journals & Magazines"
"A lingua franca for concurrent logic programming","H. Taylor","Dept. of Comput. Sci., Heriot-Watt Univ., Edinburgh, UK","IEEE Transactions on Software Engineering","","1992","18","3","225","236","Two of the more important concurrent logic programming languages with nonflat guards are GHC and Parlog. They balance the requirements of having clean semantics and providing good control facilities rather differently, and their respective merits are compared and contrasted. Since concurrent logic programming would benefit from both, but neither language is able to express all the programs expressible in the other language, a lingua franca of these languages is defined and justified. A method is given for translating GHC and Parlog to and from it. The method preserves the arities and execution conditions of each clause. It enables a lingua franca implementation to support both languages transparently, and to provide a simple concurrent logic programming language suitable for programming in its own right.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.126771","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=126771","","Logic programming;Parallel processing;Parallel programming;Bismuth;Computer science","language translation;logic programming;parallel languages;parallel programming","concurrent logic programming languages;nonflat guards;GHC;Parlog;clean semantics;control facilities;lingua franca;execution conditions","","","","21","","","","","","IEEE","IEEE Journals & Magazines"
"An empirical study of representation methods for reusable software components","W. B. Frakes; T. P. Pole","Dept. of Comput. Sci., Virginia Polytech. Inst. & State Univ., Falls Church, VA, USA; NA","IEEE Transactions on Software Engineering","","1994","20","8","617","630","An empirical study of methods for representing reusable software components is described. Thirty-five subjects searched for reusable components in a database of UNIX tools using four different representation methods: attribute-value, enumerated, faceted, and keyword. The study used Proteus, a reuse library system that supports multiple representation methods. Searching effectiveness was measured with recall, precision, and overlap. Search time for the four methods was also compared. Subjects rated the methods in terms of preference and helpfulness in understanding components. Some principles for constructing reuse libraries. Based on the results of this study, are discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.310671","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=310671","","Software reusability;Software libraries;Databases;Application software;Software quality;Computer languages;Information retrieval;Indexing;Keyword search;Buildings","software reusability;knowledge representation;subroutines","representation methods;reusable software components;UNIX tools;attribute-value;keyword;Proteus;reuse library system;multiple representation;software reuse;experimentation;empirical methods;information storage and retrieval;reuse libraries;component indexing;keyword searching;faceted classification;enumerated classification;component understanding;database","","61","","30","","","","","","IEEE","IEEE Journals & Magazines"
"An Optimizing Pascal Compiler","R. N. Faiman; A. A. Koretesoja","Manufacturing Data Systems, Inc.; NA","IEEE Transactions on Software Engineering","","1980","SE-6","6","512","519","The architecture of a production optimizing compiler for Pascal is described, and the structure of the optimizer is detailed. The compiler performs both interprocedural and global optimizations, in addition to optimization of basic blocks. We have found that a high-level structured language such as Pascal provides unique opportunities for effective optimization, but that standard optimization techniques must be extended to take advantage of these opportunities. These issues are considered in our discussion of the optimization algorithms we have developed and the sequence in which we apply them.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230800","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702776","Code optimization;compilers;Pascal;programming languages;structured programming","Optimizing compilers;Production;Program processors;Computer languages;Manufacturing;Data systems;Performance analysis;Programming profession","","Code optimization;compilers;Pascal;programming languages;structured programming","","3","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Performance Measures for Evaluating Algorithms for SIMD Machines","L. J. Siegel; H. J. Siegel; P. H. Swain","School of Electrical Engineering, Purdue University; NA; NA","IEEE Transactions on Software Engineering","","1982","SE-8","4","319","331","This paper examines measures for evaluating the performance of algorithms for single instruction streammultiple data stream (SIMD) machines. The SIMD mode of parallelism involves using a large number of processors synchronized together. All processors execute the same instruction at the same time; however, each processor operates on a different data item. The complexity of parallel algorithms is, in general, a function of the machine size (number of processors), problem size, and type of interconnection network used to provide communications among the processors. Measures which quantify the effect of changing the machine-size/problem-size/network-type relationships are therefore needed. A number of such measures are presented and are applied to an example SIMD algorithm from the image processing problem domain. The measures discussed and compared include execution time, speed, parallel efficiency, overhead ratio, processor utilization, redundancy, cost effectiveness, speed-up of the parallel algorithm over the corresponding serial algorithm, and an additive measure called ""sprice"" which assigns a weighted value to computations and processors.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235426","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702955","Algorithm evaluation;parallel processing;performance measures;reconfigurable systems;SIMD machines","Parallel processing;Multiprocessor interconnection networks;Image processing;Application software;Parallel algorithms;Velocity measurement;Time measurement;Speech processing;Gold;Costs","","Algorithm evaluation;parallel processing;performance measures;reconfigurable systems;SIMD machines","","9","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Using Predicate/Transition-Nets to Model and Analyze Distributed Database Systems","K. Voss","Institut fuer Informationssystemforschung, Gesellschaft fuer Mathematik und Datenverarbeitung","IEEE Transactions on Software Engineering","","1980","SE-6","6","539","544","In this paper, a net model for decentralized control of user accesses to a distributed database is proposed. It is developed in detail for the restricted case of updating distributed copies of a single database. Predicate/transition-nets, a first-order extension of Petri nets, are shown to provide suitable means for concise representation of complex decentralized systems and for their rigorous formal analysis. It will be demonstrated in the present paper how these net models can be constructed and interpreted in a quite natural manner and how they can be analyzed by linear algebraic methods. By this, it will be shown that the modeled distributed database system is deadlock-free and guarantees a consistent database as well as a fair and effective service to the users.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234502","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702780","Concurrency;consistency;database management;deadlock-free;decentralized control;distributed database;distributed processing;Petri nets;predicate/transition-nets;synchronization","Data analysis;Database systems;Distributed databases;Petri nets;Distributed control;System recovery;Synchronization;Distributed processing;Distributed information systems;Centralized control","","Concurrency;consistency;database management;deadlock-free;decentralized control;distributed database;distributed processing;Petri nets;predicate/transition-nets;synchronization","","20","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Components of Typical Undergraduate Software Engineering Courses: Results from a Survey","L. M. Leventhal; B. T. Mynatt","Department of Computer Science, Bowling Green State University; NA","IEEE Transactions on Software Engineering","","1987","SE-13","11","1193","1198","A survey of undergraduate software engineering courses was conducted. The survey covered the issues of course level, course content, course organization, project characteristics, and department demographics. The descriptive statistics show that the typical course focuses on the software development life cycle and includes a project intended for actual use. The project is carried out by teams of students, with student leaders. A factor analysis disclosed that three different sorts of courses are currently being offered. The most predominant course is the Later-Life Cycle course, which focuses on the later stages of the software life cycle. Detailed design, coding, testing, and maintenance receive in-depth coverage in this style of course, and the student's grades are heavily dependent upon the project. The Early-Life-Cycle course emphasizes requirements analysis, specification, and system design. Written reports are an important component of this course, and the project is again a large portion of the students' grades. The third style of course is the Theoretical-Issues course. Software metrics, project management, and legal and ethical issues are covered. The students are upper level, and they use journal articles as a source of materials. The issues of suitable textbooks and sources of materials and training for teaching user-interface design surfaced as problem areas.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232869","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702167","Projects;software engineering;software life cycle;survey;undergraduate courses","Software engineering;Demography;Statistics;Programming;Testing;System analysis and design;Software metrics;Project management;Law;Legal factors","","Projects;software engineering;software life cycle;survey;undergraduate courses","","7","","17","","","","","","IEEE","IEEE Journals & Magazines"
"A Scheme of Parallel Processing for MIMD Systems","S. Jajodia; J. Liu; P. A. Ng","Department of Computer Science, University of Missouri; NA; NA","IEEE Transactions on Software Engineering","","1983","SE-9","4","436","445","This paper presents a recognition procedure for parallel tasks in the user program written in a conventional programming language. To establish our program model, it describes the parallelism of the program in tenns of a process flow graph in which the relationships among processes are of predecessors and successors. And finally it presents a parallel processing scheme which realizes automatically the recognition of parallel tasks and schedules these tasks for parallel execution.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.234780","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703078","Parallel execution;parallelism;precedence relation;process flow graph;quasi-parallelism;synchronization;task scheduler","Parallel processing;Flow graphs;Computer languages;Processor scheduling;Computer science;Computer architecture;Instruction sets;Software design;Multiprocessor interconnection networks;System recovery","","Parallel execution;parallelism;precedence relation;process flow graph;quasi-parallelism;synchronization;task scheduler","","1","","14","","","","","","IEEE","IEEE Journals & Magazines"
"An efficient digital search algorithm by using a double-array structure","J. -. Aoe","Dept. of Inf. Sci. & Syst. Eng., Tokusima Univ., Japan","IEEE Transactions on Software Engineering","","1989","15","9","1066","1077","An efficient digital search algorithm that is based on an internal array structure called a double array, which combines the fast access of a matrix form with the compactness of a list form, is presented. Each arc of a digital search tree, called a DS-tree, can be computed from the double array in 0(1) time; that is to say, the worst-case time complexity for retrieving a key becomes 0(k) for the length k of that key. The double array is modified to make the size compact while maintaining fast access, and algorithms for retrieval, insertion, and deletion are presented. If the size of the double array is n+cm, where n is the number of nodes of the DS-tree, m is the number of input symbols, and c is a constant particular to each double array, then it is theoretically proved that the worst-case times of deletion and insertion are proportional to cm and cm/sup 2/, respectively, and are independent of n. Experimental results of building the double array incrementally for various sets of keys show that c has an extremely small value, ranging from 0.17 to 1.13.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.31365","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=31365","","Information retrieval;Data structures;Dictionaries;Filters;Natural language processing;Vocabulary;Frequency;Information science;Systems engineering and theory;Binary trees","computational complexity;data structures;search problems;trees (mathematics)","digital search algorithm;double-array structure;internal array structure;matrix form;list form;arc;digital search tree;DS-tree;worst-case time complexity;key;retrieval;insertion;deletion;nodes;input symbols;constant","","76","","32","","","","","","IEEE","IEEE Journals & Magazines"
"Program partition and logic program analysis","Jia Liang Han","Dept. of Math. & Comput., Southern Queensland Univ., Toowoomba, Qld., Australia","IEEE Transactions on Software Engineering","","1995","21","12","959","968","A program partition scheme for stratified programs introduced by Apt et al. (1988) is used to study efficient computation of logic programs. We consider three types of program partitions and their corresponding graph representations: 1) the natural partition, 2) stratified partitions, and 3) the reduced partition. The natural (program) partition consists of definitions of relations, each definition being a subprogram. Subprograms of a program partition may consist of several relations. A partition graph is introduced for a program partition, each node of which corresponds to a subprogram. The partition graph for a stratified partition is a directed acyclic graph (DAG). A stratified partition decomposes a program into modules. The stratified partition with the maximum number of modules is the reduced partition. The cost to achieve a reduced partition is linear in the program size, using well known graph algorithms. We introduce the modular interpretations, which are equivalent in semantics to the standard interpretation. The modular interpretations offer encapsulation and may reduce the computation cost for some modules significantly. The modular approach can play an important role in query optimization, efficient termination, programming design, and software engineering. We classify query types and answer types then discuss query optimization for some query types. Many efficient query processing strategies are applicable to restricted subclasses of programs. The program partition method allows us to select the most efficient strategy for each module. For example, if a module is a uniformly bounded recursion, then the module can be terminated efficiently. If a module defines the transitive closure, then efficient program transformations may be applied to this module.","0098-5589;1939-3520;2326-3881","","10.1109/32.489072","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=489072","","Logic programming;Query processing;Software maintenance;Costs;Partitioning algorithms;Software engineering;Computational efficiency;Writing;Relational databases;Automatic programming","logic programming;programming theory;directed graphs;query processing;relational databases;database theory;computational linguistics;program verification;divide and conquer methods","logic program analysis;program partition scheme;stratified programs;logic program computation;graph representations;natural partition;stratified partitions;reduced partition;relation definitions;subprogram;partition graph;directed acyclic graph;modules;graph algorithms;semantics;modular interpretations;encapsulation;computation cost;query optimization;efficient termination;programming design;software engineering","","3","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Semantics of EqL","B. Jayaraman","Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA","IEEE Transactions on Software Engineering","","1988","14","4","472","480","The formal semantics of a novel language, called EqL, are presented for first-order functional and Horn logic programming. An EqL program is a set of conditional pattern-directed rules, where the conditions are expressed as a conjunction of equations. The programming paradigm provided by this language may be called equational programming. The declarative semantics of equations is given in terms of their complete set of solutions, and the operational semantics for solving equations is an extension of reduction, called object refinement. The correctness of the operational semantics is established through the soundness and completeness theorems. Examples are given to illustrate the language and its semantics.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4670","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4670","","Equations;Logic programming;Functional programming;Acoustical engineering;Application software;Programming profession;Computer science;Modems","formal languages;formal logic;high level languages;logic programming","functional logic;Horn logic;formal semantics;EqL;logic programming;conditional pattern-directed rules;programming paradigm;equational programming;declarative semantics;object refinement","","2","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Automated analysis of concurrent systems with the constrained expression toolset","G. S. Avrunin; U. A. Buy; J. C. Corbett; L. K. Dillon; J. C. Wileden","Massachusetts, Univ., Amherst, MA, USA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1991","17","11","1204","1222","The constrained expression approach to analysis of concurrent software systems can be used with a variety of design and programming languages and does not require a complete enumeration of the set of reachable states of the concurrent system. The construction of a toolset automating the main constrained expression analysis techniques and the results of experiments with that toolset are reported. The toolset is capable of carrying out completely automated analyses of a variety of concurrent systems, starting from source code in an Ada-like design language and producing system traces displaying the properties represented bv the analysts queries. The strengths and weaknesses of the toolset and the approach are assessed on both theoretical and empirical grounds.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.106975","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=106975","","Software systems;Lifting equipment;Handicapped aids;Computer languages;Performance analysis;Frequency;Navigation;Process control;Operating systems;Error correction codes","parallel programming;software tools","concurrent systems;constrained expression toolset;programming languages;reachable states;expression analysis techniques;source code;Ada-like design language;system traces","","43","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Distribution Design of Logical Database Schemas","S. Ceri; S. Navathe; G. Wiederhold","Departimento di Elettronica, Politecnico di Milano; NA; NA","IEEE Transactions on Software Engineering","","1983","SE-9","4","487","504","The optimal distribution of a database schema over a number of sites in a distributed network is considered. The database is modeled in terms of objects (relations or record sets) and links (predefined joins or CODASYL sets). The design is driven by user-supplied information about data distribution. The inputs required by the optimization model are: 1) cardinality and size information about objects and links, 2) a set of candidate horizontal partitions of relations into fragments and the allocations of the fragments, and 3) the specification of all important transactions, their frequencies, and their sites of origin.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.234957","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703082","Database;database design;distributed database;partitioning","Distributed databases;Transaction databases;Design methodology;Network topology;Radio spectrum management;Functional programming;Integer linear programming;Cost function;Indexes","","Database;database design;distributed database;partitioning","","55","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Mechanical verification and automatic implementation of communication protocols","T. P. Blumer; D. P. Sidhu","Research and Development Division, SDCA Burroughs Company, Paoli, PA 19301; Protocol Development Corporation, 1330 Beacon Street, Brookline, MA 02146; Research and Development Division, SDCA Burroughs Company, Paoli, PA 19301; Department of Computer Science, Iowa State University, Ames, IA 50011","IEEE Transactions on Software Engineering","","1986","SE-12","8","827","843","An automated technique for protocol development is discussed along with its application to the specification, verification, and semiautomatic implementation of an authentication protocol for computer networks. An overview is given of the specification language, implementation method, and software tools used with this technique. The authentication protocol is described, along with an example of its operation. The reachability analysis technique for the verification of some protocol properties is discussed, and protocol verification software that uses this technique is described. The results of mechanical verification of some properties of this protocol are presented with a partial implementation generated automatically from the protocol specification.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312985","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312985","Authentication;automated development tools;communication protocols;encryption;formal description technique;formal modeling;key distribution protocols;protocol implementation;protocol specification;protocol verification;state transition","Protocols;Automata;Encryption;Authentication;Formal specifications;Software tools;Reachability analysis","automatic programming;computer communications software;program verification;protocols;software tools;specification languages","automatic implementation;communication protocols;protocol development;authentication protocol;computer networks;specification language;software tools;reachability analysis;protocol verification;mechanical verification;protocol specification","","23","","","","","","","","IEEE","IEEE Journals & Magazines"
"A Symbol Table Abstraction to Implement Languages with Explicit Scope Control","R. P. Cook; T. J. Leblanc","Department of Computer Sciences, University of Wisconsin; NA","IEEE Transactions on Software Engineering","","1983","SE-9","1","8","12","We are concerned with languages in which the programmer has explicit control over the referencing environment of a name. Several modern programming languages, including Ada, Euclid, Mesa, and Modula, implement these control capabilities. This paper describes a simple technique which uses the traditional concepts of a hashed symbol table and lexical level to solve many of the symbol table implemen-tation problems associated with explicit scope control. The primary ad-vantage of this technique is that a single symbol table abstraction can be used to simply and efficiently solve most problems in scope control.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236164","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703006","Lexical level;scope control;symbol table","Computer languages;Programming profession;Automatic control","","Lexical level;scope control;symbol table","","","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Specifying transaction-based information systems with regular expressions","F. Lustman","Dept. d'Inf. et de Recherche Oper., Montreal Univ., Que., Canada","IEEE Transactions on Software Engineering","","1994","20","3","207","217","The work is about the formal specification of transaction-based, interactive information systems. A transaction is a task that the user can execute independently, and the system can be defined as a partially ordered set of transactions. The general framework is the transformational paradigm, based on the classical Waterfall development model (W.W. Royce, 1970). The stages are systems analysis, software specification, design, and implementation. The systems analysis and software specification stages are covered. An informal, transaction-oriented method for systems analysis is proposed. The resulting system specification involves two parts: a high-level specification of each transaction and a formal specification of the system's control flow, i.e., the order of execution of the transactions. The system's control flow is expressed in a formal language describing concurrent regular expressions built on transaction names. At the software specification stage, some operational requirements, such as connect/disconnect transactions and the application of the all-or-nothing principle, are added to the system specification. Then a serial product automaton (SPA) is used to transform the concurrent expression into a single regular expression. This result is proven to be consistent with the system specification.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.268922","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=268922","","Information systems;Formal specifications;Automata;Software systems;Control systems;Very large scale integration;Protocols;Software design;Formal languages;Application software","formal specification;transaction processing;systems analysis;information systems","transaction-based information systems;regular expressions;formal specification;interactive information systems;transformational paradigm;classical Waterfall development model;systems analysis;software specification;transaction-oriented method;high-level specification;formal language;concurrent regular expressions;operational requirements;connect/disconnect transactions;all-or-nothing principle;serial product automaton;SPA;concurrent expression","","4","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Programming Language Constructs for Screen Definition","L. A. Rowe; K. A. Shoens","Department of Electrical Engineering and Computer Science, University of California; NA","IEEE Transactions on Software Engineering","","1983","SE-9","1","31","39","This paper describes a screen-oriented I/O facility, designed as a part of Rigel, a high-level database programming language. The novel features of the I/O facility, called Screen Rigel, include the use of formatting techniques to lay out text and data on the screen. Applications written in Screen Rigel can directly access the database using the database constructs already in Rigel. In addition, Screen Rigel has access to the data dictionary so the programmer can use the data descriptions in the database instead of respecifying them. These features make Screen Rigel programs simple to write and highly data and terminal independent.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236168","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703010","Application development;database systems;programming languages;screen I/O","Computer languages;Cathode ray tubes;Programming profession;Spatial databases;Dictionaries;Database systems;High level languages;Two dimensional displays;Protection","","Application development;database systems;programming languages;screen I/O","","14","","12","","","","","","IEEE","IEEE Journals & Magazines"
"A practical approach to programming with assertions","D. S. Rosenblum","AT&T Bell Labs., Murray Hill, NJ, USA","IEEE Transactions on Software Engineering","","1995","21","1","19","31","Embedded assertions have been recognized as a potentially powerful tool for automatic runtime detection of software faults during debugging, testing, maintenance and even production versions of software systems. Yet despite the richness of the notations and the maturity of the techniques and tools that have been developed for programming with assertions, assertions are a development tool that has seen little widespread use in practice. The main reasons seem to be that (1) previous assertion processing tools did not integrate easily with existing programming environments, and (2) it is not well understood what kinds of assertions are most effective at detecting software faults. This paper describes experience using an assertion processing tool that was built to address the concerns of ease-of-use and effectiveness. The tool is called APP, an Annotation PreProcessor for C programs developed in UNIX-based development environments, APP has been used in the development of a variety of software systems over the past five years. Based-on this experience, the paper presents a classification of the assertions that were most effective at detecting faults. While the assertions that are described guard against many common kinds of faults and errors, the very commonness of such faults demonstrates the need for an explicit, high-level, automatically checkable specification of required behavior. It is hoped that the classification presented in this paper will prove to be a useful first step in developing a method of programming with assertions.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.341844","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=341844","","Fault detection;Software tools;Software systems;Runtime;Embedded software;Software debugging;Software maintenance;Automatic testing;Software testing;System testing","formal specification;software tools;software reliability;program debugging","embedded assertions;automatic runtime detection;software faults;debugging;testing;maintenance;production versions;notations;development tool;assertion processing tools;programming environments;assertion processing tool;APP;Annotation PreProcessor;C programs;UNIX-based development environments;automatically checkable specification","","119","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Some critical remarks on a hierarchy of fault-detecting abilities of test methods [and reply]","R. A. DeMillo; A. P. Mathur; W. E. Wong; P. G. Frankl; E. J. Weyuker","Dipartimento di Elettronica e Inf., Padova Univ., Italy; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1995","21","10","858","863","In a recent article by P.G. Frankl and E.J. Weyuker (see ibid., vol.19, no.3, p.962-75, 1993), results are reported that appear to establish a hierarchy of software test methods based on their respective abilities to detect faults. The methods used by Frankl and Weyuker to obtain this hierarchy constitute a new and important addition to their arsenal of tools. These tools were developed specifically to establish simple, useful comparisons of test data generation methods. This is the latest step in an ambitious test method classification program undertaken by the Frankl and Weyuker and their collaborators. The article discusses the method and goes on to present a reply to the critique.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.469455","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=469455","","Genetic mutations;Software testing;Fault detection;Software tools;Marine vehicles","program testing;failure analysis","fault detecting abilities;fault-detecting abilities;test methods;software test methods;test data generation methods;test method classification program","","5","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Introducing object orientation into large and complex systems","H. -. Deubler; M. Koestler","Siemens Nixdorf Informationssyst. AG, Munich, Germany; Siemens Nixdorf Informationssyst. AG, Munich, Germany","IEEE Transactions on Software Engineering","","1994","20","11","840","848","The paper investigates the applicability of the object-oriented technique to large and complex systems as exemplified by the operating system BS2000 which has been under constant development for a number of years. The proposed system architecture ensures the harmonious coexistence of procedural and object-oriented parts of the system. New domains, which are implemented using the object-oriented paradigm, can be smoothly embedded in the existing system. The parallel usage of different implementation languages is rendered economically viable. In our framework some representative parts of the system were redesigned and implemented in a prototype. The extensibility of the design was checked by including further parts into this scheme. The results are encouraging, so that the object-oriented technique will be used in the further development process. The proposed technique can also be applied to systems with a different structure, even a monolithic one.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.368124","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=368124","","Operating systems;Software systems;Prototypes;Environmental economics;Computer architecture;Application software;Investments;Programming;Trademarks","object-oriented programming;operating systems (computers);structured programming","object orientation;complex systems;object-oriented technique;operating system BS2000;system architecture;object-oriented parts;object-oriented paradigm;parallel usage;implementation languages;monolithic structure;large software systems;systems architecture;OOP","","6","","41","","","","","","IEEE","IEEE Journals & Magazines"
"Integrated Performance Models for Distributed Processing in Computer Communication Networks","A. Thomasian; P. F. Bay","IBM Thomas J. Watson Research Center; NA","IEEE Transactions on Software Engineering","","1985","SE-11","10","1203","1216","This paper deals with the analysis of large-scale closed queueing network (QN) models which are used for the performance analysis of computer communication networks (CCN's). The computer systems are interconnected by a wide-area network. Users accessing local/remote computers are affected by the contention (queueing delays) at the computer systems and the communication subnet. The computational cost of analyzing such models increases exponentially with the number of user classes (chains), even when the QN is tractable (product-form). In fact, the submodels of the integrated model are generally not product-form, e.g., due to blocking at computer systems (multiprogramming level constraints) and in the communication subnet (window flow control constraints). Two approximate solution methods are proposed in this paper to analyze the integrated QN model. Both methods use decomposition and iterative techniques to exploit the structure of the QN model such that computational cost is proportional to the number of chains. The accuracy of the solution methods is validated against each other and simulation. The model is used to study the effect that channel capacity assignments, window sizes for congestion control, and routing have on system performance.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231868","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701936","Approximate solution;decomposition and iteration;distributed processing;large scale queueing network model;memory constrained multiprogrammed computer system;window flow control","Distributed processing;Computer networks;Distributed computing;Communication networks;Performance analysis;Computational efficiency;Computational modeling;Large-scale systems;Queueing analysis;Delay","","Approximate solution;decomposition and iteration;distributed processing;large scale queueing network model;memory constrained multiprogrammed computer system;window flow control","","2","","40","","","","","","IEEE","IEEE Journals & Magazines"
"The probability of load balancing success in a homogeneous network","C. G. Rommen","Dept. of Math. & Comput. Sci., Eastern Connecticut State Univ., Willimantic, CT, USA","IEEE Transactions on Software Engineering","","1991","17","9","922","933","The problem of load balancing in distributed systems composed of several homogeneous sites connected by a subnet is examined. The author determines a general formula for the probability that any one site in the system is underloaded while some other site in the system is overloaded. This probability can be used to define the likelihood of load balancing success in a distributed operating system. This probability gives insight into the utilization of the system and is an aid in determining a measure of effectiveness of the system. From this formula one can determine this probability when the workload is composed of processes typical to distributed systems. The influence of variants in the load balancing algorithm on this probability is demonstrated.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.92912","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=92912","","Load management;Intelligent networks;Local area networks;Distributed processing;Computer networks;Concurrent computing;Tail;Operating systems;Queueing analysis;Processor scheduling","computer networks;distributed processing;operating systems (computers);probability","homogeneous sites;subnet;general formula;distributed operating system;load balancing algorithm","","23","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Major Issues in Software Engineering Project Management","R. H. Thayer; A. B. Pyster; R. C. Wood","Department of Computer Science, California State University; NA; NA","IEEE Transactions on Software Engineering","","1981","SE-7","4","333","342","Software engineering project management (SEPM) has been the focus of much recent attention because of the enormous penalties incurred during software development and maintenance resulting from poor management. To date there has been no comprehensive study performed to determine the most significant problems of SEPM, their relative importance, or the research directions necessary to solve them. We conducted a major survey of individuals from all areas of the computer field to determine the general consensus on SEPM problems. Twenty hypothesized problems were submitted to several hundred individuals for their opinions. The 294 respondents validated most of these propositions. None of the propositions was rejected by the respondents as unimportant. A number of research directions were indicated by the respondents which, if followed, the respondents believed would lead to solutions for these problems.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234533","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702851","Project management;software engineering;survey;university curriculum","Software engineering;Project management;Software development management;Engineering management;Programming profession;Financial management;Resource management;Technology management;Logistics;Computer science","","Project management;software engineering;survey;university curriculum","","6","","35","","","","","","IEEE","IEEE Journals & Magazines"
"Refinement Methodology for Ada","V. Rajlich","Department of Computer Science, Wayne State University","IEEE Transactions on Software Engineering","","1987","SE-13","4","472","478","This paper presents Refinement Methodology (RM) for the design of Ada programs. The methodology combines stepwise refinement and the information hiding principle. The steps of the methodology are explained and illustrated by an example. A part of the methodology is a collection of rules by which procedures acquire parameters (called first and second rules for parameters).","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233183","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702238","Ada;information hiding;life-cycle;methodologies;program design language;programming-in-the-large;programming language constructs;software design","Packaging;Computer languages;Design methodology;Software design;Testing;Programming profession;Data structures;Process design;Computer science;Trademarks","","Ada;information hiding;life-cycle;methodologies;program design language;programming-in-the-large;programming language constructs;software design","","2","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Program Slicing","M. Weiser","Department of Computer Science, University of Maryland, College Park, MD 20742.","IEEE Transactions on Software Engineering","","1984","SE-10","4","352","357","Program slicing is a method for automatically decomposing programs by analyzing their data flow and control flow. Starting from a subset of a program's behavior, slicing reduces that program to a minimal form which still produces that behavior. The reduced program, called a ``slice,'' is an independent program guaranteed to represent faithfully the original program within the domain of the specified subset of behavior. Some properties of slices are presented. In particular, finding statement-minimal slices is in general unsolvable, but using data flow analysis is sufficient to find approximate slices. Potential applications include automatic slicing tools for debuggng and parallel processing of slices.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010248","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010248","Data flow analysis;debugging;human factors;parallel processing;program maintenance;program metrics;slicing;software tools","Trajectory;Data mining;Probability density function;Merging;Program processors;Debugging;Algorithms","","","","1224","","25","","","","","","IEEE","IEEE Journals & Magazines"
"An Application of Statistical Databases in Manufacturing Testing","S. P. Ghosh","Department of Computer Science, IBM Re-search Laboratory","IEEE Transactions on Software Engineering","","1985","SE-11","7","591","598","This paper discusses some applications of statistical and database techniques for integrating tests in manufacturing products. It shows how statistical databases can be used for automatically controlling a manufacturing process in real time. Some new statistical methods of manufacturing testing, e. g., test-compression, testing-by-sampling, testing-by-factorial-design, are discussed. All these techniques are possible because of the availability of a statistical database.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232503","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702063","Manufacturing process;manufacturing testing;statis-tical database","Databases;Manufacturing processes;System testing;Pulp manufacturing;Hardware;Automatic control;Process control;Statistical analysis;Computer aided manufacturing;Costs","","Manufacturing process;manufacturing testing;statis-tical database","","4","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Program concept recognition and transformation","W. Kozaczynski; J. Ning; A. Engberts","Center for Stratetic Technol. Res., Chicago, IL, USA; Center for Stratetic Technol. Res., Chicago, IL, USA; Center for Stratetic Technol. Res., Chicago, IL, USA","IEEE Transactions on Software Engineering","","1992","18","12","1065","1075","The automated recognition of abstract high-level conceptual information or concepts, which can greatly aid the understanding of programs and therefore support many software maintenance and reengineering activities, is considered. An approach to automated concept recognition and its application to maintenance-related program transformations are described. A unique characteristic of this approach is that transformations of code can be expressed as transformations of abstract concepts. This significantly elevates the level of transformation specifications.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.184761","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=184761","","Software maintenance;Application software","programming theory;software maintenance","program understanding;software reengineering;software maintenance;automated concept recognition;program transformations","","76","","46","","","","","","IEEE","IEEE Journals & Magazines"
"Research on Structured Programming: An Empiricist's Evaluation","I. Vessey; R. Weber","Department of Commerce, University of Queensland, St. Lucia, Qld. 4067, Australia.; Department of Commerce, University of Queensland, St. Lucia, Qld. 4067, Australia.","IEEE Transactions on Software Engineering","","1984","SE-10","4","397","407","In spite of the widespread acceptance by academics and practitioners of structured programming precepts, relatively few formal empirical studies have been conducted to obtain evidence that either supports or refutes the theory. This paper reviews the empirical studies that have been undertaken and critiques them from the viewpoints of the soundness of their methodology and their ability to contribute to scientific understanding. In general, the evidence supporting programming precepts is weak. A framework for an ongoing research program is outlined.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010252","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010252","Design;experimentation;human factors;languages;performance","Software quality;Logic programming;Mathematical programming;Psychology;Iris;Human factors;Testing;Mathematics;US Department of Commerce;Australia","","","","28","","48","","","","","","IEEE","IEEE Journals & Magazines"
"Managing standards compliance","W. Emmerich; A. Finkelstein; C. Montangero; S. Antonelli; S. Armitage; R. Stevens","Dept. of Comput. Sci., Univ. Coll. London, UK; NA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1999","25","6","836","851","Software engineering standards determine practices that ""compliant"" software processes shall follow. Standards generally define practices in terms of constraints that must hold for documents. The document types identified by standards include typical development products, such as user requirements, and also process-oriented documents, such as progress reviews and management reports. The degree of standards compliance can be established by checking these documents against the constraints. It is neither practical nor desirable to enforce compliance at all points in the development process. Thus, compliance must be managed rather than imposed. We outline a model of standards and compliance and illustrate it with some examples. We give a brief account of the notations and method we have developed to support the use of the model and describe a support environment we have constructed. The principal contributions of our work are: the identification of the issue of standards compliance; the development of a model of standards and support for compliance management; the development of a formal model of product state with associated notation; a powerful policy scheme that triggers checks; and a flexible and scalable compliance management view.","0098-5589;1939-3520;2326-3881","","10.1109/32.824413","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=824413","","Standards development;Software standards;Energy management;Environmental management;Software development management;Engineering management;Computer Society;Software engineering;Systems engineering and theory;Certification","software standards;software development management","standards compliance management;software engineering standards;document types;user requirements;process-oriented documents;formal model","","36","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Flexible software development for multiple computer systems","K. Schwan; A. K. Jones","Department of Computer and Information Science, Ohio State University, Columbus, OH 43210; Tartan Laboratories, Pittsburgh, PA 15213","IEEE Transactions on Software Engineering","","1986","SE-12","3","385","401","The authors develop a model of concurrent software and the associated programming tools that jointly permit flexible software development for experimental programming on the Cm* multiprocessor. The model's implementation in the TASK and Bliss-11 programming languages is described using a sample concurrent program.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312881","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312881","Flexible program construction;languages;program blueprints;programming environments","Force;Servers;Software;Computers;Programming;Hardware;Educational institutions","parallel processing;software engineering","software engineering;multiple computer systems;concurrent software;programming tools;flexible software development;experimental programming;Cm* multiprocessor;TASK;Bliss-11 programming languages","","4","","","","","","","","IEEE","IEEE Journals & Magazines"
"Using transformations in specification-based prototyping","V. Berzins; Luqi; A. Yehudai","Dept. of Comput. Sci., US Naval Postgraduate Sch., Monterey, CA, USA; Dept. of Comput. Sci., US Naval Postgraduate Sch., Monterey, CA, USA; Dept. of Comput. Sci., US Naval Postgraduate Sch., Monterey, CA, USA","IEEE Transactions on Software Engineering","","1993","19","5","436","452","The authors explore the use of software transformations for software evolution. Meaning-preserving program transformations have been widely used for program development from a fixed initial specification. They consider a wider class of transformations to support development in which the specification evolves, rather than being fixed in advance. A new and general classification of transformations based on their effect on system interfaces, externally observable behavior, and abstraction level of a system description is presented. This classification is used to rearrange chronological derivation sequences containing meaning-changing transformations into lattices containing only meaning-preserving transformations. A process model for software evolution that utilizes prototyping techniques is described. Ways in which this class of transformations can be used to support such a process are considered. A set of examples are presented to illustrate the ideas. Software tool support and directions for future research are discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.232011","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=232011","","Prototypes;Software prototyping;Software tools;Computer science;Lattices;Roads;Software libraries;System software;Software systems;Lead","formal specification;software prototyping","software tool support;specification-based prototyping;software transformations;software evolution;system interfaces;externally observable behavior;abstraction level;system description;chronological derivation sequences;process model","","19","","40","","","","","","IEEE","IEEE Journals & Magazines"
"A modified priority based probe algorithm for distributed deadlock detection and resolution","A. N. Choudhary; W. H. Kohler; J. A. Stankovic; D. Towsley","Dept. of Electr. & Comput. Eng., Massachusetts Univ., Amherst, MA, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1989","15","1","10","17","A modified, priority-based probe algorithm for deadlock detection and resolution in distributed database system is presented. Various examples are used to show that the original priority-based algorithm, presented by M.K. Sinha and N. Natarajan (1985), either fails to detect deadlocks or reports deadlocks that do not exist in many situations. A modified algorithm that eliminates these problems is proposed. The algorithm has been tested through simulation and appears to be errorfree. The performance of the modified algorithm is briefly discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21721","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21721","","Probes;System recovery;Database systems;Testing;Distributed control;Distributed databases;Information science;Computational modeling;Performance evaluation;Access protocols","distributed databases;system recovery","deadlock resolution;modified priority based probe algorithm;distributed deadlock detection;distributed database system","","53","","9","","","","","","IEEE","IEEE Journals & Magazines"
"The effect of data abstraction on loop programming techniques","J. M. Bishop","Dept. of Electron. & Comput. Sci., Southampton Univ., UK","IEEE Transactions on Software Engineering","","1990","16","4","389","402","It is shown how loop algorithms can be encompassed in an iterator and then activated for any data type for which a generator can be defined. It takes the iterator-generator idea a step further than previous work in that it permits variations of the iterators to be defined dynamically through the use of selectors and actors, without loss of efficiency or clarity. It is further shown that selectors can be employed in the definition of a truly generic sorting routine. Guidelines for the decomposition of a system into generic data types, abstract data types, iterators, generators, and the programs that exercise them are given, and several complete programs show the implementation of the techniques in Ada.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.54291","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=54291","","Proposals;Packaging;Computer science","data structures;software engineering","data abstraction;loop programming techniques;loop algorithms;iterator;generic sorting routine;generic data types;abstract data types;generators;Ada","","12","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Software dependability in the Tandem GUARDIAN system","Inhwan Lee; R. K. Iyer","Center for Reliable & High Performance Comput., Illinois Univ., Urbana, IL, USA; NA","IEEE Transactions on Software Engineering","","1995","21","5","455","467","Based on extensive field failure data for Tandem's GUARDIAN operating system, the paper discusses evaluation of the dependability of operational software. Software faults considered are major defects that result in processor failures and invoke backup processes to take over. The paper categorizes the underlying causes of software failures and evaluates the effectiveness of the process pair technique in tolerating software faults. A model to describe the impact of software faults on the reliability of an overall system is proposed. The model is used to evaluate the significance of key factors that determine software dependability and to identify areas for improvement. An analysis of the data shows that about 77% of processor failures that are initially considered due to software are confirmed as software problems. The analysis shows that the use of process pairs to provide checkpointing and restart (originally intended for tolerating hardware faults) allows the system to tolerate about 75% of reported software faults that result in processor failures. The loose coupling between processors, which results in the backup execution (the processor state and the sequence of events) being different from the original execution, is a major reason for the measured software fault tolerance. Over two-thirds (72%) of measured software failures are recurrences of previously reported faults. Modeling, based on the data, shows that, in addition to reducing the number of software faults, software dependability can be enhanced by reducing the recurrence rate.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.387474","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=387474","","Software measurement;Operating systems;Fault tolerant systems;Hardware;Failure analysis;Fault tolerance;Data analysis;Checkpointing;Software reliability;Programming","software fault tolerance;operating systems (computers);system recovery;back-up procedures;software performance evaluation","Tandem GUARDIAN operating system;field failure data;software dependability;operational software;software faults;major defects;processor failures;backup processes;software failures;process pair technique;software fault tolerance;reliability;improvement;checkpointing;restart;loose processor coupling;previously reported fault recurrence;modeling","","84","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Compiling real-time specifications into extended automata","X. Nicollin; J. Sifakis; S. Yovine","Lab. de Genie Inf., Inst. IMAG, Grenoble, France; Lab. de Genie Inf., Inst. IMAG, Grenoble, France; Lab. de Genie Inf., Inst. IMAG, Grenoble, France","IEEE Transactions on Software Engineering","","1992","18","9","794","804","A method for the implementation and analysis of real-time systems, based on the compilation of specification extended automata is proposed. The method is illustrated for a simple specification language that can be viewed as the extension of a language for the description of systems of communicating processes, by adding timeout and watchdog constructs. The main result is that such a language can be compiled into timed automata, which are extended automata with timers. Timers are special state variables that can be set to zero by transitions, and whose values measure the time elapsed since their last reset. Timed automata do not make any assumption about the nature of time and adopt an event-driven execution mode. Their complexity does not depend on the values of the parameters of timeouts and watchdogs used in specifications. These features allow the application on timed automata of efficient code generation and analysis techniques. In particular, it is shown how symbolic model-checking of real-time properties can be directly applied to this model.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.159837","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=159837","","Automata;Real time systems;Computer languages;Clocks;Synchronous generators;Timing;Specification languages;Time measurement;Formal verification;Logic","automata theory;communicating sequential processes;formal specification;program compilers;real-time systems;specification languages","real-time specifications;real-time systems;extended automata;simple specification language;communicating processes;timeout;watchdog constructs;timed automata;state variables;event-driven execution mode;complexity;efficient code generation;symbolic model-checking;real-time properties","","61","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Databases and Units of Measure","N. H. Gehani","Bell Laboratories","IEEE Transactions on Software Engineering","","1982","SE-8","6","605","611","A serious impediment to the integrated use of databases across international boundaries, scientific disciplines and application areas is the use of different units of measure, e.g., miles or kilometers for distance, dollars or rupees for currency, and Btu or kWh for energy. Units of measure are not specified in the data definition language but associated by convention with values in the database. Inconsistent usage of values with different units cannot be checked atuomatically. Retrieval, storage, and manipulation of data values in units other than those associated with the values requires that the user perform the appropriate conversions. This process is inconvenient and error prone. These problems are illustrated by an international database example.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.236021","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702994","Databases;data types;dimensional analysis;programming languages;relations;units of measure","Measurement units;Relational databases;Proposals;Impedance;Area measurement;Energy measurement;Information retrieval;Computer languages;Weight measurement;Power engineering and energy","","Databases;data types;dimensional analysis;programming languages;relations;units of measure","","3","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Constructing submodule specifications and network protocols","D. P. Sidhu; J. Aristizabal","Dept. Comput. Sci., Maryland Univ., Baltimore, MD, USA; NA","IEEE Transactions on Software Engineering","","1988","14","11","1565","1577","Applications of an automated tool for module specification (ATMS) that finds the specification for a submodule of a system are presented. Given the specification of a system, together with the specification for n-1 submodules, the ATMS constructs the specification for the nth addition submodule such that the interaction among the n submodules is equivalent to the specification of the system. The implementation of the technique is based on an approach proposed by P. Merlin and G.B. Bochmann (1983). The specification of a system and its submodules consists of all possible execution sequences of their individual operations. The ATMS uses finite-state machine concepts to represent the specifications and interactions of the system and its submodules. The specification found by the ATMS for a missing module of a system is the most general one, if one exists. Application of the ATMS in the area of communication protocols is discussed. A manual process to find the specification for a missing module using the Merlin-Bochmann technique is time-consuming and prone to errors. The automated tool presented proves a reliable method for constructing such a module.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9045","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9045","","Protocols;System recovery;Modular construction;Manuals;Computer science;Process control;Data communication","finite automata;formal specification;protocols;software tools","formal specification;submodule specifications;network protocols;automated tool;module specification;execution sequences;finite-state machine;communication protocols","","8","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Copying and swapping: influences on the design of reusable software components","D. E. Harms; B. W. Weide","Dept. of Math. & Comput. Sci., Muskingum Coll., New Concord, OH, USA; NA","IEEE Transactions on Software Engineering","","1991","17","5","424","435","The authors argue that a simple alternative to copying as a data movement primitive-swapping (exchanging) the values of two variables-has potentially significant advantages in the context of the design of generic reusable software components. Specifically, the authors claim that generic module designs based on a swapping style are superior to designs based on copying, both in terms of execution-time efficiency and with respect to the likelihood of correctness of client programs and module implementations. Furthermore, designs based on swapping are more reusable than traditional designs. Specific arguments and examples to support these positions are presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.90445","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=90445","","Software design;Software reusability;Embedded software;Computer science;Computer languages;Formal specifications;Object oriented programming;Mathematics;Information science","data structures;software reusability","copying;data movement primitive;generic reusable software components;generic module designs;swapping style","","32","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Ginger2: an environment for computer-aided empirical software engineering","K. Torii; K. Matsumoto; K. Nakakoji; Y. Takada; S. Takada; K. Shima","Graduate Sch. of Inf. Sci., Nara Inst. of Sci. & Technol., Japan; NA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1999","25","4","474","492","Empirical software engineering can be viewed as a series of actions to obtain knowledge and a better understanding about some aspects of software development, given a set of problem statements in the form of issues, questions or hypotheses. Experience has made us aware of the criticality of integrating the various types of data that are collected and analyzed as well as the criticality of integrating the various types of activities that take place, such as experiment design and the experiment itself. This has led us to develop a Computer-Aided Empirical Software Engineering (CAESE) framework to support the empirical software engineering lifecycle. The paper first presents the CAESE framework that consists of three elements: (1) a process model for the ""lifecycle"" of empirical software engineering studies, including needs analysis, experiment design, actual experimentation, and analyzing and packaging results; (2) a model that helps empirical software engineers decide how to look at the ""world"" to be studied in a coherent manner; (3) an architecture, based on which CAESE environments can be built, consisting of tool sets for each phase of the process model, a process management mechanism, and the two types of integration mechanism that are vital for handling multiple types of data: data integration and control integration. Next, the paper describes the Ginger2 environment as an instantiation of our framework. It concludes with reports on case studies using Ginger2, which dealt with a variety of empirical data types including mouse and keystrokes, eye traces, 3D movement, skin resistance level, and videotaped data.","0098-5589;1939-3520;2326-3881","","10.1109/32.799942","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=799942","","Software engineering;Programming;Software packages;Packaging;Software tools;Data engineering;Design engineering;Computer architecture;Environmental management;Engineering management","computer aided software engineering;data structures;software architecture","Ginger2 environment;computer aided empirical software engineering;experiment design;empirical software engineering lifecycle;CAESE framework;process model;needs analysis;packaging results;CAESE environments;tool sets;process management mechanism;integration mechanism;multiple data types;data integration;control integration;case studies;empirical data types;keystrokes;eye traces;three dimensional movement;skin resistance level;videotaped data","","19","","32","","","","","","IEEE","IEEE Journals & Magazines"
"Separate Compilation and Partial Specification in Pascal","A. Celentano; P. D. Vigna; C. Ghezzi; D. Mandrioli","Istituto di Elettrotecnica ed Elettronica, Politecnico di Milano; NA; NA; NA","IEEE Transactions on Software Engineering","","1980","SE-6","4","320","328","Separate compilation is a useful tool in the development, debugging, testing, and integration of modular systems.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230483","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702739","Abstract data types;information hiding;linkers;program libraries;separate compilation;type checkdng;type generators","Proposals;Computer languages;Debugging;System testing;Assembly;Protection;Joining processes;Software libraries;Production;Software quality","","Abstract data types;information hiding;linkers;program libraries;separate compilation;type checkdng;type generators","","4","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Code Optimization Considerations in List Processing Systems","H. Samet","Department of Computer Science, University of Maryland","IEEE Transactions on Software Engineering","","1982","SE-8","2","107","112","Code optimization is characterized as a time versus space tradeoff. Space optimizations are further decomposed into static and dynamic categories. Using this characterization, the optimization requirements of a list processing language such as LISP are examined. Scrutiny of the structure of programs written in such a language reveals that traditional code optimization techniques have little benefit. Instead, a collection of low-level time and static space optimizations is seen to lead to a potential decrease in space and execution time. Dynamic space optimization is also examined in the context of reducing the frequency of occurrence of garbage collection. Alternatively, some language extensions are proposed which reduce the amount of storage that needs to be allocated, and hence may result in a decrease in the frequency of garbage collection.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.234953","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702918","Code optimization;compilers;garbage collection;LISP;list processing;programming language design","Frequency;Computer languages;Space exploration;Radio spectrum management;Design optimization;Optimizing compilers;Program processors;Process design;Artificial intelligence;Knowledge based systems","","Code optimization;compilers;garbage collection;LISP;list processing;programming language design","","","","26","","","","","","IEEE","IEEE Journals & Magazines"
"A case-study in timed refinement: a mine pump","B. P. Mahony; I. J. Hayes","Dept. of Comput. Sci., Queensland Univ., Qld., Australia; Dept. of Comput. Sci., Queensland Univ., Qld., Australia","IEEE Transactions on Software Engineering","","1992","18","9","817","826","A specification and top-level refinement of a simple mine pump control system, as well as a proof of correctness of the refinement, are presented as an example of the application of a formal method for the development of time-based systems. The overall approach makes use of a refinement calculus for timed systems, similar to the refinement calculi for sequential programs. The specification makes use of topologically continuous functions of time to describe both analog and discrete properties of both the system and its refinements. The basic building block of specifications is a specification statement that gives a clear separation between the specification of the assumptions that the system may make about the environment in which it is to be placed, and the effect the system is guaranteed to achieve if placed in such an environment. The top-level refinement of the system is developed by application of refinement laws that allow design decisions to be made, local state to be introduced, and the decomposition of systems into pipelined and/or parallel processes.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.159841","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=159841","","Calculus;Control systems;Computer science;Water;Terminology;Topology;Interconnected systems;Australia Council;Protection;Monitoring","computerised monitoring;formal specification;mining;pumps;theorem proving","top-level refinement;simple mine pump control system;proof of correctness;formal method;time-based systems;refinement calculus;timed systems;sequential programs;topologically continuous functions;discrete properties;basic building block;specification statement;refinement laws;design decisions;pipelined;parallel processes","","39","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Identifying modules via concept analysis","M. Siff; T. Reps","Dept. of Math., Sarah Lawrence Coll., Bronxville, NY, USA; NA","IEEE Transactions on Software Engineering","","1999","25","6","749","768","Describes a general technique for identifying modules in legacy code. The method is based on concept analysis - a branch of lattice theory that can be used to identify similarities among a set of objects based on their attributes. We discuss how concept analysis can identify potential modules using both ""positive"" and ""negative"" information. We present an algorithmic framework to construct a lattice of concepts from a program, where each concept represents a potential module. We define the notion of a concept partition, present an algorithm for discovering all concept partitions of a given concept lattice, and prove the algorithm to be correct.","0098-5589;1939-3520;2326-3881","","10.1109/32.824377","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=824377","","Lattices;Partitioning algorithms;Information analysis;Reverse engineering;Software systems;Computer languages;Software tools;Prototypes;Computer science;Queueing analysis","subroutines;semantic networks;reverse engineering;software engineering;pattern matching","module identification;concept analysis;legacy code;lattice theory;similarity identification;object attributes;positive information;negative information;algorithmic framework;concept lattice;concept partitions;algorithm correctness;modularization;software migration;software restructuring;reverse engineering;design recovery","","63","","27","","","","","","IEEE","IEEE Journals & Magazines"
"A Fast Transaction-Oriented Logging Scheme for Undo Ro overy","A. Reuter","Department of Computer Sciences, Technical University of Darmstadt","IEEE Transactions on Software Engineering","","1980","SE-6","4","348","356","A special UNDO log algorithm combining the advantages of update in place strategies with the shadow page concept is introduced. It is to support applications demanding high rates of possibly long update transactions as well as fast UNDO recovery. By doubling the disk space for the database, UNDO loggng can be performed with a minimum of additional I/O operations. Thus, we gain a performance comparable to systems without any UNDO loggg. Since in this algorithm one logical slot consists of two physical blocks, the name TWIST (twin slot) algorithm is proposed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234491","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702743","Databases;logging;side fies;transaction oriented recovery","Database systems;Transaction databases;Performance gain;System recovery;Application software;Information systems;Costs;Partitioning algorithms;Indexes","","Databases;logging;side fies;transaction oriented recovery","","12","","12","","","","","","IEEE","IEEE Journals & Magazines"
"A Functional Approach to Module Verification","K. S. Shankar","Federal Systems Division, IBM Corporation","IEEE Transactions on Software Engineering","","1982","SE-8","2","147","160","The purpose of this paper is to develop a method for designing and verifying data abstractions using the functional approach. Before doing so, the existing techniques for designing and verifying procedure and data abstractions will be surveyed briefly. These techniques will then be modified and extended to verify data abstractions. By using the concept of a mathematical function, one can model the behavior of a procedure abstraction and give a more uniform and clearer meaning to the stepwise refinement and verification of procedure abstractions. The concept of a state machine is then used as a basis to specify data abstractions. Using state machine specification, a technique for expressing the design of a data abstraction is then given. A method is then developed to verify the design of a data abstraction with respect to its specifications.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235093","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702922","Abstract model specification;data abstraction;function;procedure abstraction;refinement;state machine;verification","Data structures;Design methodology;Mathematical model;Software engineering","","Abstract model specification;data abstraction;function;procedure abstraction;refinement;state machine;verification","","9","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Location Independent Remote Execution in NEST","R. Agrawal; A. K. Ezzat","AT&T Bell Laboratories; NA","IEEE Transactions on Software Engineering","","1987","SE-13","8","905","912","We consider a computing environment consisting of a network of autonomous, yet cooperating personal computer workstations and shared servers. Computing cycles in such an environment can be shared by creating a pool of compute servers in the network that may be used by the workstations to supplement their computing needs. Some processors may be permanently designated to be the compute servers. In addition, through an advertisement mechanism, any workstation may make itself temporarily available for a specific duration of time to be used as a compute server. In this paper, we present the design and implementation of a scheme for augmenting the UNIX operating system with the location independent remote execution capability. This capability allows processes to be offloaded to the compute servers and preserves the execution environment of these processes as if they were still executing locally at the originating machine. Our model provides execution location independence of processes by preserving the process view of the file system, parent-child relationships, process groups, and process signaling across machine boundaries in a transparent way. We also present our scheme that allows processors to advertise themselves as available to some or all nodes in the network and withdraw as a compute server in a distributed manner. The scheme is robust in presence of node failures.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233509","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702309","Computer network;distributed computing environment;distributed operating system;processor sharing;remote execution;UNIX system","Workstations;Network servers;Computer networks;Operating systems;File systems;Distributed computing;Intelligent networks;Microcomputers;Signal processing;Robustness","","Computer network;distributed computing environment;distributed operating system;processor sharing;remote execution;UNIX system","","13","","40","","","","","","IEEE","IEEE Journals & Magazines"
"A software size model","J. Verner; G. Tate","Sch. of Inf. Syst., New South Wales Univ., Kensington, NSW, Australia; NA","IEEE Transactions on Software Engineering","","1992","18","4","265","278","A bottom-up approach to software size estimation is described. It first identifies factors affecting software size, thus obtaining size explanation equations, and then seeks suitable predictors based on those explanation factors which can be used for size estimation. The approach, or model, is bottom-up in that it sizes individual software components or modules first, and then obtains subsystem and system sizes by summing component sizes. Since components may have different purposes and characteristics, the model allows for the partitioning of system components into several different types, each component type having different size explanation and estimation equations. The partitioning is not fixed, but depends on the particular software development technology. The model is applied to several different software systems, including both business applications and systems programs.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.129216","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=129216","","Costs;Programming;Business;Differential equations;Software systems;Application software;Software metrics;Project management;Software testing;Uncertainty","project engineering;software engineering;software metrics","software metrics;bottom-up approach;software size estimation;software development technology;business applications;systems programs","","56","","41","","","","","","IEEE","IEEE Journals & Magazines"
"Graph directed locking","M. H. Eich","Dept. of Comput. Sci., Southern Methodist Univ., Dallas, TX, USA","IEEE Transactions on Software Engineering","","1988","14","2","133","140","A non-two-phase database concurrency control technique is introduced. The technique is deadlock-free, places no restrictions on the structure of the data, never requires data to be reread, never forces a transaction to be rolled back in order to achieve serializability, applies a type of lock conversion, and allows items to be released to subsequent transactions as soon as possible. The method introduced, database flow graph locking (FGL), uses a directed acyclic graph to direct the migration of locks between transactions. Unlike many previous non-two-phase methods, the database need not be structured in any specific fashion. The effect of these changes is that, with the same serializable schedule, FGL obtains a higher degree of concurrency than two-phase locking (2PL). Overhead requirements for database flow graph locking are comparable to those for two-phase locking, with 2PL being better in low conflict situations and FGL better in high conflict.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4633","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4633","","Protocols;Transaction databases;System recovery;Concurrency control;Concurrent computing;Tree graphs;Force control;Flow graphs;Control systems;Database systems","database theory;directed graphs;distributed databases;system recovery","distributed databases;database concurrency control;deadlock-free;lock conversion;database flow graph locking;directed acyclic graph;non-two-phase methods","","6","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Distrbution and Abstract Types in Emerald","A. Black; N. Hutchinson; E. Jul; H. Levy; L. Carter","Department of Computer Science, University of Washington; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","1","65","76","Emerald is an object-based language for programming distributed subsystems and applications. Its novel features include 1) a single object model that is used both for programming in the small and in the large, 2) support for abstract types, and 3) an explicit notion of object location and mobility. This paper outlines the goals of Em-erald, relates Emerald to previous work, and describes its type system and distribution support. We are currently constructing a prototype implementation of Emerald.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232836","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702134","Abstract data types;distributed operating system;distributed programming;object-oriented programming;process migration;type checking","Computer languages;Programming profession;Object oriented modeling;Prototypes;Operating systems;Object oriented programming;Local area networks;Workstations;Art;Packaging","","Abstract data types;distributed operating system;distributed programming;object-oriented programming;process migration;type checking","","130","","37","","","","","","IEEE","IEEE Journals & Magazines"
"The Crystal Multicomputer: Design and Implementation Experience","D. J. De Witt; R. Finkel; M. Solomon","Department of Computer Sciences, University of WisconsinMadison; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","8","953","966","This paper presents an overview of the hardware and software components of the Crystal multicomputer project. The goal of the Crystal project is to design and implement a vehicle that serves a variety of research projects involving distributed computation. Crystal can be used simultaneously by multiple research projects by partitioning the available processors according to the requirements of each project. Users can employ the Crystal multicomputer in several ways. Projects such as operating systems and database machines that need direct control of processor resources (clock, memory management, communication devices) can be implemented using a reliable communication service (the ""nugget"" that resides on each node processor. Projects that prefer a higher-level interface can be implemented using the Charlotte distributed operating system. Finally, users interested in Crystal principally as a cycle server can run UNIX jobs on node machines using the ""remote"" unix service. Development, debugging, and execution of projects can take place remotely under the control of any of several UNIX hosts. Acquiring a partition of machines, resetting each machine, and then loading an application onto each machine is performed by invoking a UNIX-resident program (the ""nuggetmaster""). Communication with node machines in a partition is facilitated by a virtual terminal and window mechanism. Crystal is fully operational and has been used to support a variety of research projects. To illustrate the flexibility provided by the Crystal environment, four of these projects are described.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233513","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702313","Communication protocols;database machines;multicomputers;multiprocessors;operating systems;parallel computing","Operating systems;Communication system control;Hardware;Vehicles;Distributed computing;Database machines;Process control;Control systems;Clocks;Memory management","","Communication protocols;database machines;multicomputers;multiprocessors;operating systems;parallel computing","","7","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Process-translatable Petri nets for the rapid prototyping of process control systems","G. Bruno; G. Marchetto","Dipartimento di Automatica e Informatica, Politecnico di Torino, Corso Duca degli Abruzzi 24, 10129 Torino, Italy; Dipartimento di Automatica e Informatica, Politecnico di Torino, Corso Duca degli Abruzzi 24, 10129 Torino, Italy","IEEE Transactions on Software Engineering","","1986","SE-12","2","346","357","A methodology for the rapid prototyping of process control systems which is based on an original extension to classical Petri nets is presented. The proposed nets, called PROT nets, provide a suitable framework to support the following activities: building an operational specification model; evaluation, simulation, and validation of the model; and automatic translation into program structures. PROT nets are shown to be translatable into Ada program structures concerning concurrent processes and their synchronizations. The authors illustrate this translation in detail using, as a working example, the problem of tool handling in a flexible manufacturing system.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312948","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312948","Ada;Petri nets;process control systems;rapid prototyping;requirements specification;simulation;synchronizations","Petri nets;Prototypes;Process control;Fires;Software;Computational modeling;Firing","flexible manufacturing systems;graph theory;process computer control;software engineering","Petri nets;rapid prototyping;process control systems;PROT nets;specification model;evaluation;simulation;validation;program structures;Ada program structures;concurrent processes;tool handling;flexible manufacturing system","","66","","","","","","","","IEEE","IEEE Journals & Magazines"
"Estimating capacity for sharing in a privately owned workstation environment","M. W. Mutka","Dept. of Comput. Sci., Michigan State Univ., East Lansing, MI, USA","IEEE Transactions on Software Engineering","","1992","18","4","319","328","The author analyzes workstation patterns in order to understand opportunities for exploiting idle capacity. This study is based on traces of users workstation activity in a university environment. It identifies two areas where enhancements can be made. One area is the ability of a manager of the shared capacity of a workstation cluster to schedule jobs with deadline constraints. This opportunity is the result of the ability to make good predictions of the time-varying amount of capacity that is available for sharing. A prediction strategy is developed that is shown to have only a small amount of error. For the second area of enhancement, it is shown that it is feasible to allocate partitions of workstations for specific periods. This aids those users who on occasion need exclusive access to several machines. The author examines the profile of periods during which exclusive access to partitions can be given, the rate that owners preempt users of partitions, and the distribution of interpreemption intervals.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.129220","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=129220","","Workstations;Resource management;Quality of service;Environmental management;Pattern analysis;Operating systems;Power system modeling;Interference;Quality management","DP management;multi-access systems;resource allocation;scheduling","capacity management;partition allocation;job scheduling;workstation patterns;idle capacity;university environment;shared capacity;deadline constraints","","34","","20","","","","","","IEEE","IEEE Journals & Magazines"
"A packaging system for heterogeneous execution environments","J. R. Callahan; J. M. Purtilo","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA","IEEE Transactions on Software Engineering","","1991","17","6","626","635","A packaging system that allows diverse software components to be easily interconnected within heterogeneous programming environments is described. Interface software and stubs are generated for programmers automatically once the programmers express their application's geometry in a few simple rules and module interconnection language attributes. By generating custom interface code for each application, based on analysis and extraction of interfacing requirements, the system is able to produce executables whose run-time performance is comparable to manually integrated applications. The system is implemented within the Unix environment.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.87286","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=87286","","Packaging;Application software;Computer architecture;Software packages;Software tools;LAN interconnection;Costs;Environmental economics;Prototypes;Programming profession","automatic programming;configuration management;programming environments;user interfaces","packaging system;heterogeneous execution environments;diverse software components;heterogeneous programming environments;geometry;module interconnection language attributes;custom interface code;interfacing requirements;Unix environment","","32","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Memory access dependencies in shared-memory multiprocessors","M. Dubois; C. Scheurich","Dept. of Electr. Eng.-Syst., Univ. of Southern California, Los Angeles, CA, USA; Dept. of Electr. Eng.-Syst., Univ. of Southern California, Los Angeles, CA, USA","IEEE Transactions on Software Engineering","","1990","16","6","660","673","The presence of high-performance mechanisms in shared-memory multiprocessors such as private caches, the extensive pipelining of memory access, and combining networks may render a logical concurrency model complex to implement or inefficient. The problem of implementing a given logical concurrency model in such a multiprocessor is addressed. Two concurrency models are considered, and simple rules are introduced to verify that a multiprocessor architecture adheres to the models. The rules are applied to several examples of multiprocessor architectures.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.55094","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=55094","","Concurrent computing;Hardware;Multiprocessing systems;Program processors;Pipeline processing;Coherence;Parallel algorithms;Computer architecture;Microprocessors;Supercomputers","multiprocessing systems;multiprogramming;storage allocation","memory access dependencies;shared-memory multiprocessors;private caches;pipelining;logical concurrency model;rules;multiprocessor architectures","","44","","39","","","","","","IEEE","IEEE Journals & Magazines"
"Operational Requirements Accommodation in Distributed System Design","S. W. Smoliar","Schlumberger-Doll Research","IEEE Transactions on Software Engineering","","1981","SE-7","6","531","537","Operational requirements are qualities which influence a software system's entire development cycle. The investigation reported here concentrated on three of the most important operational requirements: reliability via fault tolerance, growth, and availability. Accommodation of these requirements is based on an approach to functional decomposition involving representation in terms of potentiafly independent processors, called virtual machines. Functional requirements may be accommodated through hierarchical decomposition of virtual machines, while performance requirements may be associated with individual virtual machines. Virtual machines may then be mapped to a representation of a confilguration of physical resources, so that performance requirements may be reconciled with available performance characteristics.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.231122","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702886","Distributed processing;fault tolerance;modularity;real-time systems;reliability;requirements engineering","Virtual machining;Real time systems;Fault tolerance;Availability;Computer network reliability;Computer network management;Resource management;Control systems;Hardware;Embedded system","","Distributed processing;fault tolerance;modularity;real-time systems;reliability;requirements engineering","","2","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Some properties of timed token medium access protocols","A. Valenzano; P. Montuschi; L. Ciminiera","Politecnico di Torino, Italy; Politecnico di Torino, Italy; NA","IEEE Transactions on Software Engineering","","1990","16","8","858","869","Timed-token protocols are used to handle, on the same local area network, both real-time and non-real-time traffic. The authors analyze this type of protocol, giving worst-case values for the throughput of non-real-time traffic and the average token rotation time. Results are obtained for synchronous traffic generated according to a generic periodic pattern under heavy conditions for non-real-time traffic and express not only theoretical lower bounds but values deriving from the analysis of some real networks. A model which addresses the asynchronous overrun problem is presented. The influence of introducing multiple priority classes for non-real-time traffic on the total throughput of this type of message is shown. It is also shown that the differences between the values obtained under worst-case assumptions are close to those obtained under best-case assumptions; the method may therefore be used to provide important guidelines in properly tuning timed-token protocol parameters for each specific network installation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.57628","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=57628","","Access protocols;Telecommunication traffic;Traffic control;Throughput;Application software;FDDI;Bandwidth;Testing;Pattern analysis;Guidelines","electronic messaging;protocols;token networks","real-time traffic;timed token medium access protocols;local area network;non-real-time traffic;worst-case values;throughput;average token rotation time;synchronous traffic;generic periodic pattern;heavy conditions;theoretical lower bounds;real networks;asynchronous overrun problem;multiple priority classes;worst-case assumptions;best-case assumptions;timed-token protocol parameters;network installation","","20","","19","","","","","","IEEE","IEEE Journals & Magazines"
"A formal model for module interconnection languages","M. D. Rice; S. B. Seidman","Dept. of Math., Wesleyan Univ., Middletown, CT, USA; NA","IEEE Transactions on Software Engineering","","1994","20","1","88","101","A model is proposed that formalizes the design of hierarchical module structures. The model is specified by a collection of Z schema type definitions that is invariant across all applications. A particular application is described by specifying the values of generic parameters and adding application-specific declarations and constraints to the schema definitions. As applications, the definitions in the model are used to describe the Conic configuration language and the STILE graphical design and development environment.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.263757","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=263757","","LAN interconnection;Libraries;Specification languages;Application software;Software systems;Assembly systems;Software reusability;Modular construction;Formal verification;Mathematics","formal specification;specification languages;systems analysis;programming environments","module interconnection languages;formal model;hierarchical module structure design;Z schema type definitions;generic parameters;application-specific declarations;constraints;Conic;configuration language;STILE;graphical design environment;development environment;specification language","","19","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Mathematical principles for a first course in software engineering","H. D. Mills; V. R. Basili; J. D. Gannon; R. G. Hamlet","Dept. of Comput. & Inf. Sci., Florida Univ., Gainesville, FL, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1989","15","5","550","559","An introductory computer science course is developed, much as calculus is a basic course for mathematics and the physical sciences, concerned primarily with theoretical foundations and methodology rather than apprenticeship through applications. In this work, the principles taught in the course are described and an example illustrating them is given.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24704","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24704","","Software engineering;Calculus;Milling machines;Computer science;Mathematics;Engineering management;Application software;Computer languages;Art;Knowledge engineering","computer science education;educational courses;mathematics computing;software engineering","mathematical principles;first course;software engineering;introductory computer science course","","5","","14","","","","","","IEEE","IEEE Journals & Magazines"
"A Shortest Tree Algorithm for Optimal Assignments Across Space and Time in a Distributed Processor System","S. H. Bokhari","Department of Electrical Engineering, University of Engineering and Technology","IEEE Transactions on Software Engineering","","1981","SE-7","6","583","589","The problem of optimally assigning the modules of a program over the processors of an inhomogeneous distributed processor system is analyzed. The objective is to assign modules, wherever possible, to the processors on which they execute most rapidly while taking into account the overhead of interprocessor communication. Factors contributing to the cost of an assignment are 1) the amount of computation required by each module, 2) the amount of data transmitted between each pair of modules, 3) the speed of each processor, and 4) the speed of the communication link between each pair of processors.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.226469","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702890","Computer networks;distributed processing;precedence trees;program assignment;scheduling;shortest trees","Dynamic programming;Processor scheduling;Distributed processing;NASA;Heuristic algorithms;Scheduling algorithm;Cost function;Delay;Computer applications;Space technology","","Computer networks;distributed processing;precedence trees;program assignment;scheduling;shortest trees","","59","","10","","","","","","IEEE","IEEE Journals & Magazines"
"A Scheme to Enforce Data Dependence on Large Multiprocessor Systems","Chuan-Qi Zhu; Pen-Chung Yew","Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign; NA","IEEE Transactions on Software Engineering","","1987","SE-13","6","726","739","Enforcement of data dependence in parallel algorithms requires certain synchronization primitives. For simple data dependence, synchronization primitives like Full/Empty bit in HEP machine [5] can be very effective. However, if data dependence cannot be determined at compile time, or if very complicated, more efficient synchronization schemes and algorithms are needed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233477","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702277","Data dependence;multiprocessor;program vectorization;synchronization","Multiprocessing systems;Testing;Program processors;Parallel algorithms;Hardware;Research and development","","Data dependence;multiprocessor;program vectorization;synchronization","","55","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Numerical analysis of superposed GSPNs","P. Kemper","Fachbereich Inf., Dortmund Univ., Germany","IEEE Transactions on Software Engineering","","1996","22","9","615","628","The numerical analysis of various modeling formalisms profits from a structured representation for the generator matrix Q of the underlying continuous-time Markov chain, where Q is described by a sum of tensor (Kronecker) products of much smaller matrices. In this paper, we describe such a representation for the class of superposed generalized stochastic Petri nets (GSPNs), which is less restrictive than in previous work. Furthermore a new iterative analysis algorithm is proposed. It pays special attention to a memory-efficient representation of iteration vectors as well as to a memory-efficient structured representation of Q in consequence the new algorithm is able to solve models which have state spaces with several million states, where other exact numerical methods become impracticable on a common workstation.","0098-5589;1939-3520;2326-3881","","10.1109/32.541433","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=541433","","Numerical analysis;Stochastic processes;Petri nets;Tensile stress;Algorithm design and analysis;State-space methods;Sparse matrices;Iterative algorithms;Steady-state;Algebra","Petri nets;iterative methods;matrix algebra;vectors;tensors;stochastic systems;state-space methods;reachability analysis;Markov processes","numerical analysis;modeling formalisms;memory-efficient structured representation;generator matrix;continuous-time Markov chain;tensor products;Kronecker products;superposed generalized stochastic Petri nets;iterative analysis algorithm;state spaces;iteration vectors;steady-state analysis;decomposition;reachability analysis","","59","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Estimating the Speedup in Parallel Parsing","J. Cohen; S. Kolodner","Department of Computer Science, Brandeis University; NA","IEEE Transactions on Software Engineering","","1985","SE-11","1","114","124","A model for the operation of bottom-up parallel parsing using asynchronous processors is proposed. The model is based on an extension of shift-reduce parsers which are able to merge the information they keep on their stacks. The main objective of the paper is to provide estimates of the speedup attainable when using the proposed model. Three programs were written to measure the speedup. The first is a classical simulator which keeps track of the times spent performing the shift, reduce, and merge operations for each processor. The second is a program which generates ""typical"" strings in a language and simultaneously keeps track of the number of operations needed to parse the generated strings. The third is a program capable of deducing the num-ber of parsing operations by counting the number of selected terminals appearing in an input string. The results, applicable to the paralel parsing of programs written in a Pascal-like language, show how the speedup varies with the number of processors for different ratios of the times to shift, reduce, and merge. Although the speedup falls considerably below that predicted by theory, substantial gains are still attainable by using a fairly large number of parallel processors. With the decreasing costs of processors, parallel parsing and parallel compilation will become increasingly important and should allow considerable gains in speedup.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231848","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701903","Compilers;parallelism;parsing","Parallel processing;Velocity measurement;Computer science;Costs;Computational modeling;Computer simulation;Concurrent computing;Production;Writing","","Compilers;parallelism;parsing","","4","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Knowledge Representation for Model Management Systems","D. R. Dolk; B. R. Konsynski","Department of Administrative Sciences, Naval Postgraduate School, Monterey, CA 93940.; Department of Management Information Systems, University of Arizona, Tucson, AZ 85721.","IEEE Transactions on Software Engineering","","1984","SE-10","6","619","628","This paper examines the concept of a model management system, what its functions are, and how they are to be achieved in a decision support context. The central issue is model representation which involves knowledge representation and knowledge management within a database environment. The model abstraction structure is introduced as a vehicle for model representation which supports both heuristic and deterministic inferencing as well as the conceptual/external schema notion familiar to database management. The model abstraction is seen as a special instance of the frame construct in artificial intelligence. Model management systems are characterized as frame-systems and a database implementation of this approach is described.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010291","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010291","Abstraction;database management system (DBMS);decision support system;frame;frame-system;knowledge management;knowledge representation (KR);model management systems","Knowledge representation;Knowledge management;Decision support systems;Resource management;Predictive models;Decision making;Database systems;Software tools;Mathematical model;Vehicles","","","","128","","26","","","","","","IEEE","IEEE Journals & Magazines"
"The Method of Layers","J. A. Rolia; K. C. Sevcik","Dept. of Syst. & Comput. Eng., Carleton Univ., Ottawa, Ont., Canada; NA","IEEE Transactions on Software Engineering","","1995","21","8","689","700","Distributed applications are being developed that contain one or more layers of software servers. Software processes within such systems suffer contention delays both for shared hardware and at the software servers. The responsiveness of these systems is affected by the software design, the threading level and number of instances of software processes, and the allocation of processes to processors. The Method of Layers (MOL) is proposed to provide performance estimates for such systems. The MOL uses the mean value analysis (MVA) linearizer algorithm as a subprogram to assist in predicting model performance measures.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.403785","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=403785","","Predictive models;Computer architecture;Hardware;Application software;Delay;Software performance;Network servers;System performance;Throughput;Electronic switching systems","distributed processing;resource allocation;software performance evaluation;client-server systems;systems analysis","distributed applications;software servers;software processes;contention delays;shared hardware;software design;threading level;processor allocation;Method of Layers;performance estimates;value analysis linearizer algorithm;model performance measures","","186","","34","","","","","","IEEE","IEEE Journals & Magazines"
"Eliminating exception handling errors with dependability cases: a comparative, empirical study","R. A. Maxion; R. T. Olszewski","Dept. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA; NA","IEEE Transactions on Software Engineering","","2000","26","9","888","906","Programs fail mainly for two reasons: logic errors in the code and exception failures. Exception failures can account for up to two-thirds of system crashes, hence, are worthy of serious attention. Traditional approaches to reducing exception failures, such as code reviews, walkthroughs, and formal testing, while very useful, are limited in their ability to address a core problem: the programmer's inadequate coverage of exceptional conditions. The problem of coverage might be rooted in cognitive factors that impede the mental generation (or recollection) of exception cases that would pertain in a particular situation, resulting in insufficient software robustness. This paper describes controlled experiments for testing the hypothesis that robustness for exception failures can be improved through the use of various coverage-enhancing techniques: N-version programming, group collaboration, and dependability cases. N-version programming and collaboration are well known. Dependability cases, derived from safety cases, comprise a new methodology based on structured taxonomies and memory aids for helping software designers think about and improve exception handling coverage. All three methods showed improvements over control conditions in increasing robustness to exception failures but dependability cases proved most efficacious in terms of balancing cost and effectiveness.","0098-5589;1939-3520;2326-3881","","10.1109/32.877848","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=877848","","Robust control;Collaboration;Software safety;Logic;Computer crashes;Vehicle crash testing;Impedance;Robustness;Taxonomy;Software design","exception handling;program debugging;software reliability","exception handling errors;dependability cases;logic errors;exception failures;system crashes;cognitive factors;software robustness;experiments;coverage-enhancing techniques;N-version programming;group collaboration;software designers;cost effectiveness;software reliability","","16","","43","","","","","","IEEE","IEEE Journals & Magazines"
"Trace specifications: methodology and models","D. Hoffman; R. Snodgrass","Dept. of Comput. Sci., Victoria Univ., BC, Canada; NA","IEEE Transactions on Software Engineering","","1988","14","9","1243","1252","The authors summarize the trace specification language and present the trace specification methodology: a set of heuristics designed to make the reading and writing of complex specifications manageable. Also described is a technique for constructing formal, executable models from specifications written using the methodology. These models are useful as proof of specification consistency and as executable prototypes. Fully worked examples of the methodology and the model building techniques are included.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6168","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6168","","Formal specifications;Computer errors;Writing;Software prototyping;Costs;Process design;Computer science;Specification languages;Prototypes;Buildings","formal specification;specification languages","formal specification;trace specification language;trace specification methodology;specification consistency;executable prototypes","","27","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Cycle Structure of the DES for Keys Having Palindromic (or Antipalindromic) Sequences of Round Keys","J. H. Moore; G. J. Simmons","Department of Applied Mathematics, Sandia National Laboratories; NA","IEEE Transactions on Software Engineering","","1987","SE-13","2","262","273","Certain DES keys have been called weak or semiweak based upon the number of distinct round keys which they produce. For the weak keys, all 16 round keys are identical and encryption is the same as decryption. For the semiweak keys, there are only two distinct round keys but no specific weakness of the DES with these keys has been demonstrated.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233150","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702205","Cryptography;cycle testing;data encryption standard (DES);fixed points and antifixed points;palindromic and antipalindromic sequences of round keys;weak and semiweak keys","Cryptography;Displays;Testing;Engines;Mathematics;Joining processes","","Cryptography;cycle testing;data encryption standard (DES);fixed points and antifixed points;palindromic and antipalindromic sequences of round keys;weak and semiweak keys","","13","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Translation and execution of distributed Ada programs: Is it still Ada?","R. A. Volz; T. N. Mudge; G. D. Buzzard; P. Krishnan","Dept. of Comput. Sci., Texas A&M Univ., College Station, TX, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1989","15","3","281","292","Some of the fundamental issues and tradeoffs involved in the translation and execution of programs written in the Ada language and intended for distributed execution are examined. The memory access architecture, binding time and degree of system homogeneity are the three basic characteristics in terms of which target systems can be described. Library subprograms and library packages are identified as natural distributable units of the language. The program-to-process/memory mapping and the unit of the language to be distributed are the key issues in the distribution of Ada. The implications of various alternatives for these are analyzed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21756","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21756","","Packaging;Real time systems;Software engineering;Libraries;Computer architecture;Memory architecture;Parallel programming;Computer errors;NASA;Computer science","Ada;distributed processing;program interpreters;programming","distributed Ada programs;distributed execution;memory access architecture;binding time;system homogeneity;library packages","","16","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Formal Specification and Verification of Distributed Systems","Bo-Shoe Chen; R. T. Yeh","Bell Laboratories; NA","IEEE Transactions on Software Engineering","","1983","SE-9","6","710","722","Computations of distributed systems are extremely difficult to specify and verify using traditional techniques because the systems are inherently concurrent, asynchronous, and nondeterministic. Furthermore, computing nodes in a distributed system may be highly independent of each other, and the entire system may lack an accurate global clock.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.235434","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703116","Distributed systems;events;fopc;liveness;safety;specification;verification","Formal specifications;Clocks;Safety;Distributed computing;Control systems;Computer science;Process control;Distributed power generation;Power generation;Petri nets","","Distributed systems;events;fopc;liveness;safety;specification;verification","","21","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Specification of the UNIX Filing System","C. Morgan; B. Sufrin","Programming Research Group, Oxford University Computing Laboratory, Oxford OX1 3QD, England.; Programming Research Group, Oxford University Computing Laboratory, Oxford OX1 3QD, England.","IEEE Transactions on Software Engineering","","1984","SE-10","2","128","142","A specification of the UNIX filing system is given using a notation based on elementary mathematical set theory. The notation used involves very few special constructs of its own. The specification is detailed enough to capture the filing system's behavior at the system call level, yet abstracts from issues of data representation, whether in programs or on the storage medium, and from the description of any algorithms which might be used to implement the system. The presentation of the specification is in several stages, each new stage building on its predecessors; major concepts are introduced separately so that they may be easily understood. The notation used allows these separate stages to be joined together to give a complete description of each filing system operation-including its error conditions. Features of the specification notation are explained as they are used, and the Appendix gives the definitions of the symbols drawn from set theory.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010215","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010215","Documentation;mathematical specification;set theory;UNIX","Set theory;Operating systems;Standards publication;Calculus;Programming profession;Abstracts;Formal specifications;Documentation;Concrete","","","","55","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Structural testing of concurrent programs","R. N. Taylor; D. L. Levine; C. D. Kelly","California Univ., Irvine, CA, USA; California Univ., Irvine, CA, USA; California Univ., Irvine, CA, USA","IEEE Transactions on Software Engineering","","1992","18","3","206","215","Although structural testing techniques are among the weakest available with regard to developing confidence in sequential programs, they are not without merit. The authors extend the notion of structural testing criteria to concurrent programs and propose a hierarchy of supporting structural testing techniques. Coverage criteria described include concurrency state coverage, state transition coverage and synchronization coverage. Requisite support tools include a static concurrency analyzer and either a program transformation system or a powerful run-time monitor. Also helpful is a controllable run-time scheduler. The techniques proposed are suitable for Ada or CSP-like languages. Best results are obtained for programs having only static naming of tasking objects.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.126769","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=126769","","Sequential analysis;Software testing;Concurrent computing;Runtime;Monitoring;Buildings;Aerospace materials;Aircraft propulsion;Computer science;Laboratories","concurrency control;parallel programming;program testing;scheduling;software metrics","structural testing techniques;sequential programs;structural testing criteria;concurrent programs;concurrency state coverage;state transition coverage;synchronization coverage;support tools;static concurrency analyzer;program transformation system;powerful run-time monitor;controllable run-time scheduler;Ada;CSP-like languages;static naming;tasking objects","","110","","26","","","","","","IEEE","IEEE Journals & Magazines"
"An acyclic expansion algorithm for fast protocol validation","Y. Kakuda; Y. Wakahara; M. Norigoe","Kokusai Denshin Denwa Co. Ltd., Saitama, Japan; Kokusai Denshin Denwa Co. Ltd., Saitama, Japan; NA","IEEE Transactions on Software Engineering","","1988","14","8","1059","1070","For the development of communications software composed of many modules, protocol validation is considered essential to detect errors in the interactions among the modules. Protocol validation techniques previously proposed have required validation time that is too long for many actual protocols. The authors propose a novel fast protocol validation technique to overcome this drawback. The proposed technique is to construct the minimum acyclic form of state transitions in individual processes of the protocol, and to detect protocol errors such as system deadlocks and channel overflows fast. The authors also present a protocol validation system based on the technique to confirm its feasibility and show validation results for some actual protocols. As a result, the protocol validation system is expected to improve productivity in the development and maintenance of communications software.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.7616","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=7616","","Protocols;Software maintenance;System recovery;Productivity;Communication system software;Automata;Programming;Software quality;Reachability analysis;Computer errors","computer communications software;finite automata;program verification;protocols;system recovery","finite state machines;acyclic expansion algorithm;protocol validation;communications software;state transitions;protocol errors;system deadlocks;channel overflows","","21","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Functional development of database applications","L. Orman","Johnson Graduate Sch. of Manage., Cornell Univ., Ithaca, NY, USA","IEEE Transactions on Software Engineering","","1988","14","9","1280","1292","A highly modular and uniformly functional development methodology for database applications is introduced. An event-oriented view of the database is adopted recording the observed events directly and treating the state of the environment as derived data. The relationship between the observed events and the derived state of the system is expressed using a purely functional language. The application systems in this environment are divided into their smallest possible components consisting of only functions and simple functional expressions. The multimode of small but highly independent components generated in this fashion are placed in the database along with the data, to utilize the database management system in maintaining the application system. The semantics of individual applications is captured within the data model serving those applications.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6172","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6172","","Data models;Database systems;Transaction databases;Information retrieval;Decision support systems;Functional programming;Real time systems;Concurrent computing;Specification languages;Data structures","database management systems;functional programming","functional development methodology;event-oriented view;database;observed events;functional language;database management system;semantics","","11","","35","","","","","","IEEE","IEEE Journals & Magazines"
"Distributed information systems: an advanced methodology","A. Aue; M. Breu","Eur. Methodology & Syst. Center, Siemens Nixdorf Informationsyst. AG, Munchen, Germany; Eur. Methodology & Syst. Center, Siemens Nixdorf Informationsyst. AG, Munchen, Germany","IEEE Transactions on Software Engineering","","1994","20","8","594","605","Information systems ranging over wide areas show properties that must be carefully analyzed and designed in order to meet the needs of the customers. Thus the development of such information systems is to be guided by software engineering methods that address problems like distribution of data and processes, communication aspects and fault tolerance. This paper shows the basic modeling concepts and the development process employed by the BOS Engineering Method to meet these requirements. The BOS Engineering Method applies the concept of business transactions to specify behavior in the early analysis phase. Appropriate abstraction levels are defined to reduce the complexity of specifying distribution issues. The development of complex distributed information systems needs a rigorous life cycle model. The BOS Engineering Method relaxes the waterfall life cycle model to allow controlled look ahead and feedback up and down the abstraction levels.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.310669","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=310669","","Distributed information systems;Information systems;Systems engineering and theory;Software engineering;Information analysis;Companies;Design engineering;Fault tolerant systems;Feedback;Hardware","software engineering;information systems;distributed processing","distributed information systems;software engineering;distribution of data;communication aspects;fault tolerance;BOS Engineering Method;business transactions;waterfall life cycle model;feedback;development process;requirements engineering;requirements analysis","","7","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Design tradeoffs for process scheduling in shared memory multiprocessor systems","L. M. Ni; C. -. E. Wu","Dept. of Comput. Sci., Michigan State Univ., East Lansing, MI, USA; Dept. of Comput. Sci., Michigan State Univ., East Lansing, MI, USA","IEEE Transactions on Software Engineering","","1989","15","3","327","334","A potential system software bottleneck is demonstrated in designing an efficient process scheduling method for multiprocessor systems with shared-memory communication mechanism. The process scheduling overhead is considered. The main contribution of this work is to find the design tradeoffs between monitor bottleneck due to scheduling overhead and low process utilization due to load imbalancing. Choosing an optimum number of scheduling monitors is the key to resolve the bottlenecks. Because of the excessive number of memory requests generated by the dynamic monitor selection method, the use of the fixed monitor selection method is recommended. An analytic estimation provides a lower bound in determining the optimum number of monitors. Hill-climbing simulation is then used to find the optimum number of monitors.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21760","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21760","","Process design;Multiprocessing systems;Monitoring;Processor scheduling;Message passing;Hardware;Computer science;Bandwidth;Load management;Concurrent computing","multiprocessing programs;multiprocessing systems;performance evaluation;scheduling;supervisory programs","hill climbing simulation;performance evaluation;process scheduling;shared memory multiprocessor systems;software bottleneck;monitor bottleneck;low process utilization;load imbalancing;memory requests;fixed monitor selection","","18","","23","","","","","","IEEE","IEEE Journals & Magazines"
"A control-flow normalization algorithm and its complexity","Z. Ammarguellat","Center for Supercomput. Res. & Dev., Illinois Univ., Urbana-Champaign, IL, USA","IEEE Transactions on Software Engineering","","1992","18","3","237","251","A single method for normalizing the control-flow of programs to facilitate program transformations, program analysis, and automatic parallelization is presented. While previous methods result in programs whose control flowgraphs are reducible, programs normalized by this technique satisfy a stronger condition than reducibility and are therefore simpler in their syntax and structure than with previous methods. In particular, all control-flow cycles are normalized into single-entry, single-exit while loops and all GOTOs are eliminated. Furthermore, the method avoids problems of code replication that are characteristic of node-splitting techniques. This restructuring obviates the control dependence graph, since afterwards control dependence relations are manifest in the syntax tree of the program. Transformations that effect this normalization are presented, and the complexity of the method is studied.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.126773","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=126773","","Automatic control;Data analysis;Tree graphs;Performance analysis;Algorithm design and analysis;Pathology;Program processors","computational complexity;graph theory;parallel algorithms;structured programming","control-flow normalization algorithm;complexity;automatic parallelization;control flowgraphs;control-flow cycles;GOTOs;node-splitting techniques;control dependence relations;syntax tree","","33","","48","","","","","","IEEE","IEEE Journals & Magazines"
"A system for generating language-oriented editors","T. Tenma; H. Tsubotani; M. Tanaka; T. Ichikawa","Dept. of Electr. Eng., Hiroshima Univ., Japan; Dept. of Electr. Eng., Hiroshima Univ., Japan; Dept. of Electr. Eng., Hiroshima Univ., Japan; Dept. of Electr. Eng., Hiroshima Univ., Japan","IEEE Transactions on Software Engineering","","1988","14","8","1098","1109","The authors seek to establish a simple and flexible framework for internal representation of language-dependent information, and the behavior of language-oriented tools for user's operations. They present a system for generating language-oriented editors based on object-oriented concepts. Features of the target language are represented as classes and their relations. A program is represented as an abstract syntax tree. Each node in the tree belongs to a node class. For generating more advanced editors, probes, internal-classes, and gates are incorporated into the system. The system generates a flexible and easily extendable language-oriented editor from a target language description in a highly modularized fashion by using the description language which the system provides.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.7620","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=7620","","Probes;Productivity;Debugging;Programming environments;Costs","application generators;data structures;software tools;text editing","application generators;software tools;data structures;language dependent data representation;language-oriented editors;language-oriented tools;object-oriented;abstract syntax tree;target language description;description language","","2","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Measuring functional cohesion","J. M. Bieman; L. M. Ott","Dept. of Comput. Sci., Colorado State Univ., Fort Collins, CO, USA; NA","IEEE Transactions on Software Engineering","","1994","20","8","644","657","We examine the functional cohesion of procedures using a data slice abstraction. Our analysis identifies the data tokens that lie on more than one slice as the ""glue"" that binds separate components together. Cohesion is measured in terms of the relative number of glue tokens, tokens that lie on more than one data slice, and super-glue tokens, tokens that lie on all data slices in a procedure, and the adhesiveness of the tokens. The intuition and measurement scale factors are demonstrated through a set of abstract transformations.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.310673","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=310673","","Software measurement;Data analysis;Software engineering;Software design;Measurement techniques;Flow graphs;Testing;Fluid flow measurement;Measurement standards;Computer languages","software metrics","functional cohesion;data slice abstraction;data tokens;glue tokens;super-glue tokens;data slices;software measurement scale;abstract transformations","","81","","43","","","","","","IEEE","IEEE Journals & Magazines"
"Synthesis of Decision-Free Concurrent Systems for Prescribed Resources and Performance","T. Murata","Department of Information Engineering, University of Illinois","IEEE Transactions on Software Engineering","","1980","SE-6","6","525","530","This paper presents a method for synthesizing or growing live and safe marked graph models of decision-free concurrent comutations. The approach is modular in the sense that subsystems r represented by arcs (and nodes) are added one by one without the need of redesigning the entire system. The foliowing properties of marked graph models can be prescribed in the synthesis: liveness (absence of deadlocks), safeness (absence of overflows), the number of reachability classes, the maximum resource (temporary storage) requirement, computation rate (performance), as well as the numbers of arcs and states.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230802","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702778","Absence of overflows;deadlock-freeness;decision-free concurrent systems;marked graphs;maximum resources;modular synthesis;parallel computation model;prescribed perfornance","Concurrent computing;Petri nets;System recovery;Computational modeling;Power system modeling;Circuit synthesis;Application software;Software systems;Hardware;Flowcharts","","Absence of overflows;deadlock-freeness;decision-free concurrent systems;marked graphs;maximum resources;modular synthesis;parallel computation model;prescribed perfornance","","36","","23","","","","","","IEEE","IEEE Journals & Magazines"
"An Automatic Generator for Compiler Testing","F. Bazzichi; I. Spadafora","Istituto di Scienze dell'Informazione, University of Pisa, Pisa, Italy, and with the Computing Center, CNUCE; NA","IEEE Transactions on Software Engineering","","1982","SE-8","4","343","353","A new method for testing compilers is presented. The compiler is exercized by compilable programs, automatically generated by a test generator. The generator is driven by a tabular description of the source language. This description is in a formalism which nicely extends context-free grammars in a context-dependent direction, but still retains the structure and readability of BNF. The generator produces a set of programs which cover all grammatical constructions of the source language, unless user supplied directives instruct otherwise. The programs generated can also be used to evaluate the performance of different compilers of the same source language.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235428","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702957","Automatic program generation;automatic test generation;compiler testing;generation of compilable programs;translator testing","Automatic testing;Program processors;Computer languages;System testing;Production;Automatic control;Runtime;Councils;Algorithm design and analysis;Performance evaluation","","Automatic program generation;automatic test generation;compiler testing;generation of compilable programs;translator testing","","45","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Automating visual language generation","C. Crimi; A. Guercio; G. Pacini; G. Tortora; M. Tucci","CRIAI, Naples, Italy; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1990","16","10","1122","1135","A system to generate and interpret customized visual languages in given application areas is presented. The generation is highly automated. The user presents a set of sample visual sentences to the generator. The generator uses inference grammar techniques to produce a grammar that generalizes the initial set of sample sentences, and exploits general semantic information about the application area to determine the meaning of the visual sentences in the inferred language. The interpreter is modeled on an attribute grammar. A knowledge base, constructed during the generation of the system, is then consulted to construct the meaning of the visual sentence. The architecture of the system and its use in the application environment of visual text editing (inspired by the Heidelberg icon set) enhanced with file management features are reported.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.60293","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=60293","","Cognitive science;User interfaces;Environmental management;Costs;Graphics;Microelectronics;Multimedia communication;Character generation","grammars;inference mechanisms;knowledge based systems;visual programming","automatic visual language generation;customized visual languages;inference grammar techniques;general semantic information;attribute grammar;knowledge base;application environment","","28","","34","","","","","","IEEE","IEEE Journals & Magazines"
"Generation of Blisses","R. F. Brender","Digital Equipment Corporation","IEEE Transactions on Software Engineering","","1980","SE-6","6","553","563","This presentation describes the simultaneous development of Bliss compilers for three machine architectures. A highly unusual combination of characteristics makes this development of general interest to the software development community: the development involved extensive sharing of code among the several compilers; involved bootstrapping and transportable programming using a machine-oriented systems implementation language; involved prototyping and subsequent evolutionary development; and involved developing software on, as well as for, three machine architectures. The unusual problems that arose are discussed and the methodologies for dealing with them are described. This experience should be of interest to others contemplating projects with similar characteristics. It should also be relevant to research in the area of software development environments as an example of the diverse needs to be met.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234504","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702782","Bliss;bootstrapping;code sharing;software tools;system implementation languages;transportable programming","Computer architecture;Software prototyping;Computer science;Optimizing compilers;Program processors;Genetic programming;Software tools;Prototypes;Planning;Software design","","Bliss;bootstrapping;code sharing;software tools;system implementation languages;transportable programming","","","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Experiments in optimizing FP","B. G. Ryder; J. S. Pendergrast","Dept. of Comput. Sci., Rutgers Univ., New Brunswick, NJ, USA; NA","IEEE Transactions on Software Engineering","","1988","14","4","444","454","FPOPT, a globally optimizing compiler for FP, was built to study the efficiency of compiling a functional programming language by translating it into an intermediate language and then optimizing that intermediate language. The FPOPT system, the design of the intermediate language and the optimizations performed are described. The relative effectiveness of these optimizations, singly and in combinations, are compared using an instrumented version of FPOPT.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4668","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4668","","Optimizing compilers;Functional programming;Design optimization;Runtime;Instruments;Computer languages;Data structures;Proposals;Code standards;Aggregates","high level languages;optimisation;program compilers;program interpreters","FPOPT;globally optimizing compiler;FP;functional programming language;intermediate language","","","","16","","","","","","IEEE","IEEE Journals & Magazines"
"IAI Corporate Software Engineering Training and Education Program","J. Z. Lavi; M. I. B. Porat; A. Ben-David","Israel Aircraft Industries, Ben Gurion International Airport; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","11","1207","1216","Israel Aircraft Industries has developed a comprehensive educational program in software engineering. Goals of the program include: the retraining of college graduates to become software engineers with specializations in one of three application areas (data processing, embedded computer systems, and CAD/CAM systems), and enhancement of the knowledge of currently practicing software engineers. The program is centered around three distinct full-time courses of study having an average duration of 7 months. The training program also includes a large number of short courses and seminars. The company is currently planning an M.Sc. program in embedded computer systems and software engineering in cooperation with one of the universities in Israel.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232871","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702169","CAD/CAM;EDP;education;embedded computer systems;industry;laboratories;software engineering;training","Software engineering;Educational programs;CADCAM;Embedded software;Data engineering;Knowledge engineering;Embedded computing;Planning;Industrial training;Computer science education","","CAD/CAM;EDP;education;embedded computer systems;industry;laboratories;software engineering;training","","1","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Echo Algorithms: Depth Parallel Operations on General Graphs","E. J. H. Chang","Department of Computer Science, University of Victoria","IEEE Transactions on Software Engineering","","1982","SE-8","4","391","401","This paper describes a method for the detection of properties of general graphs in an environment in which each node can be considered an autonomous processor, interacting with its neighbors by passing messages.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235573","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702961","Computer networks;decentralized control;distributed computing;graph algorithms","Message passing;Clocks;Concurrent computing;Distributed computing;Distributed control;Protocols;Centralized control;Multiprocessing systems;Computer science","","Computer networks;decentralized control;distributed computing;graph algorithms","","139","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Chameleon: a system for solving the data-translation problem","S. A. Mamrak; M. S. Kaelbling; C. K. Nicholas; M. Share","Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA","IEEE Transactions on Software Engineering","","1989","15","9","1090","1108","A comprehensive data translation system is described with the following characteristics: (1) it is derived from a formal model of the translation task; (2) it supports the building of translation tools; (3) it supports the use of translation tools; and (4) it is accessible to its targeted end users. A software architecture to achieve the translation capability is fully implemented. Translators have been generated using the architecture, both by the original software developers and by industrial associates who have installed the architecture at their own sites.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.31367","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=31367","","Information science;Books;Publishing;Production facilities;Laboratories;Computer architecture;Buildings;Software architecture;Computer industry;SGML","electronic data interchange","Chameleon;data-translation problem;data translation system;formal model;translation task;translation tools;software architecture","","9","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Creation of views for reuse of software with different data representations","G. S. Novak","Dept. of Comput. Sci., Texas Univ., Austin, TX, USA","IEEE Transactions on Software Engineering","","1995","21","12","993","1005","Software reuse is inhibited by the many different ways in which equivalent data can be represented. We describe methods by which views can be constructed semi-automatically to describe how application data types correspond to the abstract types that are used in numerical generic algorithms. Given such views, specialized versions of the generic algorithms that operate directly on the application data can be produced by compilation. This enables reuse of the generic algorithms for an application with minimal effort. Graphical user interfaces allow views to be specified easily and rapidly. Algorithms are presented for deriving, by symbolic algebra, equations that relate the variables used in the application data to the variables needed for the generic algorithms. Arbitrary application data structures are allowed. Units of measurement are converted as needed. These techniques allow reuse of a single version of a generic algorithm for a variety of possible data representations and programming languages. These techniques can also be applied in data conversion and in object-oriented, functional, and transformational programming.","0098-5589;1939-3520;2326-3881","","10.1109/32.489074","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=489074","","Application software;Graphical user interfaces;Algebra;Equations;Data structures;Measurement units;Computer languages;Data conversion;Functional programming;Object oriented programming","graphical user interfaces;abstract data types;data structures;software reusability;symbol manipulation;object-oriented programming;functional programming;program compilers;visual programming","view creation;software reuse;data representations;equivalent data;application data types;abstract types;numerical generic algorithms;compilation;specialized generic algorithms;graphical user interfaces;symbolic algebra;variables;measurement unit conversion;programming languages;data conversion;object-oriented programming;transformational programming;functional programming","","13","","55","","","","","","IEEE","IEEE Journals & Magazines"
"Parsing languages by pattern matching","T. Rus","Dept. of Comput. Sci., Iowa Univ., Iowa City, IA, USA","IEEE Transactions on Software Engineering","","1988","14","4","498","511","The language of universal algebras is used as an alternative approach for programming language specification. BNF (Backus-Naur form) rules are used for specifying the signature of the language algebras instead of the context-free syntax. The algorithm for program parsing is inductively defined by the following universal algebraic construction: any function defined on the generators of a free algebra taking values in the carrier of another similar algebra can be uniquely extended to a homomorphism between the two algebras; any conventional programming language can be specified by a finite set of BNF rules and its algebra of symbols is generated by a finite set of generator classes. Thus, any function defined on the finite set of generators offers an algebraic mechanism for a universal algorithm for source language program parsing. The right-hand side of the BNF rules are the patterns searched by the algorithm in the source text of the program. The essential feature of this algorithm is that it can be used as a driver for code generation and optimization in a translator.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4672","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4672","","Pattern matching;Algebra;Programming profession;Program processors;Computer languages;Text recognition;Computer science;Cities and towns;Computer aided instruction","grammars;high level languages;program compilers;program interpreters","pattern matching;universal algebras;programming language specification;BNF;Backus-Naur form;signature;language algebras;program parsing;code generation;translator","","5","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Computational efficiency of parallel combinatorial OR-tree searches","Guo-Jie Li; B. W. Wah","Inst. of Comput. Technol., Acad. Sinica, Beijing, China; NA","IEEE Transactions on Software Engineering","","1990","16","1","13","31","The performance of parallel combinatorial OR-tree searches is analytically evaluated. This performance depends on the complexity of the problem to be solved, the error allowance function, the dominance relation, and the search strategies. The exact performance may be difficult to predict due to the nondeterminism and anomalies of parallelism. The authors derive the performance bounds of parallel OR-tree searches with respect to the best-first, depth-first, and breadth-first strategies, and verify these bounds by simulation. They show that a near-linear speedup can be achieved with respect to a large number of processors for parallel OR-tree searches. Using the bounds developed, the authors derive sufficient conditions for assuring that parallelism will not degrade performance and necessary conditions for allowing parallelism to have a speedup greater than the ratio of the numbers of processors. These bounds and conditions provide the theoretical foundation for determining the number of processors required to assure a near-linear speedup.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44360","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44360","","Computational efficiency;Parallel processing;Search problems;Polynomials;Testing;Tree graphs;Performance analysis;Degradation;Operations research;Expert systems","combinatorial mathematics;database management systems;decision theory;parallel processing;performance evaluation;theorem proving;trees (mathematics)","near linear speedup;parallel combinatorial OR-tree searches;performance;error allowance function;dominance relation;search strategies;simulation;sufficient conditions","","7","","35","","","","","","IEEE","IEEE Journals & Magazines"
"Performance Analysis of FFT Algorithms on Multiprocessor Systems","L. N. Bhuyan; D. P. Agarval","Department of Electrical Engineering, University of Manitoba; NA","IEEE Transactions on Software Engineering","","1983","SE-9","4","512","521","A decimation-in-time radix-2 fast Fourier transform (FFT) algorithm is considered here for implementation in multiprocessors with shared bus, multistage interconnection network (MIN), and in mesh connected computers. Results are derived for data allocation, interprocessor communication, approximate computation time, and speedup of an N point FFT on any P available processing elements (PE's). Further generalization is obtained for a radix-r FFT algorithm. An N X N point two-dimensional discrete Fourier transform (DFT) implementation is also considered when one or more rows of the input data matrix are allocated to each PE.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.234959","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703084","FFT algorithm;interprocessor communication;multiprocessor systems;performance analysis;two-dimensional DFT","Performance analysis;Multiprocessing systems;Signal processing algorithms;Discrete Fourier transforms;Multiprocessor interconnection networks;Fast Fourier transforms;Costs;Computer networks;Switches;Communication switching","","FFT algorithm;interprocessor communication;multiprocessor systems;performance analysis;two-dimensional DFT","","11","","15","","","","","","IEEE","IEEE Journals & Magazines"
"SODOS: A software documentation support environment  Its definition","E. Horqwitz; R. C. Williamson","Department of Computer Science, University of Southern California, Los Angeles, CA 90089; Department of Computer Science, University of Southern California, Los Angeles, CA 90089; Hughes Aircraft Company, Software Engineering Division, AI Technology Department, El Segundo, CA 90245","IEEE Transactions on Software Engineering","","1986","SE-12","8","849","859","A description is given of the data abstraction mechanisms used in SODOS (software documentation support), a computerized system which supports the definition and manipulation of documents used in developing software. The generic definition of a document is given, the operations of consistency, completeness, and traceability are defined precisely, and it is shown how the generic document and associated operations are mapped onto the relational model. The SODOS system differs from others in that it is built on top of a database management system and an object-based model of the software life cycle. One advantage of this model is that it supports software documentation independently of any fixed methodology that the developers may be using. Another advantage of the system is that it permits traceability through all phases of the software life cycle, thus facilitating the testing and maintenance phases. The document representation is defined in terms of a graph model mapped into a relational data model.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312987","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312987","Database;documentation;object programming;Smalltalk-80;software","Documentation;Software;Graphics;Context;Manuals;Standards;Maintenance engineering","data structures;relational databases;system documentation","software documentation support environment;data abstraction;SODOS;relational model;database management system;object-based model;software life cycle","","23","","","","","","","","IEEE","IEEE Journals & Magazines"
"An Approach to Concurrent Control Flow Checking","S. S. Yau; Fu-Chung Chen","Department of Electrical Engineering and Computer Science, Northwestern University; NA","IEEE Transactions on Software Engineering","","1980","SE-6","2","126","137","A control flow checking scheme capable of detecting control flow errors of programs resulting from software coding errors, hardware malfunctions, or memory mutilation during the execution of the program is presented. In this approach, the program is partitioned into loop-free intervals and a database containing the path information in each of the loop-free intervals is derived from the detailed design. The path in each loop-free interval actually traversed at run time is recorded and then checked against the information provided in the database, and any discrepancy indicates an error. This approach is general, and can detect all uncompensated illegal branches. Any uncompensated error that occurs during the execution of a loop-free interval and manifests itself as a wrong branch within the loop-free interval or right after the completion of execution of the loop-free interval is also detectable. The approach can also be used to check the control flow in the testing phase of program development. The capabilities, limitations, implementation, and the overhead of using this approach are discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234478","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702710","Algorithms;capabilities;concurrency;control errors;control flow checking;illegal branches;implementation;limitations;loop-free intervals;overhead;path representation;program design;wrong branches","Testing;Error correction;Databases;Computer errors;Hardware;Runtime;Patient monitoring;Control systems;Fault detection;Relays","","Algorithms;capabilities;concurrency;control errors;control flow checking;illegal branches;implementation;limitations;loop-free intervals;overhead;path representation;program design;wrong branches","","79","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Subprogram inlining: a study of its effects on program execution time","J. W. Davidson; A. M. Holler","Dept. of Comput. Sci., Virginia Univ., Charlottesville, VA, USA; Dept. of Comput. Sci., Virginia Univ., Charlottesville, VA, USA","IEEE Transactions on Software Engineering","","1992","18","2","89","102","Equations representing the execution time performance of noninlined and inlined versions of a program have been developed. The accuracy of the equations' description of inlined program execution time behavior was demonstrated on four computer systems. Using the equations, understanding of how certain factors influence the speed of inlined code was gained. Contrary to a number of published reports in the literature, the increased size of inlined code was not found to affect its execution time performance on demand-paged virtual memory machines. On such systems, neither the use of an inlining algorithm that includes program size constraints nor the substitution of interprocedural data flow analysis for inlining is warranted. A modest improvement in the caching and paging behavior of test programs' inlined versions was also observed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.121752","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=121752","","Equations;Lifting equipment;Data analysis;Algorithm design and analysis;Program processors;Motion control;Registers;Computer science;System testing;Programming profession","program testing;programming;storage allocation;virtual storage","subprogram inlining;execution time performance;inlined versions;inlined program execution time behavior;computer systems;inlined code;demand-paged virtual memory machines;inlining algorithm;program size constraints;interprocedural data flow analysis;caching;paging behavior","","26","","40","","","","","","IEEE","IEEE Journals & Magazines"
"TLA in pictures","L. Lamport","Syst. Res. Center, Digital Equipment Corp., Palo Alto, CA, USA","IEEE Transactions on Software Engineering","","1995","21","9","768","775","Predicate-action diagrams, which are similar to standard state-transition diagrams, are precisely defined as formulas of TLA (the Temporal Logic of Actions). We explain how these diagrams can be used to describe aspects of a specification-and those descriptions then proved correct-even when the complete specification cannot be written as a diagram. We also use the diagrams to illustrate proofs.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.464544","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=464544","","Software requirements and specifications;Logic","algebraic specification;formal specification;temporal logic;diagrams","predicate-action diagrams;state-transition diagrams;Temporal Logic of Actions;TLA;diagrams;specification;concurrency","","20","","6","","","","","","IEEE","IEEE Journals & Magazines"
"Language Features for Access Control","P. Ancilotti; M. Boari; N. Lijtmaer","Istituto Elaborazione della Informazione, CNR; NA; NA","IEEE Transactions on Software Engineering","","1983","SE-9","1","16","25","The properties of a capability-based protection mechanism to be incorporated in a language for concurrent programming are presented. The protection mechanism is first abstractly characterized in terms of a protection model; the components of the protection mechanism, that is, the objects, subjects, and protection rules which govern the accessing to the objects by the subjects, are defined.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236166","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703008","Capabilities;compile-time access control;concurrent programming languages;protection mechanism;static and dynamic resource allocation","Access control;Protection;Computer languages;Object oriented modeling;Resource management;Operating systems;Software reliability;Mechanical factors;Object oriented programming;Dynamic programming","","Capabilities;compile-time access control;concurrent programming languages;protection mechanism;static and dynamic resource allocation","","2","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Optimization Algorithms for Distributed Queries","P. M. G. Apers; A. R. Hevner; S. B. Yao","Informatica Wiskundig Seminarium, Vrije Universiteit; NA; NA","IEEE Transactions on Software Engineering","","1983","SE-9","1","57","68","The efficiency of processing strategies for queries in a distributed database is critical for system performance. Methods are studied to minimize the response time and the total time for distributed queries. A new algorithm (Algorithm GENERAL) is presented to derive processing strategies for arbitrarily complex queries. Three versions of the algorithm are given: one for minimizing response time and two for minimizing total time. The algorithm is shown to provide optimal solutions under certain conditions.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236170","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703012","Computer network;database;distributed database systems;distributed processing strategy;heuristic algorithms;query processing;relational data model;system modeling","Query processing;Distributed databases;Delay;Heuristic algorithms;System performance;Relational databases;Database systems;Indexes;Distributed processing;Data models","","Computer network;database;distributed database systems;distributed processing strategy;heuristic algorithms;query processing;relational data model;system modeling","","114","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Exponential order statistic models of software reliability growth","D. R. Miller","Department of Operations Research, George Washington University, Washington, DC 20052","IEEE Transactions on Software Engineering","","1986","SE-12","1","12","24","Failure times of a software reliability growth process are modeled as order statistics of independent, nonidentically distributed exponential random variables. The Jelinsky-Moranda, Goel-Okumoto, Littlewood, Musa-Okumoto logarithmic, and power law models are all special cases of exponential order statistic models, but there are many additional examples as well. Various characterizations, properties, and examples of this class of models are developed and presented.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312915","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312915","Complete monotonicity;exponential distribution;non-homogeneous Poisson processes;order statistics;probability models;software reliability","Earth Observing System;Mathematical model;Software reliability;Stochastic processes;Computer bugs;Debugging","reliability theory;software reliability;statistical analysis","Jelinsky-Moranda models;Goel-Okumoto models;Littlewood model;Musa-Okumoto model;statistic models;software reliability growth;order statistics;distributed exponential random variables;power law models","","46","","","","","","","","IEEE","IEEE Journals & Magazines"
"Semaphore queue priority assignment for real-time multiprocessor synchronization","V. B. Lortz; K. G. Shin","Archit. Lab., Intel Corp., Hillsboro, OR, USA; NA","IEEE Transactions on Software Engineering","","1995","21","10","834","844","Prior work on real time scheduling with global shared resources in multiprocessor systems assigns as much blocking as possible to the lowest priority tasks. We show that better schedulability can be achieved if global blocking is distributed according to the blocking tolerance of tasks rather than their execution priorities. We describe an algorithm that assigns global semaphore queue priorities according to blocking tolerance, and we present simulation results demonstrating the advantages of this approach with rate monotonic scheduling. Our simulations also show that a simple FIFO usually provides better real time schedulability with global semaphores than priority queues that use task execution priorities.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.469457","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=469457","","Protocols;Processor scheduling;Real time systems;Multiprocessing systems;Scheduling algorithm;Concurrency control;Algorithm design and analysis;Kernel;Delay;System recovery","multiprocessing systems;processor scheduling;scheduling;real-time systems;queueing theory;synchronisation;concurrency control","semaphore queue priority assignment;real time multiprocessor synchronization;real time scheduling;real-time multiprocessor synchronization;global shared resources;multiprocessor systems;lowest priority tasks;blocking tolerance;global semaphore queue priorities;simulation results;rate monotonic scheduling;simple FIFO;real time schedulability;task execution priorities;concurrency control","","11","","11","","","","","","IEEE","IEEE Journals & Magazines"
"A formal analysis of the fault-detecting ability of testing methods","P. G. Frankl; E. J. Weyuker","Dept. of Comput. Sci., Polytech. Univ., Brooklyn, NY, USA; NA","IEEE Transactions on Software Engineering","","1993","19","3","202","213","Several relationships between software testing criteria, each induced by a relation between the corresponding multisets of subdomains, are examined. The authors discuss whether for each relation R and each pair of criteria, C/sub 1/ and C/sub 2/, R(C/sub 1/, C/sub 2/) guarantees that C/sub 1/ is better at detecting faults than C/sub 2/ according to various probabilistic measures of fault-detecting ability. It is shown that the fact that C/sub 1/ subsumes C/sub 2/ does not guarantee that C/sub 1/ is better at detecting faults. Relations that strengthen the subsumption relation and that have more bearing on fault-detecting ability are introduced.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.221133","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=221133","","Fault detection;Analytical models;Space technology;System testing;Software testing;NASA;Software systems;Computer science","program testing;system recovery","formal analysis;software testing criteria;multisets;subdomains;probabilistic measures;fault-detecting ability;subsumption relation","","101","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Prototyping in industrial software projects-bridging the gap between theory and practice","H. Lichter; M. Schneider-Hufschmidt; H. Zullighoven","Union Bank of Switzerland, Zurich, Switzerland; NA; NA","IEEE Transactions on Software Engineering","","1994","20","11","825","832","Prototyping, a method and technique frequently used in many engineering disciplines, has been adopted as a technique in software engineering to improve the calculation of new projects involving risks. However, there has so far been a lack of documented experience with the use of prototyping in industrial software production. The paper tries to close this gap. First, we introduce central prototyping concepts and terminology. We also present five industrial software projects in which explicit use was made of prototyping. Based on our analysis of these projects we present the resulting conclusions: prototyping means more than rapidly developing user interfaces; prototyping is a central part of a development strategy; prototyping means end user involvement; finding the right mixture of prototypes improves the development process.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.368126","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=368126","","Software prototyping;Computer industry;Prototypes;Production;Terminology;Programming;Design engineering;Software engineering;User interfaces;Planning","software prototyping;project management;software development management;human factors","industrial software projects;software prototyping;software engineering;industrial software production;central prototyping concepts;development strategy;end user involvement;pilot system;horizontal prototyping;vertical prototyping;presentation prototype","","23","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Closure and convergence: a foundation of fault-tolerant computing","A. Arora; M. Gouda","Dept. of Comput. Sci., Ohio State Univ., Columbus, OH, USA; NA","IEEE Transactions on Software Engineering","","1993","19","11","1015","1027","The authors formally define what it means for a system to tolerate a class of faults. The definition consists of two conditions. The first is that if a fault occurs when the system state is within the set of legal states, the resulting state is within some larger set and, if faults continue to occur, the system state remains within that larger set (closure). The second is that if faults stop occurring, the system eventually reaches a state within the legal set (convergence). The applicability of the definition for specifying and verifying the fault-tolerance properties of a variety of digital and computer systems is demonstrated. Using the definition, the authors obtain a simple classification of fault-tolerant systems. Methods for the systematic design of such systems are discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.256850","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=256850","","Convergence;Fault tolerance;Fault tolerant systems;Design methodology;Computer science;Law;Legal factors;Terminology;Computer errors;Computer crashes","fault tolerant computing;formal verification","fault-tolerant computing;legal states;convergence;closure;verification","","130","","41","","","","","","IEEE","IEEE Journals & Magazines"
"Modeling and Analysis of Distributed Database Concurrency Control Algorithms Using an Extended Petri Net Formalism","M. T. Ozsu","Department of Computing Science, University of Alberta","IEEE Transactions on Software Engineering","","1985","SE-11","10","1225","1240","Distributed database systems (DDBS) have received considerable attention in recent years. Being a relatively young research field, there are still many problems associated with DDB systems that need solution. Concurrency control is one of these problems and, probably, the most extensively studied. However, most of the work has concentrated on the development of alternative solutions and the field seems to be ready for some comparative analysis work. This paper reports the results of a performance evaluation study on distributed database concurrency control algorithms. The research has resulted in the development of a formalism, based on Petri nets, for modeling and analysis purposes. The formalism, called the Extended Place/Transition Nets (EPTN), is both descriptively powerful in that it can be used to model various algorithms precisely and succinctly and to communicate them in a clear manner, while at the same time lending itself to be used as a performance evaluation tool. An EPTN simulator is implemented and various algorithms are studied using this tool. This paper describes both the formalism and the performance results that have been obtained.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231870","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701938","Concurrency control;distributed databases;performance evaluation;Petri nets;simulation","Data analysis;Algorithm design and analysis;Distributed databases;Concurrency control;Analytical models;Computational modeling;Performance analysis;Petri nets;Costs;Database systems","","Concurrency control;distributed databases;performance evaluation;Petri nets;simulation","","13","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Finding idle machines in a workstation-based distributed system","M. M. Theimer; K. A. Lantz","Xerox Palo Alto Res. Center, CA, USA; NA","IEEE Transactions on Software Engineering","","1989","15","11","1444","1458","The authors describe the design and performance of scheduling facilities for finding idle hosts in a workstation-based distributed system. They focus on the tradeoffs between centralized and decentralized architectures with respect to scalability, fault tolerance, and simplicity of design, as well as several implementation issues of interest when multicast communication is used. They conclude that the principal tradeoff between the two approaches is that a centralized architecture can be scaled to a significantly greater degree and can more easily monitor global system statistics whereas a decentralized architecture is simpler to implement.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.41336","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=41336","","Workstations;Distributed computing;Computer architecture;Fault tolerant systems;Scalability;Fault tolerance;Multicast communication;Computerized monitoring;Remote monitoring;Statistical distributions","distributed processing;scheduling","design simplicity;idle machines;workstation-based distributed system;performance;scheduling facilities;idle hosts;decentralized architectures;scalability;fault tolerance;multicast communication;centralized architecture;global system statistics","","55","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Managing communication networks by monitoring databases","O. Wolfson; S. Sengupta; Y. Yemini","Dept. of Comput. Sci., Columbia Univ., New York, NY, USA; Dept. of Comput. Sci., Columbia Univ., New York, NY, USA; Dept. of Comput. Sci., Columbia Univ., New York, NY, USA","IEEE Transactions on Software Engineering","","1991","17","9","944","953","The problem of managing large communication networks using statistical tests, alerts, and correlation among alerts is considered. The authors propose a model of these network management functions as data-manipulation operations. They argue that this approach can improve the flexibility of network management systems by providing a language that is declarative and set-oriented. These are properties of existing data-manipulation languages and it is shown that any data-manipulation language, augmented with several new capabilities, can serve as a language for specifying the aforementioned network management functions. The new capabilities required are specification of events, correlation among events, and change-tracking.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.92914","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=92914","","Communication networks;Monitoring;Spatial databases;Power system management;Computer science;Research and development management;Testing;Information retrieval;Database systems;Real time systems","computer networks;data communication systems;database management systems;query languages;telecommunication network management","database monitoring;large communication networks;statistical tests;alerts;network management functions;data-manipulation operations;network management systems;data-manipulation languages;change-tracking","","34","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Statistical inference for general-order-statistics and nonhomogeneous-Poisson-process software reliability models","H. Joe","Univ. Coll., London, UK","IEEE Transactions on Software Engineering","","1989","15","11","1485","1490","There are many software reliability models that are based on the times of occurrences of errors in the debugging of software. It is shown that it is possible to do asymptotic likelihood inference for software reliability models based on order statistics or nonhomogeneous Poisson processes, with asymptotic confidence levels for interval estimates of parameters. In particular, interval estimates from these models are obtained for the conditional failure rate of the software, given the data from the debugging process. The data can be grouped or ungrouped. For someone making a decision about when to market software, the conditional failure rate is an important parameter. The use of interval estimates is demonstrated for two data sets that have appeared in the literature.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.41340","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=41340","","Fault tolerance;Software reliability;Statistics;Maximum likelihood estimation;Software debugging;Parameter estimation;Large-scale systems;Art;Programming","inference mechanisms;software reliability;statistical analysis","statistical inference;general-order-statistics;nonhomogeneous-Poisson-process software reliability models;debugging;asymptotic likelihood inference;asymptotic confidence levels;interval estimates;conditional failure rate","","33","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Support for maintaining object-oriented programs","M. Lejter; S. Meyers; S. P. Reiss","Dept. of Comput. Sci., Brown Univ., Providence, RI, USA; Dept. of Comput. Sci., Brown Univ., Providence, RI, USA; Dept. of Comput. Sci., Brown Univ., Providence, RI, USA","IEEE Transactions on Software Engineering","","1992","18","12","1045","1052","It is explained how inheritance and dynamic binding make object-oriented programs difficult to maintain, and a concrete example of the problems that arise is given. It is shown that the difficulty lies in the fact that conventional tools are poorly suited for work with object-oriented languages, and it is argued that semantics-based tools are essential for effective maintenance of object-oriented programs. A system developed for working with C++ programs is described. It comprises a relational database system for information about programs and an interactive database interface integrated with a text editor. The authors describe the system architecture, detail the database relations, provide informal evidence on the system's effectiveness, and compare it to other research with similar goals.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.184759","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=184759","","Relational databases;Object oriented databases;Concrete","C language;inheritance;object-oriented languages;object-oriented programming;relational databases;software maintenance","program maintenance;object-oriented programs;inheritance;dynamic binding;object-oriented languages;semantics-based tools;C++ programs;relational database system;interactive database interface;text editor","","41","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Design of Distributed Databases on Local Computer Systems with a Multiaccess Network","B. W. Wah; Yao-Nan Lien","School of Electrical Engineering, Purdue University; NA","IEEE Transactions on Software Engineering","","1985","SE-11","7","606","619","Concurrency control, distribution design, and query processing are some of the important issues in the design of distributed databases. In this paper, we have studied these issues with respect to a relational database on a local computer system connected by a multiaccess broadcast bus. A broadcast bus allows information to be distributed efficiently, and hence simplifies the solutions to some of these issues. A transaction model that integrates the control strategies in concurrency control and query processing is proposed. In concurrency control, the lock, unlock, and update of data are achieved by a few broadcasts. A dynamic strategy is used in query processing, as less data are transferred when compared to a static strategy. The status information needed in dynamic query processing can be conveniently obtained by broadcasting. Lastly, some NP-hard file placement problems are found to be solvable in polynomial time when updates are broadcast.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232505","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702065","Broadcast;concurrency control;file allocation;local computer network;multiaccess bus;priority;query processing;transaction","Distributed databases;Computer networks;Distributed computing;Broadcasting;Query processing;Relational databases;Concurrency control;Process design;Transaction databases;Polynomials","","Broadcast;concurrency control;file allocation;local computer network;multiaccess bus;priority;query processing;transaction","","8","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Some Equivalence Results for Load-Independent Exponential Queueing Networks","W. J. Stewart; W. P. Stohs","Department of Computer Science, North Carolina State University, Raleigh, NC 27650.; IBM Corporation, Research Triangle Park, NC 27709.","IEEE Transactions on Software Engineering","","1984","SE-10","4","414","422","In this paper we derive a number of results concerning the behavior of closed load-independent exponential queueing networks. It is shown that if the service rate of any station is increased (decreased), then the throughput of the network itself also increases (decreases). This is not true for product form networks in general. In addition, if the service rate at server i is increased then both the mean queue length and mean waiting time at server i decrease while both these quantities increase at all stations j  i. The opposite effect is observed if the senrvice rate at station i is decreased. The main result of the paper is a proof of the conjective that corresponding to any general closed queueing network consisting of M stations and in which N customers circulate according to the elements of an irreducible stochastic routing matrix Q, there exists a closed load-independent exponential queueing network with the same M, N, and Q such that the mean number of customers at each station in the exponential network is equal to that in the general network. If the network throughput is specified, it is shown that this exponential network iS unique.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010254","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010254","Equivalence properties;parameter variation;performance evalation;queeing netwrks;queueing networks;queueing theory","Network servers;Queueing analysis;Iterative methods;Throughput;Stochastic processes;Routing;Testing;Ducts;Tellurium","","","","1","","7","","","","","","IEEE","IEEE Journals & Magazines"
"Space efficient execution of deterministic parallel programs","D. J. Simpson; F. W. Burton","Simon Fraser Univ., Burnaby, BC, Canada; NA","IEEE Transactions on Software Engineering","","1999","25","6","870","882","We model a deterministic parallel program by a directed acyclic graph of tasks, where a task can execute as soon as all tasks preceding it have been executed. Each task can allocate or release an arbitrary amount of memory (i.e., heap memory allocation can be modeled). We call a parallel schedule ""space efficient"" if the amount of memory required is at most equal to the number of processors times the amount of memory required for some depth-first execution of the program by a single processor. We describe a simple, locally depth-first scheduling algorithm and show that it is always space efficient. Since the scheduling algorithm is greedy, it will be within a factor of two of being optimal with respect to time. For the special case of a program having a series-parallel structure, we show how to efficiently compute the worst case memory requirements over all possible depth-first executions of a program. Finally, we show how scheduling can be decentralized, making the approach scalable to a large number of processors when there is sufficient parallelism.","0098-5589;1939-3520;2326-3881","","10.1109/32.824415","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=824415","","Scheduling algorithm;Optimal scheduling;Processor scheduling;Memory management;Tree graphs;Parallel processing;Electronic switching systems;Computer Society;Parallel programming;Time factors","parallel programming;directed graphs;processor scheduling;storage allocation;tree searching;computational complexity","space efficient execution;deterministic parallel programs;directed acyclic graph;task allocation;heap memory allocation;parallel schedule;space efficiency;depth-first execution;locally depth-first scheduling algorithm;series-parallel structure;worst case memory requirements;depth-first executions","","4","","13","","","","","","IEEE","IEEE Journals & Magazines"
"A structure editor for abstract document objects","G. D. Kimura","DECwest Engineering, Digital Equipment Corporation, Bellevue, WA 98004","IEEE Transactions on Software Engineering","","1986","SE-12","3","417","435","The author presents an interactive document editor based on an expressive abstract document model for paper and electronic documents. The model introduces the notions of abstract and concrete objects, hierarchical composition of ordered and unordered objects, sharing of components, and reference links. It has been used to specify a wide variety of document objects, and is the basis for a document processing system that allows its users to edit the logical structure of a document using specific structure editing commands. This system introduces two new ideas. The first involves computational objects; each object can be programmed to generate its own unique view of the document, and each of these views can be displayed in a separate window on the screen. The second involves multiple windows to display the document structure. The windows are arranged hierarchically as sets and sequences, depending on the composite structure of the document. This system is used for both editing and viewing documents.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312883","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312883","Document models;document processing systems;formatting systems;structure editors;text editors","Abstracts;Mathematical model;Equations;Prototypes;Computational modeling;Concrete","text editing;word processing","software engineering;structure editor;abstract document objects;interactive document editor;electronic documents;concrete objects;hierarchical composition;unordered objects;reference links;document objects;logical structure;computational objects","","1","","","","","","","","IEEE","IEEE Journals & Magazines"
"Extending typestate checking using conditional liveness analysis","R. E. Strom; D. M. Yellin","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA","IEEE Transactions on Software Engineering","","1993","19","5","478","485","The authors present a practical extension to typestate checking, which is capable of proving programs free of uninitialized variable errors even when these programs contain conditionally initialized variables where the initialization of a variable depends upon the equality of one or more tag variables to a constant. The user need not predeclare the relationship between a conditionally initialized variable and its tags, and this relationship may change from one point in the program to another. The technique generalizes liveness analysis to conditional liveness analysis. Like typestate checking, this technique incorporates a dataflow analysis algorithm in which each point in a program is labeled with a lattice point describing statically tracked information, including the initialization of variables. The labeling is then used to check for programming errors such as referencing a variable which may be uninitialized.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.232013","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=232013","","Data analysis;Algorithm design and analysis;Lattices;Program processors;Information analysis;Labeling;Modems;Computer languages;Performance analysis;Runtime","program verification","program verification;typestate checking;conditional liveness analysis;uninitialized variable errors;dataflow analysis algorithm;statically tracked information;programming errors","","22","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Horizon: a retargetable compiler for horizontal microarchitectures","R. A. Mueller; M. R. Duda; P. H. Sweany; J. S. Walicki","Dept. of Comput. Sci., Colorado State Univ., Fort Collins, CO, USA; Dept. of Comput. Sci., Colorado State Univ., Fort Collins, CO, USA; Dept. of Comput. Sci., Colorado State Univ., Fort Collins, CO, USA; Dept. of Comput. Sci., Colorado State Univ., Fort Collins, CO, USA","IEEE Transactions on Software Engineering","","1988","14","5","575","583","The vertical migration of complex application code into horizontal microcode makes traditional methods of handwritten and hand-optimized microcode with primitive assembly languages impractical. Higher-level languages that permit abstraction from low-level timing and concurrency details are considered a major step toward alleviating the problem. This approach is feasible only if compilers for these languages exist that can produce high-quality microcode and that can be targeted to new machines with modest effort and high reliability. An overview is provided of the Horizon retargetable microcode compiler, which facilitates the production of highly optimized microcode and the targeting of the compiler to specific machines.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6135","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6135","","Microarchitecture;Timing;Assembly;Concurrent computing;Optimizing compilers;Compaction;Microprogramming;Constraint optimization;Circuit synthesis;Production","microprogramming;program compilers","retargetable compiler;horizontal microarchitectures;vertical migration;complex application code;horizontal microcode;assembly languages;abstraction;timing;concurrency;Horizon;optimized microcode","","2","","33","","","","","","IEEE","IEEE Journals & Magazines"
"Optimizing joins in fragmented database systems on a broadcast local network","J. S. J. Chen; V. O. K. Li","Teradata Corp., Los Angeles, CA, USA; NA","IEEE Transactions on Software Engineering","","1989","15","1","26","38","The problem of optimizing joins between two fragmented relations on a broadcast local network is analyzed. Data redundancy is considered. Semantic information associated with fragments are used to eliminate necessary processing. More than one physical copies of a fragment is allowed to be used in a strategy to achieve more parallelism. Join-analysis graphs are introduced to represent joins on two fragmented relations. The problem of optimizing a join is mapped into an equivalent problem of finding a minimum-weight vertex cover for the corresponding join-analysis graph. This problem is proved to be NP-hard. A four-phase approach for processing joins is proposed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21723","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21723","","Intelligent networks;Database systems;Broadcasting;Query processing;Distributed databases;Parallel processing;Computer networks;Distributed computing;Computer network management;Data communication","concurrency control;distributed databases;local area networks;relational databases","NP hardness;fragmented database systems;broadcast local network;relations;redundancy;parallelism;minimum-weight vertex cover;join-analysis graph","","12","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Optimal distributed t-resilient election in complete networks","A. Itai; S. Kutten; Y. Wolfstahl; S. Zaks","Dept. of Comput. Sci., Technion, Haifa, Israel; Dept. of Comput. Sci., Technion, Haifa, Israel; Dept. of Comput. Sci., Technion, Haifa, Israel; Dept. of Comput. Sci., Technion, Haifa, Israel","IEEE Transactions on Software Engineering","","1990","16","4","415","420","The problem of distributed leader election in an asynchronous complete network, in the presence of faults that occurred prior to the execution of the election algorithm, is discussed. Failures of this type are encountered, for example, during a recovery from a crash in the network. For a network with n processors, k of which start the algorithm that uses at most O(n log k+n+kt) messages is presented and shown to be optimal. An optimal algorithm for the case where the identities of the neighbors are known is also presented. It is noted that the order of the message complexity of a t-resilient algorithm is not always higher than that of a nonresilient one. The t-resilient algorithm is a systematic modification of an existing algorithm for a fault-free network.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.54293","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=54293","","Nominations and elections;Intelligent networks;Distributed algorithms;Costs;Computer crashes;Bidirectional control;Computer science;Routing","computer networks;distributed processing;fault tolerant computing;software engineering","optimal distributed t-resilient election;complete networks;distributed leader election;election algorithm;message complexity;fault-free network","","12","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Measures of the potential for load sharing in distributed computing systems","M. G. Sriram; M. Singhal","Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA","IEEE Transactions on Software Engineering","","1995","21","5","468","475","We are concerned with the problem of determining the potential for load balancing in a distributed computing system. We define a precise measure, called the number of sharable jobs, of this potential in terms of the number of jobs that can usefully be transferred across sites in the system. Properties of this measure are derived, including a general formula for its probability distribution, independent of any particular queuing discipline. A normalized version of the number of sharable jobs, called the job sharing coefficient, is defined. From the general formula, the probability distribution of the number of sharable jobs is computed for three important queuing models and exact expressions are derived in two cases. For queuing models in which an exact expression for the probability distribution of the number of sharable jobs is difficult to obtain, two methods are presented for numerical computation of this distribution. The job sharing coefficient is plotted against traffic intensity for various values of system parameters. Both of these measures are shown to be useful analytic tools for understanding the characteristics of load sharing in distributed systems and can aid in the design of such systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.387476","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=387476","","Distributed computing;Probability distribution;Load management;System performance;Particle measurements;Traffic control;Fluctuations;Ice;Taxonomy;Information science","distributed processing;resource allocation;probability;queueing theory","distributed computing systems;load sharing potential measurement;number of sharable jobs;probability distribution;normalized sharable job number;job sharing coefficient;queuing models;exact expressions;numerical computation;traffic intensity;system parameters;analytic tools;systems design;sharable job number","","6","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Programming and verifying real-time systems by means of the synchronous data-flow language LUSTRE","N. Halbwachs; F. Lagnier; C. Ratel","NA; NA; NA","IEEE Transactions on Software Engineering","","1992","18","9","785","793","The benefits of using a synchronous data-flow language for programming critical real-time systems are investigated. These benefits concern ergonomy (since the dataflow approach meets traditional description tools used in this domain) and ability to support formal design and verification methods. It is shown, using a simple example, how the language LUSTRE and its associated verification tool LESAR, can be used to design a program, to specify its critical properties, and to verify these properties. As the language LUSTRE and its uses have already been discussed in several papers, emphasis is put on program verification.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.159839","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=159839","","Real time systems;Differential equations;Design methodology;Formal verification;Computer languages;Difference equations;Switches;Software quality;Application software;Finite difference methods","parallel languages;parallel programming;program verification;real-time systems","data-flow language LUSTRE;synchronous data-flow language;critical real-time systems;ergonomy;dataflow approach;traditional description tools;formal design;verification methods;verification tool LESAR;critical properties;program verification","","106","","29","","","","","","IEEE","IEEE Journals & Magazines"
"An approach to software product testing","C. U. Munoz","IBM Corp., San Jose, CA, USA","IEEE Transactions on Software Engineering","","1988","14","11","1589","1596","An approach is presented that uses the following techniques: automatic test case generation, self-checking test cases, black box test cases, random test cases, sampling, a form of exhaustive testing, correctness measurements, and the correction of defects in the test cases instead of in the product (defect circumvention). The techniques are cost-effective and have been applied to very large products.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9047","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9047","","Software testing;Automatic testing;Software measurement;Productivity;Sampling methods;Costs;Algorithms;Automatic control;Performance evaluation;Milling machines","program testing","program testing;software product testing;automatic test case generation;self-checking test cases;black box test cases;random test cases;sampling;exhaustive testing;correctness measurements;defect circumvention","","3","","12","","","","","","IEEE","IEEE Journals & Magazines"
"The processor working set and its use in scheduling multiprocessor systems","D. Ghosal; G. Serazzi; S. K. Tripathi","Bell Commun. Res., Red Bank, NJ, USA; NA; NA","IEEE Transactions on Software Engineering","","1991","17","5","443","453","The concept of a processor working set (PWS) as a single value parameter for characterizing the parallel program behavior is introduced. Through detailed experimental studies of different algorithms on a transputer-based multiprocessor machine, it is shown that the PWS is a robust measure for characterizing the workload of a multiprocessor system. It is shown that processor allocation strategies based on the PWS provide significantly better throughput-delay characteristics. The robustness of PWS is further demonstrated by showing that allocation policies that allocate processors more than the PWS are inferior in performance to those that never allocate more than the PWS-even at a moderately low load. Based on the results, a simple static allocation policy that allocates the PWS at low load and adaptively fragments at high load to one processor per job is proposed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.90447","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=90447","","Processor scheduling;Multiprocessing systems;Parallel processing;Robustness;Helium;Very large scale integration;Concurrent computing;Computer science;Throughput;Computer architecture","multiprocessing systems;scheduling;transputers","scheduling;processor working set;PWS;parallel program behavior;transputer-based multiprocessor machine;processor allocation strategies;static allocation policy","","61","","17","","","","","","IEEE","IEEE Journals & Magazines"
"On the reliability of electronic payment systems","R. J. Anderson; S. J. Bezuidenhoudt","Comput. Lab., Cambridge Univ., UK; NA","IEEE Transactions on Software Engineering","","1996","22","5","294","301","One of the problems facing the builders of the 'Information Superhighway' is how to charge for services. The high costs of billing systems suggest that prepayment mechanisms could play a large part in the solution. Yet how does one go about making an electronic prepayment system (or indeed any kind of payment system) robust? We describe some recent systems engineering experience which may be relevant-the successful introduction of cryptology to protect prepayment electricity meters from token fraud. These meters are used by a number of utilities from Scotland to South Africa, and they present some interesting reliability challenges.","0098-5589;1939-3520;2326-3881","","10.1109/32.502222","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=502222","","Cryptography;Consumer electronics;Robustness;Watthour meters;Robust control;Costs;Reliability engineering;Systems engineering and theory;Protection;Africa","information services;financial data processing;cryptography","electronic payment systems reliability;Information Superhighway;billing systems;prepayment mechanisms;systems engineering experience;cryptology;prepayment electricity meter;token fraud;reliability challenges","","20","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Compile-time program restructuring in multiprogrammed virtual memory systems","S. J. Hartley","Dept. of Comput. Sci., Virginia Univ., Charlottesville, VA, USA","IEEE Transactions on Software Engineering","","1988","14","11","1640","1644","An evaluation is made of a way to reduce the cost of program restructuring by having a compiler determine the program's packing in virtual address space from an analysis of its source code. Two features of this method are the duplication of code modules in virtual address space and the inline substitution of the code for a called procedure. This compile-time restructuring algorithm is evaluated using the instruction-only address traces from a collection of programs. In a simulation of a virtual memory system using disks as secondary storage devices, the method is not successful, since it leads to a higher optimum space-time execution cost than that of the unrestructured program. The algorithm did reduce program space-time execution cost for some arbitrarily chosen memory allocations smaller than the optimum. This could be useful in a multiuser, multiprogrammed environment.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9051","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9051","","Program processors;Cost function;Computer science;Data structures;Mathematics;Computational modeling;Writing;Delay","data structures;multiprogramming;performance evaluation;program compilers;storage allocation;storage management;virtual storage","storage management;program restructuring;multiprogrammed virtual memory;compiler;virtual address space;compile-time restructuring;instruction-only address traces;optimum space-time;memory allocations","","10","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Isolation Method in a Network of Queues","J. Labetoulle; G. Pujolle","IRIA; NA","IEEE Transactions on Software Engineering","","1980","SE-6","4","373","381","In this paper a new method for analyzing complex queueing networks is proposed: the isolation method. As an example, we study packet switching networks with finite buffer size at each node.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234493","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702745","Modeling;packet switching networks;queueing networks","Intelligent networks;Mathematical model;Computer networks;Queueing analysis;Packet switching;Databases;Complex networks;Transforms;Laplace equations;Iterative methods","","Modeling;packet switching networks;queueing networks","","6","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Parallel computing optimization in the Apollo domain network","M. F. Pekergin","EHEI, Univ. Rene Descartes, Paris, France","IEEE Transactions on Software Engineering","","1992","18","4","296","303","The performance of parallel computing in a network of Apollo workstations where the processes use the remote procedure call (RPC) mechanism for communication is addressed. The speedup in such systems cannot be accurately estimated without taking into account the relatively large communication overheads. Moreover, it decreases by increasing parallelism when the latter exceeds some certain limit. To estimate the speedup and determine the optimum degree of parallelism, the author characterizes the parallelization and the communication overheads in the system considered. Then, parallel applications are modeled and their execution times are expressed for the general case of nonidentical tasks and workstations. The general case study allows the structural constraints of the applications to be taken into account by permitting their partitioning into heterogeneous tasks. A simple expression of the optimum degree of parallelism is obtained for identical tasks where the inherent constraints are neglected. The fact that the theoretical maximum speedup is bounded by half of the optimum degree of parallelism shows the importance of this measure.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.129218","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=129218","","Parallel processing;Intelligent networks;Workstations;Costs;Distributed computing;LAN interconnection;Time measurement;Velocity measurement;Concurrent computing","optimisation;parallel processing;performance evaluation","optimization;Apollo domain network;parallel computing;Apollo workstations;remote procedure call;communication overheads","","3","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Multiprocessor scheduling of processes with release times, deadlines, precedence, and exclusion relations","J. Xu","Dept. of Comput. Sci., York Univ., North York, Ont., Canada","IEEE Transactions on Software Engineering","","1993","19","2","139","154","The author presents a scheduling algorithm that solves the problem of finding a feasible nonpreemptive schedule whenever one exists on M identical processors for a given set of processes such that each process starts executing after its release time and completes its computation before its deadline. A given set of precedence relations and a given set of exclusion relations defined on ordered pairs of process segments are satisfied. This algorithm can be applied to the important problem of automated pre-run-time scheduling of processes with arbitrary precedence and exclusion relations on multiprocessors in hard-real-time systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.214831","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=214831","","Processor scheduling;Scheduling algorithm;Runtime;Computer science;Algorithm design and analysis;Timing","multiprocessing systems;real-time systems;scheduling","multiprocessor scheduling;release times;deadlines;precedence;exclusion relations;nonpreemptive schedule;automated pre-run-time scheduling;hard-real-time systems","","77","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Optimizing shadow recovery algorithms","J. Kent; H. Garcia-Molina","Dept. of Electr. Eng. & Comput. Sci., Princeton Univ., NJ, USA; Dept. of Electr. Eng. & Comput. Sci., Princeton Univ., NJ, USA","IEEE Transactions on Software Engineering","","1988","14","2","155","168","Experiments conducted on a database testbed at Princeton indicate excessive page-table I/O is the major performance drawback of shadow recovery. In light of this, a method for parameterizing shadow recovery that minimize page-table I/O without sacrificing to much disk utilization is proposed. Using a simple model, the mechanism is analyzed and evaluated, comparing it to two conventional ones.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4635","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4635","","Computer crashes;Software algorithms;Shadow mapping;Testing;Database systems;File systems;Performance analysis;Application software;Transaction databases","input-output programs;optimisation;program testing;system recovery","system recovery;optimisation;shadow recovery algorithms;database testbed;Princeton;page-table I/O;disk utilization","","6","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Language Support for Loosely Coupled Distributed Programs","M. L. Scott","Department of Computer Science, University of Rochester","IEEE Transactions on Software Engineering","","1987","SE-13","1","88","103","A distributed operating system encourages a style of programming in which independently developed processes interact in a nontrivial fashion at run time. Server processes, for example, must deal with clients that they do not understand, and certainly cannot trust. Interprocess communications can be written in a traditional, sequential language with direct calls to kernel primitives, but the result is both cumbersome and error-prone. Convenience and safety are offered by the many distributed languages proposed to date, but in a form too inflexible for anything other than the pieces of a single distributed program. A new language known as LYNX overcomes the disadvantages of both these previous approaches. Novel features of LYNX address problems encountered in the course of practical experience, writing distributed programs without high-level language support. Chief among these features are a virtual circuit abstraction called the link, and an unconventional coroutine mechanism that allows a server to maintain nested contexts for interleaved conversations with an arbitrary number of clients.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232838","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702136","Coroutines;distributed computing;late binding;links;LYNX;message passing;process independence;programming languages","Operating systems;Kernel;Safety;Distributed computing;Message passing;Computer languages;Contracts;File servers;Writing;High level languages","","Coroutines;distributed computing;late binding;links;LYNX;message passing;process independence;programming languages","","9","","58","","","","","","IEEE","IEEE Journals & Magazines"
"On Multiple Random Accesses and Physical Data Placement in Dynamic Files","Je-Hao Wang; Tak-Sun Yuen; D. H. -. Du","Research Center of Geological Tech-Economi; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","8","977","987","In the study of data storage and retrieval involving secondary storage devices, for example, magnetic disks, a simplified model of storage that is often used is that each access takes a constant amount of time. However, if some information about the accesses is known, the model should take into consideration the inherent characteristics of the storage devices. In this paper, we assume a more refined model of storage that takes into consideration the seek time, the latency time, and the transmission time of disk accesses separately. We analyze the time required to randomly access a set of records residing on a set of consecutive cylinders on a magnetic disk a number of times, say n, for n  1. This problem may arise, for example, in the processing of queries that involve several relations in a relational database system. We also analyze the more general situations in which the n operations may represent retrievals, insertions, or deletions, or a combination of them. We assume that the dynamic file structure linear hashing is used for locating and organizing the records. A linear hashing file does not employ any directory and its primary data buckets are assumed to be contiguous, therefore the data area of a linear hashing file corresponds closely to the disk space on a set of consecutive cylinders.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233515","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702315","Database management;data model;file organization;information storage and retrieval;query processing;physical design","Information retrieval;Delay;Computer science;Magnetic separation;Magnetic analysis;Memory;Magnetic devices;Magnetic heads;Engine cylinders;Relational databases","","Database management;data model;file organization;information storage and retrieval;query processing;physical design","","","","16","","","","","","IEEE","IEEE Journals & Magazines"
"A new spectral test for nonrandomness and the DES","F. A. Feldman","Dept. of Phys. & Eng., Suffolk Univ., Boston, MA, USA","IEEE Transactions on Software Engineering","","1990","16","3","261","267","A test for detecting the nonrandomness of finite binary strings is proposed. This test, based on an evaluation of the power spectrum of a finite string, extends and quantifies a similar test proposed by J. Gait (see ibid., vol.3, no.5, p.359-63, 1977). As an empirical measure of the sensitivity of the test, it was compared with a chi-square test for uniformity of distribution, which also measures nonrandomness. This comparison was performed by applying each of these tests to binary strings produced using short-round versions of the data encryption standard (DES) in output-feedback mode. By varying the number of DES rounds from 1 to 16, it was possible to gradually vary the degree of randomness of the resulting strings. The degree of randomness of the DES, including the 15 short-round versions, was also assessed. Only ensembles generated by one and two round versions were rejected as random.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.48934","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=48934","","Testing;Wideband;Gaussian noise;Statistics;Performance evaluation;Power measurement;Noise measurement;Statistical analysis;Art;Physics","cryptography;program testing;standards;statistical analysis;word processing","spectral test;nonrandomness;finite binary strings;power spectrum;empirical measure;chi-square test;short-round versions;data encryption standard;output-feedback mode;DES rounds","","1","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Comments on ""measurement of Ada overhead in OSI-style communications systems","G. M. Karam","Dept. of Syst. & Comput. Eng., Carleton Univ., Ottawa, Ont., Canada","IEEE Transactions on Software Engineering","","1990","16","12","1435","1439","The commenter disagrees with the comparison method used and questions the usefulness of the results obtained in the above named work by N.R. Howes and A.C. Weaver (see ibid., vol.15, no.12, p.1507-17, 1989). It is claimed that the comparison method is weak because Howes and Weaver did not take into account: the impact of control flow within a protocol, the coordination required between multiple entities executing within a layer and which share the services of a lower layer, and optimizations of R.J.A. Buhr's architecture (1984) which would have improved its performance efficiency.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.62440","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=62440","","Relational databases;Computer architecture;Communication system software;Protocols;Open systems;Database systems;Software measurement;Communication systems;Optimization methods;Software systems","Ada;computer communications software;open systems;programming;protocols;standards","Ada overhead;OSI-style communications systems;comparison method;control flow;protocol;coordination required;multiple entities;lower layer;optimizations;performance efficiency","","","","9","","","","","","IEEE","IEEE Journals & Magazines"
"On workload characterization of relational database environments","P. S. Yu; M. -. Chen; H. -. Heiss; S. Lee","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; NA; NA","IEEE Transactions on Software Engineering","","1992","18","4","347","355","A relational database workload analyzer (REDWAR) is developed to characterize the workload in a DB2 environment. This is applied to study a production DB2 system where a structured query language (SQL) trace for a two-hour interval and an image copy of the database catalog were obtained. The results of the workload study are summarized. The structure and complexity of SQL statements, the makeup and run-time behavior of transactions/queries, and the composition of relations and views are discussed. The results obtained provide the important information needed to build a benchmark workload to evaluate the alternative design tradeoffs of database systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.129222","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=129222","","Relational databases;Transaction databases;Image databases;Database systems;Data analysis;Runtime;Production systems;Delay;Hardware;Software design","database theory;DP management;query languages;relational databases;systems analysis","relational database workload analyzer;REDWAR;DB2 environment;structured query language;database catalog;SQL;run-time behavior;views;benchmark workload;design tradeoffs","","40","","18","","","","","","IEEE","IEEE Journals & Magazines"
"A general theory of composition for a class of ""possibilistic"" properties","J. McLean","Center for High Assurance Comput. Syst., Naval Res. Lab., Washington, DC, USA","IEEE Transactions on Software Engineering","","1996","22","1","53","67","Since the initial work of Daryl McCullough (1987) on the subject, the security community has struggled with the problem of composing ""possibilistic"" information-flow properties. Such properties fall outside of the Alpern-Schneider safety/liveness domain, and hence, they are not subject to the Abadi-Lamport Composition Principle. The paper introduces a set of trace constructors called selective interleaving functions and shows that possibilistic information-flow properties are closure properties with respect to different classes of selective interleaving functions. This provides a uniform framework for analyzing these properties, allowing us to construct both a partial ordering for them and a theory of composition for them. We present a number of composition constructs, show the extent to which each preserves closure with respect to different classes of selective interleaving functions, and show that they are sufficient for forming the general hook-up construction. We see that although closure under a class of selective interleaving functions is generally preserved by product and cascading, it is not generally preserved by feedback, internal system composition constructs, or refinement. We examine the reason for this.","0098-5589;1939-3520;2326-3881","","10.1109/32.481534","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=481534","","Interleaved codes;Information security;Flow production systems;Interconnected systems;Feedback;Refining;Laboratories;Safety","security of data;software engineering;data flow computing","possibilistic information-flow properties;trace constructors;selective interleaving functions;security;closure properties;partial ordering;composition theory;composition constructs;closure preservation;hook-up construction;product;cascading;feedback;internal system composition constructs;refinement","","65","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Detection of Mutual Inconsistency in Distributed Systems","D. S. Parker; G. J. Popek; G. Rudisin; A. Stoughton; B. J. Walker; E. Walton; J. M. Chow; D. Edwards; S. Kiser; C. Kline","Department of Computer Science, University of California; NA; NA; NA; NA; NA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1983","SE-9","3","240","247","Many distributed systems are now being developed to provide users with convenient access to data via some kind of communications network. In many cases it is desirable to keep the system functioning even when it is partitioned by network failures. A serious problem in this context is how one can support redundant copies of resources such as files (for the sake of reliability) while simultaneously monitoring their mutual consistency (the equality of multiple copies). This is difficult since network faiures can lead to inconsistency, and disrupt attempts at maintaining consistency. In fact, even the detection of inconsistent copies is a nontrivial problem. Naive methods either 1) compare the multiple copies entirely or 2) perform simple tests which will diagnose some consistent copies as inconsistent. Here a new approach, involving version vectors and origin points, is presented and shown to detect single file, multiple copy mutual inconsistency effectively. The approach has been used in the design of LOCUS, a local network operating system at UCLA.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236733","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703051","Availability;distributed systems;mutual consistency;network failures;network partitioning;replicated data","Network operating systems;Computer science;Computer crashes;Communication networks;Context;Telecommunication network reliability;Condition monitoring;Maintenance;Performance evaluation;Testing","","Availability;distributed systems;mutual consistency;network failures;network partitioning;replicated data","","106","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Executing DSP applications in a fine-grained dataflow environment","I. P. Radivojevic; J. Herath","Dept. of Electr. & Comput. Eng., California Univ., Santa Barbara, CA, USA; NA","IEEE Transactions on Software Engineering","","1991","17","10","1028","1041","An experimental approach is chosen to investigate the performance of a fine-grained dataflow architecture for numerically intensive digital signal processing (DSP) applications. The focus is on the behavior of pipelined data-parallel algorithms. However, the granularity of the high-level language programming blocks is not explicitly optimized to balance computation and communication; a natural and logical fine-grained decomposition of problems is used instead. The authors interpret their empirical data by means of parameters such as a number of instructions per generic unit of computation, a density of precedence relations, and a serial fraction. The performance and limitations of fine-grained general-purpose dataflow computing are discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.99191","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=99191","","Digital signal processing;Signal processing algorithms;Parallel processing;Computer architecture;Pipelines;Computer aided instruction;Read-write memory;Modeling;Virtual prototyping;High level languages","computerised signal processing;parallel algorithms;parallel architectures;pipeline processing","DSP applications;fine-grained dataflow architecture;numerically intensive digital signal processing;pipelined data-parallel algorithms;high-level language programming blocks;logical fine-grained decomposition;precedence relations;serial fraction;fine-grained general-purpose dataflow computing","","2","","38","","","","","","IEEE","IEEE Journals & Magazines"
"A Model for Representing Programs Using Hierarchical Graphs","S. S. Yau; P. C. Grabow","Department of Electrical Engineering and Computer Science, Northwestern University; NA","IEEE Transactions on Software Engineering","","1981","SE-7","6","556","574","In this paper a hierarchical graph model for programs based on the concepts of recursive graphs (RG's) and Codd relations is presented. The purpose of the model is to clearly represent the structure of a program implemented in a structured language, such as Pascal, Algol, or PL/1, so that the program can be analyzed and modifications to the program can be clearly specified. The model uses an RG representation for the control flow and the data flow with an equivalent relational representation. It also has a relational representation for the objects defmed within the program. The various aspects of the model are illustrated using Pascal constructs and a model for an example Pascal program is given.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.226473","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702888","Codd relations;control flow;data flow;graph grammar;hierarchical graphs;program analysis;program model;program modifications;program objects;recursive graph","Roentgenium;Database systems;Relational databases;Flow graphs;Data analysis;Contracts;Application software;Software maintenance;Performance analysis;Graphics","","Codd relations;control flow;data flow;graph grammar;hierarchical graphs;program analysis;program model;program modifications;program objects;recursive graph","","14","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Information Flow Certification Using an Intermediate Code Program Representation","A. L. Mennie; G. H. Macewen","Department of National Defence; NA","IEEE Transactions on Software Engineering","","1981","SE-7","6","594","607","This paper describes a compile-time information flow control (IFC) mechanism that certifies secure information flow within the collection of objects accessed by a program. The IFC mechanism is based on the lattice model and certification mechanism of Denning, who proposes the use of the mechanism during the analysis phase of compilation. However, IFC is placed after semantic analysis and before code optimization by ufilizing an intermediate code representation. This reduces the complexity of IFC and allows a degree of language independence. An implentation has been developed for Pascal.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.226476","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702892","Certification;compilation;information flow;intermediate code;protection;security","Certification;Information security;Lattices;Protection;Control systems;Access control;Authentication;Program processors;Councils;Information science","","Certification;compilation;information flow;intermediate code;protection;security","","3","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Improving the Performance of an Optimistic Concurrency Control Algorithm Through Timestamps and Versions","M. J. Carey","Department of Computer Sciences, University of Wisconsin","IEEE Transactions on Software Engineering","","1987","SE-13","6","746","751","This correspondence describes and analyzes two schemes for improving the performance of serial validation, an optimistic concurrency control algorithm proposed by Kutng and Robinson. It is shown that timestamp-based techniques can be used to implement serial validation, yielding an equivalent algorithm with a much lower validation cost. A multiple version variant of serial validation is then presented, and simulation results indicate that multiversion serial validation has significant performance advantages over the single version algorithm.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233479","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702279","Concurrency control;database systems;modeling and simulation;transaction processing","Concurrency control;Testing;Transaction databases;Costs;Database systems;Proposals;Performance analysis;Algorithm design and analysis;Control system synthesis;Concurrent computing","","Concurrency control;database systems;modeling and simulation;transaction processing","","5","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Optimal Dynamic Control of Resources in a Distributed System","Kang G. Shin; C. M. Krishna; Yann-hang Lee","Real-Time computing Laboratory, Department of Electrical Engineering and Computer Science, University of Massachusettes, Amherst, MA; NA; NA","IEEE Transactions on Software Engineering","","1989","15","10","1188","1198","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1989.559767","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=559767","","Optimal control;Control systems;Decision theory;Degradation;Application software;Switches;Bandwidth;Distributed computing;Power system reliability;Environmental management","","Markov decision process;optimization;performabilily;reconfiguration;repair;resource control","","16","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Sufficient conditions for existence of a fixed point in stochastic reward net-based iterative models","V. Mainkar; K. S. Trivedi","AT&T Bell Labs., Holmdel, NJ, USA; AT&T Bell Labs., Holmdel, NJ, USA","IEEE Transactions on Software Engineering","","1996","22","9","640","653","Stochastic Petri net models of large systems that are solved by generating the underlying Markov chain pose the problem of largeness of the state-space of the Markov chain. Hierarchical and iterative models of systems have been used extensively to solve this problem. A problem with models which use fixed-point iteration is the theoretical proof of the existence, uniqueness and convergence of the fixed-point equations, which still remains an ""art"". In this paper, we establish conditions, in terms of the net structure and the characteristics of the iterated variables, under which existence of a solution is guaranteed when fixed-point iteration is used in stochastic Petri nets. We use these conditions to establish the existence of a fixed point for a model of a priority scheduling system, at which tasks may arrive according to a Poisson process or due to spawning or conditional branching of other tasks in the system.","0098-5589;1939-3520;2326-3881","","10.1109/32.541435","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=541435","","Sufficient conditions;Stochastic processes;Equations;Petri nets;Stochastic systems;Power system modeling;State-space methods;Workstations;Laboratories;Iterative methods","stochastic systems;Petri nets;iterative methods;large-scale systems;Markov processes;state-space methods;hierarchical systems;scheduling;stochastic processes;queueing theory","sufficient conditions;fixed-point iteration;stochastic reward net-based iterative models;stochastic Petri nets;large systems;Markov chain;state-space size;hierarchical models;iterative models;fixed-point equations;existence proof;uniqueness proof;convergence proof;net structure;iterated variables;priority scheduling system;task arrival;Poisson process;spawning;conditional branching","","47","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Formal methods applied to a floating-point number system","G. Barrett","Programming Res. Group, Oxford Univ., UK","IEEE Transactions on Software Engineering","","1989","15","5","611","621","A formalization of the IEEE standard for binary floating-point arithmetic (ANSI/IEEE Std. 754-1985) is presented in the set-theoretic specification language Z. The formal specification is refined into four sequential components, which unpack the operands, perform the arithmetic, and pack and round the result. This refinement follows proven rules and so demonstrates a mathematically rigorous method of program development. In the course of the proofs, useful internal representations of floating-point numbers are specified. The procedures presented form the basis for the floating-point unit of the Inmos IMS T800 transputer.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24710","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24710","","Testing;Natural languages;Floating-point arithmetic;Formal specifications;Specification languages;Packaging;Algorithm design and analysis;Costs;Formal verification","digital arithmetic;specification languages","formal methods;floating-point number system;formalization;IEEE standard;binary floating-point arithmetic;ANSI/IEEE Std. 754-1985;set-theoretic specification language;Z;formal specification;sequential components;unpack;operands;pack;round;proven rules;mathematically rigorous method;program development;internal representations;floating-point unit;Inmos IMS T800 transputer","","45","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Site Initialization, Recovery, and Backup in a Distributed Database System","R. Attar; P. A. Bernstein; N. Goodman","Department of Research and Development, Computer Division, Israeli Discount Bank.; Sequoia Systems, Inc., Marlborough, MA 01752.; Sequoia Systems, Inc., Marlborough, MA 01752.","IEEE Transactions on Software Engineering","","1984","SE-10","6","645","650","Site initialization is the problem of integrating a new site into a running distributed database system (DDBS). Site recovery is the problem of integrating an old site into a DDBS when the site recovers from failure. Site backup is the problem of creating a static backup copy of a database for archival or query purposes. We present an algorithm that solves the site initialization problem. By modifying the algorithm slightly, we get solutions to the other two problems as well. Our algorithm exploits the fact that a correct DDBS must run a serializable concurrency control algorithm. Our algorithm relies on the concurrency control algorithm to handle all intersite synchronization.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010293","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010293","Distributed database systems;fault recovery;site initialization","Database systems;Concurrency control;Transaction databases;Contracts;Concurrent computing;Research and development","","","","24","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Matching Secrets in the Absence of a Continuously Available Trusted Authority","C. Meadows; D. Mutchler","Naval Research Laboratory; NA","IEEE Transactions on Software Engineering","","1987","SE-13","2","289","292","The problem of authentication of mutually suspicious parties is one that is becoming more and more important with the proliferation of distributed systems. In this paper we describe a protocol, based on the difficulty of finding discrete logarithms over finite fields, by which users can verify whether they have matching credentials without revealing their credentials to each other unless there is a match. This protocol requires a trusted third party, but does not require it to be available to the users except when they sign up for the system. Thus it is useful in situations in which a trusted third party exists but is not available to all users at all times.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233152","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702207","Authentication;cryptographic protocols;discrete logarithms;distributed systems;finite fields;matchmaking protocols;public-key cryptography","Cryptographic protocols;Authentication;Galois fields;Public key cryptography;Employment","","Authentication;cryptographic protocols;discrete logarithms;distributed systems;finite fields;matchmaking protocols;public-key cryptography","","","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Validating a demonstration tool for graphics-assisted debugging of Ada concurrent programs","M. B. Feldman; M. L. Moran","Sch. of Eng. & Appl. Sci., George Washington Univ., Washington, DC, USA; NA","IEEE Transactions on Software Engineering","","1989","15","3","305","313","A demonstration-quality graphics-assisted debugger is developed for intertask communication in Ada. Based on the static task-specification diagrams of G. Booch (Software Engineering with Ada, Benjamin/Cummings, 1983), the debugger animates the activity of a collection of communicating tasks, and it runs on a DEC GIGI terminal connected to a VAX 11-780 under TeleSoft's partial Ada compiler. The model has been subjected to empirical validation, using undergraduate students as experimental subjects. Subjects were required to debug erroneous tasking programs using both the graphical debugger and a textual one. It is concluded that although the problems to be addressed in the development and evaluation of a graphical debugging tool for Ada tasks are nontrivial, the benefits could be worth the effort.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21758","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21758","","Debugging;Concurrent computing;Programming profession;Fault detection;Phase detection;Psychology;Graphics;Workstations;Costs;Animation","Ada;computer graphics;parallel programming;program debugging;program verification;software tools","demonstration tool;graphics-assisted debugging;Ada concurrent programs;intertask communication;static task-specification diagrams;communicating tasks;DEC GIGI terminal;VAX 11-780;partial Ada compiler;tasking programs;graphical debugger","","","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Distributed Software System Design Representation Using Modified Petri Nets","S. S. Yau; M. U. Caglayan","Department of Electrical Engineering and Computer Science, Northwestern University; NA","IEEE Transactions on Software Engineering","","1983","SE-9","6","733","745","A model for representing and analyzing the design of a distributed software system is presented. The model is based on a modified form of Petri net, and enables one to represent both the structure and the behavior of a distributed software system at a desired level of design. Behavioral properties of the design representation can be verified by translating the modified Petri net into an equivalent ordinary Petri net and then analyzing that resulting Petri net. The model emphasizes the unified representation of control and data flows, partially ordered software components, hierarchical component structure, abstract data types, data objects, local control, and distributed system state. At any design level, the distributed software system is viewed as a collection of software components. Software components are externally described in terms of their input and output control states, abstract data types, data objects, and a set of control and data transfer specifications. They are interconnected through the shared control states and through the shared data objects. A system component can be viewed internally as a collection of subcomponents, local control states, local abstract data types, and local data objects.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.235581","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703118","Control flow and data flow;design analysis;distributed software system;modified Petri net;software design representation","Software systems;Software design;Petri nets;Distributed computing;Distributed control;Control systems;Hardware;Design methodology;Concurrent computing;Computer languages","","Control flow and data flow;design analysis;distributed software system;modified Petri net;software design representation","","23","","40","","","","","","IEEE","IEEE Journals & Magazines"
"SLAN-4-A software specification and design language","F. W. Beichter; O. Herzog; H. Petzsch","IBM Laboratories, Boeblingen, West Germany.; IBM Laboratories, Boeblingen, West Germany.; IBM Laboratories, Boeblingen, West Germany.","IEEE Transactions on Software Engineering","","1984","SE-10","2","155","162","SLAN-4 (""Software Language-4"") was developed to meet the need for a formal tool for specifying and designing large software systems. It provides language constructs for algebraic and axiomatic specifications and also pseudocode constructs for the design step. A major design goal was to ease subsequent refinements of a (given) specification. The design can start with a very informal specification, which can be implemented later using lower level concepts. This paper gives an overview of the SLAN-4 syntax and semantics. It concentrates on the most important aspects of: abstract data types, algebraic specification of abstract data types, and axiomatic specification of modules. Because the pseudocode part of SLAN-4 consists mainly of control structures similar to those in modern high-level programming languages, this element of the language is not separately described. The paper includes an example of how to use SLAN-4, and also the experiences gained in using the language to formally specify a real-world software product of about 18 000 lines of code written in an IBM internal high-level language.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010217","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010217","","Software design;Computer languages;Software systems;Software tools;Process design;Specification languages;High level languages;History;Algorithm design and analysis","","","","12","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Semantics-based inference algorithms for adaptive visual environments","F. Ferrucci; G. Tortora; M. Tucci; G. Vitiello","Dipartimento di Inf. ed Applicazioni, Salerno Univ., Italy; Dipartimento di Inf. ed Applicazioni, Salerno Univ., Italy; Dipartimento di Inf. ed Applicazioni, Salerno Univ., Italy; Dipartimento di Inf. ed Applicazioni, Salerno Univ., Italy","IEEE Transactions on Software Engineering","","1996","22","10","730","750","The paper presents a grammatical inference methodology for the generation of visual languages, that benefits from the availability of semantic information about the sample sentences. Several well-known syntactic inference algorithms are shown to obey a general inference scheme, which the authors call the Gen-Inf scheme. Then, all the algorithms of the Gen-Inf scheme are modified in agreement with the introduced semantics-based inference methodology. The use of grammatical inference techniques in the design of adaptive user interfaces was previously experimented with the VLG system for visual language generation. The system is a powerful tool for specifying, designing, and interpreting customized visual languages for different applications. They enhance the adaptivity of the VLG system to any visual environment by exploiting the proposed semantics-based inference methodology. As a matter of fact, a more general model of visual language generation is achieved, based on the Gen-Inf scheme, where the end-user is allowed to choose the algorithm which best fits his/her requirements within the particular application environment.","0098-5589;1939-3520;2326-3881","","10.1109/32.544351","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=544351","","Inference algorithms;User interfaces;Chromium;Senior members;Power system modeling;Pattern recognition;Artificial intelligence;Computer languages;Process design;Image processing","visual languages;grammars;computational linguistics;adaptive systems;graphical user interfaces;user interface management systems","semantics-based inference algorithms;adaptive visual environments;grammatical inference methodology;visual language generation;semantic information;sample sentences;syntactic inference algorithms;Gen-Inf scheme;adaptive user interface design;customized visual language specification;customized visual language interpretation;customized visual language design","","2","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Experience with the accuracy of software maintenance task effort prediction models","M. Jorgensen","Oslo Univ., Norway","IEEE Transactions on Software Engineering","","1995","21","8","674","681","The paper reports experience from the development and use of eleven different software maintenance effort prediction models. The models were developed applying regression analysis, neural networks and pattern recognition and the prediction accuracy was measured and compared for each model type. The most accurate predictions were achieved applying models based on multiple regression and on pattern recognition. We suggest the use of prediction models as instruments to support the expert estimates and to analyse the impact of the maintenance variables on the maintenance process and product. We believe that the pattern recognition based models evaluated, i.e., the prediction models based on the Optimized Set Reduction method, show potential for such use.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.403791","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=403791","","Software maintenance;Predictive models;Programming;Pattern recognition;Application software;Neural networks;Regression analysis;Instruments;Optimization methods;Software measurement","software maintenance;statistical analysis;pattern recognition;neural nets","software maintenance task effort prediction models;regression analysis;neural networks;pattern recognition;prediction accuracy;model type;multiple regression;prediction models;expert estimates;maintenance variables;maintenance process;pattern recognition based models;Optimized Set Reduction method","","139","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Evaluating database update schemes: a methodology and its applications to distributive systems","K. C. Kinsley; C. E. Hughes","Datawise Inc., Orlando, FL, USA; NA","IEEE Transactions on Software Engineering","","1988","14","8","1081","1089","A methodology is presented for evaluating the performance of database update schemes in a distributive environment. The methodology makes use of the history of how data are used in the database. Parameters such as update-to-retrieval ratio and average file size can be set based on the actual characterization of a system. The analysis is specifically directed toward the support of derived data within the relational model. Because concurrency is a major problem in a distributive system, the support of derived data is analyzed with respect to three distributive concurrency control techniques: master/slave, distributed, and synchronized.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.7618","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=7618","","Concurrent computing;History;Concurrency control;Relational databases;Queueing analysis;Analytical models;Data analysis;Computer science;Costs;Terminology","database theory;distributed databases;performance evaluation;queueing theory;relational databases","distributed databases;queueing theory;performance analysis;database update schemes;distributive systems;relational model;concurrency control","","1","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Dynamic transaction routing in distributed database systems","P. S. Yu; S. Balsamo; Y. -. Lee","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; NA; NA","IEEE Transactions on Software Engineering","","1988","14","9","1307","1318","The authors investigate dynamic transaction routing strategies for locally distributed database systems in which the database is partitioned and distributed among multiple transaction-processing systems, and the incoming transactions are routed by a common front-end processor. If a transaction issues a database request referencing a nonlocal database partition, the request has to be shipped to the system owing the referenced partition for processing. Various dynamic strategies are studied. Their performance is compared with that of the optimal static strategy. A class of dynamic transaction routing strategies which take into account routing history and minimize the estimated response time of incoming transactions is proposed; they are found to provide a substantial improvement over the optimal static strategy. The robustness of the strategies is further studied through sensitivity analysis over various transaction loads, communication overheads, and database reference distributions.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6174","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6174","","Routing;Database systems;Transaction databases;Delay;Queueing analysis;History;Robustness;Sensitivity analysis;Load management;Power system modeling","database theory;distributed databases;transaction processing","distributed database;dynamic transaction routing;multiple transaction-processing systems;common front-end processor;database request;response time;sensitivity analysis;communication overheads;database reference distributions","","15","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Structural approach to the estimation of the number of residual software faults based on the hyper-geometric distribution","Y. Tohma; K. Tokunaga; S. Nagase; Y. Murata","Dept. of Comput. Sci., Tokyo Inst. of Technol., Japan; Dept. of Comput. Sci., Tokyo Inst. of Technol., Japan; Dept. of Comput. Sci., Tokyo Inst. of Technol., Japan; Dept. of Comput. Sci., Tokyo Inst. of Technol., Japan","IEEE Transactions on Software Engineering","","1989","15","3","345","355","Models based on the hyper-geometric distribution for estimating the number of residual software faults are proposed. The application of the basic model shows that its fit to real data is good. Two ways of improving the model, using a segmentation technique and composite estimation, respectively, are shown. The segmentation technique appears quite effective, particularly when the growth curve of the cumulative number of detected faults bends sharply. The applications of these models to real data are demonstrated.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21762","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21762","","Software testing;Application software;Hardware;Fault detection;Software debugging;Solid modeling;Costs;Redundancy;Computer applications","program debugging;programming theory;software reliability;statistical analysis","hypergeometric distribution;debugging;software reliability;residual software faults;hyper-geometric distribution;segmentation technique;composite estimation;growth curve","","68","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Access Control with Single-Key-Lock","M. Wu; T. Hwang","Department of Mathematical Engineering, Information Engineering Laboratory, University of Tokyo, Bundyoku, Tokyo 113, Japan.; Institute for Information Industry, Taipei, Taiwan, Republic of China.","IEEE Transactions on Software Engineering","","1984","SE-10","2","185","191","Based on the concept of an access matrix, a new protection system that achieves access control is proposed. In this system, associated with each accessor is only a key, and associated with each resource is only a lock, and through simple operations on the keys and locks, privacy decisions of the protection system can be revealed. Amechanism that realizes this system is also described. Noticing the importance of the role hierarchies play in access control, another mechanism is devised such that each node in the hierarchy is assigned a key and a simple operation on any two keys reveals the relationship of the two nodes corresponding to the two keys.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010221","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010221","Access control;access control hierarchy;access matrix;key;lock;protection;security","Access control;Protection;Privacy;Information resources;Law;Legal factors;Information security;Operating systems;Laboratories;Optical character recognition software","","","","35","","11","","","","","","IEEE","IEEE Journals & Magazines"
"A synthesis of software science measures and the cyclomatic number","B. Ramamurthy; A. Melton","Dept. of Comput. Sci., State Univ. of New York, Buffalo, NY, USA; NA","IEEE Transactions on Software Engineering","","1988","14","8","1116","1121","A solution is obtained to the problem of defining a software measure or a family of measures which simultaneously detect those aspects of software complexity that are detected by the software science measures and the cyclomatic number. The authors present a family of measures, called weighted measures that is built on the software science measures by adding weights to certain operators and operands; the size of the weights is determined by a theorem which relates nesting levels and the cyclomatic number. Thus, by construction the weighted measures synthesize the software science measures and the cyclomatic number. Further, by applying the weighted measures, the software science measures, and the cyclomatic number to sample programs, it is shown that the weighted measures also synthesize in practice the software science measures and the cyclomatic number.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.7622","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=7622","","Software measurement;Weight measurement;Time measurement;Coordinate measuring machines;Particle measurements;Fluid flow measurement;Computer science","computational complexity;software engineering","software engineering;software science measures;cyclomatic number;software complexity;weighted measures;nesting levels","","16","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Weak Mutation Testing and Completeness of Test Sets","W. E. Howden","Department of Electrical Engineering and Computer Science, University of California at San Diego","IEEE Transactions on Software Engineering","","1982","SE-8","4","371","379","Different approaches to the generation of test data are described. Error-based approaches depend on the definition of classes of commonly occurring program errors. They generate tests which are specifically designed to determine if particular classes of errors occur in a program. An error-based method called weak mutation testing is described. In this method, tests are constructed which are guaranteed to force program statements which contain certain classes of errors to act incorrectly during the execution of the program over those tests. The method is systematic, and a tool can be built to help the user apply the method. It is extensible in the sense that it can be extended to cover additional classes of errors. Its relationship to other software testing methods is discussed. Examples are included.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235571","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702959","Complete;effective;mutations;testing","Genetic mutations;Software testing;Computer errors;Guidelines;System testing;Software engineering;Programming profession;Indexing","","Complete;effective;mutations;testing","","217","","29","","","","","","IEEE","IEEE Journals & Magazines"
"QBD*: a graphical query language with recursion","M. Angelaccio; T. Catarci; G. Santucci","Dipartimento di Ingegneria Elettronica, Roma II Univ., Italy; NA; NA","IEEE Transactions on Software Engineering","","1990","16","10","1150","1163","A system to query databases using diagrams as a standard user interface is proposed. The system, called Query by Diagram* (QBD*), makes use of a conceptual data model, a query language on this model, and a graphical user interface. The conceptual model is the entity-relationship model. The query language, whose expressive power allows recursive queries, supports visual interaction. The main characteristics of the interface are ease of use and the availability of a rich set of primitives for schema selection and query formulation. The expressive power of QBD* and G/sup +/, which are the only languages allowing recursive queries to be expressed graphically are compared.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.60295","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=60295","","Design for quality;Database languages;Power system modeling;Visual databases;Data mining;User interfaces;Data models;Graphical user interfaces;Spatial databases;Human computer interaction","graphical user interfaces;information retrieval;query languages","QBD*;graphical query language;recursion;databases;standard user interface;Query by Diagram*;conceptual data model","","74","","38","","","","","","IEEE","IEEE Journals & Magazines"
"An Alphard Specification of a Correct and Efficient Transformation on Data Structures","J. L. Bentley; M. Shaw","Departments of Computer Science and Mathematics, Carnegie-Mellon University; NA","IEEE Transactions on Software Engineering","","1980","SE-6","6","572","584","In this paper we study the problem of designing and specifying standard program components applicable to a wide variety of tasks; we choose for this study the specific problem domain of data structures for general searching problems. Within this domain Bentley and Saxe [1] have developed transformations for converting solutions of simple searching problems to solutions of more complex problems. We discuss one of those transformations, specify precisely the transformation and its conditions of applicability, and prove its correctness; we accomplish this by casting it in terms of abstract data typesspecifically by using the Alphard form mechanism. The costs of the structures derived by this transformation are only slightly greater than the costs of the original structures, and the correctness of the transformation definition together with the correctness of the original structure assure the correctness of the derived structure. The transformation we describe has already been used to develop a number of new algorithms, and it represents a new level of generality in software engineering tools.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234506","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702784","Abstract data types;generic definitions;program verification;searching problems;transformations on data structures","Data structures;Costs;Software engineering;Computer science;Casting;Software algorithms;Mathematics;Merging","","Abstract data types;generic definitions;program verification;searching problems;transformations on data structures","","2","","6","","","","","","IEEE","IEEE Journals & Magazines"
"Computer Program Schemata and the Processes They Generate","T. C. Wesselkamper","Department of Computer Science, Hunter College, City University of New York","IEEE Transactions on Software Engineering","","1982","SE-8","4","412","419","This paper develops definitions for a program schema, the execution of such a program schema, and a process generated by a program schema. Results due to Hartfiel are used to characterize the cone of stochastic eigenvectors of the class of homogeneous Markov processes generated by a program schema. The stochastic behavior vector of a process generated by the same schema is shown to lie in this cone. In the case of a cyclic structured program schema, all of the vertices of the base of the cone are exactly generated by the circuits of the schema. Some directions for future work are suggested.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235575","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702963","Cyclic structured program;homogeneous Markov process;process;program execution;program schema;state frequency vector;state transition matrix;stochastic eigenvector;strongly connected graph","Stochastic processes;Markov processes;Circuits;Computer science;Character generation;Frequency;Virtual manufacturing","","Cyclic structured program;homogeneous Markov process;process;program execution;program schema;state frequency vector;state transition matrix;stochastic eigenvector;strongly connected graph","","2","","5","","","","","","IEEE","IEEE Journals & Magazines"
"An entity-relationship programming language","A. Malhotra; H. M. Markowitz; Y. Tsalalikhin; D. P. Pazel; L. M. Burns","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1989","15","9","1120","1130","The syntax for an integrated E-R programming language is presented. The problems that arise when a query language is embedded in a general-purpose programming language are discussed. Other E-R languages are also discussed. The requirements for the language and a syntax for an E-R model in which entity sets are mutually disjoint and each entity type has a unique, perhaps multiattribute, key are presented. The syntax for a more limited model restricted to binary relationships between entity types and without attributes is presented. Some implementation considerations are discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.31369","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=31369","","Computer languages;Database languages;Data models;Relational databases;Runtime environment;Environmental economics;Finance","high level languages","entity-relationship programming language;syntax;integrated E-R programming language;query language;general-purpose programming language;entity sets;mutually disjoint;entity type;unique;multiattribute;key;binary relationships","","4","","34","","","","","","IEEE","IEEE Journals & Magazines"
"Necessary and sufficient ergodicity condition for open synchronized queueing networks","G. Florin; S. Natkin","Conservatoire Nat. des Arts et Metiers, Paris, France; Conservatoire Nat. des Arts et Metiers, Paris, France","IEEE Transactions on Software Engineering","","1989","15","4","367","380","A necessary and sufficient ergodicity condition for complex open queueing systems is given. The queueing networks considered belong to a particular class of unbounded Markov stochastic Petri nets. These systems can include synchronization features like fork and join arrivals and departures, and feedback between behavior of different queues. Grouped and correlated arrivals and departures are also allowed. An example and a proof of the ergodicity results are presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.16598","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=16598","","Petri nets;Stochastic processes;Cost accounting;Distributed computing;Steady-state;Sufficient conditions;Feedback;Network servers;Inhibitors","Markov processes;Petri nets;queueing theory;synchronisation","open synchronized queueing networks;ergodicity condition;queueing networks;unbounded Markov stochastic Petri nets;synchronization features;fork;join","","21","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Chidamber and Kemerer's metrics suite: a measurement theory perspective","M. Hitz; B. Montazeri","Inst. fur Angewandte Inf. und Informationssyst., Wien Univ., Austria; Inst. fur Angewandte Inf. und Informationssyst., Wien Univ., Austria","IEEE Transactions on Software Engineering","","1996","22","4","267","271","The metrics suite for object-oriented design put forward by Chidamber and Kemerer (1994) is partly evaluated by applying principles of measurement theory. Using the object coupling measure (CBO) as an example, it is shown that failing to establish a sound empirical relation system can lead to deficiencies of software metrics. Similarly, for the object-oriented cohesion measure (LCOM) it is pointed out that the issue of empirically testing the representation condition must not be ignored, even if other validation principles are carefully obeyed. As a by-product, an alternative formulation for LCOM is proposed.","0098-5589;1939-3520;2326-3881","","10.1109/32.491650","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=491650","","Software measurement;Software metrics;Testing;Software design;Guidelines;Process design;Ontologies;Network-on-a-chip;Programming profession;Predictive models","software metrics;object-oriented methods;object-oriented programming;program testing;program verification","metrics suite;object-oriented design;measurement theory;partial evaluation;object coupling measure;sound empirical relation system;software metrics;object-oriented cohesion measure;empirical testing;representation condition;validation principles","","64","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Spanner: A Tool for the Specification, Analysis, and Evaluation of Protocols","S. Aggarwal; D. Barbara; K. Z. Meth","Bellcore; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","12","1218","1237","SPANNER is a software package for the specification, analysis, and evaluation of protocols. It is based on a mathematical model of coordinating processes called the selection/resolution model.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232877","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702175","Analysis and verification;communication protocols;formal description techniques;formal specifeation;software environment;software tools;specification languages","Protocols;Mathematical model;Specification languages;Databases;Software tools;Formal specifications;Kalman filters;Software packages;Information analysis;Distributed computing","","Analysis and verification;communication protocols;formal description techniques;formal specifeation;software environment;software tools;specification languages","","12","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Petri net tools for the specification and analysis of discrete controllers","R. G. Willson; B. H. Krogh","Dept. of Electr. & Comput. Eng., Carnegie-Mellon Univ., Pittsburgh, PA, USA; Dept. of Electr. & Comput. Eng., Carnegie-Mellon Univ., Pittsburgh, PA, USA","IEEE Transactions on Software Engineering","","1990","16","1","39","50","An approach is presented for the specification, modeling, and analysis of discrete-state systems and controllers. The approach features a rule-based state-variable-specification formalism that is translated into Petri net models composed of interconnected state machines. The concept of reduced reachability graphs is introduced as a means of reducing the computational effort required to isolate and analyze subcomponent behavior within the system. The target application is discrete manufacturing systems where the costs involved in writing, debugging, and maintaining of code for online process control can be significantly reduced through the use of automated modeling and analysis techniques. The approach is illustrated by an example of a simple discrete-state system.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44362","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44362","","Control systems;Process control;Petri nets;Control system synthesis;Costs;Automatic control;Debugging;Programmable control;Mathematical model;Robots","computerised control;controllers;discrete systems;formal specification;Petri nets","Petri net tools;specification;discrete controllers;modeling;discrete-state systems;rule-based state-variable-specification formalism;interconnected state machines;reduced reachability graphs;discrete manufacturing systems","","36","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Dynamic analysis of the effects access rule modifications have upon security","R. P. Trueblood; A. Sengupta","Department of Computer Science, University of South Carolina, Columbia, SC 29208; Department of Computer Science, University of South Carolina, Columbia, SC 29208","IEEE Transactions on Software Engineering","","1986","SE-12","8","866","870","A technique is presented for analyzing the relationships among the predicates in a predicate-based security model for database management systems. The principal tool of the technique is the Boolean difference, which is used to examine the relationships among the predicates when users are allowed to be members of more than one user group. The effects of deleting or adding predicates on the user group definition are identified by the technique. The technique is most valuable to information security authorizers who define and maintain access-control rules.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312989","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312989","Access control;analysis of access rights;authorization;Boolean difference;security","Databases;Personnel;Permission;Authorization;Probes","Boolean algebra;database theory;security of data","access rule modifications;predicate-based security model;database management systems;Boolean difference;information security;access-control rules","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"A query algebra for program databases","S. Paul; A. Prakash","IBM Thomas J. Watson Res. Center, Hawthorne, NY, USA; NA","IEEE Transactions on Software Engineering","","1996","22","3","202","217","Querying source code is an essential aspect of a variety of software engineering tasks such as program understanding, reverse engineering, program structure analysis and program flow analysis. In this paper, we present and demonstrate the use of an algebraic source code query technique that blends expressive power with query compactness. The query framework of Source Code Algebra (SCA) permits users to express complex source code queries and views as algebraic expressions. Queries are expressed on an extensible, object-oriented database that stores program source code. The SCA algebraic approach offers multiple benefits such as an applicative query language, high expressive power, seamless handling of structural and flow information, clean formalism and potential for query optimization. We present a case study where SCA expressions are used to query a program in terms of program organization, resource flow, control flow, metrics and syntactic structure. Our experience with an SCA-based prototype query processor indicates that an algebraic approach to source code queries combines the benefits of expressive power and compact query formulation.","0098-5589;1939-3520;2326-3881","","10.1109/32.489080","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=489080","","Algebra;Data mining;Software maintenance;Reverse engineering;Database languages;Software systems;Humans;Software tools;Software engineering;Documentation","software engineering;reverse engineering;program diagnostics;query processing;process algebra;object-oriented databases","query algebra;syntactic structure;program databases;compact query formulation;software engineering;program understanding;reverse engineering;program structure analysis;program flow analysis;expressive power;query compactness;Source Code Algebra;algebraic expressions;extensible object-oriented database;applicative query language;seamless information handling;structural information;flow information;clean formalism;query optimization;program organization;resource flow;control flow;software metrics","","25","","34","","","","","","IEEE","IEEE Journals & Magazines"
"A Generalized Implementation Method for Relational Data Sublanguages","L. L. Beck","Department of Computer Science and Engineering, Southern Methodist University","IEEE Transactions on Software Engineering","","1980","SE-6","2","152","162","A set of primitive operations on tuples is derived; it is shown that these operations are necessary and sufficient for the implementation tion of any language equivalent in power to the relational algebra. The translation of queries from a variety of relational languages into these tuple operations is discussed and illustrated with several examples. A method is given for the conversion of such a translated query into a network of processes and files. An optimization algorithm which operates on this network is described and demonstrated. Using this method, many different relational languages can be implemented using the same data management software; furthermore, the underlying software can be changed without requiring any changes at the user interface. This approach should yield great benefits in reduced cost and increased flexibility of implementation.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230466","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702712","DBMS independence;process networks;query optimization;relational database implementation;relational query processing;relational query translation","Algebra;Query processing;Relational databases;Calculus;Switches;User interfaces;Data models;Prototypes;Authorization;Computer science","","DBMS independence;process networks;query optimization;relational database implementation;relational query processing;relational query translation","","","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Analysis of hybrid concurrency control schemes for a high data contention environment","P. S. Yu; D. M. Dias","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA","IEEE Transactions on Software Engineering","","1992","18","2","118","129","Analytical models are developed to study hybrid CC (concurrency control) schemes which employ a different CC scheme to handle rerun transactions, since their characteristics are different from the first run of transactions. These include switching to static or dynamic locking during rerun (referred to as static and dynamic hybrid OCC (optimistic concurrency control) schemes, respectively), and switching to broadcast OCC during rerun, while doing pure OCC for the first run. In a high data contention environment where locking is inferior to OCC, analysis shows that the performance can be substantially improved by using this hybrid approach and the authors study the tradeoff of the different hybrid CC schemes. The analytic models are based on a decomposition approach and use a mean-value-type analysis. The accuracy of the analysis is validated through simulations.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.121754","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=121754","","Concurrency control;Broadcasting;Performance analysis;Transaction databases;Analytical models;Hardware;Memory management;Delay","concurrency control;database theory;optimisation;transaction processing","hybrid concurrency control schemes;hybrid CC;CC scheme;rerun transactions;dynamic locking;dynamic hybrid OCC;optimistic concurrency control;broadcast OCC;high data contention environment;hybrid approach;analytic models;decomposition approach;mean-value-type analysis","","22","","34","","","","","","IEEE","IEEE Journals & Magazines"
"A model of code sharing for estimating software failure on demand probabilities","J. H. R. May; A. D. Lunn","Dept. of Comput., Open Univ., Milton Keynes, UK; NA","IEEE Transactions on Software Engineering","","1995","21","9","747","753","A statistical software testing model is proposed in which white box factors have a role. The model combines test adequacy notions with statistical analysis, and in so doing provides a rudimentary treatment of dependencies between test results caused by the execution of common code during the tests. The model is used to estimate the probability of failure on demand for software performing safety shutdown functions on large plants and concerns the case where extensive test results are available on the latest version of the software, none of which have resulted in software failure. According to the model, there are circumstances in which some current statistical models for dynamic software testing are too conservative, and others are not conservative, depending on the software architecture.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.464546","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=464546","","Software safety;Probability;Software testing;Software performance;Steady-state;Statistical analysis;Software reliability;Phase frequency detector;Sampling methods;Performance evaluation","statistical analysis;program testing;probability;program diagnostics;safety-critical software","code sharing;software failure estimation;statistical software testing model;white box factors;test adequacy notions;statistical analysis;common code execution;software failure on demand probability;safety shutdown functions;software testing","","4","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Assessment of Software Reliability Models","R. Troy; R. Moawad","VERILOG; NA","IEEE Transactions on Software Engineering","","1985","SE-11","9","839","849","This paper proposes a method for assessing software reliability models and its application to the Musa and Littlewood-Verrall models. It is divided into two parts.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232543","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702103","Model comparisons;software reliability","Software reliability;Taxonomy;Application software;Databases;Predictive models;Reliability theory;Software engineering;Quality assurance;Certification;Software measurement","","Model comparisons;software reliability","","4","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Experiments on the Knee Criterion in a Multiprogrammed Computer System","T. Nishigaki","Systems Development Laboratory, Hitachi, Ltd.","IEEE Transactions on Software Engineering","","1983","SE-9","1","79","86","Although the effectiveness of the knee criterion [7] as a virtual memory management strategy is widely accepted, it has been impossible to take advantage of it in a practical system, because little information is available about the program behavior of executing jobs.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236297","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703014","Memory management;multiprogramming;program behavior;operating system;resource scheduling;storage allocation;virtual memory;working set","Knee;Memory management;Abstracts;History;Smoothing methods;Resource management;Throughput;Operating systems","","Memory management;multiprogramming;program behavior;operating system;resource scheduling;storage allocation;virtual memory;working set","","3","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Analyzing regression test selection techniques","G. Rothermel; M. J. Harrold","Dept. of Comput. Sci., Oregon State Univ., Corvallis, OR, USA; NA","IEEE Transactions on Software Engineering","","1996","22","8","529","551","Regression testing is a necessary but expensive maintenance activity aimed at showing that code has not been adversely affected by changes. Regression test selection techniques reuse tests from an existing test suite to test a modified program. Many regression test selection techniques have been proposed, however, it is difficult to compare and evaluate these techniques because they have different goals. This paper outlines the issues relevant to regression test selection techniques, and uses these issues as the basis for a framework within which to evaluate the techniques. The paper illustrates the application of the framework by using it to evaluate existing regression test selection techniques. The evaluation reveals the strengths and weaknesses of existing techniques, and highlights some problems that future work in this area should address.","0098-5589;1939-3520;2326-3881","","10.1109/32.536955","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=536955","","Software testing;Software maintenance;Costs;Production;Performance evaluation;Computer science;Information science;Computational efficiency;Software measurement","program testing;program debugging;software maintenance;statistical analysis;software reusability","regression test selection techniques;software maintenance;program test reuse;test suite;framework;selective retest","","293","","46","","","","","","IEEE","IEEE Journals & Magazines"
"Analysis of software availability/reliability under the influence of hardware failures","U. Sumita; Y. Masuda","Graduate School of Management, University of Rochester, Rochester, NY 14627; Graduate School of Management, University of Rochester, Rochester, NY 14627","IEEE Transactions on Software Engineering","","1986","SE-12","1","32","41","A new hardware-software reliability model is developed where lifetimes and repair times of the software subsystem have general system state-dependent distributions. The hardware subsystem constitutes an independent alternating renewal process having exponential up-times and general down-times. Multiple errors may be introduced or removed through repairs. The model is formulated as a multivariate stochastic process. To study the performance of the software subsystem under the influence of hardware failures, expressions of various time dependent performance measures are derived. Using the matrix Laguerre transform of U. Sumita (1984), corresponding computational procedures are also developed. A numerical example is given demonstrating the speed, accuracy, and stability of these procedures.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312917","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312917","Integrated hardware-software reliability model;matrix Laguerre transform;multiple error generation and removal;state-dependent general lifetimes and repair times;time-dependent compound performance measures","Hardware;Maintenance engineering;Transforms;Software systems;Vectors;Software reliability","reliability theory;software reliability","software availability;reliability;hardware failures;lifetimes;repair times;system state-dependent distributions;exponential up-times;down-times;repairs;multivariate stochastic process;time dependent performance measures;matrix Laguerre transform;computational procedures","","5","","","","","","","","IEEE","IEEE Journals & Magazines"
"A formal semantics for object model diagrams","R. H. Bourdeau; B. H. C. Cheng","Consortium of Int. Earth Sci. & Inf. Network, Saginaw, MI, USA; NA","IEEE Transactions on Software Engineering","","1995","21","10","799","821","Informal software development techniques, such as the object modeling technique (OMT), provide the user with easy to understand graphical notations for expressing a wide variety of concepts central to the presentation of software requirements. OMT combines three complementary diagramming notations for documenting requirements: object models, dynamic models, and functional models. OMT is a useful organizational tool in the requirements analysis and system design processes. Currently, the lack of formality in OMT prevents the evaluation of completeness, consistency, and content in requirements and design specifications. A formal method is a mathematical approach to software development that begins with the construction of a formal specification describing the system under development. However, constructing a formal specification directly from a prose description of requirements can be challenging. The paper presents a formal semantics for the OMT object model notations, where an object model provides the basis for the architecture of an object oriented system. A method for deriving modular algebraic specifications directly from object model diagrams is described. The formalization of object models contributes to a mathematical basis for deriving system designs.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.469459","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=469459","","Object oriented modeling;Formal specifications;System analysis and design;Software safety;Computer Society;Programming;Mathematical model;Costs;Formal languages;Software engineering","object-oriented programming;formal specification;systems analysis;algebraic specification","formal semantics;object model diagrams;informal software development techniques;object modeling technique;prose description;OMT object model notations;object oriented system;modular algebraic specifications;mathematical basis;complementary diagramming notations;object models;dynamic models;functional models;requirements analysis;system design process","","73","","36","","","","","","IEEE","IEEE Journals & Magazines"
"A technique for drawing directed graphs","E. R. Gansner; E. Koutsofios; S. C. North; K. -. Vo","AT&T Bell Labs., Murray Hill, NJ, USA; AT&T Bell Labs., Murray Hill, NJ, USA; AT&T Bell Labs., Murray Hill, NJ, USA; AT&T Bell Labs., Murray Hill, NJ, USA","IEEE Transactions on Software Engineering","","1993","19","3","214","230","A four-pass algorithm for drawing directed graphs is presented. The fist pass finds an optimal rank assignment using a network simplex algorithm. The seconds pass sets the vertex order within ranks by an iterative heuristic, incorporating a novel weight function and local transpositions to reduce crossings. The third pass finds optimal coordinates for nodes by constructing and ranking an auxiliary graph. The fourth pass makes splines to draw edges. The algorithm creates good drawings and is fast.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.221135","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=221135","","Iterative algorithms;Data visualization;Data structures;Automata;Flow graphs;Bibliographies;Spline","computer graphics;directed graphs;optimisation;splines (mathematics)","directed graphs;four-pass algorithm;optimal rank assignment;network simplex algorithm;vertex order;iterative heuristic;novel weight function;local transpositions;optimal coordinates;auxiliary graph;splines","","249","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Assessing software designs using capture-recapture methods","S. A. Vander Wiel; L. G. Votta","AT&T Bell Labs., Murray Hill, NJ, USA; NA","IEEE Transactions on Software Engineering","","1993","19","11","1045","1054","The number of faults not discovered by the design review can be estimated by using capture-recapture methods. Since these methods were developed for wildlife population estimation, the assumptions used to derive them do not match design review applications. The authors report on a Monte Carlo simulation to study the effects of broken assumptions on maximum likelihood estimators (MLEs) and jackknife estimators (JEs) of faults remaining. It is found that the MLE performs satisfactorily if faults are classified into a small number of homogeneous groups. Without grouping, the MLE can perform poorly, but it generally does better than the JE.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.256852","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=256852","","Design methodology;Software design;Process design;Maximum likelihood estimation;Fault detection;Software systems;Wildlife;Software quality;Probability;Application software","maximum likelihood estimation;software quality;software reliability;statistical analysis","software designs;capture-recapture methods;wildlife population estimation;Monte Carlo simulation;broken assumptions;maximum likelihood estimators;jackknife estimators;software quality assurance;statistical estimation;design reviews","","55","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Concurrency and forward recovery in atomic actions","D. J. Taylor","Department of Computer Science, University of Waterloo, Waterloo, Ont. N2L 3GI, Canada","IEEE Transactions on Software Engineering","","1986","SE-12","1","69","78","Some difficulties and complexities in atomic actions occur only when the concept of atomic actions is extended to allow concurrency within atomic actions and to allow a single atomic action to execute at a number of different sites. Also, providing facilities for both forward and backward recovery presents problems not found in the more usual case of allowing only backward recovery. The author presents an analysis of these problems and proposes a general structure for a solution. A syntax which might be used to specify this structure is also given and illustrated with examples. The practicality of the scheme is justified by sketching one possible implementation.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312921","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312921","Atomic actions;backward recovery;concurrency;exception handling;forward recovery;software reliability","Concurrent computing;Context;Computer languages;Synchronization;Proposals;Syntactics;Educational institutions","fault tolerant computing;parallel processing;software reliability","parallel processing;fault tolerance;software reliability;forward recovery;atomic actions;complexities;concurrency;backward recovery","","2","","","","","","","","IEEE","IEEE Journals & Magazines"
"Critical races in Ada programs","G. M. Karam; C. M. Stanczyk; G. W. Bond","Dept. of Syst. & Comput. Eng., Carleton Univ., Ottawa, Ont., Canada; Dept. of Syst. & Comput. Eng., Carleton Univ., Ottawa, Ont., Canada; Dept. of Syst. & Comput. Eng., Carleton Univ., Ottawa, Ont., Canada","IEEE Transactions on Software Engineering","","1989","15","11","1471","1480","It is noted that critical races in concurrent Ada programs are an insidious source of system errors, and that the Ada language does not have concurrency features to ease the development of critical race-free programs. The authors illustrate this using the CRF language, which extends the Ada language by the addition of a powerful caller selection mechanism. It is this facility that implements a discriminatory mutual exclusion (dimutex) construct, an important feature for building less critical race-prone programs. The MLog language supports the CRF caller selection mechanisms; thus it is convenient as a rapid-prototyping platform. A design method for systematically converting CRF designs into Ada designs is presented. The method uses a mixture of mechanical and creative transformations that are guaranteed not to introduce critical races. D. Helmbold and D. Luckham's (1985) gas-station example is used to illustrate the various approaches to applying the design method.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.41338","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=41338","","Bonding;Design methodology;Computer errors;Buildings;Computer aided software engineering;Software design;Application software;Process control;Aerospace electronics","Ada;parallel programming","critical races;concurrent Ada programs;system errors;Ada language;CRF language;caller selection mechanism;discriminatory mutual exclusion;dimutex;MLog language;rapid-prototyping;gas-station example","","5","","15","","","","","","IEEE","IEEE Journals & Magazines"
"A management tool for evaluation of software design","S. Cardenas-Garcia; M. V. Zelkowitz","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA","IEEE Transactions on Software Engineering","","1991","17","9","961","971","A model for evaluating software designs based on extending the functional model of program verification with concepts from economic decision theory has been proposed. The authors describe the method, and discuss a prototype implementation of a tool, called Selector, which implements this technique. It is suggested that a system like Selector can be used in two ways: as a decision support system for management to be used in the process of making choices among various alternatives; and as a prototyping investigative system for proposing and answering a series of 'what if' scenarios. The proposed model depends on a risk analysis, of each potential solution and aspects of decision theory to modify the evaluation strategy. The model depends on equilibrium probabilities for generating answers.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.92916","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=92916","","Software design;Object oriented modeling;Software prototyping;Prototypes;Software development management;Software tools;Computer science;Personnel;Quality management;Software quality","decision support systems;program verification;software prototyping;software tools","management tool;software designs;functional model;program verification;economic decision theory;Selector;decision support system;prototyping investigative system;risk analysis;evaluation strategy;equilibrium probabilities","","14","","8","","","","","","IEEE","IEEE Journals & Magazines"
"RT-ASLAN: A specification language for real-time systems","B. Auernheimer; R. A. Kemmerer","Department of Computer Science, University of California, Santa Barbara, CA 93106; Department of Computer Science, University of California, Santa Barbara, CA 93106","IEEE Transactions on Software Engineering","","1986","SE-12","9","879","889","RT-ASLAN, a formal language for specifying real-time systems, is an extension of the ASLAN specification language for sequential systems. Some of the features of the ASLAN language, such as constructs for writing procedural semantics in a nonprocedural logical language, are highlighted. The RT-ASLAN language supports specification of parallel real-time processes through arbitrary levels of abstraction; processes do not have to be specified to the same level of detail. Communicating processes use an interface process as an abstract data type representing shared information. From RT-ASLAN specifications, performance correctness conjectures are generated. These conjectures are logic statements whose proof guarantees that the specification meets critical time bounds. A detailed example as well as a discussion of the advantages and disadvantages of formal specification and verification are included.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313044","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313044","Data abstraction;formal specification;formal verification;real-time system specification;real-time validation;temporal logic","Real-time systems;Specification languages;Semantics;Abstracts;Software;Clocks","real-time systems;specification languages","RT ASLAN;specification language;real-time systems;real-time systems;sequential systems;procedural semantics;nonprocedural logical language;parallel real-time processes;interface process;abstract data type;logic statements;time bounds","","25","","","","","","","","IEEE","IEEE Journals & Magazines"
"Model checking large software specifications","W. Chan; R. J. Anderson; P. Beame; S. Burns; F. Modugno; D. Notkin; J. D. Reese","Dept. of Comput. Sci. & Eng., Washington Univ., Seattle, WA, USA; NA; NA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","7","498","520","In this paper, we present our experiences in using symbolic model checking to analyze a specification of a software system for aircraft collision avoidance. Symbolic model checking has been highly successful when applied to hardware systems. We are interested in whether model checking can be effectively applied to large software specifications. To investigate this, we translated a portion of the state-based system requirements specification of Traffic Alert and Collision Avoidance System II (TCAS II) into input to a symbolic model checker (SMV). We successfully used the symbolic model checker to analyze a number of properties of the system. We report on our experiences, describing our approach to translating the specification to the SMV language, explaining our methods for achieving acceptable performance, and giving a summary of the properties analyzed. Based on our experiences, we discuss the possibility of using model checking to aid specification development by iteratively applying the technique early in the development cycle. We consider the paper to be a data point for optimism about the potential for more widespread application of model checking to software systems.","0098-5589;1939-3520;2326-3881","","10.1109/32.708566","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=708566","","Data structures;Boolean functions;Software systems;Aircraft;Air traffic control;Collision avoidance;Aerospace electronics;Hardware;Traffic control;Road accidents","air traffic control;formal specification;safety-critical software;formal verification","large software specifications;symbolic model checking;aircraft collision avoidance;state-based system requirements specification;Traffic Alert and Collision Avoidance System II;specification development","","126","","56","","","","","","IEEE","IEEE Journals & Magazines"
"An Algebra for a General Entity-Relationship Model","C. Parent; S. Spaccapietra","Institut Universitaire de Technologie; NA","IEEE Transactions on Software Engineering","","1985","SE-11","7","634","643","Although many data manipulation languages (DML's) have been proposed for the entity-relationship (ER) model, there is no agreement on what are the basic manipulations that any ER DML must offer. Moreover, there is no DML which fully supports all the capabilities of a general ER model with n-ary relationships, relationships with attributes, optional, complex, and multivalued attributes. This paper consequently proposes a definition of a set of algebraic operators to be applied on a general ER database. The algebra is said to be complete through equivalence with the usual definition of completeness for relational data manipulation languages. This work is intended to provide a sound basis for the definition of complete entity-relationship DML's, an essential feature to make the ER model fully operational.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232507","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702067","Algebra;algebraic operators;completeness;data manipulation language;data model;entity-relationship model","Algebra;Erbium;Data models;Power system modeling;Relational databases;Spatial databases;Database systems;Proposals;Calculus","","Algebra;algebraic operators;completeness;data manipulation language;data model;entity-relationship model","","8","","32","","","","","","IEEE","IEEE Journals & Magazines"
"The effect of execution policies on the semantics and analysis of stochastic Petri nets","M. Ajmone Marsan; G. Balbo; A. Bobbio; G. Chiola; G. Conte; A. Cumani","Dept. of Inf. Sci., Milan Univ., Italy; NA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1989","15","7","832","846","Petri nets in which random delays are associated with atomic transitions are defined in a comprehensive framework that contains most of the models already proposed in the literature. To include generally distributed firing times into the model one must specify the way in which the next transition to fire is chosen, and how the model keeps track of its past history; this set of specifications is called an execution policy. A discussion is presented of the impact that different execution policies have on semantics of the mode, as well as the characteristics of the stochastic process associated with each of these policies. When the execution policy is completely specified by the transition with the minimum delay (race policy) and the firing distributions are of the phase type, an algorithm is provided that automatically converts the stochastic process into a continuous time homogeneous Markov chain. An execution policy based on the choice of the next transition to fire independently of the associated delay (preselection policy) is introduced, and its semantics is discussed together with possible implementation strategies.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.29483","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=29483","","Stochastic processes;Petri nets;Delay effects;Fires;Power system modeling;History;Concurrent computing;Timing;State-space methods","Markov processes;performance evaluation;Petri nets","execution policies;semantics;stochastic Petri nets;atomic transitions;race policy;continuous time homogeneous Markov chain","","150","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Data Flow Anomaly Detection","J. Jachner; V. K. Agarwal","Department of Electrical Engineering, McGill University, Montreal, P.Q., Canada H3A 2A7.; Bell Northern Research, Verdun, P.Q., Canada.; Department of Electrical Engineering, McGill University, Montreal, P.Q., Canada H3A 2A7.","IEEE Transactions on Software Engineering","","1984","SE-10","4","432","437","The occurrence of a data flow anomaly is often an indication of the existence of a programming error. The detection of such anomalies can be used for detecting errors and to upgrade software quality. This paper introduces a new, efficient algorithm capable of detecting anomalous data flow patterns in a program represented by a graph. The algorithm based on static analysis scans the paths entering and leaving each node of the graph to reveal anomalous data action combinations. An algorithm implementing this type of approach was proposed by Fosdick and Osterweil [2]. Our approach presents a general framework which not only fillls a gap in the previous algorithm, but also provides time and space improvements.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010256","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010256","Data flow anomalies;detection of data flow anomalies;flow graphs;segmentation;smart compilers;static analysis","Flow graphs;Software quality;Algorithm design and analysis;Program processors;Data flow computing;Debugging;Data analysis","","","","11","","7","","","","","","IEEE","IEEE Journals & Magazines"
"From safety analysis to software requirements","K. M. Hansen; A. P. Ravn; V. Stavridou","Danish Nat. Rail Agency, Copenhagen, Denmark; NA; NA","IEEE Transactions on Software Engineering","","1998","24","7","573","584","Software for safety critical systems must deal with the hazards identified by safety analysis. This paper investigates, how the results of one safety analysis technique, fault trees, are interpreted as software safety requirements to be used in the program design process. We propose that fault tree analysis and program development use the same system model. This model is formalized in a real-time, interval logic, based on a conventional dynamic systems model with state evolving over time. Fault trees are interpreted as temporal formulas, and it is shown how such formulas can be used for deriving safety requirements for software components.","0098-5589;1939-3520;2326-3881","","10.1109/32.708570","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=708570","","Software safety;Fault trees;Logic;Aerospace engineering;Digital-to-frequency converters;Real time systems;Aerospace control;NASA;Reliability engineering;Hardware","fault trees;safety-critical software;temporal logic;real-time systems;formal specification","safety analysis;software requirements;safety critical systems;fault trees;software safety requirements;program design process;real-time interval logic;temporal formulas;software components;requirements engineering;formal methods;temporal logic;real-time systems","","59","","33","","","","","","IEEE","IEEE Journals & Magazines"
"Derivation of a parallel algorithm for balancing binary trees","A. Moitra; S. S. Iyengar","Department of Computer Science, Cornell University, Ithaca, NY 14853; Department of Computer Science, Louisiana State University, Baton Rouge, LA 70803","IEEE Transactions on Software Engineering","","1986","SE-12","3","442","449","A recent trend in program methodologies is to derive efficient parallel programs from sequential programs. This study explores the question of transforming a sequential algorithm into an efficient parallel algorithm by considering the problem of balancing binary search trees. The derivation of the parallel algorithm makes use of stepwise refinement. The authors first derive a new iterative balancing algorithm that exploits the similarity of point restructuring required at all the nodes at the same level. From this they derive a parallel algorithm that has time complexity O(1) on an <i>N</i>-processor configuration. This achieves the theoretical limit of speedup possible in a multiprocessor configuration.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312885","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312885","Balancing parallel algorithms;program transformation;search trees;stepwise refinement","Binary search trees;Parallel algorithms;Program processors;Arrays;Indexes;Vegetation","parallel processing;programming;trees (mathematics)","software engineering;parallel algorithm;binary trees;program methodologies;sequential programs;binary search trees;stepwise refinement;iterative balancing algorithm;point restructuring;time complexity;multiprocessor configuration","","5","","","","","","","","IEEE","IEEE Journals & Magazines"
"Estimating the Number of Faults in Code","J. E. Gaffney","National Weather Service, U.S. Department of Commerce, Silver Spring, MD, 20910.; Federal System Division, IBM Corporation, Gaithersburg, MD 20879.","IEEE Transactions on Software Engineering","","1984","SE-10","4","459","464","This paper provides formulas relating the number of faults or ``bugs'' to the number of lines of code and to the number of conditional jumps. A result is that there are, on the average, about 21 bugs per KSLOC discoverable after successful compilation. A major motivation for the work presented here was to determine if some published data suggest any relationship between the level of the coding language employed (e.g., Jovial is a ``high'' level language) and the number of bugs found. It is shown that the number of bugs appears not to be a function of the ``level'' of the coding language employed. In addition, knowledge of items such as the size of the vocabulary (operator and operand) used appears to be of little consequence to the estimate of bug content beyond that based on SLOC count.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010260","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010260","","Computer bugs;Assembly;Vocabulary;Books;High level languages;Weather forecasting;Business;Silver;Springs;Bismuth","","","","58","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Formal derivation of concurrent programs: an example from industry","M. G. Staskauskas","Dept. of Comput. Sci., Texas Univ., Austin, TX, USA","IEEE Transactions on Software Engineering","","1993","19","5","503","528","The formal derivation of an implementation of the I/O (input/output) subsystem portion of an existing operating system is presented. The I/O subsystem is responsible for allocating I/O resources such as tapes, disks, I/O channels in response to requests from user processes. The derivation employs the UNITY methodology which captures the concurrent interaction of the I/O subsystem with its environment. The verified resource allocation algorithm that results from the derivation has been used as part of a high-level design by software engineers implementing the I/O subsystem. As the largest application to date of the UNITY methodology, the derivation illustrates a number of techniques for organizing large specifications and proofs.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.232015","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=232015","","Resource management;Logic programming;Operating systems;Software design;Information systems;Software algorithms;Algorithm design and analysis;Design engineering;Application software;Organizing","formal specification;parallel programming;program verification","formal derivation;I/O subsystem;concurrent programs;operating system;tapes;disks;I/O channels;UNITY methodology;resource allocation algorithm;specifications;proofs","","9","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Compaction with general synchronous timing","V. H. Allan; R. A. Mueller","Dept. of Comput. Sci., Utah State Univ., Logan, UT, USA; NA","IEEE Transactions on Software Engineering","","1988","14","5","595","599","In current microcode generation systems, one simplification that is frequently made is to assume an absence of timing restrictions. It is critical that timing is considered when the target architecture involves branch delays, volatile registers, or microoperations requiring multiple microinstructions to complete. A general form for representing synchronous timing in clocked microarchitectures and methods of compacting data-dependency graphs with general timing are described.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6137","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6137","","Compaction;Timing;Signal processing algorithms;Delay;Clocks;Counting circuits;Scheduling;Registers;Synchronous generators;Signal design","microprogramming;program compilers;synchronisation","compilers;general synchronous timing;microcode generation systems;target architecture;branch delays;volatile registers;microoperations;multiple microinstructions;clocked microarchitectures;data-dependency graphs","","5","","4","","","","","","IEEE","IEEE Journals & Magazines"
"Data and time abstraction techniques for analyzing multilevel concurrent systems","T. Minoura; S. S. Iyengar","Dept. of Comput. Sci., Oregon State Univ., Corvallis, OR, USA; NA","IEEE Transactions on Software Engineering","","1989","15","1","47","59","It is argued that the design and analysis of a concurrent system can be made simpler and more intuitive if execution times of abstract operations are arbitrarily but systematically defined. This technique (time abstraction) is complementary to data abstraction and is more effective when used in combination with data abstraction. As examples, a bounced-buffer monitor and a multilevel concurrency scheme for a database system are analyzed by using data and time abstraction.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21725","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21725","","Software systems;Concurrency control;Concrete;Computer science;Monitoring;Database systems;Imaging phantoms;Humans;Algorithms;Control systems","concurrency control;distributed databases","time abstraction techniques;multilevel concurrent systems;data abstraction;bounced-buffer monitor;multilevel concurrency scheme;database system","","3","","31","","","","","","IEEE","IEEE Journals & Magazines"
"The use of self checks and voting in software error detection: an empirical study","N. G. Leveson; S. S. Cha; J. C. Knight; T. J. Shimeall","Dept. of Inf. & Comput. Sci., California Univ., Irvine, CA, USA; Dept. of Inf. & Comput. Sci., California Univ., Irvine, CA, USA; NA; NA","IEEE Transactions on Software Engineering","","1990","16","4","432","443","The results of an empirical study of software error detection using self checks and N-version voting are presented. Working independently, each of 24 programmers first prepared a set of self checks using just the requirements specification of an aerospace application, and then each added self checks to an existing implementation of that specification. The modified programs were executed to measure the error-detection performance of the checks and to compare this with error detection using simple voting among multiple versions. The analysis of the checks revealed that there are great differences in the ability of individual programmers to design effective checks. It was found that some checks that might have been effective failed to detect an error because they were badly placed, and there were numerous instances of checks signaling nonexistent errors. In general, specification-based checks alone were not as effective as specification-based checks combined with code-based checks. Self checks made it possible to identify faults that had not been detected previously by voting 28 versions of the program over a million randomly generated inputs. This appeared to result from the fact that the self checks could examine the internal state of the executing program, whereas voting examines only final results of computations. If internal states had to be identical in N-version voting systems, then there would be no reason to write multiple versions.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.54295","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=54295","","Voting;Computer science;Fault detection;Fault diagnosis;Hardware;Computer errors;Fault tolerance;Application software;Programming profession;Testing","fault tolerant computing;software reliability","self checks;voting;software error detection;N-version voting;requirements specification;code-based checks","","59","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Exception handling in workflow management systems","C. Hagen; G. Alonso","Credit Suisse, Zurich, Switzerland; NA","IEEE Transactions on Software Engineering","","2000","26","10","943","958","Fault tolerance is a key requirement in process support systems (PSS), a class of distributed computing middleware encompassing applications such as workflow management systems and process centered software engineering environments. A PSS controls the flow of work between programs and users in networked environments based on a ""metaprogram"" (the process). The resulting applications are characterized by a high degree of distribution and a high degree of heterogeneity (properties that make fault tolerance both highly desirable and difficult to achieve). We present a solution for implementing more reliable processes by using exception handling, as it is used in programming languages, and atomicity, as it is known from the transaction concept in database management systems. We describe the mechanism incorporating both transactions and exceptions and present a validation technique allowing to assess the correctness of process specifications.","0098-5589;1939-3520;2326-3881","","10.1109/32.879818","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=879818","","Workflow management software;Fault tolerant systems;Fault tolerance;Application software;Runtime environment;Process design;Computer Society;Distributed computing;Middleware;Software engineering","exception handling;workflow management software;software fault tolerance;client-server systems;database management systems","exception handling;workflow management systems;fault tolerance;process support systems;distributed computing middleware;process centered software engineering;metaprogram;programming languages;atomicity;transaction concept;database management systems;validation technique;process specifications","","160","","","","","","","","IEEE","IEEE Journals & Magazines"
"Distributed system software design paradigm with application to computer networks","N. F. Schneidewind","US Naval Postgraduate Sch., Monterey, CA, USA","IEEE Transactions on Software Engineering","","1989","15","4","402","412","A paradigm for the system and software design of distributed systems is presented with application to an actual large-scale computer network involving both local area networks and a wide area network. A number of design principles are offered with particular reference to how they can be applied to the design of distributed systems. The author's major point is an explanation of how to make design decisions about distributed systems in a way which will enhance maintainability and understandability of the software and, at the same time, result in good system performance. The aim is to recognize the implications for software quality of various decisions which must be made in the process of specifying a distributed system.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.16601","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=16601","","System software;Software design;Application software;Large-scale systems;Computer networks;Local area networks;Wide area networks;Software maintenance;Software performance;System performance","computer networks;distributed processing;software reliability","distributed systems;large-scale computer network;local area networks;wide area network;distributed systems;maintainability;understandability;system performance;software quality","","4","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Modeling and analysis of the behavior of information systems","G. Lausen","Karlsruhe Univ., West Germany","IEEE Transactions on Software Engineering","","1988","14","11","1610","1620","Many widely used specification techniques for information systems are based on a hierarchy of information flow diagrams. A method is introduced which preserves the benefits of these techniques and adds the precision of the Petri net formalism. Information-flow diagram hierarchies are formalized by notions of net theory. The bottom-level nets of a hierarchy are treated as Petri nets. The behavior model of the information system is the Petri net derived by repeatedly replacing each part of a net by its associated refinement. As a prerequisite for such replacements, the data abstractions relation information flows of different level are specified by a semantic hierarchy data model. The nets in the hierarchy are appended by dynamic counterparts of the abstractions so that a consistent replacement becomes possible. The interface behavior of the nets in the hierarchy is analyzed, using the concept of behavior constraints as a formal measure of correct interface behavior. The behavior model can be derived in an iterative bottom-up way by first analyzing a net for fulfillment of its associated behavior constraint and afterward integrating it into the next-higher-level net.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9049","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9049","","Information analysis;Information systems;Petri nets;Data models;Topology","data structures;flowcharting;formal specification;Petri nets","information systems;specification techniques;Petri net;data abstractions;information flows;semantic hierarchy data model;behavior constraints","","12","","33","","","","","","IEEE","IEEE Journals & Magazines"
"Teamwork support in a knowledge-based information systems environment","U. Hahn; M. Jarke; T. Rose","Passau Univ., Germany; Passau Univ., Germany; Passau Univ., Germany","IEEE Transactions on Software Engineering","","1991","17","5","467","482","Development assistance for interactive database applications (DAIDA) is an experimental environment for the knowledge-assisted development and maintenance of database-intensive information systems from object-oriented requirements and specifications. Within the DAIDA framework, an approach to integrate different tasks encountered in software projects via a conceptual modeling strategy has been developed. Emphasis is put on integrating the semantics of the software development domain with aspects of group work, on social strategies to negotiate problems by argumentation, and on assigning responsibilities for task fulfillment by way of contracting. The implementation of a prototype is demonstrated with a sample session.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.90449","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=90449","","Teamwork;Information systems;Programming;Project management;Collaborative work;Software tools;Object oriented databases;Object oriented modeling;Software prototyping;Prototypes","groupware;interactive systems;knowledge based systems;object-oriented databases;software maintenance","development assistance for interactive database applications;database maintenance;object-oriented specification;knowledge-based information systems;knowledge-assisted development;database-intensive information systems;DAIDA framework;software projects;conceptual modeling strategy;software development;group work;social strategies","","26","","44","","","","","","IEEE","IEEE Journals & Magazines"
"An efficient pictorial database system for PSQL","N. Roussopoulos; C. Faloutsos; T. Sellis","Maryland Univ., College Park, MD, USA; Maryland Univ., College Park, MD, USA; Maryland Univ., College Park, MD, USA","IEEE Transactions on Software Engineering","","1988","14","5","639","650","Pictorial databases require efficient and direct spatial search based on the analog form of spatial objects and relationships instead of search based on some cumbersome alphanumeric encodings of the pictures. A description is given of PSQL, a query language that allows pictorial domains to be presented to the user in their analog form and allows him or her to do direct manipulation on the objects found on those domains. Direct spatial search and computation on the pictures is done using efficient data structures, R- and R/sup +/-trees (multidimensional B-trees), which are excellent devices for searching spatial objects and relationships found on pictures.<<ETX>></ETX>","0098-5589;1939-3520;2326-3881","","10.1109/32.6141","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6141","","Database systems;Spatial databases;Database languages;Image databases;Image coding;Data structures;Relational databases;Computer science;Object oriented databases;Encoding","data structures;database management systems;query languages;user interfaces","pictorial database system;PSQL;spatial search;spatial objects;alphanumeric encodings;query language;data structures;R/sup +/-trees;multidimensional B-trees","","113","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Accountability in electronic commerce protocols","R. Kailar","Hewlett-Packard Co., Atlanta, GA, USA","IEEE Transactions on Software Engineering","","1996","22","5","313","328","In most commercial and legal transactions, the ability to hold individuals or organizations accountable for transactions is important. Hence, electronic protocols that implement commercial transactions must be designed to provide adequate accountability assurances for transacting parties. A framework is proposed for the analysis of communication protocols that require accountability, such as those for electronic commerce. This framework can be used to analyze protocol designs to detect accountability (or lack thereof). Arguments are presented to show that a heretofore unexplored property ""provability"" is pertinent to examining the potential use of communication protocols in the context of litigation, and in the context of audit. A set of postulates which are applicable to the analysis of proofs in general and the proofs of accountability in particular, are proposed. The proposed approach is more natural for the analysis of accountability than the existing belief logics (e.g., M. Burrows et al., 1990) that have been used in the past for the analysis of key distribution protocols. Some recently proposed protocols for electronic commerce and public key delegation are analyzed to illustrate the use of the new analysis framework in detecting (and suggesting remedies for eliminating) their lack of accountability, and in detecting and eliminating redundancies.","0098-5589;1939-3520;2326-3881","","10.1109/32.502224","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=502224","","Electronic commerce;Logic;Cryptographic protocols;Business;Context;Redundancy;Access protocols;Wide area networks;Internet;Law","business data processing;law administration;protocols;cryptography","accountability;electronic commerce protocols;legal transactions;commercial transactions;accountability assurances;transacting parties;communication protocols;protocol designs;provability;litigation;audit;belief logics;key distribution protocols;public key delegation","","88","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Petri-net-based modeling and evaluation of pipelined processing of concurrent database queries","K. P. Mikkilineni; Y. -. Chow; S. Y. W. Su","Honeywell, Golden Valley, MN, USA; NA; NA","IEEE Transactions on Software Engineering","","1988","14","11","1656","1667","A description is given of a Petri-net-based methodology for modeling and evaluation of pipelined processing of concurrent database queries in an integrated data network (IDN). An extended Petri-net model is presented and used to model two key approaches to concurrent database query processing in the IDN, namely, pipelined and data-flow-based execution of queries and intermediate data sharing among concurrent queries. Database operations are categorized, and the models for the data flow and control flow in them are presented. A general-purpose Petri-net simulator has been developed using event-driven programming techniques and used to simulate the execution of the Petri-net models of some test queries. The results validate the results of a previous analytical evaluation in which the advantages of pipeline and intermediate data sharing were established. Since all the essential details of query processing in the IDN have been simulated, the results of this simulation study are believed to present closely the workings of the actual system.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9053","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9053","","Query processing;Computer architecture;Relational databases;Computational modeling;Petri nets;Data models;Software engineering;Discrete event simulation;Testing;Pipeline processing","computer networks;digital simulation;distributed databases;Petri nets;pipeline processing;program testing","distributed databases;pipelined processing;concurrent database queries;integrated data network;Petri-net model;query processing;intermediate data sharing;event-driven programming","","8","","38","","","","","","IEEE","IEEE Journals & Magazines"
"Resource allocation for primary-site fault-tolerant systems","Y. Huang; S. K. Tripathi","AT&T Bell Labs, Murray Hill, NJ, USA; NA","IEEE Transactions on Software Engineering","","1993","19","2","108","119","Resource allocation for a distributed system employing the primary site approach for fault tolerance is discussed. Two kinds of systems are considered. The first consists of fault-tolerant nodes where each node has many duplicated servers. One server is the primary, which serves user requests, and the rest are backup. The second does not have fault-tolerant nodes. To tolerate node failures, each node uses other nodes as backups. When a node fails, all requests initially allocated to the node are served by one of its backups. To study the resource allocation for such systems, an approximate model for each system is developed. Using these models, efficient allocation algorithms that take into account the failure/repair rates of the system and the fault-tolerant overheads are presented. Using experimental results, it is shown that the algorithms give the optimal or suboptimal allocations. The algorithms, which incur little overhead, can improve the system performance significantly over an intuitive allocation algorithm.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.214829","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=214829","","Resource management;Fault tolerant systems;Fault tolerance;System performance;Throughput;Delay;Availability;Distributed computing;Real time systems","distributed processing;fault tolerant computing;file servers;performance evaluation;resource allocation","resource allocation;primary-site fault-tolerant systems;distributed system;server;node failures;approximate model;system performance","","1","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Specification and validation of control-intensive IC's in hopCP","V. Akella; G. Gopalakrishnan","Dept. of Electr. & Comput. Eng., California Univ., Davis, CA, USA; NA","IEEE Transactions on Software Engineering","","1994","20","6","405","423","Control-intensive IC's pose a significant challenge to the users of formal methods in designing hardware. These IC's have to support a wide variety of requirements including synchronous and asynchronous operations, polling and interrupt driven modes of operation, multiple concurrent threads of execution, nontrivial computational requirements, and programmability. We illustrate the use of formal methods in the design of a control-intensive IC called the ""Intel 8251"" Universal Synchronous/Asynchronous Receiver/Transmitter (USART), using our hardware description language ""hopCP"". A feature of hopCP is that it supports communication via asynchronous ports in addition to synchronous message passing. Asynchronous ports are distributed shared variables writable by exactly one process. We show the usefulness of this combination of communication constructs. We outline algorithms to determine safe usages of asynchronous ports, and also to discover other static properties of the specification. We discuss a compiled-code concurrent functional simulator called CFSIM, as well as the use of concurrent testers for driving CFSIM. The use of a semantically well-specified and simple language, and the associated analysis/simulation tools helps conquer the complexity of specifying and validating control-intensive IC's.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.295890","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=295890","","Hardware design languages;Very large scale integration;Design methodology;Concurrent computing;Communication system control;Message passing;Testing;Analytical models;Formal specifications","microprocessor chips;message passing;specification languages;formal specification;digital simulation;formal verification","control-intensive integrated circuits;hopCP;validation;specification;formal methods;hardware design;synchronous operations;asynchronous operations;polling;interrupt;multiple concurrent threads;computational requirements;Intel 8251;Universal Synchronous/Asynchronous Receiver/Transmitter;USART;hardware description language;synchronous message passing;distributed shared variables;asynchronous ports;compiled-code concurrent functional simulator;CFSIM","","","","46","","","","","","IEEE","IEEE Journals & Magazines"
"On the use of testability measures for dependability assessment","A. Bertolino; L. Strigini","Istituto di Elaborazione dell'Inf., CNR, Pisa, Italy; NA","IEEE Transactions on Software Engineering","","1996","22","2","97","108","Program ""testability"" is informally, the probability that a program will fail under test if it contains at least one fault. When a dependability assessment has to be derived from the observation of a series of failure free test executions (a common need for software subject to ""ultra high reliability"" requirements), measures of testability can-in theory-be used to draw inferences on program correctness. We rigorously investigate the concept of testability and its use in dependability assessment, criticizing, and improving on, previously published results. We give a general descriptive model of program execution and testing, on which the different measures of interest can be defined. We propose a more precise definition of program testability than that given by other authors, and discuss how to increase testing effectiveness without impairing program reliability in operation. We then study the mathematics of using testability to estimate, from test results: the probability of program correctness and the probability of failures. To derive the probability of program correctness, we use a Bayesian inference procedure and argue that this is more useful than deriving a classical ""confidence level"". We also show that a high testability is not an unconditionally desirable property for a program. In particular, for programs complex enough that they are unlikely to be completely fault free, increasing testability may produce a program which will be less trustworthy, even after successful testing.","0098-5589;1939-3520;2326-3881","","10.1109/32.485220","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=485220","","Software testing;Computer bugs;Software measurement;Mathematics;Bayesian methods;Safety;Lead","program testing;software reliability;Bayes methods;program verification;programming theory","testability measures;software dependability assessment;probability;failure free test executions;ultra high reliability;program correctness;program execution;testing effectiveness;program reliability;Bayesian inference procedure;software testing;test oracle","","43","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Toward a rigorous interpretation of ESML-extended systems modeling language","G. Richter; B. Maffeo","German Nat. Res. Center for Comput. Sci., Saint Augustin, Germany; NA","IEEE Transactions on Software Engineering","","1993","19","2","165","180","A graphics-based language known as ESML (extended systems modeling language), which is an extension of the data flow diagram notation for representing control logic in models of real-time systems, is analyzed and summarized to provide a rigorous interpretation of ESML symbols and their combinations. Based on elementary and compact (high-level) Petri nets (PNs), to which a succinct introduction is given, formal foundations for ESML, and in particular for its transformation schema (TS) notation, are proposed. Translation principles as well as examples of usual transformation and flow patterns are presented both in TS and PN notation. The resulting PN models are rigorous and accurate models of the dynamics of real-time systems with signals, prompts, and data flows of various kinds. Due to their formally defined token game they can be executed and used to study indeterminism and concurrency of events.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.214833","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=214833","","Modeling;Real time systems;Logic;Petri nets;Design for disassembly;Flow graphs;Concurrent computing;Monitoring;Control systems;Proposals","Petri nets;real-time systems;systems analysis;visual languages","translation principles;rigorous interpretation;ESML;extended systems modeling language;graphics-based language;data flow diagram notation;control logic;real-time systems;Petri nets;transformation schema;token game","","10","","33","","","","","","IEEE","IEEE Journals & Magazines"
"A relational algebraic approach to protocol verification","T. T. Lee; M. -. Lai","Bell Commun. Res., Morristown, NJ, USA; Bell Commun. Res., Morristown, NJ, USA","IEEE Transactions on Software Engineering","","1988","14","2","184","193","Communications protocols are usually modeled by a pair of finite-state machines that generate the interaction between processes. Protocol verification is a procedure to validate the logical correctness of these interaction sequences and to detect potential design errors. A relational approach is proposed to represent a finite-state machine as a transition table. On this basis, the well-established theory of relational databases can be utilized to derive the global-state transitions of the system. Furthermore, logical errors of a protocol such as deadlocks, incomplete specifications and nonexecutable interactions can be formulated in terms of relational algebra. This approach has been implemented on the INGRES database system and applied to the verification of several protocols.<<ETX>></ETX>","0098-5589;1939-3520;2326-3881","","10.1109/32.4637","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4637","","Protocols;Relational databases;Algebra;Channel capacity;System recovery;Visual databases;Calculus;Database systems;Automata;Data models","database theory;finite automata;program verification;protocols;relational databases","protocol verification;logical correctness;finite-state machine;transition table;relational databases;global-state transitions;deadlocks;INGRES","","19","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Data-driven parallel production systems","J. -. Gaudiot; A. Sohn","Dept. of Electr. Eng., Univ. of Southern California, Los Angeles, CA, USA; Dept. of Electr. Eng., Univ. of Southern California, Los Angeles, CA, USA","IEEE Transactions on Software Engineering","","1990","16","3","281","293","Much effort has been expended on developing special architectures dedicated to the efficient execution of production systems. While data-flow principles of execution offer the promise of high programmability for numerical computations, it is shown that the data-driven principles can also be applied to symbolic computations. In particular, a mapping of the RETE match algorithm along the line of production systems is considered. Bottlenecks of the RETE match algorithm in a multiprocessor environment are identified and possible solutions are suggested. The modifications to the actor set as well as the program graph design are shown for execution on the tagged data-flow computer. The results of a deterministic simulation of this multiprocessor architecture demonstrate that artificial intelligence production systems can be efficiently mapped on data-driven architectures.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.48936","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=48936","","Production systems;Artificial intelligence;Expert systems;Computer architecture;Parallel processing;Pattern matching;Decision making;Data structures;Databases;Delay","expert systems;parallel architectures;parallel programming;symbol manipulation","parallel production systems;data-flow principles;high programmability;numerical computations;data-driven principles;symbolic computations;RETE match algorithm;multiprocessor environment;actor set;program graph design;tagged data-flow computer;deterministic simulation;multiprocessor architecture;artificial intelligence production systems;data-driven architectures","","13","","41","","","","","","IEEE","IEEE Journals & Magazines"
"The derivation of conformance tests from LOTOS specifications","D. H. Pitt; D. E. Freestone","Dept. of Math., Surrey Univ., Guildford, UK; NA","IEEE Transactions on Software Engineering","","1990","16","12","1337","1343","The derivation of conformance tests for communication protocols is discussed. Protocol specifications are considered in the formal description technique LOTOS, which has been developed by the International Standards Organization. Test processes which preserve the structure of the protocol specifications are constructed. Laws are presented for handling basic LOTOS operators. The test processes obtained by applying these laws are related to the theoretical notion of canonical testers. The conversion of the test processes into finite test suites is discussed. Their relationship to current practice in test suite design is discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.62442","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=62442","","Testing;Protocols;Telecommunications;ISO;Formal languages;Manufacturing;Information technology;Permission;Mathematics;Laboratories","conformance testing;formal languages;formal specification;open systems;protocols;standards","OSI;conformance tests;communication protocols;formal description technique LOTOS;International Standards Organization;protocol specifications;basic LOTOS operators;test processes;theoretical notion;canonical testers;finite test suites;test suite design","","27","","20","","","","","","IEEE","IEEE Journals & Magazines"
"An expert database design system based on analysis of forms","J. Choobineh; M. V. Mannino; J. F. Nunamaker; B. R. Konsynski","Coll. of Bus. Adm., Texas Univ., Austin, TX, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1988","14","2","242","253","A form model and an expert database system that analyzes instances of the form model to derive a conceptual schema are proposed. The form model describes the properties of form fields such as their origin, hierarchical structure, and cardinality. The expert database design system creates a conceptual schema by incrementally integrating related collections of forms. The rules of the expert systems are divided into six phases form selection; entity identification; attribute attachment; relationship identification; cardinality identification; and integrity constraints. The rules of the first phase use knowledge about the form flow to determine the order in which forms are analyzed. The rules in other phases are used in conjunction with a designer dialog to identify the entities, relationships, and attributes of a schema that represents the collection of forms.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4641","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4641","","Databases;Expert systems;Process design;Information management;Management information systems;Vehicles;User interfaces;Information retrieval;Natural languages","database management systems;expert systems","expert systems;expert database design system;form model;conceptual schema;form selection;entity identification;attribute attachment;relationship identification;cardinality identification;integrity constraints;form flow;designer dialog","","44","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Stochastic bounds on execution times of parallel programs","N. Yazia-Pekergin; J. -. Vincent","EHEI, Rene Descartes, Paris, France; NA","IEEE Transactions on Software Engineering","","1991","17","10","1005","1012","Stochastic bounds are obtained on execution times of parallel programs when the number of processors is unlimited. A parallel program is considered to consist of interdependent tasks with synchronization constraints. These constraints are described by an acyclic directed graph called a task graph. The execution times of tasks are considered to be independently identically distributed (i.i.d.) random variables. The performance measure of interest is the overall execution of the considered parallel program (task graph). Stochastic bound methods are applied to obtain lower and upper bounds on this measure. Another upper bound is obtained for parallel programs having 'new better than used in expectation' (NBUE) random variables as task execution times. NBUE random variables are replaced with exponential random variables of the same mean to derive this upper bound.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.99189","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=99189","","Stochastic processes;Random variables;Upper bound;Parallel processing;Stochastic systems;Tree graphs;Distributed computing;Probability distribution;Equations;Stability analysis","directed graphs;parallel programming;performance evaluation;stochastic processes","stochastic bound methods;execution times;parallel programs;interdependent tasks;synchronization constraints;acyclic directed graph;task graph;performance measure;NBUE;exponential random variables","","20","","17","","","","","","IEEE","IEEE Journals & Magazines"
"File Structures, Program Structures, and Attributed Grammars","L. Logrippo; D. R. Skuce","Software Reliability Research Group, Department of Computer Science, University of Ottawa; NA","IEEE Transactions on Software Engineering","","1983","SE-9","3","260","266","A language for defining sequential file structures, characterized as nested sequences of records having in common certain keys and types, is presented. ""Input schemata"" are defined as program skeletons that contain all the necessary control structure to process a specified file. A method for obtaining an input schema from the corresponding file structure definition is given. The method is based on attributed grammars, and has been implemented in the programming language PROLOG. This constitutes a formalization of some aspects of the data-directed program design method of Jackson and Warnier. Examples of applications of this method to business data processing problems such as file updating and report generation are given.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236735","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703053","Attributed grammars;data-directed program design;data processing;logical construction of programs;logic programming;program generation;program structure;PROLOG;sequential file structures;software engineering","Data processing;Business;Computer languages;Application software;Logic programming;Computer science;Skeleton;Process control;Design methodology;Process design","","Attributed grammars;data-directed program design;data processing;logical construction of programs;logic programming;program generation;program structure;PROLOG;sequential file structures;software engineering","","3","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Semiautomatic Implementation of Communication Protocols","G. v. Bochmann; G. W. Gerber; J. -. Serre","Department of Computer Science and Operations Research, University of Montreal; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","9","989","1000","The use of formal specifications in software development allows the use of certain automated tools during the specification and software development process. Formal description techniques have been developed for the specification of communication protocols and services. This paper describes the partial automation of the protocol implementation process based on a formal specification of the protocol to be implemented. An implementation strategy and a related software structure for the implementation of state transition oriented specifications is presented. Its application is demonstrated with a much simplified Transport protocol. The automated translation of specifications into implementation code in a high-level language is also discussed. A semiautomated implementation strategy is explained which highlights several refinement steps, part of which are automated, which lead from a formal protocol specifieation to an implementation. Experience with several full implementations of the OSI Transport protocol is described.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233521","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702321","Communication protocols;Estelle;formal description techniques;formal specification;implementation methodology;protocol implementation;specification translation;transport protocol implementation","Formal specifications;Transport protocols;Open systems;Operations research;Automation;Application software;Computer science;Programming;Software tools;High level languages","","Communication protocols;Estelle;formal description techniques;formal specification;implementation methodology;protocol implementation;specification translation;transport protocol implementation","","16","","33","","","","","","IEEE","IEEE Journals & Magazines"
"The C information abstraction system","Y. -. Chen; M. Y. Nishimoto; C. V. Ramamoorthy","Dept. of Electr. Eng. & Comput. Sci., California Univ., Berkeley, CA, USA; Dept. of Electr. Eng. & Comput. Sci., California Univ., Berkeley, CA, USA; Dept. of Electr. Eng. & Comput. Sci., California Univ., Berkeley, CA, USA","IEEE Transactions on Software Engineering","","1990","16","3","325","334","A system for analyzing program structures is described. The system extracts relational information from C programs according to a conceptual model and stores the information in a database. It is shown how several interesting software tasks can be performed by using the relational views. These tasks include generation of graphical views, subsystem extraction, program layering, dead code elimination and binding analysis.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.48940","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=48940","","Relational databases;Computer science;Software reusability;Software maintenance;Data mining;Software metrics;Computer languages;Software tools;Production;Information analysis","C language;data structures;programming;relational databases","C information abstraction system;program structures;relational information;C programs;conceptual model;software tasks;relational views;graphical views;subsystem extraction;program layering;dead code elimination;binding analysis","","146","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Efficient decentralized consensus protocols","T. V. Lakshman; A. K. Agrawala","Systems Design and Analysis Group, Department of Computer Science, University of Maryland, College Park, MD 20742; Systems Design and Analysis Group, Department of Computer Science, University of Maryland, College Park, MD 20742","IEEE Transactions on Software Engineering","","1986","SE-12","5","600","607","Decentralized consensus protocols are characterized by successive rounds of message interchanges. Protocols which achieve a consensus in one round of message interchange require O(<i>N</i><sup>2</sup>) messages, where<i>N</i>is the number of participants. A communication scheme based on finite projective planes is presented which requires only O(<i>N</i><i>N</i>) messages for each round. Using this communication scheme, decentralized consensus protocols which achieve a consensus within two rounds of message interchange are developed. The protocols are symmetric, and the communication scheme does not impose any hierarchical structure. The scheme is illustrated using blocking and nonblocking commit protocols, decentralized extrema finding, and computation of the sum function.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312956","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312956","Commit protocols;crash recovery;distributed database systems;distributed systems;fault tolerance;message complexity;transaction management","Protocols;Clocks;Checkpointing;Concurrent computing;Distributed databases;Computer science","distributed processing;protocols","distributed systems;decentralized consensus protocols;message interchanges;communication scheme;finite projective planes;commit protocols;decentralized extrema finding","","32","","","","","","","","IEEE","IEEE Journals & Magazines"
"Querying of executable software specifications","G. Nota; G. Pacini","Dipartimento di Inf. ed Applicazioni, Salerno Univ., Italy; NA","IEEE Transactions on Software Engineering","","1992","18","8","705","716","The availability of executable specification languages allows testing to be carried out soon after or concurrently with the requirements specification phase. In addition, it becomes possible to use these languages for rapid prototyping, making it possible to gather information on properties of the specified target system including its behavior in response to external events. The inspection of software behavior is viewed as the querying of executable specifications. A language RSQ is defined for the purpose of constructing queries against executable specifications expressed in RSF, a language for the description of systems with time constraints. A query is able to single out a subclass of possible behaviors based on properties supplied by the query. The integration of RSQ with RSF enhances the analytical abilities of the software designer and developer.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.153380","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=153380","","Formal specifications;Software prototyping;System testing;Specification languages;Prototypes;Inspection;Logic;Time factors;Software design","formal specification;query languages;software prototyping;specification languages","querying;executable software specifications;specification languages;requirements specification phase;rapid prototyping;external events;language RSQ;RSF;time constraints;software designer","","6","","42","","","","","","IEEE","IEEE Journals & Magazines"
"Performance prediction and evaluation of parallel processing on a NUMA multiprocessor","X. Zhang; X. Qin","Div. of Math. & Comput. Sci., Texas Univ., San Antonio, TX, USA; Div. of Math. & Comput. Sci., Texas Univ., San Antonio, TX, USA","IEEE Transactions on Software Engineering","","1991","17","10","1059","1068","The efficiency of the basic operations of a NUMA (nonuniform memory access) multiprocessor determines the parallel processing performance on a NUMA multiprocessor. The authors present several analytical models for predicting and evaluating the overhead of interprocessor communication, process scheduling, process synchronization, and remote memory access, where network contention and memory contention are considered. Performance measurements to support the models and analyses through several numerical examples have been done on the BBN GP1000, a NUMA shared-memory multiprocessor. Analytical and experimental results give a comprehensive understanding of the various effects, which are important for the effective use of NUMA shared-memory multiprocessor. The results presented can be used to determine optimal strategies in developing an efficient programming environment for a NUMA system.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.99193","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=99193","","Parallel processing;Processor scheduling;Computer architecture;Memory architecture;Multiprocessor interconnection networks;Dynamic programming;Large-scale systems;Communication switching;Analytical models;Measurement","multiprocessing systems;parallel processing;performance evaluation;scheduling","nonuniform memory access;parallel processing performance;analytical models;interprocessor communication;process scheduling;process synchronization;remote memory access;network contention;memory contention;BBN GP1000;NUMA shared-memory multiprocessor;optimal strategies;programming environment","","12","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Direct implementation of abstract data types from abstract specifications","B. Belkhouche; J. E. Urban","Department of Computer Science, Tulane University, New Orleans, LA 70118; Center for Advanced Computer Studies, University of Southwestern Louisiana, Lafayette, LA 70504","IEEE Transactions on Software Engineering","","1986","SE-12","5","649","661","The development of correct specifications is a critical task in the software development process. An alternative approach for the development of specifications is described. The approach relies on a specification language for abstract data types and synthesis system. The system is capable of translating in abstract data type specification into an executable program. This process defines an alternative methodology that provides the necessary tools for the early testing of the specifications and for the development of prototypes and implementation models.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312960","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312960","Abstract data types;abstract model;implementation models;language translation;prototyping;specifications;specification testing;synthesis;transformation rules","Abstracts;Libraries;Software;Specification languages;Semantics;Testing;Syntactics","data structures;software engineering;specification languages","abstract data types;abstract specifications;software development;specification language;synthesis system;executable program","","4","","","","","","","","IEEE","IEEE Journals & Magazines"
"Molecule: a language construct for layered development of parallel programs","Z. Xu; K. Hwang","Dept. of Electr. & Comput. Eng., Rutgers Univ., Piscataway, NJ, USA; NA","IEEE Transactions on Software Engineering","","1989","15","5","587","599","A new language construct, called molecule, is described for the efficient implementation of algorithms on parallel computers. A molecule can be considered a procedure associated with a molecule type. Each molecule type characterizes a particular computation mode (sequential, pipelining, array processing, dataflow, multiprocessing, etc.). Basic concepts of molecule are introduced with a procedural language, called PAL. A concrete example is presented to illustrate layered software development using PAL on a multicomputer (the iPSC). It is concluded that high-level languages, augmented with the molecule construct, offer application flexibility, user friendliness, and efficiency in implementing parallel programs.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24708","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24708","","Concurrent computing;Parallel processing;Pipeline processing;Parallel programming;Distributed computing;Array signal processing;Application software;Human computer interaction;Multitasking;Concrete","parallel programming","language construct;layered development;parallel programs;algorithms;parallel computers;molecule type;computation mode;sequential;pipelining;array processing;dataflow;multiprocessing;procedural language;PAL;layered software development;multicomputer;iPSC;high-level languages;application flexibility;user friendliness","","10","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Evaluating Software Development by Analysis of Changes: Some Data from the Software Engineering Laboratory","D. M. Weiss; V. R. Basili","Naval Research Laboratory; NA","IEEE Transactions on Software Engineering","","1985","SE-11","2","157","168","An effective data collection methodology for evaluating software development methodologies was applied to five different software development projects. Results and data from three of the projects are presented. Goals of the data collection included characterizing changes, errors, projects, and programmers, identifying effective error detection and correction techniques, and investigating ripple effects.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232190","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701983","Software change analysis;software change data;software errors;software measurement","Software engineering;Laboratories;Error correction;Data analysis;Programming profession;Application software;Error correction codes;Software testing;Pattern analysis;Hardware","","Software change analysis;software change data;software errors;software measurement","","58","","10","","","","","","IEEE","IEEE Journals & Magazines"
"On the Cycle Time Distribution in a Two-Stage Cyclic Network with Blocking","S. Balsamo; L. Donatiello","Department Of Mathematics, University Of Modeoa, Via Campi 2 13/b, 41100 Modena. Italy.; NA","IEEE Transactions on Software Engineering","","1989","15","10","1206","1216","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1989.559769","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=559769","","Intelligent networks;Network servers;Computer networks;Steady-state;Distributed computing;Polynomials;Performance analysis;Queueing analysis;Central Processing Unit","","BCMP network;blocking;cycle time distribution;cycte time moments;performance analysis;state space transformation;two-stage cyclic queue","","9","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Derivation of data intensive algorithms by formal transformation: the Schnorr-Waite graph marking algorithm","M. Ward","Dept. of Comput. Sci., Durham Univ., UK","IEEE Transactions on Software Engineering","","1996","22","9","665","686","Considers a particular class of algorithms which present certain difficulties to formal verification. These are algorithms which use a single data structure for two or more purposes, which combine program control information with other data structures or which are developed as a combination of a basic idea with an implementation technique. Our approach is based on applying proven semantics-preserving transformation rules in a wide spectrum language. Starting with a set theoretical specification of ""reachability"", we are able to derive iterative and recursive graph marking algorithms using the ""pointer switching"" idea of Schorr and Waite (1967). There have been several proofs of correctness of the Schorr-Waite algorithm, and a small number of transformational developments of the algorithm. The great advantage of our approach is that we can derive the algorithm from its specification using only general-purpose transformational rules, without the need for complicated induction arguments. Our approach applies equally well to several more complex algorithms which make use of the pointer switching strategy, including a hybrid algorithm which uses a fixed length stack, switching to the pointer switching strategy when the stack runs out.","0098-5589;1939-3520;2326-3881","","10.1109/32.541437","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=541437","","Iterative algorithms;Data structures;Formal verification;Logic;Computer bugs;Computer science","formal verification;data structures;graph colouring;program control structures;set theory;algorithm theory;reachability analysis;formal specification","data-intensive algorithm derivation;formal transformation;Schnorr-Waite graph marking algorithm;formal verification;program control information;data structures;implementation technique;semantics-preserving transformation rules;wide spectrum language;reachability;iterative algorithms;recursive algorithms;pointer switching strategy;fixed length stack;program development;transformational development;set theoretical specification;ghost variables;data refinement;recursion removal","","17","","49","","","","","","IEEE","IEEE Journals & Magazines"
"The computational completeness of extended database query languages","D. A. Varvel; L. Shapiro","Dept. of Comput. Sci., North Dakota Univ., Grand Forks, ND, USA; NA","IEEE Transactions on Software Engineering","","1989","15","5","632","638","The computational completeness is demonstrated of certain extended database query languages, namely, POSTGRES and GENESIS, and a language defined by A. Aho and J. Ullman (1979). The method used is to implement a Turing machine interpreter in each of the languages. These query languages were defined as extensions to traditional database languages in order to encompass certain specific new applications. Results show that these extensions have already encompassed all the computational power of any programming language.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24712","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24712","","Database languages;Turing machines;Calculus;Computer languages;Mathematical model;Algebra;Computer science;Relational databases;Mathematical programming","database management systems;query languages","computational completeness;extended database query languages;POSTGRES;GENESIS;Turing machine interpreter;traditional database languages;computational power;programming language","","3","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Gandalf: Software development environments","A. N. Habermann; D. Notkin","Department of Computer Science, Carnegie-Mellon University, Pittsburgh, PA 15213; Department of Computer Science, University of Washington, Seattle, WA 98195","IEEE Transactions on Software Engineering","","1986","SE-12","12","1117","1127","Different programming projects require different environments, but handcrafting a separate environment for each project is not economically feasible. Gandalf solves this problem by permitting environment designers to generate families of software development environments semiautomatically without excessive cost. Environments generated using Gandalf address programming environments, which help ease the programming process, as well as system development environments, which reduce the degree to which a software project is dependent on the good will of its members. Gandalf environments integrate programming and system development, permitting interactions not available in traditional environments. The paper covers the basic characteristics of Gandalf environments. The method used to generate these environments, the structure and function of several existing environments, and ongoing research on the project.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313007","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313007","Environment generation;incremental program construction;programming environments;project management;software development environments;structure-oriented editing;syntax-directed editing;system development environments;system version control","Software;Syntactics;Programming environments;Programming;Control systems;Abstracts;Concrete","automatic programming;programming environments","software development environments;Gandalf;programming environments;system development","","64","","","","","","","","IEEE","IEEE Journals & Magazines"
"Teapot: a domain-specific language for writing cache coherence protocols","S. Chandra; B. Richards; J. R. Larus","Lucent Technol., Bell Labs., Naperville, IL, USA; NA; NA","IEEE Transactions on Software Engineering","","1999","25","3","317","333","In this paper, we describe Teapot, a domain-specific language for writing cache coherence protocols. Cache coherence is of concern when parallel and distributed systems make local replicas of shared data to improve scalability and performance. In both distributed shared memory systems and distributed file systems, a coherence protocol maintains agreement among the replicated copies as the underlying data are modified by programs running on the system. Cache coherence protocols are notoriously difficult to implement, debug, and maintain. Moreover, protocols are not off-the-shelf, reusable components, because their details depend on the requirements of the system under consideration. The complexity of engineering coherence protocols can discourage users from experimenting with new, potentially more efficient protocols. We have designed and implemented Teapot, a domain-specific language that attempts to address this complexity. Teapot's language constructs, such as a state-centric control structure and continuations, are better suited to expressing protocol code than those of a typical systems programming language. Teapot also facilitates automatic verification of protocols, so hard to find protocol bugs, such as deadlocks, can be detected and fixed before encountering them on an actual execution. We describe the design rationale of Teapot, present an empirical evaluation of the language using two case studies, and relate the lessons that we learned in building a domain-specific language for systems programming.","0098-5589;1939-3520;2326-3881","","10.1109/32.798322","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=798322","","Domain specific languages;Writing;Protocols;Scalability;File systems;Maintenance engineering;Automatic control;Control systems;Computer languages;Computer bugs","memory protocols;cache storage;distributed shared memory systems;distributed databases;distributed programming;formal verification;high level languages","Teapot;domain-specific language;cache coherence protocol writing;parallel systems;distributed systems;local shared data replicas;scalability;performance;distributed shared memory systems;distributed file systems;state-centric control structure;continuations;automatic verification;deadlocks;debugging;systems programming","","16","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Software development productivity of European space, military, and industrial applications","K. D. Maxwell; L. Van Wassenhove; S. Dutta","INSEAD, Fontainebleau, France; INSEAD, Fontainebleau, France; INSEAD, Fontainebleau, France","IEEE Transactions on Software Engineering","","1996","22","10","706","718","The identification, combination, and interaction of the many factors which influence software development productivity makes the measurement, estimation, comparison and tracking of productivity rates very difficult. Through the analysis of a European Space Agency database consisting of 99 software development projects from 37 companies in a European countries, the paper seeks to provide significant and useful Information about the major factors which influence the productivity of European space, military, and industrial applications, as well as to determine the best metric for measuring the productivity of these projects. Several key findings emerge from the study. The results indicate that some organizations are obtaining significantly higher productivity than others. Some of this variation is due to the differences in the application category and programming language of projects in each company; however, some differences must also be due to the ways in which these companies manage their software development projects. The use of tools and modern programming practices were found to be major controllable factors in productivity improvement. Finally, the lines-of-code productivity metric is shown to be superior to the process productivity metric for projects in the authors' database.","0098-5589;1939-3520;2326-3881","","10.1109/32.544349","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=544349","","Programming;Productivity;Software measurement;Extraterrestrial measurements;Databases;Application software;Information analysis;Aerospace industry;Computer industry;Defense industry","human resource management;software metrics;aerospace computing;military computing;production engineering computing;high level languages;software tools;programming","software development productivity;European Space Agency database;software development projects;European space applications;European military applications;European industrial applications;programming language;tools;lines-of-code productivity metric;process productivity metric","","56","","39","","","","","","IEEE","IEEE Journals & Magazines"
"A Scheme for Batch Verification of Integrity Assertions in a Database System","L. Lilien; B. Bhargava","Department of Computer Science, University of Pittsburgh, Pittsburgh, PA 15260.; Department of Electrical Engineering and Computer Science, University of Illinois at Chicago, Chicago, IL 60680.; Department of Computer Science, University of Pittsburgh, Pittsburgh, PA 15260.; Department of Computer Sciences, Purdue University, West Lafayette, IN 47907.","IEEE Transactions on Software Engineering","","1984","SE-10","6","664","680","A database management system can ensure the semantic integrity of a database via an integrity control subsystem. A technique for implementation of such a subsystem is proposed. After a database is updated by transactions, its integrity must be verified by evaluation of a set of semantic integrity assertions. For evaluation of an integrity assertion a number of database pages need to be transferred from the secondary storage to the fast memory. Since certain pages may be required for evaluation of different integrity assertions, the order of the evaluation of the integrity assertions determines the total number of pages fetched from the secondary storage. Hence, the schedule for the evaluation determines the cost of the database verification process. We show that the search for an optimal schedule is an NP-hard problem. Four approximation algorithms that find suboptimal schedules are proposed. They are based on the utilization of intersections among sets of pages required for the evaluation of different integrity assertions. The theoretical worst case behaviors of these algorithms are studied. Finally, the algorithms are compared via a simulation study to a naive, random order verification approach. The methods proposed for minimizing the costs of the batch integrity verification also apply to other problems that can be abstracted to the directed traveling salesman optimization problem. For example, the methods are applicable to multiple to multiple-query optimization and to concurrency control via the predicate locks.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010295","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010295","Approximation algorithms;database crash and recovery;database systems;design for error control;directed traveling salesman problem;NP-completeness;semantic database integrity;software reliability","Database systems;Transaction databases;Optimal scheduling;Optimization methods;Control systems;NP-hard problem;Approximation algorithms;Scheduling algorithm;Cost function;Traveling salesman problems","","","","7","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Optimization Strategies for Relational Queries","P. Ciaccia; M. R. Scalas","Dipartimento di Elettronica, informatica e Sistemistica, University di Bologna, Viale Risorgimento 2.40136 Bologna. Italy.; NA","IEEE Transactions on Software Engineering","","1989","15","10","1217","1235","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1989.559773","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=559773","","Costs;Query processing;US Department of Transportation;Hip;Indexes;Relational databases;Standardization;Environmental economics;Algebra","","Disjunctive expressions;join algorithms;query models;query optimisation;relational databases","","5","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Conversion of units of measurement","G. S. Novak","Dept. of Comput. Sci., Texas Univ., Austin, TX, USA","IEEE Transactions on Software Engineering","","1995","21","8","651","661","Algorithms are presented for converting units of measurement from a given form to a desired form. The algorithms are fast, are able to convert any combination of units to any equivalent combination, and perform dimensional analysis to ensure that the conversion is legitimate. Algorithms are also presented for simplification of symbolic combinations of units. Application of these techniques to perform automatic unit conversion and unit checking in a programming language is described.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.403789","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=403789","","Measurement units;Books;Computer languages;Performance analysis;Programming profession;Data analysis;Algorithm design and analysis;Application software;Web sites;Guidelines","programming languages;software metrics;data structures","units of measurement;equivalent combination;dimensional analysis;symbolic combinations;automatic unit conversion;unit checking;programming language;symbolic representation;software measurement","","13","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Persistent Software Errors","R. L. Glass","Boeing Aerospace Company","IEEE Transactions on Software Engineering","","1981","SE-7","2","162","168","Persistent software errors-those which are not discovered until late in development, such as when the software becomes operational-are by far the most expensive kind of error. Via analysis of software problem reports, it is discovered that the predominant number of persistent errors in large-scale software efforts are errors of omitted logic..., that is, the code is not as complex as required by the problem to be solved. Peer design and code review, desk checking, and ultrarigorous testing may be the most helpful of the currently available technologies in attacking this problem. New and better methodologies are needed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230831","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702822","Complexity;omitted logic;persistent software error;research in the large;software problem report;testing rigor","Error correction;Costs;Computer errors;Embedded software;Software maintenance;Embedded computing;Software systems;Logic testing;Software testing;Software debugging","","Complexity;omitted logic;persistent software error;research in the large;software problem report;testing rigor","","80","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Guaranteeing good memory bounds for parallel programs","F. W. Burton","Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada","IEEE Transactions on Software Engineering","","1996","22","10","762","773","The amount of memory required by a parallel program may be spectacularly larger than the memory required by an equivalent sequential program, particularly for programs that use recursion extensively. Since most parallel programs are nondeterministic in behavior, even when computing a deterministic result, parallel memory requirements may vary from run to run, even with the same data. Hence, parallel memory requirements may be both large (relative to memory requirements of an equivalent sequential program) and unpredictable. Assume that each parallel program has an underlying sequential execution order that may be used as a basis for predicting parallel memory requirements. We propose a simple restriction that is sufficient to ensure that any program that will run in n units of memory sequentially can run in mn units of memory on m processors, using a scheduling algorithm that is always within a factor of two of being optimal with respect to time. Any program can be transformed into one that satisfies the restriction, but some potential parallelism may be lost in the transformation. Alternatively, it is possible to define a parallel programming language in which only programs satisfying the restriction can be written.","0098-5589;1939-3520;2326-3881","","10.1109/32.544353","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=544353","","Processor scheduling;Concurrent computing;Parallel processing;Parallel programming;Scheduling algorithm;Dynamic programming","storage allocation;parallel programming;processor scheduling;parallel languages;storage management","memory bounds;parallel programs;sequential program;recursion;nondeterministic programs;parallel memory requirements;sequential execution order;scheduling algorithm;optimal time;parallel programming language","","4","","13","","","","","","IEEE","IEEE Journals & Magazines"
"A Loosely Coupled Distributed System for Reliably Storing Data","A. J. Bernstein","Department of Computer Science, State University of New York","IEEE Transactions on Software Engineering","","1985","SE-11","5","446","454","An algorithm for storing information redundantly on the nodes of a broadcast network is proposed. A voting technique is used to increase reliability. Since multiple votes are cast only when copies of a data item disagree, the algorithm has the property that communication overhead is minimal. In addition, nodes storing erroneous copies are automatically resynchronized. A Markov analysis is performed which relates parameters of the algorithm to the mean time to failure.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232483","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702034","Broadcast network;Markov analysis;multiple copy database;redundancy;reliability;stable storage;voting algorithm","Telecommunication network reliability;Voting;Computer crashes;Broadcasting;Algorithm design and analysis;Transaction databases;Failure analysis;Performance analysis;Data analysis;Redundancy","","Broadcast network;Markov analysis;multiple copy database;redundancy;reliability;stable storage;voting algorithm","","3","","16","","","","","","IEEE","IEEE Journals & Magazines"
"A trace-driven simulation study of dynamic load balancing","S. Zhou","Div. of Comput. Sci., California Univ., Berkeley, CA, USA","IEEE Transactions on Software Engineering","","1988","14","9","1327","1341","A trace-driven simulation study of dynamic load balancing in homogeneous distributed systems supporting broadcasting is presented. Information about job CPU and input/output (I/O) demands collected from production systems is used as input to a simulation model that includes a representative CPU scheduling policy and considers the message exchange and job transfer cost explicitly. Seven load-balancing algorithms are simulated and their performances compared. Load balancing is capable of significantly reducing the mean and standard deviation of job response times, especially under heavy load, and for jobs with high resource demands. Algorithms based on periodic or nonperiodic load information exchange provide similar performance, and, among the periodic policies, the algorithms that use a distinguished agent to collect and distribute load information cut down the overhead and scale better. With initial job placements only, source initiative algorithms were found to perform better than server initiative algorithms. The performances of all hosts, even those originally with light loads, are generally improved by load balancing.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6176","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6176","","Load management;Costs;Delay;Computer networks;Computer science;Broadcasting;Job production systems;Processor scheduling;Computational modeling;Hardware","distributed databases;input-output programs;scheduling","trace-driven simulation;dynamic load balancing;homogeneous distributed systems;broadcasting;CPU;input/output;scheduling;message exchange;job transfer;job response times","","172","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Design Considerations for a Message File Server","S. Christodoulakis; C. Faloutsos","Computer Systems Research Group, University of Toronto, Toronto, Ont., Canada.; Computer Systems Research Group, University of Toronto, Toronto, Ont., Canada.","IEEE Transactions on Software Engineering","","1984","SE-10","2","201","210","In this paper we describe a message server facility for handling large organizational archives of messages in an office information system environment. Messages can be retrieved according to attribute values specified and to some pattern of words appearing in the text of the message. We discuss design decisions and performance considerations in this environment and we derive analytic formulas for the optimal choice of the parameters of the message file organization.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010223","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010223","Electronic message filing;office automation text retrieval;superimposed coding","File servers;Information systems;Workstations;Network servers;Performance analysis;Office automation;Frequency;System performance;Power system interconnection;Microprocessors","","","","55","","22","","","","","","IEEE","IEEE Journals & Magazines"
"An integrated life-cycle model for software maintenance","S. S. Yau; R. A. Nicholl; J. J. -. Tsai; S. -. Liu","Dept. of Elect. Eng. & Comput. Sci., Northwestern Univ., Evanston, IL, USA; Dept. of Elect. Eng. & Comput. Sci., Northwestern Univ., Evanston, IL, USA; Dept. of Elect. Eng. & Comput. Sci., Northwestern Univ., Evanston, IL, USA; Dept. of Elect. Eng. & Comput. Sci., Northwestern Univ., Evanston, IL, USA","IEEE Transactions on Software Engineering","","1988","14","8","1128","1144","An integrated life-cycle model is presented for use in a software maintenance environment. The model represents information about the development and maintenance of software systems, emphasizing relationships between different phases of the software life cycle. It provides the basis for automated tools to assist maintenance personnel in making changes to existing software systems. The model is independent of particular specification, design, and programming languages because it represents only certain 'basic' semantic properties of software systems: control flow, data flow, and data structure. The software development processes by which one phase of the software life cycle is derived from another are represented by graph rewriting rules, which indicate how various components of a software system have been implemented. This approach permits analysis of the basic properties of a software system throughout the software life cycle. Examples are given to illustrate the integrated software life-cycle model during evolution.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.7624","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=7624","","Software maintenance;Software systems;Software tools;Computer science;Proposals;Costs;Personnel;Computer languages;Control system synthesis","data structures;graph theory;programming environments;software reliability;software tools","software tools;graph theory;programming environments;integrated life-cycle model;software maintenance;software life cycle;semantic properties;control flow;data flow;data structure;graph rewriting rules","","26","","19","","","","","","IEEE","IEEE Journals & Magazines"
"User validation of information system requirements: some empirical results","J. T. Nosek; R. B. Schwartz","Dept. of Comput. & Inf. Sci., Temple Univ., Philadelphia, PA, USA; Dept. of Comput. & Inf. Sci., Temple Univ., Philadelphia, PA, USA","IEEE Transactions on Software Engineering","","1988","14","9","1372","1375","While validation of user requirements has become an important goal for information system designers, little empirical research has been done in this area. Many methodologies have been presented as the best procedures for achieving user validation of design. An attempt is made to consider four of these methodologies in four different experimental settings. In the four experiments, the following treatments were examined: HIPO (hierarchy plus input, process, and output) vs. system flowcharts; DFD (data-flow diagram) narrative; DFD vs. Warnier-Orr diagrams; and DFD vs. HIPO. The main result of all four experiments was that choice of design methodology had no effect on the level of user understanding of system requirements.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6180","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6180","","Information systems;Design for disassembly;Design methodology;Testing;Flowcharts;Data processing;Design for experiments;Documentation;Information analysis;Software engineering","systems analysis","systems analysis;information system requirements;user requirements;HIPO;system flowcharts;DFD;data-flow diagram;Warnier-Orr diagrams;user understanding","","10","","21","","","","","","IEEE","IEEE Journals & Magazines"
"An iconic programming system, HI-VISUAL","M. Hirakawa; M. Tanaka; T. Ichikawa","Dept. of Inf. Syst., Hiroshima Univ., Japan; Dept. of Inf. Syst., Hiroshima Univ., Japan; Dept. of Inf. Syst., Hiroshima Univ., Japan","IEEE Transactions on Software Engineering","","1990","16","10","1178","1184","A framework for icon management which is quite object-oriented is proposed, and an iconic programming system named HI-VISUAL is presented on the basis of the framework. In the framework, icons represent real objects or concepts already established in a target application environment, whereas icons representing functions are not provided. A function is represented by a combination of two different icons. Each icon can take an active or a passive role against the other. The role sharing is determined dynamically, depending on the environment in which the icons are activated. Programming in HI-VISUAL and implementation issues of the system prototype, now in operation in a laboratory environment, are extensively discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.60297","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=60297","","Programming profession;Man machine systems;Prototypes;Laboratories;Object oriented programming;Programming environments;Two dimensional displays;Information systems;Systems engineering and theory","object-oriented programming;visual programming","iconic programming system;HI-VISUAL;object-oriented;real objects;target application environment;role sharing;system prototype","","27","","12","","","","","","IEEE","IEEE Journals & Magazines"
"A formal analysis of the subsume relation between software test adequacy criteria","Hong Zhu","Inst. of Comput. Software, Nanjing Univ., China","IEEE Transactions on Software Engineering","","1996","22","4","248","255","Software test adequacy criteria are rules to determine whether a software system has been adequately tested. A central question in the study of test adequacy criteria is how they relate to fault detecting ability. We identify two idealized software testing scenarios. In the first scenario, which we call prior testing scenario, software testers are provided with an adequacy criterion in addition to the software under test. The knowledge of the adequacy criterion is used to generate test cases. In the second scenario, which we call posterior testing scenario, software testers are not provided with the knowledge of adequacy criterion. The criterion is only used to decide when to stop the generation of test cases. In 1993, Frankl and Weyuker proved that the subsume relation between software test adequacy criteria does not guarantee better fault detecting ability in the prior testing scenario. We investigate the posterior testing scenario and prove that in this scenario the subsume relation does guarantee a better fault detecting ability. Two measures of fault detecting ability will be used, the probability of detecting faults and the expected number of exposed errors.","0098-5589;1939-3520;2326-3881","","10.1109/32.491648","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=491648","","Software testing;Fault detection;System testing;Genetic mutations;Software measurement;Software systems;Linear code","program testing;probability;program diagnostics","software test adequacy criteria;software system;formal analysis;subsume relation;fault detecting ability;idealized software testing scenarios;prior testing scenario;software testers;test case generation;posterior testing scenario;fault detection probability;expected exposed errors","","22","","33","","","","","","IEEE","IEEE Journals & Magazines"
"Redundancy in Data Structures: Some Theoretical Results","D. J. Taylor; D. E. Morgan; J. P. Black","Department of Computer Science and the Computer Communications Networks Group, University of Waterloo; NA; NA","IEEE Transactions on Software Engineering","","1980","SE-6","6","595","602","A companion paper, ""Redundancy in Data Structures: Improving Software Fault Tolerance,"" provides an infonnal introduction to robust data structures. Here, we present the underlying theory for them, and use it to discuss the synthesis and cost effectiveness of robust data structures.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230803","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702786","Compound data structures;error correction;error detection;redundancy;robust data structures;software fault tolerance;software reliability","Data structures;Robustness;Redundancy;Upper bound;Fault tolerance;Costs;Error correction;Fault detection;Software reliability;Councils","","Compound data structures;error correction;error detection;redundancy;robust data structures;software fault tolerance;software reliability","","22","","4","","","","","","IEEE","IEEE Journals & Magazines"
"Evaluating deadlock detection methods for concurrent software","J. C. Corbett","Dept. of Inf. & Comput. Sci., Hawaii Univ., Honolulu, HI, USA","IEEE Transactions on Software Engineering","","1996","22","3","161","180","Static analysis of concurrent programs has been hindered by the well-known state explosion problem. Although many different techniques have been proposed to combat this state explosion, there is little empirical data comparing the performance of the methods. This information is essential for assessing the practical value of a technique and for choosing the best method for a particular problem. In this paper, we carry out an evaluation of three techniques for combating the state explosion problem in deadlock detection: reachability searching with a partial-order state-space reduction, symbolic model checking and inequality-necessary conditions. We justify the method used for the comparison, and carefully analyze several sources of potential bias. The results of our evaluation provide valuable data on the kinds of programs to which each technique might best be applied. Furthermore, we believe that the methodological issues we discuss are of general significance in comparison of analysis techniques.","0098-5589;1939-3520;2326-3881","","10.1109/32.489078","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=489078","","System recovery;Explosions;State-space methods;Software safety;Concurrent computing;Software tools;Application software;Protocols;Reachability analysis;Data analysis","concurrency control;state-space methods;software engineering;system monitoring;multiprocessing programs;programming theory","deadlock detection methods;concurrent software;static analysis;state explosion problem;performance;reachability search;partial-order state-space reduction;symbolic model checking;inequality-necessary conditions;concurrency analysis;empirical evaluation;Ada tasking","","95","","47","","","","","","IEEE","IEEE Journals & Magazines"
"Quality improvement using a software reuse failure modes model","W. B. Frakes; C. J. Fox","Dept. of Comput. Sci., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA; NA","IEEE Transactions on Software Engineering","","1996","22","4","274","279","The paper presents a failure modes model of parts-based software reuse, and shows how this model can be used to evaluate and improve software reuse processes. The model and the technique are illustrated using survey data about software reuse gathered from 113 people from 29 organizations.","0098-5589;1939-3520;2326-3881","","10.1109/32.491652","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=491652","","Software quality;Application software;Environmental economics;Law;Failure analysis;Software systems;Legal factors;Computer languages;Pareto analysis;Knowledge engineering","software reusability;software quality;failure analysis;system monitoring","software reuse failure modes model;parts-based software reuse;quality improvement;software reuse process evaluation;software reuse process improvement","","39","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Performance analysis of parallel processing systems","R. Nelson; D. Towsley; A. N. Tantawi","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; NA; NA","IEEE Transactions on Software Engineering","","1988","14","4","532","540","A bulk arrival M/sup x//M/c queuing system is used to model a centralized parallel processing system with job splitting. In such a system, jobs wait in a central queue, which is accessible by all the processors, and are split into independent tasks that can be executed on separate processors. The job response-time consists of three components: queuing delay, service time, and synchronization delay. An expression for the mean job response-time is obtained for this centralized parallel-processing system. Centralized and distributed parallel-processing systems (with and without job-splitting) are considered and their performances compared. Furthermore, the effects of parallelism and overheads due to job-splitting are investigated.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4676","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4676","","Performance analysis;Parallel processing;Delay effects;Queueing analysis;Tree graphs;Difference equations","parallel processing;performance evaluation;queueing theory","parallel processing systems;queuing system;job splitting;independent tasks;job response-time;queuing delay;service time;synchronization delay","","79","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Facilitating Mixed Language Programming in Distrbuted Systems","R. Hayes; R. D. Schlichting","Department of Computer Science, University of Arizona; NA","IEEE Transactions on Software Engineering","","1987","SE-13","12","1254","1264","An approach for facilitating mixed language programming in distributed systems is presented. It is based on adding a generic remote procedure call facility to each language, and the use of a type system to describe procedural interfaces, as well as data to be transferred between procedures. This type scheme also specifies a machine-independent representation for all data. By defining standard mappings for each programming language, the data conversions required for cross-langauge calls may be performed, automatically in most cases, by active agents that provide the interface between program components written in different languages. When necessary, explicit control of the conversation is possible. A prototype implementation of a system based on this approach has been constructed on a collection of machines running Berkeley UNIX.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232879","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702177","Data type;distributed systems;mixed language programming;programming languages;remote procedure call","Computer languages;Programming profession;Data conversion;Automatic control;Prototypes;Algorithms;Libraries;Data analysis;Supercomputers;User interfaces","","Data type;distributed systems;mixed language programming;programming languages;remote procedure call","","15","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Function points in the estimation and evaluation of the software process","G. C. Low; D. R. Jeffery","Sch. of Inf. Syst., New South Wales Univ., Kensington, NSW, Australia; Sch. of Inf. Syst., New South Wales Univ., Kensington, NSW, Australia","IEEE Transactions on Software Engineering","","1990","16","1","64","71","The authors report the results of an empirical research project on the consistency and limitations of the number of function points as an a priori measure of system size rather than the traditional lines-of-code measure. They conclude that function points are a more consistent a priori measure of system size. The results also indicate that the function-point estimate of size is lower for analysts experienced both in software development and in function-point estimation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44364","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44364","","Size measurement;Project management;Software measurement;Gain measurement;Environmental management;Application software;Life estimation;System testing;Performance analysis;Productivity","software engineering","estimation;evaluation;consistency;limitations;function points;a priori measure;system size;software development;function-point estimation","","109","","19","","","","","","IEEE","IEEE Journals & Magazines"
"A Case for Non-Two-Phase Locking Protocols that Ensure Atomicity","A. Silberschatz","Department of Computer Science, University of Texas","IEEE Transactions on Software Engineering","","1983","SE-9","4","535","538","A transaction is atomic if it can be considered, as far as other transactions are concerned, to be indivisible and instantaneous even in the case of failure. An almost universally accepted way to ensure atomicity is to use a strict two-phase locking protocol with a roll-back scheme for recovery in case of deadlock or failure. In this note, we argue that this method is not the most economical way to achieve this end. We develop a Dependency Graph model which is used to analyze the two-phase and non-two-phase locking schemes. It is shown that one way of choosing between the two types of schemes is to estimate the number of rollbacks required. If this number is large, a two-phase scheme is preferable; if small, a non-two-phase scheme should be selected. We demonstrate that with reasonable discipline, the number of such rollbacks can be minimized. Thus, contrary to common practice and belief, non-two-phase protocols can be effectively used in guaranteeing atomicity.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.235107","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703088","Atomicity;concurrency;consistency;database systems;deadlocks;lockdng protocols;rollbacks;transactions","Computer aided software engineering;System recovery;Robustness;Database systems;Transaction databases;Contracts;Computer science;Concurrent computing;Access protocols;Environmental economics","","Atomicity;concurrency;consistency;database systems;deadlocks;lockdng protocols;rollbacks;transactions","","2","","18","","","","","","IEEE","IEEE Journals & Magazines"
"On Development of Iterative Programs from Function Specifications","S. K. Basu","Department of Computer Sciences, University of Nebraska","IEEE Transactions on Software Engineering","","1980","SE-6","2","170","182","A systematic approach to the development of totally correct iterative programs is investigated for the class of accumulation problems. In these problems, the required output information is usually obtained by accumulation during successive passes over input data structures. The development of iterative programs for accumulation problems is shown to involve successive generalizations of the data domain and the corresponding function specifications. The problem of locating these generalizations is discussed. It is shown that not all function specifications can be realized in terms of terminating computations of a stand-alone iterative program. A linear data domain is defined in terms of decomposition and finiteness axioms, and the property of well behavedness of a loop body over a linear data domain is introduced. It is shown that this property can be used to generate loop body specifications from specifically chosen examples of program behavior. An abstract program for an accumulation problem is developed using these considerations. The role of generalizations as an added parameter to the program development process is discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230468","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702714","Function specifications;generalizations;iterative programs;linear data domain;program development;total correctness","Data structures;Iterative methods;Equations;Programming profession;Binary trees;Programmable logic arrays","","Function specifications;generalizations;iterative programs;linear data domain;program development;total correctness","","2","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Perfornance Study of Two Phase Locking in Single-Site Database Systems","K. H. Pun; G. G. Belford","Centre of Computer Studies, University of Hong Kong; NA","IEEE Transactions on Software Engineering","","1987","SE-13","12","1311","1328","Many database systems guarantee the consistency of the database for concurrent transaction processing by a standard locking protocol called two phase locking. The performance of such systems is dependent on various factors, among which are the choices of locking granularity (the amount of data controlled by a single lock) and degree of multiprogramming (the maximum number of transactions allowed to run concurrently in the system). Previous simulation and experimental studies on such systems suggest that the choices are dependent on the properties of the application.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233142","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702181","Degree of multiprogramming;granularity;performance mance study;queueing networks;simulation;single-site database systems;two-phase locking","Database systems;Predictive models;Transaction databases;Processor scheduling;Computer science;Concurrency control;Protocols;Control systems;System recovery;Analytical models","","Degree of multiprogramming;granularity;performance mance study;queueing networks;simulation;single-site database systems;two-phase locking","","7","","27","","","","","","IEEE","IEEE Journals & Magazines"
"A dynamic load-balancing policy with a central job dispatcher (LBC)","H. -. Lin; C. S. Raghavendra","Dept. of Electr. Eng.-Syst., Univ. of Southern California, Los Angeles, CA, USA; Dept. of Electr. Eng.-Syst., Univ. of Southern California, Los Angeles, CA, USA","IEEE Transactions on Software Engineering","","1992","18","2","148","158","A dynamic load-balancing policy is proposed with a central job dispatcher called the LBC policy for distributed systems. The design of this policy is motivated by the operation of a single-queue multiserver queueing system, and the average job response time is the same as that of a single-queue multiserver system, which is the best achievable performance when the communication delay is reduced to zero. Hence, near-minimum average job response time is expected for distributed systems with high-speed communication subnets. The performance is studied for systems with nonnegligible job transfer delays in the following three aspects: average job response time, overhead due to information exchanges, and sensitivity to heterogeneous load.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.121756","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=121756","","Load management;Delay effects;Delay estimation;Communication networks;Computer networks;Distributed computing;Time factors;Time measurement","distributed processing;operating systems (computers);queueing theory","dynamic load-balancing policy;central job dispatcher;LBC policy;distributed systems;single-queue multiserver queueing system;average job response time;communication delay;near-minimum average job response time;high-speed communication subnets;nonnegligible job transfer delays;information exchanges;heterogeneous load","","84","","27","","","","","","IEEE","IEEE Journals & Magazines"
"An event-based architecture definition language","D. C. Luckham; J. Vera","Comput. Syst. Lab., Stanford Univ., CA, USA; Comput. Syst. Lab., Stanford Univ., CA, USA","IEEE Transactions on Software Engineering","","1995","21","9","717","734","This paper discusses general requirements for architecture definition languages, and describes the syntax and semantics of the subset of the Rapide language that is designed to satisfy these requirements. Rapide is a concurrent event-based simulation language for defining and simulating the behavior of system architectures. Rapide is intended for modelling the architectures of concurrent and distributed systems, both hardware and software in order to represent the behavior of distributed systems in as much detail as possible. Rapide is designed to make the greatest possible use of event-based modelling by producing causal event simulations. When a Rapide model is executed it produces a simulation that shows not only the events that make up the model's behavior, and their timestamps, but also which events caused other events, and which events happened independently. The architecture definition features of Rapide are described: event patterns, interfaces, architectures and event pattern mappings. The use of these features to build causal event models of both static and dynamic architectures is illustrated by a series of simple examples from both software and hardware. Also we give a detailed example of the use of event pattern mappings to define the relationship between two architectures at different levels of abstraction. Finally, we discuss briefly how Rapide is related to other event-based languages.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.464548","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=464548","","Computer architecture;Object oriented modeling;Discrete event simulation;Hardware;History;System testing;Virtual prototyping;Concurrent computing;Object oriented programming;Large-scale systems","simulation languages;virtual machines;hardware description languages;distributed processing;discrete event simulation","event-based architecture definition language;syntax;semantics;Rapide language;concurrent event-based simulation language;distributed systems;causal event simulations;timestamps;event patterns;event pattern mappings;interfaces;causal event models;event-based languages","","164","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Efficient evaluation of multiple linear recursions","J. Han; L. Liu","Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada; Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada","IEEE Transactions on Software Engineering","","1991","17","12","1241","1252","The authors study the efficient evaluation of side-coherent multiple linear recursions, which can be further classified into three types: multiple one-sided, multiple balanced k-sided, and multiple mixed k-sided. New techniques are developed by integrating the existing single-linear recursive query evaluation methods with the idea of side-relation unioned processing, which leads to a set of efficient query evaluation algorithms such as a side-relation unioned transitive closure algorithm for the processing of Type I ML recursions and a generalized side-relation unioned magic sets method for the processing of Types II and III ML recursions. The authors describe the processing of single-probe queries on side-coherent ML recursions. They outline the processing of complex queries on ML recursions.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.106985","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=106985","","Query processing;Deductive databases;Logic programming;Helium;Councils","database theory;deductive databases;information retrieval;recursive functions","multiple one sided linear recursions;deductive database;multiple balanced K-sided recursions;multiple mixed K-sided recursion;side-coherent multiple linear recursions;single-linear recursive query evaluation;side-relation unioned processing;side-relation unioned transitive closure algorithm;side-relation unioned magic sets method;single-probe queries","","4","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Functional addressing in Gutenberg: Interprocess communication without process identifiers","D. W. Stemple; S. T. Vinter; K. Ramamritham","Department of Computer and Information Science, University of Massachusetts, Amherst, MA 01003; BBN Laboratories, Inc., 10 Moulton Street, Cambridge, MA 02238; Department of Computer and Information Science, University of Massachusetts, Amherst, MA 01003","IEEE Transactions on Software Engineering","","1986","SE-12","11","1056","1066","An interprocess communication facility provided by the kernel of the Gutenberg experimental operating system is presented. In Gutenberg all interprocess communication is via channels (ports) that are typed by the service which can be requested on them. Ports are created by reference to their service without using the identifier of the process providing the service, a technique the authors refer to as functional addressing. By using functional addressing, interprocess transfer of port use privileges and a new concept of cooperation class, arbitrary process interconnection topologies can be achieved without any explicit use of process identifiers by processes. Examples of object sharing with abstract data type managers and data-driven protocols of database query execution are presented to illustrate the methods of constructing systems of cooperation processes using the Gutenberg system.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312995","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312995","Capabilities;functional addressing;interprocess communication;operating systems;port","Servers;Protocols;Kernel;Topology;Switches","computer communications software;database management systems;operating systems (computers);protocols","functional addressing;interprocess communication facility;Gutenberg experimental operating system;interprocess transfer;cooperation class;arbitrary process interconnection topologies;abstract data type managers;data-driven protocols;database query execution","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"On the Uncertainty in the Correctness of Computer Programs","F. B. Bastani","Department of Computer Science, University of Houston","IEEE Transactions on Software Engineering","","1985","SE-11","9","857","864","The use of digital computers in critical process control systems requires the formal assessment of the system reliability. Failures can be due to either component malfunctions or design faults. Only the latter are relevant in evaluating software reliability. Although it is preferable to prove whether the program meets its specification, this is not yet practical for real-time control programs. Further, the specification itself can be incorrect or incomplete due to the complex requirements.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232545","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702105","Boundary values;computational correctness possibility;control flow correctness possibility;evaluation of design decisions;fuzzy equivalence classes;observability;program correctness possibility;test oracle;testing effort","Uncertainty;Testing;Software reliability;Control systems;Fuzzy sets;Power system reliability;Error correction;Process control;Data structures;Process design","","Boundary values;computational correctness possibility;control flow correctness possibility;evaluation of design decisions;fuzzy equivalence classes;observability;program correctness possibility;test oracle;testing effort","","15","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Measuring the Performance and Behavior of Icon Programs","C. A. Coutant; R. E. Griswold; D. R. Hanson","Information Systems Laboratory; NA; NA","IEEE Transactions on Software Engineering","","1983","SE-9","1","93","103","The importance of the ability to measure the performance of programs written in high-level languages is well known. Performance measurement enables users to locate and correct program inefficiencies where automatic optimizations fail and provides a tool for understanding program behavior. This paper describes performance measurement facilities for the Icon programming language, and shows not only how these facilities provided insight into program behavior, but also how they were used to improve the implementation.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236299","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703016","Icon;program measurement;storage management","High level languages;Computer languages;Programming profession;Measurement;Program processors;Optimizing compilers;Computer science;Instruments;Testing;Performance evaluation","","Icon;program measurement;storage management","","8","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Evaluating the mediator method: Prism as a case study","K. J. Sullivan; I. J. Kalet; D. Notkin","Dept. of Comput. Sci., Virginia Univ., Charlottesville, VA, USA; NA; NA","IEEE Transactions on Software Engineering","","1996","22","8","563","579","A software engineer's confidence in the profitability of a novel design technique depends to a significant degree on previous demonstrations of its profitability in practice. Trials of proposed techniques are thus of considerable value in providing factual bases for evaluation. We present our experience with a previously presented design approach as a basis for evaluating its promise and problems. Specifically, we report on our use of the mediator method to reconcile tight behavioral integration with ease of development and evolution of Prism, a system for planning radiation treatments for cancer patients. Prism is now in routine clinical use in several major research hospitals. Our work supports two claims. In comparison to more common design techniques, the mediator approach eases the development and evolution of integrated systems; and the method can be learned and used profitably by practising software engineers.","0098-5589;1939-3520;2326-3881","","10.1109/32.536957","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=536957","","Computer aided software engineering;Design engineering;Profitability;Medical treatment;Cancer;Computer science;Hospitals;Design methodology;Computer Society;Oncology","medical computing;patient treatment;software reusability;object-oriented methods","mediator method;Prism;case study;software engineering;design technique profitability;behavioral integration;radiation treatment planning;cancer patient treatment;research hospitals;integrated systems development;object oriented method;software reuse","","23","","45","","","","","","IEEE","IEEE Journals & Magazines"
"Software reliability in the system context","H. Hecht; M. Hecht","SoHaR Incorporated, Los Angeles, CA 90035; SoHaR Incorporated, Los Angeles, CA 90035","IEEE Transactions on Software Engineering","","1986","SE-12","1","51","58","A systems approach to the analysis and control of software reliability is described which is intended to supplement conventional software reliability models which focus on program attributes under the control of the software professionals. A review of software reliability experience during the operations and maintenance (O&amp;M) phase is presented. This is followed by a description of a basic failure model that supports a unified approach to software and hardware reliability and of the implications of that model for conventional software reliability approaches. Next, the effect of management activities on reliability is investigated, and an outline of a combined hardware/software reliability model suitable for the planning phase is presented.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312919","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312919","Computer failure models;computer system reliability;software management;software reliability","Software;Hardware;Software reliability;Computers;Maintenance engineering;Computational modeling","DP management;software reliability","systems approach;software reliability;program attributes;software professionals;failure model;hardware reliability;management activities;hardware/software reliability model;planning phase","","8","","","","","","","","IEEE","IEEE Journals & Magazines"
"A new approach to version control","J. Plaice; W. W. Wadge","Dept. d'Inf., Laval Univ., Que., Canada; NA","IEEE Transactions on Software Engineering","","1993","19","3","268","276","A method for controlling versions of software and other hierarchically structured entities is presented. Using the variant structure principle, a particular version of an entire system is formed by combining the most relevant existing versions of the various components of the system. An algebraic version language that allows histories (numbered series), subversions (or variants), and joins is described. It is shown that the join operation is simply the lattice least upper bound and together with the variant structure principle, provides a systematic framework for recombining divergent variants. The utility of this approach is demonstrated using LEMUR, a programming environment for modular C programs, which was developed using itself. The ways in which this notion of versions is related to the possible world semantics of intensional logic are discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.221137","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=221137","","Tree data structures;Lattices;Programming environments;Programming profession;History;Upper bound;Logic programming;Computer languages;Software engineering;Computer bugs","configuration management;formal languages;formal logic;programming environments","version control;hierarchically structured entities;variant structure principle;algebraic version language;numbered series;subversions;join operation;lattice least upper bound;systematic framework;divergent variants;LEMUR;programming environment;modular C programs;world semantics;intensional logic","","24","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Modeling correlation in software recovery blocks","L. A. Tomek; J. K. Muppala; K. S. Trivedi","Dept. of Comput. Sci., Duke Univ., Durham, NC, USA; NA; NA","IEEE Transactions on Software Engineering","","1993","19","11","1071","1086","The authors examine the problem of accurately modeling the software fault-tolerance technique based on recovery blocks. Analysis of some systems have investigated the correlation between software modules, which may be due to a portion of the functional specification that is common to all software modules, or to the inherent hardness of some problems. Three types of dependence which can be captured using measurements are considered. These are correlation between software modules for a single input, correlation between successive acceptance tests on correct module outputs and incorrect module outputs, and correlation between subsequent inputs. The authors' technique is quite general and can be applied to other types of correlation. In accounting for dependence, they use the intensity distribution introduced by D.E. Eckhardt and L.D. Lee (1985). A method of generating the intensity distribution that is based on the pairwise correlation between modules is discussed. This method is contrasted with the assumption of independent modules as well as the use of the beta-binomial density introduced by V.F. Nicola and A. Goyai (1990). The effects of dependencies were studied using a Stochastic Reward Network (SRN) that incorporates all of the above dependencies and a modeling tool called Stochastic Petri Net Package (SPNP).<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.256854","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=256854","","Fault tolerance;Stochastic processes;Software reliability;Availability;Computer science;Software testing;Packaging;Petri nets;Application software;Hardware","fault tolerant computing;Petri nets;software reliability;statistical analysis;system recovery","software recovery blocks;software fault-tolerance technique;recovery blocks;functional specification;successive acceptance tests;correct module outputs;pairwise correlation;beta-binomial density;Stochastic Reward Network;Stochastic Petri Net Package;SPNP;Markov models;software reliability;stochastic modeling;stochastic Petri nets;correlation","","40","","27","","","","","","IEEE","IEEE Journals & Magazines"
"A watchdog processor based general rollback technique with multiple retries","J. S. Upadhyaya; K. K. Saluja","Department of Electrical and Computer Engineering, University of Newcastle, N.S.W. 2308, Australia; Department of Electrical and Computer Engineering, University of Newcastle, N.S.W. 2308, Australia","IEEE Transactions on Software Engineering","","1986","SE-12","1","87","95","A common assumption in the existing rollback techniques is that transients, the cause of most failures, subside very quickly, implying that a single story retry of the program from the previous rollback point is sufficient. The authors discuss a general rollback strategy with<i>n</i>(<i>n</i>2) retries which takes into consideration multiple transient failures as well as transients of long duration. Ways of deriving practical values of<i>n</i>for a given program are also discussed. Furthermore, the authors propose the use of a watchdog processor as an error detection tool to initiate recovery action through rollback, since the watchdog processor offers low error latency. They also discuss the merging of the watchdog processor with rollback recovery technique for enhancing the overall system reliability.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312923","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312923","Error detection;error latency;recovery time;rollback recovery;program retry;transient errors","Transient analysis;Load modeling;Computational modeling;Hardware;Australia;Computers;Image edge detection","fault tolerant computing;program processors;software reliability;system recovery","watchdog processor;rollback technique;multiple retries;transients;error detection tool;recovery action;system reliability","","16","","","","","","","","IEEE","IEEE Journals & Magazines"
"Modechart: a specification language for real-time systems","F. Jahanian; A. K. Mok","Dept. of Electr. Eng. & Comput. Sci., Michigan Univ., Ann Arbor, MI, USA; NA","IEEE Transactions on Software Engineering","","1994","20","12","933","947","Present a specification language for real-time systems called Modechart. The semantics of Modechart is given in terms of real-time logic (RTL), which is especially amenable to reasoning about the absolute (real-time clock) timing of events. The semantics of Modechart has an important property that the translation of a Modechart specification into RTL formulas results in a hierarchical organization of the resulting RTL assertions. This gives us significant leverage in reasoning about properties of a system by allowing us to filter out assertions that concern lower levels of abstraction. Some results about desirable properties of Modechart specifications are given. A graphical implementation of Modechart has been completed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.368134","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=368134","","Specification languages;Real time systems;Timing;Logic;Prototypes;Contracts;Clocks;Filters;Application software;Laboratories","real-time systems;specification languages;logic programming languages","Modechart;specification language;real-time systems;semantics;real-time logic;absolute timing;real-time clock;RTL formulas;hierarchical organization;RTL assertions;abstraction levels;graphical implementation;rapid prototyping;timing constraints;SARTOR","","88","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Automating the Transformational Development of Software","S. F. Fickas","Department of Computer Science, University of Oregon","IEEE Transactions on Software Engineering","","1985","SE-11","11","1268","1277","This paper reports on efforts to extend the transformational implementation (TI) model of software development [1]. In particular, we describe a system that uses AI techniques to automate major portions of a transformational implementation. The work has focused on the formalization of the goals, strategies, selection rationale, and finally the transformations used by expert human developers. A system has been constructed that includes representations for each of these problem-solving components, as well as machinery for handling human-system interaction and problem-solving control. We will present the system and illustrate automation issues through two annotated examples.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231878","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701946","Knowledge-based software development;program transformation systems","Programming;Humans;Problem-solving;Machinery;Automatic control;Control systems;Automation;Formal specifications;Computer science;Specification languages","","Knowledge-based software development;program transformation systems","","44","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Call path refinement profiles","R. J. Hall","AT&T Bell Labs., Murray Hill, NJ, USA","IEEE Transactions on Software Engineering","","1995","21","6","481","496","In order to effectively optimize complex programs built in a layered or recursive fashion (possibly from reused general components), the programmer has a critical need for performance information connected directly to the design decisions and other optimization opportunities present in the code. Call path refinement profiles are novel tools for guiding the optimization of such programs, that: (1) provide detailed performance information about arbitrarily nested (direct or indirect) function call sequences, and (2) focus the user's attention on performance bottlenecks by limiting and aggregating the information presented. This paper discusses the motivation for such profiles, describes in detail their implementation in the CPPROF profiler, and relates them to previous profilers, showing how most widely available profilers can be expressed simply and efficiently in terms of call path refinements.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.391375","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=391375","","Cost function;Design optimization;Programming profession;Optimizing compilers;Finite difference methods;Inspection;Data structures","software tools;optimisation;software performance evaluation;program diagnostics;optimising compilers","call path refinement profiles;complex programs;recursive fashion;reused general components;performance information;design decisions;optimization opportunities;function call sequences;performance bottlenecks;CPPROF profiler;performance tuning","","10","","22","","","","","","IEEE","IEEE Journals & Magazines"
"On hierarchical design of computer systems for critical applications","P. G. Neumann","SRI International, Menlo Park, CA 94025","IEEE Transactions on Software Engineering","","1986","SE-12","9","905","920","Considers the design of computer systems that must be trusted to satisfy simultaneously a variety of critical requirements such as human safety, fault tolerance, high availability, security, privacy, integrity, and timely responsiveness, and that must continue to do so throughout maintenance and long-term evolution. Hierarchical abstraction is shown to provide the basis for successive layers of trust with respect to the full set of critical requirements, explicitly reflecting differing degrees of criticality.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313046","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313046","Abstraction;critical requirements;hierarchical design;kernels;reliability;safety;security;trusted subsystems","Security;Safety;Fault tolerance;Fault tolerant systems;Humans;Computers","fault tolerant computing;hierarchical systems","computer systems;critical applications;computer systems;critical requirements;human safety;fault tolerance;high availability;security;privacy;integrity;timely responsiveness","","19","","","","","","","","IEEE","IEEE Journals & Magazines"
"Tool support for planning the restructuring of data abstractions in large systems","W. G. Griswold; M. I. Chen; R. W. Bowdidge; J. L. Cabaniss; V. B. Nguyen; J. D. Morgenthaler","Dept. of Comput. Sci. & Eng., California Univ., San Diego, La Jolla, CA, USA; NA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","7","534","558","Restructuring software to improve its design can lower software maintenance costs. One problem encountered during restructuring is formulating the new design. A meaning-preserving program restructuring tool with a star diagram manipulable visualization can help a programmer redesign a program based on abstract data types. However, the transformational support required for meaning-preserving restructuring is costly to provide. Also, programmers encounter comprehension and recall difficulties in complex restructuring tasks. Consequently, transformations were replaced with visual and organizational aids that help a programmer to plan and carry out a complex restructuring. For example, a star diagram manipulation called trimming was added, which mimics the way that basic restructuring transformations affect the star diagram display, allowing a programmer to plan a restructuring without depending upon restructuring transformations. With the ability to annotate trimmed star diagram components, plans can be recorded and later recalled. Programmer-controlled elision was added to help remove clutter from star diagram views. We implemented a star diagram planning tool for C programs, measured its elision capabilities, and performed a programmer study. We found that elision is effective in controlling star diagram size, and the study revealed that each programming team successfully planned its restructuring in rather different, unanticipated ways. These experiments resulted in important improvements in the tool's software design and user interface.","0098-5589;1939-3520;2326-3881","","10.1109/32.708568","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=708568","","Programming profession;Software maintenance;Costs;Data structures;Software design;Data visualization;User interfaces;Computer interfaces;Displays;Performance evaluation","software tools;abstract data types;software maintenance;systems re-engineering","tool support;data abstractions restructuring planning;software maintenance costs;meaning-preserving program restructuring tool;star diagram manipulable visualization;programmer-controlled elision;re-engineering;abstract data types;modularity;information hiding;graphical user interlace design","","9","","44","","","","","","IEEE","IEEE Journals & Magazines"
"Enhanced Maintenance and Explanation of Expert Systems Through Explicit Models of Their Development","R. Neches; W. R. Swartout; J. D. Moore","Information Sciences Institute, University of Southern California; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","11","1337","1351","Principled development techniques could greatly enhance the understandability of expert systems for both users and system developers. Current systems have limited explanatory capabilities and present maintenance problems because of a failure to explicitly represent the knowledge and reasoning that went into their design. This paper describes a paradigm for constructing expert systems which attempts to identify that tacit knowledge, provide means for capturing it in the knowledge bases of expert systems, and, apply it towards more perspicuous machine-generated explanations and more consistent and maintainable system organization.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231882","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701950","Expert systems;explanation;natural language generation;software development;software maintenance","Expert systems;History;Knowledge engineering;Costs;Natural languages;Programming;Software maintenance;Encoding;Knowledge representation;Collaborative work","","Expert systems;explanation;natural language generation;software development;software maintenance","","22","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Analysis of Long Term File Reference Patterns for Application to File Migration Algorithms","A. J. Smith","Department of Electrical Engineering and Computer Science and the Lawrence Berkeley Laboratory, University of California","IEEE Transactions on Software Engineering","","1981","SE-7","4","403","417","In most large computer installations files are moved between on-line disk and mass storage (tape, integrated mass storage device) either automatically by the system and/or at the direction of the user. In this paper we present and analyze long term file reference data in order to develop a basis for the construction of algorithms for file migration. Specifically, we examine the use of the on-line user (primarily text editor) data sets at the Stanford Linear Accelerator Center (SLAC) computer installation through the analysis of 13 months of file reference data. We find that most files are used very few times. Of those that are used sufficiently frequently that their reference patterns may be examined, we find that: 1) about a third show declining rates of reference during their lifetime, 2) of the remainder, very few (about 5 percent) show correlated interreference intervals, and 3) interreference intervals (in days) appear to be more skewed than would occur with the Bernoulli process. Thus, about two-thirds of all suffi1ciently active files appear to be referenced as a renewal process with a skewed interreference distribution. A large number of other file reference statistics (file lifetimes, interference distributions, moments, means, number of uses/ file, file sizes, file rates of reference, etc.) are computed and presented. Throughout, statistical tests are described and explained. The results of our analysis of file reference patterns are applied in a companion paper to the development and comparative evaluation of file migration algorithms.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230843","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702861","File migration;mass storage;memory hierarchies;replacement algorithm;time series analysis","Pattern analysis;Algorithm design and analysis;Application software;Storage automation;Linear accelerators;Cache storage;Data analysis;Statistical analysis;Statistical distributions;Interference","","File migration;mass storage;memory hierarchies;replacement algorithm;time series analysis","","21","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Evaluation of competing software reliability predictions","A. A. Abdel-Ghaly; P. Y. Chan; B. Littlewood","Centre for Software Reliability, City University, Northampton Square, London ECIV OHB, England; Centre for Software Reliability, City University, Northampton Square, London ECIV OHB, England; Centre for Software Reliability, City University, Northampton Square, London ECIV OHB, England","IEEE Transactions on Software Engineering","","1986","SE-12","9","950","967","Different software reliability models can produce very different answers when called on to predict future reliability in a reliability growth context. Users need to know which, if any, of the competing predictions are trustworthy. Some techniques are presented which form the basis of a partial solution to this problem. Rather than attempting to decide which model is generally best, the approach adopted allows a user to decide on the most appropriate model for each application.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313050","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313050","Prediction analysis;prediction biasedness and noise;prediction systems;predictive quality;prequential likelihood;software reliability models","Software reliability;Predictive models;Random variables;Maximum likelihood estimation;Bayesian methods;Analytical models","software reliability","software reliability predictions;software reliability models;reliability growth context;partial solution","","91","","","","","","","","IEEE","IEEE Journals & Magazines"
"Multisystem coupling by a combination of data sharing and data partitioning","J. L. Wolf; D. M. Dias; B. R. Iyer; P. S. Yu","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA","IEEE Transactions on Software Engineering","","1989","15","7","854","860","A hybrid architecture is proposed that combines the approaches of a multisystem partitioned database system and a data-sharing multisystem approach offering the advantages of each. With this architecture some databases are shared between systems, while others are retained private by specific systems. The authors examine how to determine which databases to share, which to retain private, and how to route transactions and partition the private databases among systems so as to minimize response time or overheads while balancing the load among systems. A simulated annealing heuristic is used to solve this optimizing problem. Trace data from large mainframe systems running IBM's Information Management System database management system are used to illustrate the methodology and to demonstrate the advantages of the hybrid approach.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.29485","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=29485","","Transaction databases;Database systems;Simulated annealing;Spatial databases;Delay;Computational modeling;Operating systems;Control systems;Cost function","database management systems;multiprocessing systems;transaction processing","multisystem coupling;IBM;data sharing;data partitioning;hybrid architecture;database system;transactions;simulated annealing heuristic;Information Management System","","7","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Intent specifications: an approach to building human-centered specifications","N. G. Leveson","Dept. of Aeronaut. & Astronaut., MIT, Cambridge, MA, USA","IEEE Transactions on Software Engineering","","2000","26","1","15","35","This paper examines and proposes an approach to writing software specifications, based on research in systems theory, cognitive psychology and human-machine interaction. The goal is to provide specifications that support human problem solving and the tasks that humans must perform in software development and evolution. A type of specification, called intent specifications, is constructed upon this underlying foundation.","0098-5589;1939-3520;2326-3881","","10.1109/32.825764","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=825764","","Humans;Software systems;Programming;Design engineering;Psychology;Man machine systems;Software maintenance;Software design;Software debugging;Software performance","formal specification;user centred design;user interfaces;human factors","intent specifications;human-centered specifications;systems theory;cognitive psychology;human-machine interaction;human problem solving;software development","","99","","48","","","","","","IEEE","IEEE Journals & Magazines"
"On the Execution of Large Batch Programs in Unreliable Computing Systems","C. H. C. Leung; Q. H. Choo","Department of Computer Science, University College, London University, London WC1E 6BT, England.; Division of Mathematics and Computing, London Research Station, British Gas Corporation, London SW6 2AD, England.","IEEE Transactions on Software Engineering","","1984","SE-10","4","444","450","The execution of long-running batch programs imposes severe reliability constraints on a computing system since the occurrence of a failure during its execution is more likely and that once occurred, a failure would destroy all the processing perfonned thus far. This paper studies the execution delay and machine resources consumed in supporting the running of large batch programs in a computing environment interrupted by failures. The effect of checkpoints and their optimal insertion are also considered. The results are applicable to arbitrary law of failure.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010258","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010258","Batch program;checkpoint;failure law","Delay;Computational modeling;Computer industry;Numerical simulation;Physics computing;Computer science;Thermodynamics;Computer simulation;Mathematics;Protection","","","","8","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Experience with performance testing of software systems: issues, an approach, and case study","E. J. Weyuker; F. I. Vokolos","AT&T Labs., Florham Park, NJ, USA; NA","IEEE Transactions on Software Engineering","","2000","26","12","1147","1156","An approach to software performance testing is discussed. A case study describing the experience of using this approach for testing the performance of a system used as a gateway in a large industrial client/server transaction processing application is presented.","0098-5589;1939-3520;2326-3881","","10.1109/32.888628","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=888628","","Software testing;System testing;Software systems;Computer aided software engineering;Computer architecture;Vehicle crash testing;Software performance;Application software;Computer industry;Computer crashes","software performance evaluation;program testing;transaction processing;client-server systems;network servers","software performance testing;case study;gateway;industrial client/server transaction processing application","","92","","11","","","","","","IEEE","IEEE Journals & Magazines"
"A Test Design Methodology for Protocol Testing","B. Sarikaya; G. v. Bochmann; E. Cerny","Department of Electrical Engineering, Concordia University; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","5","518","531","Communication protocol testing can be done with a test architecture consisting of remote Lower Tester and local Upper Tester processes. For real protocols, tests can be designed based on the formal specification of the protocol which uses an extended finite state machine model. The specification is transformed into a simpler form consisting of normal form transitions. It can then be modeled by a control and a data flow graph. The graphs are decomposed into subtours and data flow functions, respectively. Tests are designed by considering parameter variations of the input primitives of each data flow function and determining the expected outputs. The methodology gives complete test coverage of all data flow functions and control paths in the specification. Functional fault models are proposed for functions that are not formally specified.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233197","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702252","Extended finite state automata;fault models;formal specification;normal form transitions;symbolic execution;test sequences","Design methodology;Open systems;Formal specifications;Flow graphs;Specification languages;Automata;ISO standards;Access protocols;System testing;Automatic control","","Extended finite state automata;fault models;formal specification;normal form transitions;symbolic execution;test sequences","","40","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Commutable transactions and the time_pad synchronization mechanism for distributed systems","M. K. Sinha","National Centre for Software Technology, Tata Institute of Fundamental Research, Homi Bhabha Road, Colaba, Bombay 400 005, India","IEEE Transactions on Software Engineering","","1986","SE-12","3","462","476","The author develops the concept of commutable transactions, where a user initiating a commutable transaction permits the system to commute (recorder) his transaction in relation to other concurrent transactions so that the transaction, in case it faces abortion due to conflict, can be salvaged without the user's intervention. The user specifies a limit to the commutability of his transaction. A new synchronization mechanism for distributed system, called time-pad, is developed which allows a user to express the commutability of his transaction and reduces the probability of its eventual rejection. The two-phase lock synchronization scheme and the timestamp synchronization scheme can be viewed as special cases of the time-pad synchronization scheme. It is a user-controlled synchronization mechanism which can be tuned to improve the performance of those distributed database systems where the communication delay is large and the probability of transaction conflict is high.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312887","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312887","Deadlock;distributed system;performance;synchronization;timestamp;transaction;two_phase lock protocol","Synchronization;System recovery;Protocols;Database systems;Delay;Laser mode locking","database management systems;distributed processing","software engineering;time-pad synchronization mechanism;distributed systems;commutable transactions;concurrent transactions;abortion;conflict;two-phase lock synchronization scheme;timestamp synchronization scheme;user-controlled synchronization mechanism;distributed database systems;communication delay;transaction conflict","","1","","","","","","","","IEEE","IEEE Journals & Magazines"
"Secure execution of Java applets using a remote playground","D. Malkhi; M. K. Reiter","Dept. of Comput. Sci., Hebrew Univ., Jerusalem, Israel; NA","IEEE Transactions on Software Engineering","","2000","26","12","1197","1209","Mobile code presents a number of threats to machines that execute it. We introduce an approach for protecting machines and the resources they hold from mobile code and describe a system based on our approach for protecting host machines from Java 1.1 applets. In our approach, each Java applet downloaded to the protected domain is rerouted to a dedicated machine (or set of machines), the playground, at which it is executed. Prior to execution, the applet is transformed to use the downloading user's Web browser as a graphics terminal for its input and output, and so the user has the illusion that the applet is running on his own machine. In reality, however, mobile code runs only in the sanitized environment of the playground, where user files cannot be mounted and from which only limited network connections are accepted by machines in the protected domain. Our playground thus provides a second level of defense against mobile code that circumvents language-based defenses. This paper presents the design and implementation of a playground for Java 1.1 applets and discusses extensions of it for other forms of mobile code, including Java 1.2.","0098-5589;1939-3520;2326-3881","","10.1109/32.888632","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=888632","","Java;Protection;Mobile computing;Computer security;Data security;Computer displays;Graphics;Computer networks;Computer errors;Physics computing","Java;distributed programming;object-oriented programming;security of data;remote procedure calls;online front-ends","secure execution;dowloaded Java applets;remote playground;mobile code;protected domain;applet rerouting;dedicated machine;Web browser;graphics terminal;user files;limited network connections;Java 1.1;Java 1.2;remote method invocation","","10","","32","","","","","","IEEE","IEEE Journals & Magazines"
"The design and implementation of an ASN.1-C compiler","G. N. Neufeld; Y. Yang","Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada; Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada","IEEE Transactions on Software Engineering","","1990","16","10","1209","1220","Abstract syntax notation one (ASN.1) has been widely used in international standard specification: its transfer-syntax, the basic encoding rules (BER), is used as the external data representation. A BER implementation called the ED library is presented. The ED library includes a number of encoding and decoding routines that may be used as primitive functions to compose encoders and decoders for arbitrarily complicated ASN.1 data types. Based on the ED library an ASN.1-C compiler, called CASN1, is designed and implemented to free the protocol implementers from the arduous work of translating protocol-defined data-types and constructing their encoders and decoders. Given an ASN.1 protocol specification, CASN1 automatically translates the input ASN.1 modules into C and generates the BER encoders and decoders for the protocol defined data-types. The CASN1 design principles, user interface, and some example applications are discussed. The performance of the ED library and generated CASN1 code is also measured and discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.60300","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=60300","","Decoding;Bit error rate;Libraries;Encoding;Protocols;Computer languages;Computer science;ISO standards;Communication standards;User interfaces","decoding;encoding;program compilers;protocols;standards","abstract syntax notation one;design;implementation;ASN.1-C compiler;international standard specification;transfer-syntax;basic encoding rules;external data representation;ED library;decoding;CASN1;protocol;C;user interface","","14","","22","","","","","","IEEE","IEEE Journals & Magazines"
"PROBE spatial data modeling and query processing in an image database application","J. A. Orenstein; F. A. Manola","Computer Corp. of America, Cambridge, MA, USA; Computer Corp. of America, Cambridge, MA, USA","IEEE Transactions on Software Engineering","","1988","14","5","611","629","The PROBE research project has produced results in the areas of data modeling, spatial/temporal query processing, recursive query processing, and database system architecture for nontraditional application areas, many of which involve spatial data and data with complex structure. An overview of PROBE is provided, focusing on the facilities for dealing with spatial and temporal data. It is shown how the PROBE database system and simple application-specific object classes combine to efficiently support PROBE's spatial data model. It is also shown how an image-database application can be supported using PROBE's data model and spatial query processor. The current status of the PROBE project and future plans are discussed.<<ETX>></ETX>","0098-5589;1939-3520;2326-3881","","10.1109/32.6139","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6139","","Probes;Query processing;Image databases;Application software;Filters;Geometry;Database systems;Data models;Military computing;Bridges","data structures;database management systems;query languages","spatial data modeling;query processing;image database application;PROBE;temporal data;application-specific object classes","","130","","38","","","","","","IEEE","IEEE Journals & Magazines"
"Resilient objects in broadband networks","P. Jalote","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA","IEEE Transactions on Software Engineering","","1989","15","1","68","72","An object is said to be resilient if operations on the object can be performed even if some nodes of the network fail. To support resiliency, copies of the objects are stored on different nodes, and access to different copies is coordinated. The properties of broadcast networks are utilized to devise a distributed scheme for implementing resilient objects. All the copies of an object are equivalent. If an operation is requested on an object, the operation is performed on all the copies of the object. No special mechanisms are needed if some copies are not available due to node failures, as long as there is at least one active node that has a copy of the object and the network does not get partitioned. Simulation results indicate that the number of messages needed to perform an operation increases slowly and the response time for performing an operation decreases as the number of copies increases.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21727","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21727","","Intelligent networks;Broadband communication;Broadcasting;Network servers;Delay;Fault tolerance;Local area networks;Ethernet networks;Telecommunication network reliability;Checkpointing","broadband networks;distributed databases;network operating systems","broadband networks;resiliency;broadcast networks;resilient objects","","7","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Recalibrating software reliability models","S. Brocklehurst; P. Y. Chan; B. Littlewood; J. Snell","City Univ., London, UK; City Univ., London, UK; City Univ., London, UK; City Univ., London, UK","IEEE Transactions on Software Engineering","","1990","16","4","458","470","There is no universally applicable software reliability growth model which can be trusted to give accurate predictions of reliability in all circumstances. A technique of analyzing predictive accuracy called the u-plot allows a user to estimate the relationship between the predicted reliability and the true reliability. It is shown how this can be used to improve reliability predictions in a very general way by a process of recalibration. Simulation results show that the technique gives improved reliability predictions in a large proportion of cases. However, a user does not need to trust the efficacy of recalibration, since the new reliability estimates produced by the technique are truly predictive and their accuracy in a particular application can be judged using the earlier methods. The generality of this approach suggests its use whenever a software reliability model is used. Indeed, although this work arose from the need to address the poor performance of software reliability models, it is likely to have applicability in other areas such as reliability growth modeling for hardware.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.54297","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=54297","","Software reliability;Hardware;Predictive models;Software measurement;Reliability theory;Context modeling;Accuracy;Random processes;Reliability engineering","software reliability","software reliability models recalibrating;simulation results;predictive accuracy;u-plot","","85","","20","","","","","","IEEE","IEEE Journals & Magazines"
"A macroscopic profile of program compilation and linking","M. A. Linton; R. W. Quong","Comput. Syst. Lab., Stanford Univ., CA, USA; NA","IEEE Transactions on Software Engineering","","1989","15","4","427","436","To profile the changes made to programs during development and maintenance, the authors have instrumented the 'make' utility that is used to compile and link programs. With minor modifications, they have used 'make' to find out how much time programmers spend waiting for compiling and linking, how many modules are compiled each time a program is linked, and the change in size of the compiled modules. Measurements show that most programs are relinked after only one or two modules are recompiled, and that over 90% of all recompilations yield object code that is less than 100 bytes larger in size. The authors are using these results to guide the design of an incremental programming environment, particularly with respect to an incremental linker.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.16603","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=16603","","Joining processes;Programming profession;Instruments;Programming environments;Productivity;Software maintenance;Force feedback;Size measurement;Delay effects;Laboratories","program compilers","macroscopic profile;program compilation;incremental programming environment;incremental linker","","1","","5","","","","","","IEEE","IEEE Journals & Magazines"
"From CSP models to Markov models","E. V. Sorensen; J. Nordahl; N. H. Hansen","Tech. Univ. of Denmark, Lyngby, Denmark; Tech. Univ. of Denmark, Lyngby, Denmark; Tech. Univ. of Denmark, Lyngby, Denmark","IEEE Transactions on Software Engineering","","1993","19","6","554","570","It is shown how a probabilistic dependability model of a safety-critical system can be derived from a trace-based functional model of the system. The functional model is a communicating sequential process (CSP) that includes command, failure, and repair events. The dependability model is a time homogeneous Markov process with transitions determined by these events. The method applies to deterministic systems that can be described in terms of a finite number of states and in which all event occurrences are stochastic with exponential time distribution. The derivation is carried out in two steps. An algorithmic determination is made of a finite automaton from the specification of the CSP process. The automaton is transformed into a Markov process. The Markov model for this system is used to determine the waiting time to terminal failure. The theory is applied to a larger and more realistic example: a gas burner system operating in the on-off mode. For this system, the waiting time to terminal failure is calculated, and the number of failures per year in a large population of identical, independently operated systems is estimated.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.232021","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=232021","","Automata;Markov processes;Stochastic systems;Stochastic processes;Safety;Explosions;Computational modeling;Computer science;Mathematical model;Logic","communicating sequential processes;fault tolerant computing;finite automata;Markov processes","probabilistic dependability model;safety-critical system;trace-based functional model;communicating sequential process;time homogeneous Markov process;deterministic systems;event occurrences;stochastic;exponential time distribution;finite automaton;specification;waiting time;terminal failure;gas burner system","","5","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Software Engineering for User Interfaces","S. W. Draper; D. A. Norman","Institute for Cognitive Science, University of California; NA","IEEE Transactions on Software Engineering","","1985","SE-11","3","252","258","The discipline of software engineering can be extended in a natural way to deal with the issues raised by a systematic approach to the design of human-machine interfaces. Two main points are made: that the user should be treated as part of the system being designed, and that projects should be organized to take account of the current (small) state of a priori knowledge about how to design interfaces.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232208","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702001","Benchmarks;debugging;documentation;human-computer interaction;interfaces;psychology;rapid prototyping;software engineering;testing;user interfaces;user-interface management systems","Software engineering;User interfaces;Debugging;Man machine systems;Documentation;Design engineering;Computer bugs;Benchmark testing;Psychology;Software prototyping","","Benchmarks;debugging;documentation;human-computer interaction;interfaces;psychology;rapid prototyping;software engineering;testing;user interfaces;user-interface management systems","","34","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Threaded linear hierarchical quadtrees for computation of geometric properties of binary images","A. Unnikrishnan; P. Shankar; Y. V. Venkatesh","Indian Inst. of Sci., Bangalore, India; Indian Inst. of Sci., Bangalore, India; Indian Inst. of Sci., Bangalore, India","IEEE Transactions on Software Engineering","","1988","14","5","659","665","A modification of the linear quadtree, the threaded linear hierarchical quadtree (TLHQT), is proposed for the computation of geometric properties of binary images. Since most of the algorithms used in connection with computation of geometric properties require frequent exploration of adjacencies, a structure that keeps permanently in memory some adjacency links is introduced. Some results obtained by using the TLHQT for labeling connected components and for evaluating the perimeter and Euler's number in a quadtree environment are presented. The performance of the TLHQT is discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6143","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6143","","Labeling;Image storage;Ear;Performance evaluation;Merging;Timing;Data structures;Pixel;Computer science;Image converters","computational geometry;computerised picture processing;data structures","Euler number;geometric properties;binary images;linear quadtree;threaded linear hierarchical quadtree;TLHQT;adjacencies;structure;adjacency links;labeling connected components;perimeter;quadtree environment","","5","","21","","","","","","IEEE","IEEE Journals & Magazines"
"The influence of scale on distributed file system design","M. Satyanarayanan","Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA","IEEE Transactions on Software Engineering","","1992","18","1","1","9","The proposition that scale should be recognized as a primary factor influencing the architecture and implementation of distributed systems is validated using Andrew and Coda, two distributed file systems. Performance, operability, and security are dominant considerations in the design of these systems. Availability is a further consideration the design of Coda. Client caching, bulk data transfer, token-based mutual authentication and hierarchical organization of the protection domain have emerged as mechanisms that enhance scalability. The separation of concerns made possible by functional specialization has also proved valuable in scaling. Heterogeneity is an important by-product of growth, but the mechanisms available to cope with it are rudimentary. Physical separation of clients and servers turns out to be a critical requirement for scalability.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.120311","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=120311","","File systems;Scalability;Availability;Workstations;Data security;Authentication;Protection;Large-scale systems;Humans;Aerospace electronics","distributed processing;file organisation","client caching;distributed file system design;Andrew;Coda;security;bulk data transfer;token-based mutual authentication;hierarchical organization;protection domain;scalability;functional specialization","","35","","31","","","","","","IEEE","IEEE Journals & Magazines"
"A dynamic voting scheme in distributed systems","D. Davcev","Fac. of Electr. Eng. & Comput. Sci., Skopje Univ., Yugoslavia","IEEE Transactions on Software Engineering","","1989","15","1","93","97","A dynamic weighted voting scheme for consistency and recovery control of replicated files in distributed systems is presented. The purpose of a replicated file is to improve the availability of a logical file in the presence of site failures and network partitions. The accessible physical copies of a replicated file will be mutually consistent and behave as a single copy. The recovery scheme requires no manual intervention. The control scheme tolerates any number of site failures and network partitions as well as repairs. Correctness results are given.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21731","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21731","","Voting;Control systems;File systems;Partitioning algorithms;Intelligent networks;Transaction databases;Computer science;Manuals","data integrity;distributed databases;system recovery","dynamic voting scheme;distributed systems;consistency;recovery control;replicated files;distributed systems;site failures;network partitions","","16","","26","","","","","","IEEE","IEEE Journals & Magazines"
"A knowledge-based approach to the analysis of loops","S. K. Abd-El-Hafiz; V. R. Basili","Dept. of Eng. Math., Cairo Univ., Giza, Egypt; NA","IEEE Transactions on Software Engineering","","1996","22","5","339","360","The paper presents a knowledge-based analysis approach that generates first order predicate logic annotations of loops. A classification of loops according to their complexity levels is presented. Based on this taxonomy, variations on the basic analysis approach that best fit each of the different classes are described. In general, mechanical annotation of loops is performed by first decomposing them using data flow analysis. This decomposition encapsulates closely related statements in events, that can be analyzed individually. Specifications of the resulting loop events are then obtained by utilizing patterns, called plans, stored in a knowledge base. Finally, a consistent and rigorous functional abstraction of the whole loop is synthesized from the specifications of its individual events. To test the analysis techniques and to assess their effectiveness, a case study was performed on an existing program of reasonable size. Results concerning the analyzed loops and the plans designed for them are given.","0098-5589;1939-3520;2326-3881","","10.1109/32.502226","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=502226","","Performance analysis;Logic;Programming profession;Algorithm design and analysis;Computer Society;Taxonomy;Data analysis;Testing;Performance evaluation;Formal specifications","data flow analysis;program diagnostics;knowledge based systems;formal specification;formal logic;computational complexity;reverse engineering;subroutines;planning (artificial intelligence)","knowledge-based analysis approach;loop analysis;first order predicate logic annotations;complexity levels;mechanical annotation;data flow analysis;closely related statements;events;specifications;patterns;plans;functional abstraction","","23","","51","","","","","","IEEE","IEEE Journals & Magazines"
"Clustering a DAG for CAD databases","J. Banerjee; W. Kim; S. -. Kim; J. F. Garza","MCC, Austin, TX, USA; MCC, Austin, TX, USA; NA; NA","IEEE Transactions on Software Engineering","","1988","14","11","1684","1699","A DAG (direct acyclic graph) is an important data structure which requires efficient support in CAD (computer-aided design) databases. It typically arise from the design hierarchy, which describes complex designs in terms of subdesigns. A study is made of the properties of the three types of clustered sequences of nodes for hierarchies and DAGs, and algorithms are developed for generating the clustered sequences, retrieving the descendants of a given node, and inserting new nodes into existing clustered sequences of nodes which preserve their clustering properties. The performance of the clustering sequences is compared.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9055","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9055","","Databases;Design automation;Information retrieval;Data structures;Clustering algorithms;Design engineering;Microprocessor chips;Software systems;Assembly systems","CAD;data structures;database management systems;directed graphs;storage management","storage management;DAG;CAD databases;direct acyclic graph;data structure;computer-aided design;design hierarchy;clustered sequences;clustering sequences","","53","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Adaptive location policies for global scheduling","P. Krueger; N. G. Shivaratri","Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA","IEEE Transactions on Software Engineering","","1994","20","6","432","444","Two important components of a global scheduling algorithm are its transfer policy and its location policy. While the transfer policy determines whether a task should be transferred, the location policy determines where it should be transferred. Based on their location policies, global scheduling algorithms can be broadly classified as receiver-initiated, sender-initiated, or symmetrically-initiated. The relative performance of these classes of algorithms has been shown to depend on the system workload. We present two adaptive location policies for global scheduling in distributed systems. These location policies are general, and can be used in conjunction with many existing transfer policies. By adapting to the system workload, the proposed policies capture the advantages of both sender-initiated and receiver-initiated policies. In addition, by adaptively directing their search activities toward the nodes that are most likely to be suitable counterparts in task transfers, the proposed policies provide short transfer latency and low overhead, and more important, high probability of finding a suitable counterpart if one exists. These properties allow these policies to deliver good performance over a very wide range of system operating conditions. The proposed policies are compared with nonadaptive policies, and are shown to considerably improve performance and to avoid causing system instability.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.295892","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=295892","","Scheduling algorithm;Processor scheduling;Distributed computing;Information science;High performance computing;Delay;Adaptive scheduling;Adaptive algorithm;Performance analysis","scheduling;distributed processing;resource allocation;performance evaluation","adaptive location policies;global scheduling algorithm;transfer policy;location policy;location policies;receiver-initiated;sender-initiated;symmetrically-initiated;system workload;distributed systems;search activities;short transfer latency;low overhead;probability;nonadaptive policies;system instability;distributed scheduling;load sharing;load balancing;task migration","","34","","22","","","","","","IEEE","IEEE Journals & Magazines"
"A formal framework for on-line software version change","D. Gupta; P. Jalote; G. Barua","Dept. of Comput. Sci. & Eng., Indian Inst. of Technol., Kanpur, India; Dept. of Comput. Sci. & Eng., Indian Inst. of Technol., Kanpur, India; NA","IEEE Transactions on Software Engineering","","1996","22","2","120","131","The usual way of installing a new version of a software system is to shut down the running program and then install the new version. This necessitates a sometimes unacceptable delay during which service is denied to the users of the software. An online software replacement system replaces parts of the software while it is in execution, thus eliminating the shutdown. While a number of implementations of online version change systems have been described in the literature, little investigation has been done on its theoretical aspects. We describe a formal framework for studying online software version change. We give a general definition of validity of an online change, show that it is in general undecidable and then develop sufficient conditions for ensuring validity for a procedural language.","0098-5589;1939-3520;2326-3881","","10.1109/32.485222","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=485222","","Software systems;Delay;Senior members;Sufficient conditions;Data analysis;Software development management;Computer science;Electronic switching systems","configuration management;computer installation;utility programs;formal specification;decidability","formal framework;online software version change;on-line software version change;software system;online software replacement system;online version change systems;validity;undecidable;sufficient conditions;procedural language","","88","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Measuring and evaluating maintenance process using reliability, risk, and test metrics","N. F. Schneidewind","Div. of Comput. & Inf. Sci. & Oper., Naval Postgraduate Sch., Monterey, CA, USA","IEEE Transactions on Software Engineering","","1999","25","6","769","781","In analyzing the stability of a software maintenance process, it is important that it is not treated in isolation from the reliability and risk of deploying the software that result from applying the process. Furthermore, we need to consider the efficiency of the test effort that is a part of the process and a determinate of reliability and risk of deployment. The relationship between product quality and process capability and maturity has been recognized as a major issue in software engineering based on the premise that improvements in the process will lead to higher-quality products. To this end, we have been investigating an important facet of process capability-stability-as defined and evaluated by trend, change and shape metrics, across releases and within a release. Our integration of product and process measurement serves the dual purpose of using metrics to assess and predict reliability and risk and to evaluate process stability. We use the NASA Space Shuttle flight software to illustrate our approach.","0098-5589;1939-3520;2326-3881","","10.1109/32.824387","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=824387","","Stability criteria;Software maintenance;Shape;Stability analysis;Software measurement;NASA;Space shuttles;Software testing;Risk analysis;Software engineering","software maintenance;software metrics;software process improvement;software reliability;stability;program testing;risk management;software quality","software maintenance process;software reliability;process stability;risk;software deployment;software test effort efficiency;test metrics;product quality;process capability;process maturity;software engineering;software process improvement;trend metrics;change metrics;shape metrics;software releases;software product measurement;software process measurement;NASA Space Shuttle flight software","","34","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Deterministic model and transient analysis of virtual circuits","A. K. Agrawala; B. N. Jain","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; NA","IEEE Transactions on Software Engineering","","1993","19","2","187","197","A model for a virtual circuit in the form of a tandem of servers that process incoming packets using a FIFO (first-in, first-out) discipline is proposed. The service times are assumed to be known completely. These may differ from packet to packet and from server to server. The model permits a variety of buffer or transit time constraints to be incorporated into the model. Several results that help one to understand the transient behavior of a virtual circuit are presented. On the basis of these results, a number of schemes that may be used to determine the time when the next packet must be sent over the network are presented. Transit delay and throughput are used to evaluate a given schedule. Solutions are given for maximum throughput, minimum transit delay, and maximum throughput under transit delay constraints. It is expected that these results will have a substantial bearing on the study of congestion control policies in computer networks, particularly those based on predicting network behavior.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.214835","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=214835","","Transient analysis;Computer networks;Delay;Throughput;Computer science;Relays;Routing;Circuit analysis;Time factors;Processor scheduling","computer networks;delays;open systems","transit delay;deterministic model;transient analysis;virtual circuits;tandem of servers;FIFO;service times;transit time constraints;throughput;maximum throughput;minimum transit delay;congestion control;computer networks","","2","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Dependence directed reasoning and learning in systems maintenance support","V. Dhar; M. Jarke","Grad. Sch. of Bus. Adm., New York Univ., NY, USA; NA","IEEE Transactions on Software Engineering","","1988","14","2","211","227","The maintenance of large information systems involves continuous modifications in response to evolving business conditions or changing user requirements. Based on evidence from a case study, it is shown that the system maintenance activity would benefit greatly if the process knowledge reflecting the teleology of a design could be captured and used in order to reason about he consequences of changing conditions or requirements, A formalism called REMAP (representation and maintenance of process knowledge) that accumulates design process knowledge to manage systems evolution is described. To accomplish this, REMAP acquires and maintains dependencies among the design decisions made during a prototyping process, and is able to learn general domain-specific design rules on which such dependencies are based. This knowledge cannot only be applied to prototype refinement and systems maintenance, but can also support the reuse of existing design or software fragments to construct similar ones using analogical reasoning techniques.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4639","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4639","","Process design;Information systems;Software prototyping;Prototypes;Knowledge management;Software design;Software maintenance;Information analysis;Computer errors;Error correction","expert systems;software reliability;software tools","software tools;expert systems;dependency directed reasoning;systems maintenance support;information systems;user requirements;teleology;REMAP;process knowledge;prototyping;domain-specific design rules;software fragments","","28","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Separate computation of alias information for reuse","M. J. Harrold; G. Rothermel","Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA","IEEE Transactions on Software Engineering","","1996","22","7","442","460","Interprocedural data flow information is useful for many software testing and analysis techniques, including data flow testing, regression testing, program slicing and impact analysis. For programs with aliases, these testing and analysis techniques can yield invalid results, unless the data flow information accounts for aliasing effects. Recent research provides algorithms for performing interprocedural data flow analysis in the presence of aliases; however, these algorithms are expensive, and achieve precise results only on complete programs. This paper presents an algorithm for performing alias analysis on incomplete programs that lets individual software components such as library routines, subroutines or subsystems be independently analyzed. The paper also presents an algorithm for reusing the results of this separate analysis when the individual software components are linked with calling modules. Our algorithms let us analyze frequently used software components, such as library routines or classes, independently, and reuse the results of that analysis when analyzing calling programs, without incurring the expense of completely reanalyzing each calling program. Our algorithms also provide a way to analyze large systems incrementally.","0098-5589;1939-3520;2326-3881","","10.1109/32.538603","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=538603","","Information analysis;Independent component analysis;Algorithm design and analysis;Software testing;Performance analysis;Data analysis;Software algorithms;Computer Society;Software libraries;Data flow computing","program testing;data flow analysis;software libraries;subroutines;software reusability;program diagnostics","separate computation;alias information;analysis results reuse;interprocedural data flow analysis;software testing;software analysis techniques;data flow testing;regression testing;program slicing;impact analysis;invalid results;incomplete programs;library routines;subroutines;subsystems;independently analyzed software components;calling modules;frequently used software components;classes;incremental analysis;aliasing;pointers;static analysis","","10","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Multiversion cautious schedulers for database concurrency control","T. Ibaraki; T. Kameda; N. Katoh","Dept. of Appl. Math. & Phys., Kyoto Univ., Japan; NA; NA","IEEE Transactions on Software Engineering","","1990","16","3","302","315","Let MC stand for a class of logs (i.e. sequences of read/write steps of transactions) that are serializable when multiple versions of the data items are maintained. The multiversion cautious scheduler, MCS(MC) which is introduced, outputs a sequence belonging to MC by reordering, if necessary, the incoming sequence of requests from transactions and it never resorts to rollbacks. In the model, transactions on arrival predeclare their read sets and write sets. It is shown that MCS(MWW) and MCS(MWRW) can be executed in polynomial time, where MWW and MWRW are multiversion classes of logs serializable under the write-write and write-read-write constraints respectively. For any multiversion class MC of interest, MCS(MC) does not exhibit cancellation anomaly, i.e. it functions correctly even if some of the predeclared steps are canceled. Furthermore, MCS(MWW) functions correctly, even if transactions issue more read operations than they predeclared. Thus, MCS(MWW) allows each transaction to predeclare only its write set.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.48938","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=48938","","Concurrency control;Transaction databases;Polynomials;Concurrent computing;Database systems;Councils;Physics education;Systems engineering education;Mathematics;Business","concurrency control;database management systems;scheduling;transaction processing","database concurrency control;read/write steps;multiversion cautious scheduler;MC;reordering;incoming sequence;rollbacks;read sets;write sets;polynomial time;MWW;MWRW;multiversion classes;logs;write-write;write-read-write constraints;cancellation anomaly;predeclared steps;transactions;read operations","","2","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Specification of iterators","D. A. Lamb","Dept. of Comput. & Inf. Sci., Queen's Univ., Kingston, Ont., Canada","IEEE Transactions on Software Engineering","","1990","16","12","1352","1360","Iterators are defined, and previously published methods for defining their meanings are outlined. It is shown how to use trace specifications to define a common form of iterator module (Alphard-style iterators). A form of specification for an iterator is shown which can capture the key differences between a set and a sequence at a few particular places in the specification. The trace specification of a sequence iterator is compared to an algebraic specification. It is concluded that the algebraic specification is possible but somewhat clumsier. Traces are used to give partial specifications of iterator construct that make sequences of calls on procedural parameters.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.62444","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=62444","","Writing;Formal specifications;Software engineering;Observability;Programming profession;Guidelines;Councils;Information science;Binary trees;Tree data structures","data structures;formal specification;high level languages","trace specifications;common form;iterator module;Alphard-style iterators;sequence iterator;algebraic specification;partial specifications;iterator construct;procedural parameters","","4","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Working with persistent objects: to swizzle or not to swizzle","J. E. B. Moss","Dept. of Comput. Sci., Massachusetts Univ., Amherst, MA, USA","IEEE Transactions on Software Engineering","","1992","18","8","657","673","Pointer swizzling is the conversion of database objects between an external form (object identifiers) and an internal form (direct memory pointers). Swizzling is used in some object-oriented databases, persistent object stores, and persistent and database programming language implementations to speed manipulation of memory resident data. The author describes a simplifying model of application behavior, revealing those aspects where swizzling is most relevant in both benefits and costs. The model has a number of parameters, which the authors have measured for a particular instance of the Mneme persistent object store, varying the swizzling technique used. The results confirm most of the intuitive, qualitative tradeoffs, with the quantitative data showing that some performance differences between schemes are smaller than might be expected. However, there are some interesting effects that run counter to naive intuition, most of which are explained using deeper analysis of the algorithms and data structures.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.153378","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=153378","","Object oriented databases;Computer languages;Costs;Object oriented modeling;Spatial databases;Particle measurements;Counting circuits;Algorithm design and analysis;Data structures;Computer science","data structures;object-oriented databases;software engineering","pointer swizzling;persistent objects;database objects;object identifiers;direct memory pointers;object-oriented databases;persistent object stores;database programming language implementations;manipulation;memory resident data;Mneme persistent object store;quantitative data;data structures","","32","","60","","","","","","IEEE","IEEE Journals & Magazines"
"Preserving abstraction in concurrent programming","R. C. B. Cooper; K. G. Hamilton","Comput. Lab., Cambridge Univ., UK; Comput. Lab., Cambridge Univ., UK","IEEE Transactions on Software Engineering","","1988","14","2","258","263","Recent programming languages have attempted to provide support for concurrency and for modular programming based on abstract interfaces. Building on experience of adding monitors to CLU, a language oriented towards data abstraction, it is explained how these two goals conflict. In particular, the clash between conventional views on interface abstraction and the programming style required for avoiding monitor deadlock is discussed. It is argued that the best compromise between these goals is a combination of a fine-grain locking mechanism together with a method for explicitly defining concurrency properties for selected interfaces.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4643","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4643","","Concurrent computing;Computer languages;System recovery;Laboratories;Bridges;Stochastic processes;Reliability engineering;Mechanical factors;Operating systems","data structures;high level languages;parallel programming;system recovery","concurrent programming;programming languages;modular programming;abstract interfaces;CLU;data abstraction;interface abstraction;monitor deadlock;fine-grain locking","","4","","10","","","","","","IEEE","IEEE Journals & Magazines"
"A Diagrammatic Notation for Abstract Syntax and Abstract Structured Objects","F. G. Pagan","Department of Computer Science, Southern Illinois University","IEEE Transactions on Software Engineering","","1983","SE-9","3","280","289","The concept of abstract syntax is commonly applied to the formal specification of programming language semantics and is also useful in the broader context of software design. This paper proposes a scheme for the representation of abstract syntax specifications in the form of easily understood charts. The structuring primitives considered are those of scalar enumeration, heterogeneous aggregation, homogeneous lists and sets, disjunction, and partial functions. Secondarily, a related system of charts for depicting particular objects with a given structure is proposed. Examples are given to illustrate the use of these diagrammatic notations in the contexts of language description and software design and documentation.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.237016","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703055","Abstract syntax;data structure diagrams;software design;structured data types;syntax charts","Computer languages;Software design;Formal specifications;Documentation;Data structures;Computer science;Writing;Education;Application software","","Abstract syntax;data structure diagrams;software design;structured data types;syntax charts","","1","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Software and Hardware in Data Processing Budgets","V. Gurbaxani; H. Mendelson","Graduate School of Management, University of California; NA","IEEE Transactions on Software Engineering","","1987","SE-13","9","1010","1017","This paper develops a microeconomic framework for the determination of data-processing budgets over time, and, in particular, the allocation of these budgets between software and hardware. The model dynamically balances the value and cost of information services, given the prevailing cost trends. It regards software and hardware as inputs to the process of producing information services, and identifies the complementarity and substitution between them as major determinants of the efficient budget allocation. The theory provides a basis for understanding the budgeting process and for predicting future trends, and is applied to actual budget data.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233523","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702323","Cobb-Douglas production function;cost trends;data processing budgets;programmer productivity;software engineering economics;substitution and complementarity","Hardware;Data processing;Production;Microeconomics;Programming profession;Productivity;Investments;Cost function;Software engineering;Economic forecasting","","Cobb-Douglas production function;cost trends;data processing budgets;programmer productivity;software engineering economics;substitution and complementarity","","5","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Modeling of correlated failures and community error recovery in multiversion software","V. F. Nicola; A. Goyal","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA","IEEE Transactions on Software Engineering","","1990","16","3","350","359","Three aspects of the modeling of multiversion software are considered. First, the beta-binomial distribution is proposed for modeling correlated failures in multiversion software. Second, a combinatorial model for predicting the reliability of a multiversion software configuration is presented. This model can take as inputs failure distributions either from measurements or from a selected distribution (e.g. beta-binomial). Various recovery methods can be incorporated in this model. Third, the effectiveness of the community error recovery method based on checkpointing is investigated. This method appears to be effective only when the failure behaviors of program versions are lightly correlated. Two different types of checkpoint failure are also considered: an omission failure where the correct output is recognized at a checkpoint but the checkpoint fails to correct the wrong outputs and a destructive failure where the good versions get corrupted at a checkpoint.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.48942","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=48942","","Software reliability;Random variables;Predictive models;Checkpointing;Fault tolerance;Parallel programming;Voting;Software systems;Hardware;Costs","fault tolerant computing;software reliability;system recovery","correlated failures;community error recovery;multiversion software;beta-binomial distribution;combinatorial model;software configuration;failure distributions;selected distribution;recovery methods;checkpointing;failure behaviors;lightly correlated;checkpoint failure;omission failure;destructive failure","","49","","13","","","","","","IEEE","IEEE Journals & Magazines"
"ARES: A relational database with the capability of performing flexible interpretation of queries","T. Ichikawa; M. Hirakawa","Faculty of Engineering, Hiroshima University, Shitami, Saijo-cho, Higashi-Hiroshima 724, Japan; Faculty of Engineering, Hiroshima University, Shitami, Saijo-cho, Higashi-Hiroshima 724, Japan","IEEE Transactions on Software Engineering","","1986","SE-12","5","624","634","In ARES, relational operations have been functionally augmented with an additional comparison operator. This operator implies `approximately equal to' or `similar to' for cases in which the user expects the system to perform a flexible interpretation of the query conditions. The functional augmentation is simply achieved by a combination of conventional relational operations. ARES is now in actual operation in a research environment, and will contribute to the next step of research toward implementation of highly intelligent data processing facilities beyond the present scope of database technology.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312958","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312958","Data similarity;query representation/transformation;relational algebra;relational database;similarity graph;similarity relation","Algebra;Semantics;Strontium;Relational databases;Estimation;Data models","query languages;relational databases","flexible query interpretation;ARES;relational database;additional comparison operator;intelligent data processing facilities","","20","","","","","","","","IEEE","IEEE Journals & Magazines"
"Computer aided analysis and derivation for artificial neural systems","D. Wang; B. Schurmann","Res. Inst. for Symbolic Comput., Johannes Kepler Univ., Linz, Austria; NA","IEEE Transactions on Software Engineering","","1992","18","8","728","735","The theoretical analysis and derivation of artificial neural systems, which consists essentially of manipulating symbolic mathematical objects according to certain mathematical and biological knowledge, can be done more efficiently with computer assistance by using and extending methods and systems of symbolic computation. After presenting the mathematical characteristics of neural systems and a brief review on Lyapunov stability theory, the authors present some features and capabilities of existing systems and the extension for manipulating objects occurring in the analysis of neural systems. Some strategies and a toolkit developed in MACSYMA for computer-aided analysis and derivation are described. A concrete example is given to demonstrate the derivation of a hybrid neural system, i.e. a system which in its learning rule combines elements of supervised and unsupervised learning. Future work and research directions are indicated.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.153382","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=153382","","Computer aided analysis;Stability analysis;Concrete;Biology computing;Differential equations;Neurodynamics;Software systems;Unsupervised learning;Neurons;Humans","artificial intelligence;computer aided analysis;Lyapunov methods;mathematics computing;neural nets;symbol manipulation","computer aided analysis and derivation;symbolic mathematical objects manipulation;artificial neural systems;biological knowledge;symbolic computation;Lyapunov stability theory;toolkit;MACSYMA;learning rule","","1","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Task response time for real-time distributed systems with resource contentions","W. W. Chu; C. -. Sit; K. K. Leung","Dept. of Comput. Sci., California Univ., Los Angels, CA, USA; NA; NA","IEEE Transactions on Software Engineering","","1991","17","10","1076","1092","An analytic model is proposed for estimating task response times in distributed systems with resource contentions. The model consists of two submodels. The first submodel is an extended queuing network model used for approximating module response times. This submodel is solved by a decomposition technique which reduces the computational complexity by two to three orders of magnitude when compared with a direct approach. The second submodel is a weighted control-flow graph model from which task response time can be obtained by aggregating module response time in accordance with the precedence relationships. Task response times estimated by the analytic model compare closely with simulation results. It is shown that resource contention delays depend on the availability of resources as well as on the invocation rates and response times of the modules that use the resources. The model can be used to study the tradeoffs among module assignments, scheduling policies, interprocessor communications, and resource contentions in distributed processing systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.99195","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=99195","","Real time systems;Time measurement;Processor scheduling;Performance analysis;Added delay;Weight control;Computational modeling;Analytical models;Availability;Distributed processing","computational complexity;distributed processing;graph theory;queueing theory;real-time systems;resource allocation","real-time distributed systems;analytic model;task response times;resource contentions;submodels;extended queuing network model;module response times;decomposition technique;computational complexity;weighted control-flow graph model;task response time;simulation results;invocation rates;module assignments;scheduling policies;interprocessor communications;distributed processing systems","","16","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Statically safe speculative execution for real-time systems","M. F. Younis; T. J. Marlowe; A. D. Stoyen; G. Tsai","Adv. Syst. Technol. Group, Allied-Signal Inc., Columbia, MD, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1999","25","5","701","721","Deterministic worst-case execution for satisfying hard-real-time constraints, and speculative execution with rollback for improving average-case throughput, appear to lie on opposite ends of a spectrum of performance requirements and strategies. Nonetheless, we show that there are situations in which speculative execution can improve the performance of a hard real-time system, either by enhancing average performance while not affecting the worst-case, or by actually decreasing the worst-case execution time. The paper proposes a set of compiler transformation rules to identify opportunities for speculative execution and transform the code. Moreover, we have conducted an extensive experiment using simulation of randomly generated real-time programs to evaluate applicability and profitability of speculative execution. The simulation results indicate that speculative execution improves average execution time and program timeliness. Finally, a prototype implementation is described in which these transformations have been evaluated for realistic applications.","0098-5589;1939-3520;2326-3881","","10.1109/32.815328","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=815328","","Real time systems;Timing;Aerospace electronics;Multimedia communication;Computer science;Computer Society;Throughput;Profitability;Computational modeling;Prototypes","system monitoring;real-time systems;software performance evaluation;program compilers","statically safe speculative execution;real-time systems;deterministic worst-case execution;real-time constraints;rollback;average-case throughput;performance requirements;worst-case execution time;compiler transformation rules;experiment;simulation","","3","","64","","","","","","IEEE","IEEE Journals & Magazines"
"IOTA: A Modular Programming System","T. Yuasa; R. Nakajima","Research Institute for Mathematical Sciences, Kyoto University; NA","IEEE Transactions on Software Engineering","","1985","SE-11","2","179","187","A highly interactive programming system is presented which supports hierarchical and modular program development with abstraction mechanisms. By taking advantage of abstraction mechanisms, the system provides a ""truly modular"" environment, in which modules are constructed, debugged, verified, and compiled in a module-by-module fashion. Such an environment naturally requires system management of the information concerning ongoing program development, in the form of module databases. As a result, further problems arise as to how to modify the information in efficient and consistent ways. This paper discusses design objectives for modular programming systems by focusing on such issues as information management, interactive construction and modification of modules, separate processing, specification and verification, and supports for cooperative program development.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232192","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701985","Cooperative program development;data abstraction;formal specification;modular programming;module database;program verification;programming system;separate compilation;syntax-directed editing","Information management;Databases;Environmental management;Modular construction;Formal specifications;Computer languages;Books;Logic;Reactive power","","Cooperative program development;data abstraction;formal specification;modular programming;module database;program verification;programming system;separate compilation;syntax-directed editing","","1","","21","","","","","","IEEE","IEEE Journals & Magazines"
"An efficient distributed knot detection algorithm","I. Cidon","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA","IEEE Transactions on Software Engineering","","1989","15","5","644","649","A distributed knot detection algorithm for general graphs is presented. The knot detection algorithm uses at most O(n log n+m) messages and O(m+n log n) bits of memory to detect all knots' nodes in the network (where n is the number of nodes and m is the number of links). This is compared to O(n/sup 2/) messages needed in the best algorithm previously published. The knot detection algorithm makes use of efficient cycle detection and clustering techniques. Various applications for the knot detection algorithms are presented. In particular, its importance to deadlock detection in store and forward communication networks and in transaction systems is demonstrated.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24714","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24714","","Detection algorithms;System recovery;Costs;Clustering algorithms;Buffer storage;Topology;Testing;Communication networks;Floods","computational complexity;distributed processing;graph theory","memory bits;store communication networks;distributed knot detection algorithm;general graphs;messages;nodes;links;cycle detection;clustering;deadlock detection;forward communication networks;transaction systems","","22","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Guaranteed response times in a distributed hard-real-time environment","D. W. Leinbaugh; M. Yamini","AT&T Bell Laboratories, Columbus, OH 43213; AT&T Bell Laboratories, Columbus, OH 43213","IEEE Transactions on Software Engineering","","1986","SE-12","12","1139","1144","A distributed real-time programming model is presented. It consists of a set of tasks whose segments require processor time and devices, and which is run on a dedicated network of microcomputers. A task is started upon receipt of an external signal or the completion of other tasks. Segments communicate via message passing, and there may be a limited number of transient communication errors. A heuristic algorithm is developed to determine an upper bound on the response time of each task. This algorithm is useful in a hard-real-time environment for determining if response times will always be met.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313009","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313009","Distributed operating system;guaranteed response time;hard-real-time;process control;programming model;response time analysis","Time factors;Upper bound;Operating systems;Optimal scheduling;Performance evaluation;Delay;Real-time systems","computer networks;network operating systems;real-time systems","distributed operating system;computer networks;response times;real-time programming model;message passing;transient communication errors;heuristic algorithm;hard-real-time environment","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"The Path Prefix Software Testing Strategy","R. E. Prather; J. P. Myers","Department of Computer Science, Trinity University; NA","IEEE Transactions on Software Engineering","","1987","SE-13","7","761","766","A new software testing strategy is described. The strategy is ""adaptive"" in that previous test paths (inputs) are used as a guide in the selection of subsequent paths (inputs). Preliminary implementations have successfully exploited the method's inherent user-interactive capability. The method ensures branch coverage, requires only ""order n"" tests (n being the number of decision nodes in the program flowgraph), and offers considerable advantages over existing strategies in its computational requirements.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233487","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702287","Branch coverage;path selection;program flowgraph analysis;software testing","Software testing;Control systems;Input variables;Computer science;Remuneration;Computer errors;Sufficient conditions;Software engineering","","Branch coverage;path selection;program flowgraph analysis;software testing","","31","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Independent recovery in large-scale distributed systems","P. Triantafiliou","Dept. of Comput. Eng., Tech. Univ. of Crete, Chania, Greece","IEEE Transactions on Software Engineering","","1996","22","11","812","826","In large systems, replication can become important means to improve data access times and availability. Existing recovery protocols, on the other hand, were proposed for small-scale distributed systems. Such protocols typically update stale, newly-recovered sites with replicated data and resolve the commit uncertainty of recovering sites. Thus, given that in large systems failures are more frequent and that data access times are costlier, such protocols can potentially introduce large overheads in large systems and must be avoided, if possible. We call these protocols dependent recovery protocols since they require a recovering site to consult with other sites. Independent recovery has been studied in the context of one-copy systems and has been proven unattainable. This paper offers independent recovery protocols for large-scale systems with replicated data. It shows how the protocols can be incorporated into several well-known replication protocols and proves that these protocols continue to ensure data consistency. The paper then addresses the issue of nonblocking atomic commitment. It presents mechanisms which can reduce the overhead of termination protocols and the probability of blocking. Finally, the performance impact of the proposed recovery protocols is studied through the use of simulation and analytical studies. The results of these studies show that the significant benefits of independent recovery can be enjoyed with a very small loss in data availability and a very small increase in the number of transaction abortions.","0098-5589;1939-3520;2326-3881","","10.1109/32.553700","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=553700","","Large-scale systems;Electronic mail;Costs;Data engineering;Delay effects;Terminology;Access protocols;Abortion","system recovery;software fault tolerance;data integrity;software performance evaluation;protocols;replicated databases;concurrency control;distributed databases;transaction processing","independent recovery;large-scale distributed systems;replication protocols;data access times;data availability;recovery protocols;commit uncertainty;large overheads;one-copy systems;data consistency;nonblocking atomic commitment;termination protocols;probability;performance impact;simulation;transaction abortions;concurrency control;replicated database","","5","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Criteria for Software Reliability Model Comparisons","A. Iannino; J. D. Musa; K. Okumoto; B. Littlewood","AT&amp;T Bell Laboratories, Whippany, NJ 07981.; AT&amp;T Bell Laboratories, Whippany, NJ 07981.; AT&amp;T Bell Laboratories, Whippany, NJ 07981.; City University, London, England.","IEEE Transactions on Software Engineering","","1984","SE-10","6","687","691","A set of criteria is proposed for the comparison of software reliability models. The intention is to provide a logically organized basis for determining the superior models and for the presentation of model characteristics. It is hoped that in the future, a software manager will be able to more easily select the model most suitable for his/her requirements from among the preferred ones.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010297","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010297","Model comparisons;predictive validity;software failures;software reliability","Software reliability;Software systems;Engineering management;Reliability engineering;Battery powered vehicles;Software measurement;Software development management;Costs;Predictive models","","","","50","","18","","","","","","IEEE","IEEE Journals & Magazines"
"On the Minimization of Loads/Stores in Local Register Allocation","Wei-Chung Hsu; C. N. Fischer; J. R. Goodman","Department of Development, CRAY Research, Inc., Chippewa Falls, WI; NA; NA","IEEE Transactions on Software Engineering","","1989","15","10","1252","1260","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1989.559775","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=559775","","Registers;Heuristic algorithms;Reduced instruction set computing;Performance evaluation;Compaction;Parallel processing;Optimizing compilers;Algorithm design and analysis","","Computer architecture;local register allocation;program esptimization","","17","","40","","","","","","IEEE","IEEE Journals & Magazines"
"Unreachable states in model-oriented specifications","R. A. Nicholl","Dept. of Comput. Sci., Univ. of Western Ontario, London, Ont., Canada","IEEE Transactions on Software Engineering","","1990","16","4","472","477","Formal specification methods are being used to improve the quality of written specifications and to eliminate errors at an early stage of software development. The detection of errors in a specification generally requires that the specification be compared against some loosely defined real-world concepts. A criterion for evaluating the quality of a model-oriented specifications is introduced and the problems associated with specifications which do not meet this criterion are explained. These problems are particularly troublesome when reusable software components are being specified or when a bottom-up implementation strategy is being used.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.54300","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=54300","","Computer errors;Costs;Equations;Councils;Formal specifications;Mathematical model","formal specification","unreachable states;formal specification;model-oriented specifications;software development;detection of errors;software components;bottom-up implementation strategy","","","","7","","","","","","IEEE","IEEE Journals & Magazines"
"Communication Issues in the Design and Analysis of Parallel Algorithms","B. Lint; T. Agerwala","IBM Federal Systems Division; NA","IEEE Transactions on Software Engineering","","1981","SE-7","2","174","188","As multiple processor systems become more widely accepted the importance of parallel programming increases. In this paper, approaches to the design and analysis of parallel algorithms are investigated. Through several examples, the importance of interprocessor communication in parallel processing is demonstrated. Various techniques that are applicable in the design and analysis of parallel algorithms are examined with emphasis on those techniques that incorporate communication aspects. The paper discusses several models of synchronous and asynchronous parallel computation and their use in analyzing algorithms. Relatively primitive methodologies for designing parallel algorithms are discussed and the need for more general and practical methodologies is indicated.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230833","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702824","Analysis of algorithms;models of parallel computation;module assignment problem;multiprocessing;parallel programming","Algorithm design and analysis;Parallel algorithms;Concurrent computing;Distributed computing;Circuits;Parallel programming;Parallel processing;Distributed databases;Pins;Communication system control","","Analysis of algorithms;models of parallel computation;module assignment problem;multiprocessing;parallel programming","","46","","71","","","","","","IEEE","IEEE Journals & Magazines"
"Pre-run-time scheduling to reduce schedule length in the FieldBus environment","S. Cavalieri; A. Di Stefano; O. Mirabella","Istituto di Inf. e Telecommun., Catania Univ., Italy; Istituto di Inf. e Telecommun., Catania Univ., Italy; Istituto di Inf. e Telecommun., Catania Univ., Italy","IEEE Transactions on Software Engineering","","1995","21","11","865","880","The paper deals with the problem of scheduling the transmission of periodic processes in a distributed FieldBus system, defining the conditions guaranteeing correct transmission. The scheduling of periodic processes fixes the transmission times for each process in a table, whose length is equal to the Least Common Multiple (LCM) of all the periods. This involves great memorization problems when some periods are relatively prime. The authors identify the theoretical conditions which allow the length of the scheduling table to be drastically reduced, but still guarantee correct transmission. On the basis of the theoretical conditions given, the authors present a pre-run-time scheduling algorithm which determines a transmission sequence for each producing process within the desired scheduling interval. An online scheduling algorithm is also proposed to schedule new transmission requests which are made while the system is functioning. The reduction in the schedule length may increase the number of transmissions, thus reducing the effective bandwidth and increasing the communication overload. In order to make as complete an analysis as possible of the scheduling solution, the authors also present an analysis of both the computational complexity of the algorithms proposed and the communication overload introduced.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.473215","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=473215","","Field buses;Processor scheduling;Communication system control;Time factors;Scheduling algorithm;Process control;Temperature control;Control systems;Algorithm design and analysis;Application software","field buses;scheduling;computational complexity;distributed algorithms;online operation;process control","pre-run-time scheduling;schedule length;FieldBus;periodic process scheduling;FieldBus system;transmission times;Least Common Multiple;memory problems;transmission sequence;online scheduling algorithm;communication overload;computational complexity","","25","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Two Access Methods Using Compact Binary Trees","W. De Jonge; A. S. Tanenbaum; R. P. Van De Riet","Department of Mathematics and Computer Science, Vrije Universiteit; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","7","799","810","It is shown how a highly compact representation of binary trees can be used as the basis of two access methods for dynamic files, called BDS-trees and S-trees, respectively. Both these methods preserve key-order and offer easy and efficient sequential access. They are different in the way the compact binary trees are used for searching. With a BDS-tree the search is a digital search using binary digits. Although the S-tree search is performed on a bit-by-bit basis as well, it will appear to be slightly different. Actually, with S-trees the compact binary trees are used to represent separators at low storage costs. As a result, the fan-out, and thus performance, of a B-tree can be improved by using within each index page an S-tree for representing separators efficiently.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233491","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702291","Access iethod;B-tree;file;searching;tree","Binary trees;Particle separators;Data structures;Costs;Personnel;Database systems;Mathematics;Computer science","","Access iethod;B-tree;file;searching;tree","","9","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Model checking in practice: the T9000 virtual channel processor","G. Barrett","PACT, Bristol, UK","IEEE Transactions on Software Engineering","","1995","21","2","69","78","One of the major obstacles to the integration of formal methods in the design of industrial products is the height and gradient of the learning curve, Anything which can alleviate this problem is of enormous benefit. Automatic model checking and visual specification styles provide a gentle introduction to the concept of refinement. The paper presents a case study of the design of the T9000 virtual channel processor as an illustration of the use of some nonstandard CSP operators and a visual specification style. The development which is shown here has been implemented in a single model checking tool which is currently being integrated into the INMOS CAD system.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.345823","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=345823","","Design engineering;Design methodology;Hardware;Testing;Product design;Refining;Design automation;Manufacturing processes;Geometry;Process design","transputers;circuit CAD;formal specification;circuit analysis computing","model checking;T9000 virtual channel processor;formal method;industrial products;visual specification styles;case study;nonstandard CSP operators;visual specification style;INMOS CAD system","","13","","6","","","","","","IEEE","IEEE Journals & Magazines"
"Atomic Actions and Resource Coordination Problems Having Nonunique Solutions","M. K. Sinha","National Centre for Software Development and Computing Techniques, Tata Institute of Fundamental Research","IEEE Transactions on Software Engineering","","1985","SE-11","5","461","471","The concept of atomic actions is decomposed into database-dependent atomic actions and application-dependent atomic actions. There is a broad class of application-dependent atomic actions that can have nonunique solutions. These are resource coordination problems and are classified as problems of NU class. It is argued that a transaction modeling a problem of NU class provides lower concurrency. A concept of coordination is proposed which can model a broad range of NU class problems. An object model and a protocol are sugested which utilize the nonunique character of the solution to provide higher concurrency.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232485","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702036","Access synchronization;algorithms;atomic actions;concurrency control;crash recovery;design;performance","Transaction databases;Concurrent computing;Concurrency control;Calendars;Protocols;Computer crashes;Algorithm design and analysis;Programming;Database systems;Application software","","Access synchronization;algorithms;atomic actions;concurrency control;crash recovery;design;performance","","","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Evaluating software complexity measures","E. J. Weyuker","Dept. of Comput. Sci., Courant Inst. of Math. Sci., New York Univ., NY, USA","IEEE Transactions on Software Engineering","","1988","14","9","1357","1365","A set of properties of syntactic software complexity measures is proposed to serve as a basis for the evaluation of such measures. Four known complexity measures are evaluated and compared using these criteria. This formalized evaluation clarifies the strengths and weaknesses of the examined complexity measures, which include the statement count, cyclomatic number, effort measure, and data flow complexity measures. None of these measures possesses all nine properties, and several are found to fail to possess particularly fundamental properties; this failure calls into question their usefulness in measuring synthetic complexity.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6178","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6178","","Software measurement;Software metrics;Fluid flow measurement;Software testing;Software reliability;Computer science;Concrete;Particle measurements;Computer languages;Arithmetic","software engineering","software engineering;software complexity measures;syntactic software complexity;statement count;cyclomatic number;effort measure;data flow complexity;synthetic complexity","","355","","33","","","","","","IEEE","IEEE Journals & Magazines"
"Cognitive fit: an empirical study of recursion and iteration","A. P. Sinha; I. Vessey","Dept. of MIS & Decision Sci., Dayton Univ., OH, USA; NA","IEEE Transactions on Software Engineering","","1992","18","5","368","379","A laboratory experiment was conducted to assess the basic theory and extensions to the theory for recursive tasks across programming languages. The experiment used 34 LISP and 48 PASCAL computer science students in two repeated measures designs. Findings of the study are reported and analyzed. The results strongly suggest that investigation of programming constructs should take place in the context of specific programming languages. Since a number of languages provide similar kinds of programming constructs, it is difficult for programmers to choose those implementations that best suit their needs. One way of encouraging the use of desirable constructs would be to develop languages adapted to certain types of tasks. Such an approach would inherently lead to cognitive fit and the attendant performance benefits would be realized.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.135770","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=135770","","Programming profession;Computer languages;Cognitive science;Iris;Laboratories;Computer science;Mathematical programming;Iterative algorithms;Problem-solving;Availability","human factors;LISP;Pascal;programming;programming theory;recursive functions","laboratory experiment;basic theory;recursive tasks;programming languages;LISP;PASCAL computer science students;repeated measures designs;programming constructs;specific programming languages;cognitive fit;performance benefits","","26","","46","","","","","","IEEE","IEEE Journals & Magazines"
"Techniques for process model evolution in EPOS","M. L. Jaccheri; R. Conradi","Dipartimento di Autom. e Inf., Politecnico di Torino, Italy; NA","IEEE Transactions on Software Engineering","","1993","19","12","1145","1156","The authors categorize some aspects of software process evolution and customization, and describe how they are handled in the EPOS PM system. Comparisons are made to other PM systems. A process model in EPOS consists of a schema of classes and meta-classes, and its model entities and relationships. There is an underlying software engineering database, EPOSDB, offering uniform versioning of all model parts and a context of nested cooperating transactions. Then, there is a reflective object-oriented process specification language, on top of the EPOSDB. Policies for model creation, composition, change, instantiation, refinement, and enaction are explicitly represented and are used by a set of PM automatic tools. The main tools are a planner to instantiate tasks, an execution manager to enact such tasks, and a PM manager to define, analyze, customize, and evolve the process schema.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.249660","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=249660","","Object oriented modeling;Production;Software tools;Humans;Software engineering;Software libraries;Life testing;Software testing;Object oriented databases;Transaction databases","configuration management;object-oriented databases;object-oriented languages;object-oriented programming;programming environments;specification languages","process model evolution;schema;software process evolution;EPOS PM system;meta-classes;model entities;underlying software engineering database;EPOSDB;uniform versioning;nested cooperating transactions;reflective object-oriented process specification language;model creation;PM automatic tools;planner;execution manager;PM manager;process schema;process support environment;SPELL","","53","","42","","","","","","IEEE","IEEE Journals & Magazines"
"Optimal Load Balancing in a Multiple Processor System with Many Job Classes","L. M. Ni; Kai Hwang","Department of Computer Science, Michigan State University; NA","IEEE Transactions on Software Engineering","","1985","SE-11","5","491","496","A loosely coupled multiprocessor system contains multiple processors which have their own local memories. To balance the load among multiple processors is of fundamental importance in enhancing the performance of such a multiple processor system. Probabilistic load balancing in a heterogeneous multiple processor system with many job classes is considered in this study. The load balancing scheme is formulated as a nonlinear programming problem with linear constraints. An optimal probabilistic load balancing algorithm is proposed to solve this nonlinear programming problem. The proposed load balancing method is proven globally optimum in the sense that it results in a minimum overall average job response time on a probabilistic basis.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232489","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702040","Job response time;job scheduling;load balancing;M/M/1 queue;multiple processor system;nonlinear programming;probabilistic scheduling","Load management;Processor scheduling;Delay;Dynamic scheduling;Multiprocessing systems;System performance;Linear programming;Computer science;Resource management;Throughput","","Job response time;job scheduling;load balancing;M/M/1 queue;multiple processor system;nonlinear programming;probabilistic scheduling","","98","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Learning dominance relations in combined search problems","C. -. Yu; B. W. Wah","Intel Corp., Santa Clara, CA, USA; NA","IEEE Transactions on Software Engineering","","1988","14","8","1155","1175","Dominance relations are used to prune unnecessary nodes in search graphs, but they are problem-dependent and cannot be derived by a general procedure. The authors identify machine learning of dominance relations and the applicable learning mechanisms. A study of learning dominance relations using learning by experimentation is described. This system has been able to learn dominance relations for the 0/1-knapsack problem, an inventory problem the reliability-by-replication problem, the two-machine flow shop problem, a number of single-machine scheduling problems, and a two-machine scheduling problem. It is considered that the same methodology can be extended to learn dominance relations in general.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.7626","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=7626","","Search problems;Tree graphs;Machine learning;Job shop scheduling;Constraint optimization;Artificial intelligence;Laboratories;Software engineering","artificial intelligence;combinatorial mathematics;learning systems;optimisation;scheduling","artificial intelligence;optimisation;dominance relations;combined search problems;search graphs;machine learning;0/1-knapsack problem;inventory problem;reliability-by-replication;two-machine flow shop problem;single-machine scheduling;two-machine scheduling","","11","","55","","","","","","IEEE","IEEE Journals & Magazines"
"Rough grammar for efficient and fault-tolerant computing on a distributed system","Z. M. Wojcik; B. E. Wojcik","Div. of Math., Comput. Sci. & Stat., Texas Univ., San Antonio, TX, USA; Div. of Math., Comput. Sci. & Stat., Texas Univ., San Antonio, TX, USA","IEEE Transactions on Software Engineering","","1991","17","7","652","668","A method that combines global load balancing with dynamic task scheduling on a multiprocessor machine is presented. This method does not require prior knowledge of the run times of tasks, and is based on a rough grammar representing distributed computation is presented. Production rules are dynamically constructed when a concurrent program is run. The set of the rough grammar production rules is updated and rolled in a pipeline fashion, together with codes of the processes. This pipeline fashion of rolling the jobs defines the global job balancing. The rough grammar uses any operators and metrics, not only concatenation, inside its production rules. Performance parameters for the combination of a global load balancing and decentralized dynamic task scheduling are derived and compared with those for a statically scheduled multiprocessor. Based on these parameters, the decentralized methodology is shown to attain a much higher performance level and a highly improved fault tolerance.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.83902","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=83902","","Fault tolerant systems;Distributed computing;Pipelines;Dynamic scheduling;Fault tolerance;Production;Centralized control;Control systems;Costs;Processor scheduling","fault tolerant computing;grammars;parallel processing;pipeline processing;scheduling","fault-tolerant computing;global load balancing;dynamic task scheduling;multiprocessor machine;rough grammar;distributed computation;concurrent program;rough grammar production rules;pipeline fashion;statically scheduled multiprocessor;decentralized methodology;fault tolerance","","2","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Delay-independent design for distributed systems","G. Von Bochmann","Dept. d' Inf. et de Recherche Oper., Montreal Univ., Que., Canada","IEEE Transactions on Software Engineering","","1988","14","8","1229","1237","Methods of limiting the impact of communication delays on the logical behavior of distributed systems are considered. It is assumed that a distributed system is described in terms of a number of interconnected modules, and each module is described in terms of its possible states and the possible state transitions. Transitions may be initiated spontaneously by a module and may give rise to output messages, which will be received, after some possible delay, by another module as an input. Otherwise, transitions may be initiated by received input. If the system has the property called regularity, its behavior is logically independent of the communication delays. A simple condition for regularity is given. This condition is the basis for the implementation of counter-based synchronization conditions in a distributed environment. Weaker forms of regularity, which make abstraction of internal operations invisible from the point of view of an outside observer, are also considered. The application of these concepts to the design of module interfaces involving 'collisions' and to communication including timeouts is discussed in some detail with examples.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.7630","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=7630","","Delay effects;Distributed computing;Real time systems;Protocols;Parallel processing;Operating systems;Concurrent computing;Art;Software engineering","delays;distributed processing;protocols","protocols;distributed systems;communication delays;interconnected modules;regularity;synchronization;module interfaces","","3","","29","","","","","","IEEE","IEEE Journals & Magazines"
"The rejection rate for tasks with random arrivals, deadlines, and preemptive scheduling","D. W. Craig; C. M. Woodside","Dept. of Syst. & Comput. Eng., Carleton Univ., Ottawa, Ont., Canada; Dept. of Syst. & Comput. Eng., Carleton Univ., Ottawa, Ont., Canada","IEEE Transactions on Software Engineering","","1990","16","10","1198","1208","A means of approximating light-traffic performance of RAD (random-arrivals-with-deadlines) systems for four basic preemptive scheduling policies is presented. The design goal is to keep congestion low enough to make the probability of rejection acceptably small. These designs must have low processor utilization. The study analyzes rejection probabilities at utilizations up to 20% and rejection probabilities up to about 10% for various well-known preemptive scheduling disciplines (shortest job first, earliest due date, and least laxity first), as well as first-come, first-served. Good approximations for the rejection probability and for a number of other properties, such as the distribution of time-to-go at rejection, are found.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.60299","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=60299","","Processor scheduling;Air traffic control;Real time systems;Radar tracking;Target tracking;Air safety;Power generation;Missiles;Queueing analysis","performance evaluation;queueing theory;real-time systems;scheduling","rejection rate for tasks;random arrivals;deadlines;preemptive scheduling;RAD;random-arrivals-with-deadlines;rejection probabilities","","7","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Comparing the Effectiveness of Software Testing Strategies","V. R. Basili; R. W. Selby","Department of Computer Science, University of Maryland; NA","IEEE Transactions on Software Engineering","","1987","SE-13","12","1278","1296","This study applies an experimentation methodology to compare three state-of-the-practice software testing techniques: a) code reading by stepwise abstraction, b) functional testing using equivalence partitioning and boundary value analysis, and c) structural testing using 100 percent statement coverage criteria. The study compares the strategies in three aspects of software testing: fault detection effectiveness, fault detection cost, and classes of faults detected. Thirty-two professional programmers and 42 advanced students applied the three techniques to four unit-sized programs in a fractional factorial experimental design. The major results of this study are the following. 1) With the professional programmers, code reading detected more software faults and had a higher fault detection rate than did functional or structural testing, while functional testing detected more faults than did structural testing, but functional and structural testing were not different in fault detection rate. 2) In one advanced student subject group, code reading and functional testing were not different in faults found, but were both superior to structural testing, while in the other advanced student subject group there was no difference among the techniques. 3) With the advanced student subjects, the three techniques were not different in fault detection rate. 4) Number of faults observed, fault detection rate, and total effort in detection depended on the type of software tested. 5) Code reading detected more interface faults than did the other methods. 6) Functional testing detected more control faults than did the other methods.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232881","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702179","Code reading;empirical study;functional testing;methodology evaluation;off-line software review;software measurement;software testing;structural testing","Software testing;Fault detection;Computer science;Programming profession;Costs;Design for experiments;Software measurement;Uncertainty;Military computing;NASA","","Code reading;empirical study;functional testing;methodology evaluation;off-line software review;software measurement;software testing;structural testing","","131","","56","","","","","","IEEE","IEEE Journals & Magazines"
"Reducing null messages in Misra's distributed discrete event simulation method","R. C. De Vries","Dept. of Electr. & Comput. Eng., New Mexico Univ., Albuquerque, NM, USA","IEEE Transactions on Software Engineering","","1990","16","1","82","91","Consideration is given to the implementation of distributed discrete-event simulation (DDES) using what has been commonly called the Misra approach, after one of its inventors. A major problem with DDES is that deadlock can occur. Therefore, DDES algorithms must either avoid deadlock in the first place, or detect the existence of deadlock when it does occur and eliminate it. J. Misra (1986) proposes the use of null messages as one way to circumvent the deadlock problem. However the number of null messages can become quite large. Methods are presented for reducing the number of null messages through the prediction of channel times. A framework is presented on the basis of which distributed discrete-event simulation can be built for applications that can be decomposed into feedforward and feedback networks.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44366","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44366","","Discrete event simulation;System recovery;Feedback;Out of order;Forward contracts;Message passing","distributed processing;program verification","null messages reduction;distributed discrete event simulation method;Misra approach;feedforward;feedback networks","","20","","6","","","","","","IEEE","IEEE Journals & Magazines"
"Communication Port: A Language Concept for Concurrent Programming","T. W. Mao; R. T. Yeh","Department of Computer Science, University of Texas; NA","IEEE Transactions on Software Engineering","","1980","SE-6","2","194","204","A new language conceptcommunication port (CP), is introduced for programming on distributed processor networks. Such a network can contain an arbitrary number of processors each with its own private storage but with no memory sharing. The processors must communicate via explicit message passing. Communication port is an encapsulation of two language properties: ""communication non-determinism"" and ""communication disconnect time."" It provides a tool for progranmers to write well-structured, modular, and efficient concurrent programs. A number of examples are given in the paper to demonstrate the power of the new concepts.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230470","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702716","Communicating sequential processes;communication disconnection;communication ports;concurrent programming;distributed networks;distributed processes;messages;nondeterminism","Distributed computing;Computer science;Hardware;Application software;Message passing;Encapsulation;Power generation economics;Attitude control;Computer networks;Microcomputers","","Communicating sequential processes;communication disconnection;communication ports;concurrent programming;distributed networks;distributed processes;messages;nondeterminism","","23","","24","","","","","","IEEE","IEEE Journals & Magazines"
"An Algorithm to Decide Feasibility of Linear Integer Constraints Occurrng in Decision Tables","S. Biswas; V. Rajaraman","Department of Computer Science and Engineering, Indian Institute of Technology; NA","IEEE Transactions on Software Engineering","","1987","SE-13","12","1340","1347","To detect errors in decision tables one needs to decide whether a given set of constraints is feasible or not. This paper describes an algorithm to do so when the constraints are linear in variables that take only integer values. Decision tables with such constraints occur frequently in business data processing and in nonnumeric applications. The aim of the algorithm is to exploit. the abundance of very simple constraints that occur in typical decision table contexts. Essentially, the algorithm is a backtrack procedure where the the solution space is pruned by using the set of simple constrains. After some simplications, the simple constraints are captured in an acyclic directed graph with weighted edges. Further, only those partial vectors are considered from extension which can be extended to assignments that will at least satisfy the simple constraints. This is how pruning of the solution space is achieved. For every partial assignment considered, the graph representation of the simple constraints provides a lower bound for each variable which is not yet assigned a value. These lower bounds play a vital role in the algorithm and they are obtained in an efficient manner by updating older lower bounds. Our present algorithm also incorporates an idea by which it can be checked whether or not an (m 2)-ary vector can be extended to a solution vector of m components, thereby backtracking is reduced by one component.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233144","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702183","Backtrack algorithm;decision tables;detection of errors;integer programming","Testing;Data processing;Linear programming;Calculus;Computer science;Integer linear programming","","Backtrack algorithm;decision tables;detection of errors;integer programming","","1","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Prism-methodology and process-oriented environment","N. H. Madhavji; W. Schafer","Sch. of Comput. Sci., McGill Univ., Montreal, Que., Canada; NA","IEEE Transactions on Software Engineering","","1991","17","12","1270","1283","The Prism model of engineering processes and an architecture which captures this model in its various components are described. The architecture has been designed to hold a product software process description the life-cycle of which is supported by an explicit representation of a higher-level (or meta) process description. The central part of this paper describes the nine-step Prism methodology for building and tailoring process models and gives several scenarios to support this description. In Prism, process models are built using a hybrid process modeling language that is based on a high-level Petri net formalism and rules. An important observation is that this environment should be seen as an infrastructure for carrying out the more difficult task of creating sound process models.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.106987","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=106987","","Software maintenance;Project management;Computer architecture;Software engineering;Computer science;Environmental management;Financial management;Human resource management;Software tools;Buildings","Petri nets;software engineering","process-oriented environment;Prism model;product software process description;hybrid process modeling language;high-level Petri net formalism;rules","","19","","48","","","","","","IEEE","IEEE Journals & Magazines"
"Software Engineering Economics","B. W. Boehm","Software Information Systems Division, TRW Defense Systems Group, Redondo Beach, CA 90278.","IEEE Transactions on Software Engineering","","1984","SE-10","1","4","21","This paper summarizes the current state of the art and recent trends in software engineering economics. It provides an overview of economic analysis techniques and their applicability to software engineering and management. It surveys the field of software cost estimation, including the major estimation techniques available, the state of the art in algorithmic cost models, and the outstanding research issues in software cost estimation.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010193","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010193","Computer programming costs;cost models;management decision aids;software cost estimation;software economics;software engineering;software management","Software engineering;Microeconomics;Costs;Engineering management;Power generation economics;Life estimation;State estimation;Software prototyping;Resource management;Analytical models","","","","223","","61","","","","","","IEEE","IEEE Journals & Magazines"
"SODOS: A software documentation support environment  Its use","E. Horowitz; R. C. Williamson","Department of Computer Science, University of Southern California, Los Angeles, CA 90089; Department of Computer Science, University of Southern California, Los Angeles, CA 90089; Hughes Aircraft Company, Software Engineering Division, AI Technology Department, El Segundo, CA 90245","IEEE Transactions on Software Engineering","","1986","SE-12","11","1076","1087","A description is given of a computerized environment, SODOS (Software Documentation Support), which supports the definition and manipulation of documents used in developing software. An object-oriented environment is used as a basis for the SODOS interface. SODOS is built around a software life-cycle model that structures all access to the documents stored in the environment. This model supports software documentation independently of any fixed methodology that the developers may be using. The main advantage of the system is that it permits traceability through each phase of the life cycle, thus facilitating the test and maintenance phases. The effort involved in learning and using SODOS is simplified by a sophisticated, user-friendly interface.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312997","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312997","Objects;requirements traceability;software development environment;software documentation;software life cycle","Software;Databases;Documentation;Syntactics;Maintenance engineering;Browsers;Manuals","software engineering","software development;SODOS;software documentation support environment;computerized environment;manipulation of documents;object-oriented environment;software life-cycle model;user-friendly interface","","11","","","","","","","","IEEE","IEEE Journals & Magazines"
"An Implementation of an Automated Protocol Synthesizer (APS) and Its Application to the X.21 Protocol","C. V. Ramamoorthy; S. T. Dong; Y. Usuda","Department of Electrical Engineering and Computer Science and the Electronics Research Laboratory, University of California; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","9","886","908","In the past, a number of methods have been proposed to model and validate communication protocols that have already been designed. However, design criteria and design aids are still lacking for designing correct protocols. The objective of developing automated protocol synthesizers is to provide a systematic way of designing new communication protocols such that their correctness can be ensured.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232547","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702107","Computer network;design tool;Petri net;protocol;protocol synthesis","Protocols;Synthesizers;Computer network reliability;Network synthesis;Process design;Computer networks;Maintenance;Telecommunication network reliability;Availability;Reachability analysis","","Computer network;design tool;Petri net;protocol;protocol synthesis","","23","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Towards the automatic generation of software diagrams","L. B. Protsko; P. G. Sorenson; J. P. Tremblay; D. A. Schaefer","Dept. of Comput. Sci., Saskatchewan Univ., Saskatoon, Sask., Canada; Dept. of Comput. Sci., Saskatchewan Univ., Saskatoon, Sask., Canada; Dept. of Comput. Sci., Saskatchewan Univ., Saskatoon, Sask., Canada; Dept. of Comput. Sci., Saskatchewan Univ., Saskatoon, Sask., Canada","IEEE Transactions on Software Engineering","","1991","17","1","10","21","The authors formulate the criteria for drawing dataflow diagrams and describe the placement and routing algorithms used in a system called MONDRIAN. A generalized approach to the question of software diagrams is proposed based on the authors' experience with MONDRIAN and a metasystem approach to the creation of CASE (computer-aided software engineering) environments. A formal approach to the definition of software objects and their graphical representation is given. The use of location constraints as a basis for generalized layout algorithms is discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.67575","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=67575","","Productivity;Specification languages;Layout;Routing;Programming;Design for disassembly;Costs;Documentation;Flow production systems;Computer aided software engineering","diagrams;flowcharting;programming","placement algorithms;CASE environments;automatic generation;software diagrams;drawing;dataflow diagrams;routing algorithms;MONDRIAN;metasystem;computer-aided software engineering;software objects;graphical representation;location constraints;layout algorithms","","29","","43","","","","","","IEEE","IEEE Journals & Magazines"
"User navigation in computer applications","J. P. Ukelson; J. D. Gould; S. J. Boies","IBM Thomas J. Watson Res. Centr, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Centr, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Centr, Yorktown Heights, NY, USA","IEEE Transactions on Software Engineering","","1993","19","3","297","306","An abstract model of keyboard navigation that is based on real-world requirements is described. The importance of keyboard navigation is discussed, and the current approaches to keyboard navigation are reviewed. Several requirements for a successful model of keyboard navigation, including that keyboard navigation and direct manipulation must coexist in the same application, are described. Examples of successful use of the proposed approach to keyboard navigation in application development are presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.221139","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=221139","","Navigation;Computer applications;Keyboards;User interfaces;Application software;Graphical user interfaces;Hardware;Jacobian matrices;Man machine systems;Mice","human factors;interactive systems;user interfaces","user navigation;abstract model;keyboard navigation;real-world requirements;direct manipulation;application development","","1","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Software reliability model with optimal selection of failure data","N. F. Schneidewind","US Naval Postgraduate Sch., Monterey, CA, USA","IEEE Transactions on Software Engineering","","1993","19","11","1095","1104","The possibility of obtaining more accurate predictions of future failures by excluding or giving lower weight to the earlier failure counts is suggested. Although data aging techniques such as moving average and exponential smoothing are frequently used in other fields, such as inventory control, the author did not find use of data aging in the various models surveyed. A model that includes the concept of selecting a subset of the failure data is the Schneidewind nonhomogeneous Poisson process (NHPP) software reliability model. In order to use the concept of data aging, there must be a criterion for determining the optimal value of the starting failure count interval. Four criteria for identifying the optimal starting interval for estimating model parameters are evaluated The first two criteria treat the failure count interval index as a parameter by substituting model functions for data vectors and optimizing on functions obtained from maximum likelihood estimation techniques. The third uses weighted least squares to maintain constant variance in the presence of the decreasing failure rate assumed by the model. The fourth criterion is the familiar mean square error. It is shown that significantly improved reliability predictions can be obtained by using a subset of the failure data. The US Space Shuttle on-board software is used as an example.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.256856","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=256856","","Software reliability;Aging;Smoothing methods;Inventory control;Parameter estimation;Maximum likelihood estimation;Least squares methods;Maintenance;Mean square error methods;Space shuttles","aerospace computing;maximum likelihood estimation;software reliability;space vehicles","software reliability model;failure data;failure counts;moving average;data aging techniques;exponential smoothing;Schneidewind nonhomogeneous Poisson process;failure count interval index;data vectors;weighted least squares;constant variance;mean square error;US Space Shuttle on-board software;NHPP software reliability","","54","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Experiments in software reliability: Life-critical applications","J. R. Dunham","Center for Digital Systems Research, Research Triangle Institute, Research Triangle Park, NC 27709","IEEE Transactions on Software Engineering","","1986","SE-12","1","110","123","Digital computers are being used more frequently for process control applications in which the cost of system failure is high. Consideration of the potentially life-threatening risk, resulting from the high degree of functionality being ascribed to the software components of these systems, has stimulated the recommendation of various designs for tolerating software faults. The author discusses four reliability data gathering experiments which were conducted using a small sample of programs for two problems having ultrareliability requirements: <i>n</i>-version programming for fault detection, and repetitive run modeling for failure and fault rate estimation. The experimental results agree with those of M. Nagel and J.A. Skrivan (1982) in that the program error rates suggest an approximate log-linear pattern and the individual faults occurred with significantly different error rates.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312925","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312925","Life-critical software;real-time software;software experiments;software modeling and measurement;software reliability","Software;Software reliability;Software measurement;Error analysis;Aerospace control","fault tolerant computing;process computer control;software reliability","software reliability;process control applications;system failure;life-threatening risk;reliability data gathering experiments;n-version programming;fault detection;repetitive run modeling;fault rate estimation;program error rates;log-linear pattern","","12","","","","","","","","IEEE","IEEE Journals & Magazines"
"A Successful Software Development","C. Wong","System Development Corporation, Santa Monica, CA 90406.; University of California, Los Angeles, CA 90024.","IEEE Transactions on Software Engineering","","1984","SE-10","6","714","727","In 1980, System Development Corporation (SDC) delivered software for a modern air defense system (ADS) for a foreign country. Development of the ADS software was a successful SCD project where all products were delivered within budget and within an ambitious 25 month schedule. This paper describes SDC's approach and experience in developing ADS software. SDC's software development approach included the first time use of an off-the-shelf operating system for a major air defense system, the application of a selective set of modern software development techniques, and use of a matrix management structure. SDC's successful application on ADS of a commercial operating system, a higher order language, a Program Design Language, a Program Production Library, structured walk-throughs, structured programming techniques, incremental build implementation and testprocedures, interactive development, and word processing is described. A discussion of the advantages realized and difficulties encountered in the ADS matrix management structure is presented. The paper concludes with a summary of how SDC will develop software on future projects as a result of its experience on ADS.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010300","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010300","Air defense system;command and control system;commercial operating system;incremental build test;matrix management;Program Design Language;Program Production Library;software development tools and techniques;structured programming;structured walk-throughs","Programming;Hardware;Software tools;Operating systems;Software development management;Application software;Radar;Command and control systems;Software systems;Software testing","","","","6","","34","","","","","","IEEE","IEEE Journals & Magazines"
"POEMS: end-to-end performance design of large parallel adaptive computational systems","V. S. Adve; R. Bagrodia; J. C. Browne; E. Deelman; A. Dube; E. N. Houstis; J. R. Rice; R. Sakellariou; D. J. Sundaram-Stukel; P. J. Teller; M. K. Vernon","Dept. of Comput. Sci., Illinois Univ., Urbana, IL, USA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","2000","26","11","1027","1048","The POEMS project is creating an environment for end-to-end performance modeling of complex parallel and distributed systems, spanning the domains of application software, runtime and operating system software, and hardware architecture. Toward this end, the POEMS framework supports composition of component models from these different domains into an end-to-end system model. This composition can be specified using a generalized graph model of a parallel system, together with interface specifications that carry information about component behaviors and evaluation methods. The POEMS Specification Language compiler will generate an end-to-end system model automatically from such a specification. The components of the target system may be modeled using different modeling paradigms and at various levels of detail. Therefore, evaluation of a POEMS end-to-end system model may require a variety of evaluation tools including specialized equation solvers, queuing network solvers, and discrete event simulators. A single application representation based on static and dynamic task graphs serves as a common workload representation for all these modeling approaches. Sophisticated parallelizing compiler techniques allow this representation to be generated automatically for a given parallel program. POEMS includes a library of predefined analytical and simulation component models of the different domains and a knowledge base that describes performance properties of widely used algorithms. The paper provides an overview of the POEMS methodology and illustrates several of its key components. The modeling capabilities are demonstrated by predicting the performance of alternative configurations of Sweep3D, a benchmark for evaluating wavefront application technologies and high-performance, parallel architectures.","0098-5589;1939-3520;2326-3881","","10.1109/32.881716","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=881716","","Adaptive systems;Concurrent computing;Application software;Runtime environment;Operating systems;Software performance;Software systems;Hardware;Computer architecture;Specification languages","performance evaluation;parallel programming;parallel architectures;message passing;parallelising compilers;adaptive systems;object-oriented programming;formal specification;software libraries","modeling paradigms;end-to-end performance design;large parallel adaptive computational systems;POEMS project;end-to-end performance modeling;distributed systems;application software;operating system software;hardware architecture;component models;end-to-end system model;generalized graph model;parallel system;interface specifications;component behaviors;evaluation methods;POEMS Specification Language compiler;specialized equation solvers;queuing network solvers;discrete event simulators;application representation;dynamic task graphs;common workload representation;parallelizing compiler techniques;parallel program;simulation component models;knowledge base;performance properties;POEMS methodology;Sweep3D;benchmark;wavefront application technologies;high performance parallel architectures","","40","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Observer-a concept for formal on-line validation of distributed systems","M. Diaz; G. Juanole; J. -. Courtiat","Lab. d'Analyse et d'Archit. des Systemes, CNRS, Toulouse, France; Lab. d'Analyse et d'Archit. des Systemes, CNRS, Toulouse, France; Lab. d'Analyse et d'Archit. des Systemes, CNRS, Toulouse, France","IEEE Transactions on Software Engineering","","1994","20","12","900","913","Proposes the observer concept for designing self-checking distributed systems, i.e. systems that detect erroneous behaviors as soon as errors act at some observable output level. The approach provides a solution to build systems whose on-line behavior is checked against a formal model derived from a formal description. In other words, the actual implementation is continuously checked against a reference, this reference being a formal and verified model of some adequately selected aspects of the system behavior. The corresponding methodology, the software concepts and some applications of the observer are presented. General definitions are given first that theoretically define self-checking systems as systems that include and implement complete on-line validation. The basic concepts and the difficulties to implement self-checking validation are then given. In order to provide simple implementations, the previous definitions are weakened to design quasi-self-checking observers for LANs using a broadcast service. Three specific applications are given to illustrate the proposed approach: testing a virtual ring MAC protocol, checking the link and transport layers in an industrial LAN, and managing a complete OSI layering, from layer 2 to layer 6, in an open system architecture.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.368136","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=368136","","System testing;Runtime;Application software;Broadcasting;Media Access Protocol;Transport protocols;Local area networks;Open systems;Petri nets;Measurement","formal verification;open systems;local area networks;transport protocols;online operation;distributed processing;access protocols","observer concept;formal online validation;self-checking distributed systems design;erroneous behavior detection;observable output level;continuous checking;reference;formal verified model;quasi-self-checking observers;industrial LAN;broadcast service;virtual ring MAC protocol testing;link layer;transport layer;OSI layering management;open system architecture;run-time validation;Petri net based models;performance measurements;layered distributed architectures;formal description techniques","","55","","35","","","","","","IEEE","IEEE Journals & Magazines"
"The Programmer's Apprentice: A Session with KBEmacs","R. C. Waters","M.I.T. Artificial Intelligence Laboratory","IEEE Transactions on Software Engineering","","1985","SE-11","11","1296","1320","The Knowledge-Based Editor in Emacs (KBEmacs) is the current demonstration system implemented as part of the Programmer's Apprentice project. KBEmacs is capable of acting as a semiexpert assistant to a person who is writing a program-taking over some parts of the programming task. Using KBEmacs, it is possible to construct a program by issuing a series of high level comnmands. This series of commands can be as much as an order of magnitude shorter than the program it describes.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231880","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701948","Computer-aided design;program editing;programming environments;reusable software components;Programmer's Apprentice","Automatic programming;Programming profession;Productivity;Artificial intelligence;High level languages;Writing;Robustness;Software prototyping;Prototypes;Programming environments","","Computer-aided design;program editing;programming environments;reusable software components;Programmer's Apprentice","","79","","54","","","","","","IEEE","IEEE Journals & Magazines"
"Verifying definite iteration over data structures","A. M. Stavely","Dept. of Comput. Sci., New Mexico Techl., Socorro, NM, USA","IEEE Transactions on Software Engineering","","1995","21","6","506","514","Methods are presented for verifying loops which iterate over elements of data structures. This verification is done in the functional style developed by Mills and others, in which code is verified against the function that the code is intended to compute. The methods allow the verifier to concentrate on the essential computation performed on each element of the structure, and separate out such concerns as data-structure access and termination so that they do not need to be verified again for every loop in the program. The methods are applicable to a large class of data structures and iterations over them.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.391377","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=391377","","Data structures;Computer languages;Milling machines;Functional programming;Programming profession","data structures;program verification;formal specification;iterative methods;program control structures","definite iteration;data structures;verification;functional style;data-structure access;data-structure termination;functional specifications;program verification;programming language constructs;structured programming","","7","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Performance Modeling of Shared-Resource Array Processors","L. M. Ni; Kai Hwang","Department of Computer Science, Michigan State University; NA","IEEE Transactions on Software Engineering","","1981","SE-7","4","386","394","This paper presents a Markov chain model to analyze the performance of shared-resource array processors for multiple vector processing. Such a parallel processor contains multiple control units sharing a resource pool of processing elements and operating with multiple single-instruction multiple-data streams (MSIMD). In the steady state, the Markov model corresponds to a two-dimensional Markov chain, which can be expressed by a set of equilibrium equations. An iterative method is developed to solve the Markov chain after projecting the equilibrium equations onto a one-dimensional state space. The convergence rate of the iterative method can be greatly enhanced by choosing starting values corresponding to the approximated analytical results obtained earlier by the authors.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234541","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702859","Array processor;Markov chain;multiple SIMD computer;performance evaluation;queueing network;resource sharing;system throughput;vector processing","Equations;Iterative methods;State-space methods;Convergence;Approximation methods;Steady-state;Resource management;Computer networks;Intelligent networks;Performance analysis","","Array processor;Markov chain;multiple SIMD computer;performance evaluation;queueing network;resource sharing;system throughput;vector processing","","1","","14","","","","","","IEEE","IEEE Journals & Magazines"
"PODS  A project on diverse software","P. G. Bishop; D. G. Esp; M. Barnes; P. Humphreys; G. Dahll; J. Lahti","Central Electricity Research Laboratories, UK Central Electricity Generating Board, Surrey KT22 7SE, England; Central Electricity Research Laboratories, UK Central Electricity Generating Board, Surrey KT22 7SE, England; UK Atomic Energy Authority; UK Atomic Energy Authority; Institute for Energy; Technical Research Center of Finland","IEEE Transactions on Software Engineering","","1986","SE-12","9","929","940","A review of the Project on Diverse Software (PODS), a collaborative software reliability research project, is presented. The purpose of the project was to determine the effect of a number of different software development techniques on software reliability. The main objectives were to evaluate the merits of using diverse software, evaluate the specification language X-SPEX, and compare the productivity and reliability associated with high-level and low-level languages. A secondary objective was to monitor the software development process, with particular reference to the creation and detection of software faults. To achieve these objectives, an experiment was performed which simulated a normal software development process to produce three diverse programs to the same requirement. The requirement was for a reactor over-power protection (trip) system. After careful independent development and testing, the three programs were tested against each other in a special test harness to locate residual faults. The conclusions drawn from this project are discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313048","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313048","Fault classification;n-version programming;PODS;programming languages;reactor protection;software diversity;software faults;software reliability;specification languages;X","Software;Testing;Inductors;Specification languages;Software reliability;Documentation;Quality assurance","software reliability;specification languages","diverse software;Project on Diverse Software;PODS;software reliability research project;software development techniques;software reliability;diverse software;specification language X-SPEX;software development process;software faults;reactor over-power protection","","32","","","","","","","","IEEE","IEEE Journals & Magazines"
"Understanding and Automating Algorithm Design","E. Kant","Schlumberger-Doll Research","IEEE Transactions on Software Engineering","","1985","SE-11","11","1361","1374","Algorithm design is a challenging intellectual activity that provides a rich source of observation and a test domain for a theory of problem-solving behavior. This paper describes a theory of the algorithm design process based on observations of human design and also outlines a framework for automatic design. The adaptation of the theory of human design to a framework for automation in the DESIGNER system helps us understand human design better, and the implementation process helps validate the framework. Issues discussed in this paper include the problem spaces used for design, the loci of knowledge and problem-solving power, and the relationship to other methods of algorithm design and to automatic programming as a whole.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231884","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701952","Automatic programming;automating algorithm design;human problem solving;program synthesis;protocol analysis","Algorithm design and analysis;Humans;Problem-solving;Process design;Automatic programming;Testing;Design automation;Design methodology;Protocols;High level languages","","Automatic programming;automating algorithm design;human problem solving;program synthesis;protocol analysis","","18","","29","","","","","","IEEE","IEEE Journals & Magazines"
"An Approach to Distributed Computing System Software Design","S. S. Yau; Chen-Chau Yang; S. M. Shatz","Department of Electrical Engineering and Computer Science, Northwestern University; NA; NA","IEEE Transactions on Software Engineering","","1981","SE-7","4","427","436","Distributed computing systems represent a wide variety of computer systems, ranging from a centralized star network to a completely decentralized computer system. The design of software for distributed computing systems is more complicated due to many design constraints and interactions of software components of the system.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230845","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702863","Concurrent processing;data and functional components;distributed computing systems;performance estimation;software design approach;specification","Distributed computing;System software;Software design;Computer networks;Software performance;Software systems;Control systems;Hardware;Communication system software;Resource management","","Concurrent processing;data and functional components;distributed computing systems;performance estimation;software design approach;specification","","18","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Extensions to an approach to the modeling of software testing with some performance comparisons","T. Downs","Department of Electrical Engineering, University of Queensland, St. Lucia, Qld., 4067, Australia","IEEE Transactions on Software Engineering","","1986","SE-12","9","979","987","It is shown how a major (and questionable) assumption underlying a previously reported approach to the modeling of software testing can be relaxed in order to provide a more realistic model. Under the assumption of uniform execution the new model is found to perform only marginally better than the previous model, indicating that the uniform execution assumption is a poor one. A nonuniform execution model is then shown to give very good performance on application to three sets of software reliability data. Attention is also devoted to the problem of comparing the performance of different models, and some difficulties in this area are noted.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313052","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313052","Probability models;reliability growth;software reliability;software testing","Software systems;Mathematical model;Random variables;Software testing;Data models","software reliability","modeling;software testing;software testing;execution assumption;nonuniform execution model;software reliability data","","4","","","","","","","","IEEE","IEEE Journals & Magazines"
"Reasoning about time in higher-level language software","A. C. Shaw","Dept. of Comput. Sci., Washington Univ., Seattle, WA, USA","IEEE Transactions on Software Engineering","","1989","15","7","875","889","A methodology for specifying and providing assertions about time in higher-level-language programs is described. The approach develops three ideas: the distinction between, and treatment of, both real-time and computer times; the use of upper and lower bounds on the execution times of program elements; and a simple extension of Hoare logic to include the effects of the passage of real-time. Schemas and examples of timing bounds and assertions are presented for a variety of statement types and programs, such as conventional sequential programs including loops, time-related statements such as delay, concurrent programs with synchronization, and software in the presence of interrupts. Examples of assertions that are proved include deadlines, timing invariants for periodic processes, and the specification of time-based events such as those needed for the recognition of single and double clicks from a mouse button.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.29487","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=29487","","Timing;Logic;Software maintenance;Clocks;Mice;Springs;Computer science;Code standards;Software standards;Synchronization","formal logic;formal specification;real-time systems;synchronisation","upper bounds;higher-level language software;assertions;real-time;computer times;lower bounds;execution times;program elements;Hoare logic;timing bounds;sequential programs;time-related statements;delay;concurrent programs;synchronization;deadlines;timing invariants;periodic processes;specification","","186","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Automatically checking an implementation against its formal specification","S. Antoy; D. Hamlet","Dept. of Comput. Sci., Portland State Univ., OR, USA; NA","IEEE Transactions on Software Engineering","","2000","26","1","55","69","We propose checking the execution of an abstract data type's imperative implementation against its algebraic specification. An explicit mapping from implementation states to abstract values is added to the imperative code. The form of specification allows mechanical checking of desirable properties such as consistency and completeness, particularly when operations are added incrementally to the data type. During unit testing, the specification serves as a test oracle. Any variance between computed and specified values is automatically detected. When the module is made part of some application, the checking can he removed, or may remain in place for further validating the implementation. The specification, executed by rewriting, can be thought of as itself an implementation with maximum design diversity, and the validation as a form of multiversion-programming comparison.","0098-5589;1939-3520;2326-3881","","10.1109/32.825766","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=825766","","Formal specifications;Application software;Java;Mechanical factors;Software testing;Computer languages;Software engineering;Software maintenance;Equations;Software prototyping","algebraic specification;program verification;abstract data types;program testing;object-oriented programming","implementation checking;formal specification;abstract data type;imperative implementation;algebraic specification;imperative code;unit testing;rewriting;multiversion programming;object oriented program testing","","45","","59","","","","","","IEEE","IEEE Journals & Magazines"
"Cooperative Distributed Algorithms for Dynamic Cycle Prevention","S. Katz; O. Shmueli","Department of Computer Science, Technion; NA","IEEE Transactions on Software Engineering","","1987","SE-13","5","540","552","Parallel distributed algorithms are presented for adding and deleting edges in a directed graph without creating a cycle. Such algorithms are useful for a variety of problems in distributed systems such as preventing deadlock or ordering priorities. The algorithms operate in a realistic asynchronous computer network environment in which there are numerous possible interactions among overlapping instances of the algorithms.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233199","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702254","Concurrent programming;distributed systems","Distributed algorithms;System recovery;Computer science;Computer networks;Computational modeling;Distributed computing;Message passing;Drives;Concurrency control;Data structures","","Concurrent programming;distributed systems","","6","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Optimal partitioning of randomly generated distributed programs","B. Indurkhya; H. S. Stone; L. Xi-Cheng","Department of Computer and Information Science, University of Massachusetts, Amherst, MA 01003; Department of Computer Science, Boston University, Boston, MA 02215; Department of Electrical and Computer Engineering, University of Massachusetts, Amherst, MA 01003; IBM Thomas J. Watson Research Center, Yorktown Heights, NY 10598; Department of Electrical and Computer Engineering, University of Massachusetts, Amherst. MA 01003; Changsha Institutute, Changsha, Republic of China","IEEE Transactions on Software Engineering","","1986","SE-12","3","483","495","An investigation is made of an optimal task-assignment policy for a random-graph model of a distributed program. The model of the distributed computer system assumes that communications overhead adds to total run time and that total run time decreases as the number of processors running the program is increased. When the processors are homogeneous, the optimal task-assignments are external in the sense that tasks are totally distributed among all processors as evenly as possible or not distributed at all. The point at which the policy shows a sharp change of behavior depends upon the ratio of run times to communication times. The authors derive two important properties of the optimal task-assignments for heterogeneous processors. The first property is that an optimal policy distributes the cost of processing among the processors as evenly as possible so that a processor with higher speed gets more tasks and vice versa. The second property determines the number of processors among which to distribute the tasks evenly. In the special case when there is a uniform degradation of processing speed, it is shown that the optimal policy again exhibits an extremal characteristic.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312889","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312889","Computer networks;distributed computers;local area networks;multiprocessors;optimal partitioning;random-graph models;task assignments","Program processors;Computational modeling;Bandwidth;Computers;Runtime;Delay;Educational institutions","distributed processing;local area networks;operating systems (computers);scheduling","scheduling;software engineering;LAN;random graph models;randomly generated distributed programs;optimal task-assignment policy;random-graph model;communications overhead;total run time;optimal task-assignments;run times;communication times;optimal task-assignments;heterogeneous processors","","20","","","","","","","","IEEE","IEEE Journals & Magazines"
"A compact Petri net representation and its implications for analysis","M. B. Dwyer; L. A. Clarke","Dept. of Comput. & Inf. Sci., Kansas State Univ., Manhattan, KS, USA; NA","IEEE Transactions on Software Engineering","","1996","22","11","794","811","We explore a property-independent, coarsened, multilevel representation for supporting state reachability analysis for a number of different properties. This multilevel representation comprises a reachability graph derived from a highly optimized Petri net representation that is based on task interaction graphs and associated property-specific summary information. This highly optimized representation reduces the size of the reachability graph but may increase the cost of the analysis algorithm for some types of analyses. We explore this tradeoff. To this end, we have developed a framework for checking a variety of properties of concurrent programs using this optimized representation and present empirical results that compare the cost to an alternative Petri net representation. In addition, we present reduction techniques that can further improve the performance and yet still preserve analysis information. Although worst-case bounds for most concurrency analysis techniques are daunting, we demonstrate that the techniques that we propose significantly broaden the applicability of reachability analyses.","0098-5589;1939-3520;2326-3881","","10.1109/32.553699","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=553699","","Information analysis;Algorithm design and analysis;Petri nets;Electronic mail;Costs;Failure analysis;System recovery;Software engineering;Production systems;Software systems","reachability analysis;parallel programming;Petri nets;programming theory;optimisation;software cost estimation;program verification","Petri net representation;property-independent multilevel representation;state reachability analysis;reachability graph;optimization;task interaction graphs;property-specific summary information;concurrent program property checking;cost;reduction techniques;performance;worst-case bounds;concurrency analysis techniques;software validation","","16","","28","","","","","","IEEE","IEEE Journals & Magazines"
"An empirical study of a model for program error prediction","M. Takahashi; Y. Kamayachi","Electr. Commun. Labs., NTT Corp., Tokyo, Japan; Electr. Commun. Labs., NTT Corp., Tokyo, Japan","IEEE Transactions on Software Engineering","","1989","15","1","82","86","A model is presented for estimating the number of errors remaining in a program at the beginning of the testing phase of development. The relationships between the errors occurring in a program and the various factors that affect software development, such as programmer skill, are statistically analyzed. The model is then derived using the factors significantly identified in the analysis. On the basis of data collected during the development of large-scale software systems, it is shown that factors such as frequency of program specification change, programmer skill, and volume of program design documentation are significant and that the model based on these factors is more reliable than conventional error prediction methods based on program size alone.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21729","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21729","","Predictive models;Error correction;Environmental factors;Large-scale systems;Software systems;Testing;Programming;Software quality;Communication system control;Data analysis","program testing;software engineering","program error prediction;testing phase;software development;programmer skill;large-scale software systems;program specification change;program design documentation","","30","","16","","","","","","IEEE","IEEE Journals & Magazines"
"A theory of attributed equivalence in databases with application to schema integration","J. A. Larson; S. B. Navathe; R. Elmasri","Honeywell, Minneapolis, MN, USA; NA; NA","IEEE Transactions on Software Engineering","","1989","15","4","449","463","The authors present a common foundation for integrating pairs of entity sets, pairs of relationship sets, and an entity set with a relationship set. This common foundation is based on the basic principle of integrating attributes. Any pair of objects whose identifying attributes can be integrated can themselves be integrated. Several definitions of attribute equivalence are presented. These definitions can be used to specify the exact nature of the relationship between a pair of attributes. Based on these definitions, several strategies for attribute integration are presented and evaluated.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.16605","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=16605","","Transaction databases;Data models;Database systems;Computer science","database theory;equivalence classes","attributed equivalence;schema integration;entity sets;relationship sets;attribute integration","","157","","16","","","","","","IEEE","IEEE Journals & Magazines"
"A unified interprocedural program representation for a maintenance environment","M. J. Harrold; B. Malloy","Dept. of Comput. Sci., Clemson Univ., SC, USA; Dept. of Comput. Sci., Clemson Univ., SC, USA","IEEE Transactions on Software Engineering","","1993","19","6","584","593","Unified interprocedural graph (UIG) that extracts the important features of existing program representations and adds new information to provide an integrated representation for maintenance tasks is presented. Algorithms that were developed for previous representations are adapted to use the UIG by identifying the subset of nodes and edges in the UIG required for that computation. Newly developed algorithms can use the UIG since it contains data flow, control flow, data dependence, and control dependence information. The main benefits of this approach are the reduction in storage space since individual representations are not kept, the savings in maintenance time of a single representation over the individual representations, and the convenience of accessing a single program representation without increase in access time. A single program representation also assists in program understanding since relationships among program elements are incorporated into one graph.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.232023","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=232023","","Testing;Debugging;Error correction;Data mining;Feature extraction;Computer science;Parallel processing;Data analysis","programming theory;software maintenance","software maintenance;unified interprocedural graph;unified interprocedural program representation;nodes;edges;data flow;control flow;data dependence;control dependence;storage space;access time;program understanding","","15","","21","","","","","","IEEE","IEEE Journals & Magazines"
"PROUST: Knowledge-Based Program Understanding","W. L. Johnson; E. Soloway","Department of Computer Science, Yale University; NA","IEEE Transactions on Software Engineering","","1985","SE-11","3","267","275","This paper describes a program called PROUST which does on-line analysis and understanding of Pascal written by novice programmers. PROUST takes as input a program and a nonalgorithmic description of the program requirements, and finds the most likely mapping between the requirements and the code. This mapping is in essence a reconstruction of the design and implementation steps that the programmer went through in writing the program. A knowledge base of programming plans and strategies, together with common bugs associated with them, is used in constructing this mapping. Bugs are discovered in the process of relating plans to the code; PROUST can therefore give deep explanations of program bugs by relating the buggy code to its underlying intentions.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232210","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702003","Artificial inteiligence;program debugging;programmer training;program understanding","Programming profession;Computer bugs;Writing;Debugging;Personnel;Psychology;Computer science;Machinery;Reactive power","","Artificial inteiligence;program debugging;programmer training;program understanding","","131","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Information extraction from images of paper-based maps","R. Kasturi; J. Alemany","Dept. of Electr. Eng., Pennsylvania State Univ., University Park, PA, USA; Dept. of Electr. Eng., Pennsylvania State Univ., University Park, PA, USA","IEEE Transactions on Software Engineering","","1988","14","5","671","675","The design of a system to extract information automatically from paper-based maps and answer queries related to spatial features and structure of geographic data is considered. The foundation of such a system is a set of image-analysis algorithms for extracting spatial features. Efficient algorithms to detect symbols, identify and track various types of lines, follow closed contours, compute distances, find shortest paths, etc. from simplified map images have been developed. A query processor analyzes the queries presented by the user in a predefined syntax, controls the operation of the image processing algorithms, and interacts with the user. The query processor is written in Lisp and calls image-analysis routines written in Fortran.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6145","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6145","","Data mining;Image analysis;Image databases;Data processing;Database systems;Image processing;Deductive databases;Pattern recognition;Graphics;Feature extraction","cartography;database management systems;information retrieval;query languages;user interfaces","paper-based maps;spatial features;geographic data;image-analysis algorithms;closed contours;distances;shortest paths;map images;query processor;syntax;Lisp;Fortran","","38","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Language design for program manipulation","E. A. T. Merks; J. M. Dyck; R. D. Cameron","Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada; Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada; Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada","IEEE Transactions on Software Engineering","","1992","18","1","19","32","The design of procedural and object-oriented programming languages is considered with respect to how easily programs written in those languages can be formally manipulated. Current procedural languages such as Pascal, Modula-2 and Ada; generally support such program manipulations, except for some annoying anomalies and special cases. Three main areas of language design are identified as being of concern from a manipulation viewpoint: the interface between concrete and abstract syntax; the relationship between the abstract syntax and static semantics naming, scoping and typing; and the ability to express basic transformations (folding and unfolding). Design principles are suggested so that the problems identified for current languages can be avoided in the future.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.120313","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=120313","","Concrete;Instruments;Process design;Data structures;Appropriate technology;Synthesizers","high level languages;object-oriented programming;software engineering","program manipulation;object-oriented programming languages;procedural languages;Pascal;Modula-2;Ada;program manipulations;language design;abstract syntax;static semantics;naming;scoping;typing;unfolding","","4","","43","","","","","","IEEE","IEEE Journals & Magazines"
"GENESIS: an extensible database management system","D. S. Batoory; J. R. Barnett; J. F. Garza; K. P. Smith; K. Tsukuda; B. C. Twichell; T. E. Wise","Dept. of Comput. Sci., Texas Univ., Austin, TX, USA; Dept. of Comput. Sci., Texas Univ., Austin, TX, USA; Dept. of Comput. Sci., Texas Univ., Austin, TX, USA; Dept. of Comput. Sci., Texas Univ., Austin, TX, USA; Dept. of Comput. Sci., Texas Univ., Austin, TX, USA; Dept. of Comput. Sci., Texas Univ., Austin, TX, USA; Dept. of Comput. Sci., Texas Univ., Austin, TX, USA","IEEE Transactions on Software Engineering","","1988","14","11","1711","1730","A novel yet simple technology is presented that enables customized database management systems (DBMSs) to be developed rapidly. The authors are designing an extensible DBMS, called GENESIS, which is based on this theory. They give a detailed description of their first operational prototype. DBMS software components in GENESIS can be written in a few months. When all components for a target DBMS are present, writing the architecture specification of the DBMS and reconfiguring GENESIS takes a few hours and can be accomplished with negligible cost.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9057","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9057","","Database systems;Computer architecture;Transaction databases;Software libraries;Information retrieval;Costs;Application software;Software prototyping;Prototypes;Writing","database management systems;software reusability;software tools","software reusability;software tools;GENESIS;extensible database management system;customized database management systems;architecture specification","","63","","58","","","","","","IEEE","IEEE Journals & Magazines"
"A framework for source code search using program patterns","S. Paul; A. Prakash","Dept. of Electr. Eng. & Comput. Sci., Michigan Univ., Ann Arbor, MI, USA; Dept. of Electr. Eng. & Comput. Sci., Michigan Univ., Ann Arbor, MI, USA","IEEE Transactions on Software Engineering","","1994","20","6","463","475","For maintainers involved in understanding and reengineering large software, locating source code fragments that match certain patterns is a critical task. Existing solutions to the problem are few, and they either involve manual, painstaking scans of the source code using tools based on regular expressions, or the use of large, integrated software engineering environments that include simple pattern-based query processors in their toolkits. We present a framework in which pattern languages are used to specify interesting code features. The pattern languages are derived by extending the source programming language with pattern-matching symbols. We describe SCRUPLE, a finite state machine-based source code search tool, that efficiently implements this framework. We also present experimental performance results obtained from a SCRUPLE prototype, and the user interface of a source code browser built on top of SCRUPLE.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.295894","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=295894","","Software maintenance;Pattern matching;Design engineering;Programming profession;Software engineering;Computer languages;Software prototyping;Prototypes;User interfaces;Database languages","software maintenance;query languages;software tools;programming environments;formal specification;finite state machines;user interfaces","source code search;program patterns;software maintenance;software understanding;software reengineering;source code fragments;source code;software tools;integrated software engineering environments;pattern-based query processors;software toolkits;pattern languages;source programming language;SCRUPLE;source code search tool;finite state machine;prototype;user interface;source code browser","","73","","32","","","","","","IEEE","IEEE Journals & Magazines"
"Learning from examples: generation and evaluation of decision trees for software resource analysis","R. W. Selby; A. A. Porter","Dept. of Inf. & Comput. Sci., California Univ., Irvine, CA, USA; Dept. of Inf. & Comput. Sci., California Univ., Irvine, CA, USA","IEEE Transactions on Software Engineering","","1988","14","12","1743","1757","A general solution method for the automatic generation of decision (or classification) trees is investigated. The approach is to provide insights through in-depth empirical characterization and evaluation of decision trees for one problem domain, specifically, that of software resource data analysis. The purpose of the decision trees is to identify classes of objects (software modules) that had high development effort, i.e. in the uppermost quartile relative to past data. Sixteen software systems ranging from 3000 to 112000 source lines have been selected for analysis from a NASA production environment. The collection and analysis of 74 attributes (or metrics), for over 4700 objects, capture a multitude of information about the objects: development effort, faults, changes, design style, and implementation style. A total of 9600 decision trees are automatically generated and evaluated. The analysis focuses on the characterization and evaluation of decision tree accuracy, complexity, and composition. The decision trees correctly identified 79.3% of the software modules that had high development effort or faults, on the average across all 9600 trees. The decision trees generated from the best parameter combinations correctly identified 88.4% of the modules on the average. Visualization of the results is emphasized, and sample decision trees are included.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9061","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9061","","Decision trees;Machine learning;Fault diagnosis;Classification tree analysis;Data analysis;Software systems;NASA;Information analysis;Termination of employment;Analysis of variance","artificial intelligence;decision theory;software engineering;trees (mathematics)","software engineering;machine learning;artificial intelligence;decision trees;software resource analysis;software modules;NASA;production environment;metrics","","138","","56","","","","","","IEEE","IEEE Journals & Magazines"
"Evolution and reuse of orthogonal architecture","V. Rajlich; J. H. Silva","Dept. of Comput. Sci., Wayne State Univ., Detroit, MI, USA; NA","IEEE Transactions on Software Engineering","","1996","22","2","153","157","We present a case study of evolution (or vertical reuse) in the domain of visual interactive software tools. We introduce an architecture suitable for this purpose, called orthogonal architecture. The paper describes the architecture itself, the reverse engineering process by which it was obtained, and the forward engineering process by which it was evolved.","0098-5589;1939-3520;2326-3881","","10.1109/32.485224","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=485224","","Computer architecture;Software tools;Reverse engineering;Computer Society;Object oriented programming;Software maintenance;Application software;Software architecture;Computer science","software tools;interactive systems;software reusability;reverse engineering;visual programming","orthogonal architecture evolution;vertical reuse;visual interactive software tools;reverse engineering process;forward engineering process","","24","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Elements of style: analyzing a software design feature with a counterexample detector","D. Jackson; C. A. Damon","Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA; Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA","IEEE Transactions on Software Engineering","","1996","22","7","484","495","Demonstrates how Nitpick, a specification checker, can be applied to the design of a style mechanism for a word processor. The design is cast, along with some expected properties, in a subset of Z. Nitpick checks a property by enumerating all possible cases within some finite bounds, displaying as a counterexample the first case for which the property fails to hold. Unlike animation or execution tools, Nitpick does not require state transitions to be expressed constructively, and unlike theorem provers, Nitpick operates completely automatically without user intervention. Using a variety of reduction mechanisms, it can cover an enormous number of cases in a reasonable time, so that subtle flaws can be rapidly detected.","0098-5589;1939-3520;2326-3881","","10.1109/32.538605","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=538605","","Software design;Detectors;Hardware;Protocols;Process design;Animation;Formal specifications;Software testing;Computer architecture;Formal languages","word processing;formal specification;program testing;program verification","word processor style mechanism;software design feature analysis;counterexample detector;Nitpick;formal specification checker;Z specification language subset;case enumeration;finite bounds;state transitions;automatic operation;reduction mechanisms;subtle flaw detection;abstract modeling;Z notation;model checking;exhaustive testing","","41","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Resilient Extended True-Copy Token Scheme for a Distributed Database System","T. Minoura; G. Wiederhold","Department of Electrical Engineering-Systems, University of Southern California; NA","IEEE Transactions on Software Engineering","","1982","SE-8","3","173","189","A new resiliency scheme for a distributed database system with replicated data is presented. One salient feature of the scheme is that it does not employ a log subsystem; hence, it can be used for a highly reliable system that must tolerate a total crash of a site. In addition, the scheme supports system partitioning without any consistency problem. The new scheme is based on a precise treatment of logical data; in particular, a precise definition of resilient system operation is given in terms of logical data.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235105","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702934","Distributed database system;logical data;replicated data;resiliency control;true-copy token","Database systems;Contracts;Computer crashes;Control systems;Concurrency control;Application specific processors;Physics computing;Distributed databases;Transaction databases;Reliability engineering","","Distributed database system;logical data;replicated data;resiliency control;true-copy token","","22","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Application of real-time monitoring to scheduling tasks with random execution times","D. Haban; K. G. Shin","Daimler Benz AG, Stuttgart, West Germany; NA","IEEE Transactions on Software Engineering","","1990","16","12","1374","1389","A real-time monitor is employed to aid in scheduling tasks with random execution times in a real-time computing system. The real-time monitor is composed of dedicated hardware called test and measurement processors (TMPs). It is used to measure accurately and with minimal interference the true execution time, which consists of pure execution time and resource sharing delay. The monitor is a permanent and transparent part of a real-time system. It degrades system performance by less than 0.1% and does not interfere with the host system's execution. The measured pure execution time and resource sharing delay for each task have been used to develop a mechanism that reduces the discrepancy between the worst-case execution time (WET) and the estimated execution time. This result is used to decide at the earliest possible time whether or not a task can meet its deadline. A set of example tasks are experimentally measured in a simulated environment while their characteristics are varied. The measured data are analyzed, demonstrating the utility and power of the proposed real-time monitor.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.62446","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=62446","","Monitoring;Real time systems;Processor scheduling;Time measurement;Resource management;Delay effects;Delay estimation;Hardware;Testing;Interference","real-time systems;scheduling","task scheduling;test/measurement processors;real-time monitoring;random execution times;real-time monitor;real-time computing system;dedicated hardware;TMPs;true execution time;pure execution time;resource sharing delay;transparent part;system performance;worst-case execution time;WET;estimated execution time;simulated environment","","35","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Reasoning about interactive system","V. Ambriola; D. Notkin","Dep. of Inf., Pisa Univ., Italy; NA","IEEE Transactions on Software Engineering","","1988","14","2","272","276","Interactive systems have goals and characteristics that differ from those of batch systems. These differences lead to a need for new techniques, methods, and tools for manipulating and constructing interactive systems. The difference in structure between batch and interactive systems. The difference is considered, focusing on the distinction between command decomposition and component decomposition. The possible ways of solving a problem using an interactive system using action paths, which account for the relatively unconstrained actions of interactive users, are described. It is shown that interactivity is not an inherent characteristic of a system but rather a characteristic that depends on the error profile of its users. The requirements that interaction places on the underlying implementation, specifically the need for incrementality and integration, are considered. The results are applied to several existing classes of systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4645","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4645","","Interactive systems;Displays;Productivity;Hardware;Power generation economics;Computer science;Computer errors;Mice;Delay;Software systems","interactive systems;user interfaces","interactive system;command decomposition;component decomposition;action paths;unconstrained actions;error profile","","1","","18","","","","","","IEEE","IEEE Journals & Magazines"
"An Information-Theoretic Analysis of Relational DatabasesPart II: Information Structures of Database Schemas","T. T. Lee","Bell Communications Research","IEEE Transactions on Software Engineering","","1987","SE-13","10","1062","1072","The structural properties of acyclic database schemas, especially the interrelationships between acyclic join dependencies and multivalued dependencies, are examined in this paper. The intersection closure of a database schema is a semilattice, which is usually represented by Hasse diagram in algebra. The Hasse diagram of a schema is analogous to the Bachman diagram of a network model. Based on the topological structures of Hasse diagrams, the acyclic join dependency is proved to be equivalent to a set of conflict-free multivalued dependencies. Furthermore, we show that if the Hasse diagram is loop free, then the corresponding set of multivalued dependencies is also contention-free. This result is consistent with previous results derived from the Bachman diagram.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232848","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702146","Bachman diagram;conflict-free MVD's;contention free MVD's;Hasse diagram;semilattice","Relational databases;Data analysis;Information analysis;Algebra;Data structures;Entropy;Information theory","","Bachman diagram;conflict-free MVD's;contention free MVD's;Hasse diagram;semilattice","","","","10","","","","","","IEEE","IEEE Journals & Magazines"
"VSWS: The Variable-Interval Sampled Working Set Policy","D. Ferrari; Yiu-yoo Yih","Computer Science Division, Department of Electrical Engineering and Computer Sciences, and the Electronics Research Laboratory, University of California; NA","IEEE Transactions on Software Engineering","","1983","SE-9","3","299","305","A local variable-size memory policy called the variable-interval sampled working set (VSWS) policy is described. The results of trace-driven simulation experiments reported here show that VSWS has a static performance comparable to those of the working set (WS) and sampled working set (SWS) policies, a dynamic performance better than those of WS, SWS, and the page fault frequency (PFF) policy, and similar to that of the damped working set (DWS) policy. Furthermore, VSWS generaly causes substantially less process suspensions than SWS, and is less expensive to implement than WS or DWS, since it requires the same hardware support as SWS and PFF. The sampling overhead of VSWS is comparable to that of SWS and lower than that of PFF.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236865","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703057","Damped working set policy;local replacement policy;memory management;page fault frequency policy;program behavior;replacement algorithm;sampled working set policy;variable-size policy;virtual memory;working set policy","Memory management;Frequency;Automatic control;Suspensions;Hardware;Sampling methods;Computer science;Laboratories;Scheduling algorithm;Operating systems","","Damped working set policy;local replacement policy;memory management;page fault frequency policy;program behavior;replacement algorithm;sampled working set policy;variable-size policy;virtual memory;working set policy","","2","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Cleanroom Software Development: An Empirical Evaluation","R. W. Selby; V. R. Basili; F. T. Baker","Department of Information and Computer Science, University of California; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","9","1027","1037","The Cleanroom software development approach is intended to produce highly reliable software by integrating formal methods for specification and design, nonexecution-based program development, and statistically based independent testing. In an empirical study, 15 three-person teams developed versions of the same software system (800-2300 source lines); ten teams applied Cleanroom, while five applied a more traditional approach. This analysis characterizes the effect of Cleanroom on the delivered product, the software development process, and the developers.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233525","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702325","Empirical study;methodology evaluation;off-line software review;software development methodology;software management;software measurement;software testing","Programming;Software testing;Computer science;System testing;Control systems;Software measurement;Software systems;Computer aided software engineering;Frequency measurement;Software development management","","Empirical study;methodology evaluation;off-line software review;software development methodology;software management;software measurement;software testing","","68","","48","","","","","","IEEE","IEEE Journals & Magazines"
"Functional data structures as updatable objects","J. Milewski","Inst. of Inf., Warsaw Univ., Poland","IEEE Transactions on Software Engineering","","1990","16","12","1427","1432","The threat of continuous data copying is one of the key problems in applicative programming. The opportunities to implement functional data structures as updatable objects, thus avoiding any form of copying, are discussed. The notion of incremental structures and associated storage is used. Its specification is modified so as to handle sequential and shared structures. The former can be used in the case when only data dependencies and not data values are considered in source program analysis. The latter can be used for nondeterministic applications such as system programming.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.62450","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=62450","","Data structures;Parallel processing;Concurrent computing;Functional programming;Informatics","data structures;functional programming;parallel programming","continuous data copying;applicative programming;functional data structures;updatable objects;incremental structures;associated storage;shared structures;data dependencies;source program analysis;nondeterministic applications;system programming","","2","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Detecting unsafe error recovery schedules","R. R. Lutz; J. S. K. Wong","Dept. of Comput. Sci., Iowa State Univ., Ames, IA, USA; Dept. of Comput. Sci., Iowa State Univ., Ames, IA, USA","IEEE Transactions on Software Engineering","","1992","18","8","749","760","A mechanism for modeling timing, precedence, and data-consistency constraints on concurrently executing processes is presented. The model allows durations and intervals between events to be specified. An algorithm is provided to detect schedules which may be unsafe with respect to the constraints. This work, motivated by the design and validation of autonomous error-recovery strategies on the Galileo spacecraft, appears to be applicable to a variety of asynchronous real-time systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.153384","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=153384","","Space vehicles;Timing;Testing;Scheduling algorithm;Safety;Software tools;Software algorithms;Interleaved codes;Computer science;Hardware","aerospace computing;fault tolerant computing;real-time systems;scheduling","unsafe error recovery schedules;modeling timing;precedence;data-consistency constraints;concurrently executing processes;Galileo spacecraft;asynchronous real-time systems","","7","","40","","","","","","IEEE","IEEE Journals & Magazines"
"Performance and Reliability Analysis Using Directed Acyclic Graphs","R. A. Sahner; K. S. Trivedi","Gould Computer Systems Division; NA","IEEE Transactions on Software Engineering","","1987","SE-13","10","1105","1114","A graph-based modeling technique has been developed for the stochastic analysis of systems containing concurrency. The basis of the technique is the use of directed acyclic graphs. These graphs represent event-precedence networks where activities may occur serially, probabilistically, or concurrently. When a set of activities occurs concurrently, the condition for the set of activities to complete is that a specified number of the activities must complete. This includes the special cases that one or all of the activities must complete. The cumulative distribution function associated with an activity is assumed to have exponential polynomial form. Further generality is obtained by allowing these distributions to have a mass at the origin and/or at infinity. The distribution function for the time taken to complete the entire graph is computed symbolically in the time parameter t. The technique allows two or more graphs to be combined hierarchically. Applications of the technique to the evaluation of concurrent program execution time and to the reliability analysis of fault-tolerant systems are discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232852","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702150","Availability;directed acyclic graphs;fault-tolerance;Markov models;performance evaluation;program performance;reliability","Performance analysis;Concurrent computing;Distribution functions;Availability;Stochastic systems;Polynomials;H infinity control;Distributed computing;Fault tolerant systems;Fault tolerance","","Availability;directed acyclic graphs;fault-tolerance;Markov models;performance evaluation;program performance;reliability","","54","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Temporal logic-based deadlock analysis for Ada","G. M. Karam; R. J. A. Buhr","Dept. of Syst. & Comput. Eng., Carleton Univ., Ottawa, Ont., Canada; Dept. of Syst. & Comput. Eng., Carleton Univ., Ottawa, Ont., Canada","IEEE Transactions on Software Engineering","","1991","17","10","1109","1125","A temporal logic-based specification language and deadlock analyzer for Ada is described. The deadlock analyzer is intended for use within Timebench, a concurrent system-design environment with support for Ada. The specification language, COL, uses linear-time temporal logic to provide a formal basis for axiomatic reasoning. The deadlock analysis tool uses the reasoning power of COL to demonstrate that Ada designs specified in COL are systemwide deadlock-free: in essence, it uses a specialized theorem prover to deduce the absence of deadlock. The deadlock algorithm is shown to be decidable for finite systems and acceptable otherwise. It is also shown to have a worst-case computational complexity that is exponential with the number of tasks. The analyzer has been implemented in Prolog. Numerous examples are evaluated using the analyzer, including readers and writers, gas station, five dining philosophers, and a layered communications system. The results indicate that analysis time is reasonable for moderate designs in spite of the worst-case complexity of the algorithm.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.99197","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=99197","","System recovery;Specification languages;Algorithm design and analysis;Design methodology;Computational complexity;Communication systems;Logic design;Process design;Design automation;Software design","Ada;computational complexity;inference mechanisms;logic programming;specification languages;system recovery;temporal logic","temporal logic-based specification language;deadlock analyzer;Timebench;concurrent system-design environment;specification language;COL;linear-time temporal logic;formal basis;axiomatic reasoning;deadlock analysis tool;reasoning power;Ada designs;systemwide deadlock-free;theorem prover;deadlock algorithm;finite systems;worst-case computational complexity;Prolog;readers;writers;gas station;dining philosophers;layered communications system","","6","","46","","","","","","IEEE","IEEE Journals & Magazines"
"Combining Testing with Formal Specifications: A Case Study","P. R. McMullin; J. D. Gannon","Applied Physics Laboratory, The Johns Hopkins University; NA","IEEE Transactions on Software Engineering","","1983","SE-9","3","328","335","This paper describes our experience specifying, implementing, and validating a record-oriented text editor similar to one discussed in [7]. Algebraic axioms served as the specification notation; and the implementation was tested with a compiler-based system that uses the axioms to test implementations with a finite collection of test cases. Formal specifications were sometimes difficult to produce, but helped reveal errors during unit testing. Thorough exercising of the implementations by the specifications resulted in few errors persisting until integration.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236869","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703061","Data types;specification;testing","Formal specifications;Computer aided software engineering;System testing;User interfaces;Computer science;Production;Information retrieval;Displays;Programming profession;Contracts","","Data types;specification;testing","","10","","8","","","","","","IEEE","IEEE Journals & Magazines"
"On the efficient engineering of ambitious program analysis","Jong-Deok Choi; R. Cytron; J. Ferrante","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; NA; NA","IEEE Transactions on Software Engineering","","1994","20","2","105","114","Recent advances in languages, software design methodologies, and architecture have prompted the development of improved compile-time methods for analyzing the effects of procedure calls, pointer references, and array accesses. Such sophistication, however, generally implies that compilers and programming environments will experience a corresponding increase in the volume of analysis information, which may be difficult to use efficiently. In this paper, we consider the practical accommodation of such information. Our results show how to engineer a compiler such that its optimization phase takes time proportional to the benefit, rather than the size, of such information.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.265631","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=265631","","Program processors;Information analysis;Optimizing compilers;Software design;Computer architecture;Programming environments;Data analysis;Computer languages;Aggregates;Data structures","program diagnostics;program compilers;software engineering;optimisation","efficient engineering;program analysis;compile-time methods;procedure calls;pointer references;array accesses;compilers;programming environments;optimization phase;information benefit;analysis information volume;data-flow analysis;data-flow chains;reaching definitions;static single assignment;compact representation;demand-driven computation","","5","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Product-Form Synthesis of Queueing Networks","S. Balsamo; G. Iazeolla","Dipartimento di Informatica, University of Pisa; NA","IEEE Transactions on Software Engineering","","1985","SE-11","2","194","199","The mathematics of product-form queueing networks has traditionally dealt with the ""analysis"" of computer systems. That is, the system is assumed to be given and the question of how it performs is answered. In this paper the opposite process of system ""synthesis"" is dealt with: i.e., we answer the question of what the system topology and parameters should be in order to achieve a given performance objective. Possible research and industry applications range from the hierarchial top-down design of software systems to the management and design of computer installations.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232194","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701987","Aggregation;disaggregation;equivalent network;hierarchical design;networks of queues;queueing theory;software engineering;system synthesis","Network synthesis;Mathematics;Queueing analysis;Performance analysis;Computer networks;Software design;Software systems;Network topology;Industry applications;Software engineering","","Aggregation;disaggregation;equivalent network;hierarchical design;networks of queues;queueing theory;software engineering;system synthesis","","","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Managerial use of metrics for object-oriented software: an exploratory analysis","S. R. Chidamber; D. P. Darcy; C. F. Kemerer","Advisory Board Co., Washington, DC, USA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","8","629","639","With the increasing use of object-oriented methods in new software development, there is a growing need to both document and improve current practice in object-oriented design and development. In response to this need, a number of researchers have developed various metrics for object-oriented systems as proposed aids to the management of these systems. In this research, an analysis of a set of metrics proposed by Chidamber and Kemerer (1994) is performed in order to assess their usefulness for practising managers. First, an informal introduction to the metrics is provided by way of an extended example of their managerial use. Second, exploratory analyses of empirical data relating the metrics to productivity, rework effort and design effort on three commercial object-oriented systems are provided. The empirical results suggest that the metrics provide significant explanatory power for variations in these economic variables, over and above that provided by traditional measures, such as size in lines of code, and after controlling for the effects of individual developers.","0098-5589;1939-3520;2326-3881","","10.1109/32.707698","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=707698","","Programming;Performance analysis;Power system management;Data analysis;Productivity;Power system economics;Power generation economics;Power measurement;Size measurement;Size control","object-oriented programming;software metrics;software development management;project management","managerial use;software metrics;object-oriented software;object-oriented design;exploratory analyses;productivity;rework effort;design effort;economic variables;program size;lines of code;individual developer effects;SLOC;WMC;NOC;DIT;LCOM;CBO;RFC;programming;project management","","99","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Authentication mechanisms in microprocessor-based local area networks","L. Ciminiera; A. Valenzano","Dipartimento di Autom. e Inf., Politecnico di Torino, Italy; NA","IEEE Transactions on Software Engineering","","1989","15","5","654","658","The problem of authenticating the users of a computer network in order to protect the shared resources against unauthorized use is discussed. Since intruders could enter the network and try to use services they have no right to access, the host implementing the service (or server) has to check the user's identity and access rights by searching in the relevant database. The author presents a method of carrying out such checks efficiently. The basic idea is that a suitable interface process is associated with each user-server connection in order to filter out unauthorized requests, thus implementing a sort of cache with parallel search where the working set of the whole database is stored and explored. The use of the interface process enables the system to exploit the hardware support for capability checking provided by new microprocessors. In particular, an implementation using iAPX432-based hosts is illustrated and performance issues are discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24716","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24716","","Authentication;Databases;Computer networks;Protection;File servers;Network servers;Permission;Filters;Hardware;Microprocessors","local area networks;security of data","authentication mechanisms;microprocessor-based local area networks;protect;shared resources;unauthorized use;intruders;service;server;check;identity;access rights;searching;database;interface process;user-server connection;unauthorized requests;cache;parallel search;hardware support;capability checking;iAPX432-based hosts;performance issues","","","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Hardware-Related Software Errors: Measurement and Analysis","R. K. Iyer; P. Velardi","Computer Systems Group at the Coordinated Science Laboratory and the Department of Electrical and Computer Engineering, University of Illinois; NA","IEEE Transactions on Software Engineering","","1985","SE-11","2","223","231","This paper describes an analysis of hardware-related software (HW/SW) errors on an MVS/SP operating system at Stanford University. The analysis procedure demonstrates a methodology for evaluating the interaction between hardware and software as it relates to system reliability. The paper examines the operating system's handling of HW/SW errors and also the effectiveness of recovery management. Nearly 35 percent of all observed software failures were found to be hareware-related. The analysis shows that the operating system is seldom able to diagnose that a software error may be hardware-related. The impact of HW/SW errors on the system is evaluated by measuring the effectiveness of system recovery in containing the propagation of HW/SW errors. The system failure probability for HW/SW errors is close to three times that for software errors in general. The observed HW/SW errors are seen to have a specific pattern, suggesting the possibility of the use of such error patterns for intelligent error prediction and recovery.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232198","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701991","Hardware/software interactions;recovery analysis;software reliability","Software measurement;Error analysis;Operating systems;Hardware;Computer errors;Military computing;Reliability;Software systems;Laboratories;System recovery","","Hardware/software interactions;recovery analysis;software reliability","","38","","16","","","","","","IEEE","IEEE Journals & Magazines"
"A Recursion Theoretic Approach to Program Testing","J. C. Cherniavsky; C. H. Smith","Department of Computer Science, Georgetown University, Washington, DC 20057 and the Institute for Computer Science and Technology, National Bureau of Standards; NA","IEEE Transactions on Software Engineering","","1987","SE-13","7","777","784","Inductive inference, the automatic synthesis of programs, bears certain ostensible relationships with program testing. For inductive inference, one must take a finite sample of the desired input/output behavior of some program and produce (synthesize) an equivalent program. In the testing paradigm, one seeks a finite sample for a function such that any program (in a given set) which computes something other than the object function differs from the object function on the finite sample. In both cases, the finite sample embodies sufficient knowledge to isolate the desired program from all other possibilities. These relationships are investigated and general recursion theoretic properties of testable sets of functions are exposed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233489","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702289","Inductive inference;program testing;recursion theory;white box testing","Computer science;NIST;Automatic testing;National security;Chemical technology;Computer languages","","Inductive inference;program testing;recursion theory;white box testing","","6","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Dependability Evaluation of Software Systems in Operation","J. Laprie","Laboratoire d'Automatique et d'Analyse des Systemes, 31400 Toulouse, France.","IEEE Transactions on Software Engineering","","1984","SE-10","6","701","714","This paper deals with evaluation of the dependability (considered as a generic term, whose main measures are reliability, availability, and maintainability) of software systems during their operational life, in contrast to most of the work performed up to now, devoted mainly to development and validation phases. The failure process due to design faults, and the behavior of a software system up to the first failure and during its life cycle are successively examined. An approximate model is derived which enables one to account for the failures due to the design faults in a simple way when evaluating a system's dependability. This model is then used for evaluating the dependability of 1) a software system tolerating design faults, and 2) a computing system with respect to physical and design faults.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010299","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010299","Design faults;Markov processes;software reliability;tolerance to design faults","Software systems;Physics computing;Process design;Terminology;Telecommunication computing;Humans;Software measurement;Software maintenance;Software design;Markov processes","","","","98","","49","","","","","","IEEE","IEEE Journals & Magazines"
"Some Results of the Earliest Deadline Scheduling Algorithm","H. Chetto; M. Chetto","Laboratoire d'Automatique de Nantes, U.A. au CNRS 823. ENSM 1. Rue de la Noe 44072 Nantes Cedex 03. France.; NA","IEEE Transactions on Software Engineering","","1989","15","10","1261","1269","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1989.559777","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=559777","","Scheduling algorithm;Processor scheduling;Real time systems;Control systems;Timing;Application software;Algorithm design and analysis;Fault tolerant systems;Software performance;System performance","","Deadline rnechanism;idle time;preemptive scheduling;real-time","","232","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Allocating Independent Subtasks on Parallel Processors","C. P. Kruskal; A. Weiss","Department of Computer Science, University of Illinois; NA","IEEE Transactions on Software Engineering","","1985","SE-11","10","1001","1016","When using MIMD (multiple instruction, multiple data) parallel computers, one is often confronted with solving a task composed of many independent subtasks where it is necessary to synchronize the processors after all the subtasks have been completed. This paper studies how the subtasks should be allocated to the processors in order to minimize the expected time it takes to finish all the subtasks (sometimes called the makespan). We assume that the running times of the subtasks are independent, identically distributed, increasing failure rate random variables, and that assigning one or more subtasks to a processor entails some overhead, or communication time, that is independent of the number of subtasks allocated. Our analyses, which use ideas from renewal theory, reliability theory, order statistics, and the theory of large deviations, are valid for a wide class of distributions. We show that allocating an equal number of subtasks to each processor all at once has good efficiency. This appears as a consequence of a rather general theorem which shows how some consequences of the central limit theorem hold even when we cannot prove that the central limit theorem applies.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231547","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701915","Parallel processing;performance analysis;queueing analysis;scheduling","Computer aided instruction;Concurrent computing;Random variables;Performance analysis;Finishing;Reliability theory;Statistical analysis;Statistical distributions;Queueing analysis;Processor scheduling","","Parallel processing;performance analysis;queueing analysis;scheduling","","174","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Constructing distributed systems in Conic","J. Magee; J. Kramer; M. Sloman","Dept. of Comput., Imperial Coll. of Sci. & Technol., London, UK; Dept. of Comput., Imperial Coll. of Sci. & Technol., London, UK; Dept. of Comput., Imperial Coll. of Sci. & Technol., London, UK","IEEE Transactions on Software Engineering","","1989","15","6","663","675","The Conic environment provides a language-based approach to the building of distributed systems which combines the simplicity and safety of a language approach with the flexibility and accessibility of an operating systems approach. It provides a comprehensive set of tools for program compilation, configuration, debugging, and execution in a distributed environment. A separate configuration language is used to specify the configuration of software components into logical nodes. This provides a concise configuration description and facilitates the reuse of program components in different configurations. Applications are constructed as sets of one or more interconnected logical nodes. Arbitrary, incremental change is supported by dynamic configuration. In addition, the system provides user-transparent datatype transformation between heterogeneous processors. Applications may be run on a mixed set of interconnected computers running the Unix operating system and on base target machines with no resident operating system. The basic principles adopted in the construction of the Conic environment are outlined and the configuration and run-time facilities provided are described.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24720","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24720","","LAN interconnection;Application software;Operating systems;Computer languages;Writing;Buildings;Safety;Debugging;Runtime environment;Dynamic programming","distributed processing;high level languages;operating systems (computers);programming;programming environments","distributed systems construction;Conic environment;language-based approach;operating systems approach;program compilation;distributed environment;configuration language;software components;concise configuration description;program components;interconnected logical nodes;incremental change;dynamic configuration;user-transparent datatype transformation;heterogeneous processors;interconnected computers;Unix operating system;base target machines;run-time facilities","","157","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Constructing the procedure call multigraph","D. Callahan; A. Carle; M. W. Hall; K. Kennedy","Dept. of Comput. Sci., Rice Univ., Houston, TX, USA; Dept. of Comput. Sci., Rice Univ., Houston, TX, USA; Dept. of Comput. Sci., Rice Univ., Houston, TX, USA; Dept. of Comput. Sci., Rice Univ., Houston, TX, USA","IEEE Transactions on Software Engineering","","1990","16","4","483","487","An algorithm for constructing a precise call multigraph for languages that permit procedure parameters, extending the method of B. Ryder (see ibid., vol.5, no.3, p.216-225 (1979)) for handling recursion, is presented. If it is assumed that there is a constant upper bound on the number of procedure parameters to any procedure in the program, then the algorithm is polynomial in the total number of procedures in the program.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.54302","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=54302","","Throughput;Delay;Databases;Concurrency control;Flow graphs;Information retrieval;Erbium;Etching;Upper bound","parallel programming","procedure call multigraph;algorithm;precise call multigraph;recursion;upper bound;polynomial","","14","","11","","","","","","IEEE","IEEE Journals & Magazines"
"The Determination of Loop Invariants for Programs with Arrays","H. A. Ellozy","Computer Sciences Department, IBM Thomas J. Watson Research Center","IEEE Transactions on Software Engineering","","1981","SE-7","2","197","206","This paper describes a method for the generation of loop predicates (or invariant assertions) for programs operating on arrays. The technique described is an application of difference equations.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234517","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702826","Difference equations;inductive assertions;invariant assertions;loop predicates;program validation","Input variables;Difference equations;Flowcharts;Terminology;Counting circuits;Control systems","","Difference equations;inductive assertions;invariant assertions;loop predicates;program validation","","4","","7","","","","","","IEEE","IEEE Journals & Magazines"
"Reflections on metaprogramming","A. H. Lee; J. L. Zachary","Dept. of Comput. Sci., Korea Univ., Seoul, South Korea; NA","IEEE Transactions on Software Engineering","","1995","21","11","883","893","By encapsulating aspects of language semantics within a set of default classes and allowing the programmer to derive new versions, object-oriented languages whose semantics can be tailored to the needs of individual programmers have been provided. The degree to which such languages are simultaneously flexible and efficient is an open question. We describe our experience with using this technique to incorporate transparent support for persistence into the Common Lisp Object System via its metaobject protocol, an open implementation based on reflection. For many aspects of our implementation the metaobject protocol was perfectly suitable. In other cases we had to choose between extending the protocol, requiring the application programmer to employ special idioms, and tolerating a large performance penalty. Based on our experience we evaluate the metaobject protocol, propose some improvements and extensions, and present performance measurements that reveal the need for improved language implementation techniques.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.473217","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=473217","","Reflection;Protocols;Programming profession;Computer science;Object oriented programming;Computer languages;Electronic switching systems;Design automation;Cities and towns","object-oriented languages;LISP;object-oriented programming;data encapsulation;software performance evaluation","metaprogramming;language semantics;encapsulation;default classes;object-oriented languages;persistence;Common Lisp Object System;metaobject protocol;reflection;performance penalty;performance measurements;object oriented programming","","5","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Theory of Modules","J. D. Gannon; R. G. Hamlet; H. D. Mills","Department of Computer Science and the Institute for Advanced Computer Studies, University of Maryland; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","7","820","829","Because large-scale software development is a struggle against internal program complexity, the modules into which programs are divided play a central role in software engineering. A module encapsulating a data type allows the programmer to ignore both the details of its operations, and of its value representations. It is a primary strength of program proving that as modules divide a program, making it easier to understand, so do they divide its proof. Each module can be verified in isolation, then its internal details ignored in a proof of its use. This paper describes proofs of module abstractions based on functional semantics, and contrasts this with the Alphard formalism based on Hoare logic.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233493","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702293","Abstract data types;functional semantics;modules;programming methodology;program specifications;program verification","Concrete;Programming profession;Computer science;Milling machines;Computer languages;Large-scale systems;Software engineering;Logic programming;Functional programming;Encapsulation","","Abstract data types;functional semantics;modules;programming methodology;program specifications;program verification","","16","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Formal methods reality check: industrial usage","D. Craigen; S. Gerhart; T. Ralston","ORA Canada, Ottawa, Ont., Canada; NA; NA","IEEE Transactions on Software Engineering","","1995","21","2","90","98","Based on a systematic survey and analysis of the use of formal methods in the development of a dozen industrial applications, we summarize the methods being used, characterize the styles of industrial usage, and provide recommendations for evolutionary enhancements to the technology base of formal methods. The industrial applications ranged from reverse engineering to system certification; code scale ranges from 1 KLOC to 10 KLOC's. Applications included a software infrastructure for oscilloscopes; a shutdown system for a nuclear generating station; a train protection system; an airline collision avoidance system; an engine monitoring system for shipboard engines; attitude control of satellites; security properties of both a smartcard device and a network; arithmetic units; transaction processing; a real-time database for a medical instrument; and a restructuring program for COBOL.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.345825","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=345825","","Application software;Engines;Electrical equipment industry;Reverse engineering;Certification;Oscilloscopes;Nuclear power generation;Protection;Collision avoidance;Biomedical monitoring","formal specification;program verification;real-time systems;manufacture","formal methods reality check;industrial usage;systematic survey;industrial applications;evolutionary enhancements;reverse engineering;system certification;code scale ranges;KLOC;software infrastructure","","44","","5","","","","","","IEEE","IEEE Journals & Magazines"
"A Formal Model for Software Project Management","Lung-chun Liu; E. Horowitz","Cadence Design Systems. Inc.. Santa Clara, CA 9S054.; NA","IEEE Transactions on Software Engineering","","1989","15","10","1280","1293","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1989.559781","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=559781","","Project management;Programming;Software tools;Virtual manufacturing;Software prototyping;Prototypes;Monitoring;Electric breakdown;Marine vehicles;Aggregates","","software development;software project management","","41","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Simplifld Alfu-N2merik FOnetiks (Sanf)","R. Sanford; J. Gibson","Department of Electrical and Computing Engineering, Clarkson College of Technology; NA","IEEE Transactions on Software Engineering","","1981","SE-7","2","241","248","A simplified alpha-numeric phonetic alphabet is proposed. It uses digits, standard keyboard symbols, and upper-and lowercase letters to give a computer-compatible unambiguous single-character phonetic writing of English. Such a phonetic spelling, in conjunction with a pronouncing dictionary giving standardized pronunciation of English words in this phonetic alphabet, together with appropriate computer compilers and speech synthesizers and recognition systems, would facilitate man-machine oral communication and expand the use of talking and listening computers. This phonetic text is considerably shorter than standard English, can be written on any typewriter or computer terminal, and is easily learned in a short time. Rules and characteristics of this language are given, and it is compared to other phonetic alphabets.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234521","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702830","Alphabet;ARPABET;man-machine communication;oral communication;phonetic alphabets;phonetics;speech recognition;speech synthesizers","Keyboards;Writing;Dictionaries;Speech synthesis;Synthesizers;Speech recognition;Man machine systems;Oral communication;Computer peripherals;Natural languages","","Alphabet;ARPABET;man-machine communication;oral communication;phonetic alphabets;phonetics;speech recognition;speech synthesizers","","","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Understanding Software Maintenance Work","S. Bendifallah","Department of Computer Science, University of Southern California","IEEE Transactions on Software Engineering","","1987","SE-13","3","311","323","Software maintenance can be successfully accomplished if the computing arrangements of the people doing the maintenance are compatible with their established patterns of work in the setting. To foster and achieve such compatibility requires an understanding of the reasons and the circumstances in which participants carry out maintenance activities. In particular, it requires an understanding of how software users and maintainers act toward the changing circumstances and unexpected events in their work situation that give rise to software system alterations. To contribute to such an understanding, we describe a comparative analysis of the work involved in maintaining and evolving text-processing systems in two academic computer science organizations. This analysis shows that how and why software systems are maintained depends on occupational and workplace contingencies, and vice versa.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233162","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702217","Articulation work;computing milieux;maintenance work;primary work;social analysis of computing;software evolution;software maintenance;software productivity;text-processing","Software maintenance;Software systems;Employment;Computer science;Costs;Distributed computing;Software tools;Productivity;Life estimation;Adaptive systems","","Articulation work;computing milieux;maintenance work;primary work;social analysis of computing;software evolution;software maintenance;software productivity;text-processing","","21","","41","","","","","","IEEE","IEEE Journals & Magazines"
"Data-oriented exception handling","Q. Cui; J. Gannon","McCabe & Associates, Columbia, MD, USA; NA","IEEE Transactions on Software Engineering","","1992","18","5","393","401","Exception handling mechanisms were added to programming languages to segregate normal algorithmic processing from error processing. However, handlers which are typically associated with exceptions through a program's control features, clutter source text when features are nested or when different objects require different responses to exceptions. The authors describe a method for associating handlers with data objects in declarations that better segregates algorithmic and error processing. They call their notion data-oriented exception handling to distinguish it from more conventional, control-oriented mechanisms. Empirical studies of Ada programs indicate that conventional exception handling mechanisms are more complex than necessary and that data-oriented exception handling can be used to produce programs that are smaller, better structured, and easier to understand and modify.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.135772","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=135772","","Signal processing;Computer languages;Software reliability;Condition monitoring;Joining processes;Process control;Computer science;Testing;Performance evaluation;Automatic programming","Ada;data structures;programming","programming languages;normal algorithmic processing;error processing;control features;source text;data objects;declarations;data-oriented exception handling;Ada programs","","15","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Modified rate-monotonic algorithm for scheduling periodic jobs with deferred deadlines","Wei Kuan Shih; J. W. S. Liu; C. L. Liu","Dept. of Comput. Sci., Illinois Univ., Urbana, IL, USA; Dept. of Comput. Sci., Illinois Univ., Urbana, IL, USA; Dept. of Comput. Sci., Illinois Univ., Urbana, IL, USA","IEEE Transactions on Software Engineering","","1993","19","12","1171","1179","The deadline of a request is the time instant at which its execution must complete. The deadline of the request in any period of a job with deferred deadline is some time instant after the end of the period. The authors describe a semi-static priority-driven algorithm for scheduling periodic jobs with deferred deadlines: each job is assigned two priorities, the higher one for old requests and the lower one for the current request. This algorithm is called the modified rate-monotonic algorithm and is based on the well-known rate-monotonic algorithm. It is shown that the modified rate-monotonic algorithm is optimal when the deadline of every job is deferred by max (1, gamma -1) periods or more, where gamma is the ratio between the longest period and the shortest period. When the deadline of each job is deferred by one period of the job, any set of n independent jobs whose total utilization is equal to or less than (1+n(2/sup 1/n/-1))/2 can be feasibly scheduled by this algorithm. This bound approaches 0.845 when n approaches infinity.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.249662","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=249662","","Scheduling algorithm;Processor scheduling;Real time systems;H infinity control;Operating systems;Aerospace control;Computer science","computational complexity;multiprogramming;operating systems (computers);real-time systems;scheduling","modified rate-monotonic algorithm;periodic jobs;deferred deadlines;semi-static priority-driven algorithm;time instant;old requests;current request;independent jobs;feasibly scheduled;job scheduling;request deadline;deterministic scheduling theory;embedded systems;operating system;real-time systems;scheduling algorithms","","21","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Semantic feedback in the Higgens UIMS","S. E. Hudson; R. King","Dept. of Comput. Sci., Arizona Univ., Tucson, AZ, USA; NA","IEEE Transactions on Software Engineering","","1988","14","8","1188","1206","Almost all applications using interactive graphics contain important structures and concepts which are deeper than the geometres used to display them to the user. One of the major tasks of the system implementer is to cause the user interface to reflect this deeper structure accurately so that it may be directly manipulated by the user. The authors describe a tool, the Higgens user interface management system (UIMS), which can automate much of this task for a wide class of systems using interactive graphics. It is able to generate graphical user interfaces automatically from a high-level interface specification. These specifications are primarily nonprocedural in nature. They describe how graphical images can be automatically derived and updated based on applications entities, and how graphical inputs can be translated back into terms which are appropriate to the application.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.7628","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=7628","","Feedback;User interfaces;Computer graphics;Application software;Computer interfaces;Displays;Graphical user interfaces;Face;Computer science;Image converters","automatic programming;computer graphics;interactive programming;software tools;user interfaces","semantic feedback;automatic programming;software tools;Higgens UIMS;interactive graphics;user interface;user interface management system;high-level interface specification;graphical images;applications entities","","9","","35","","","","","","IEEE","IEEE Journals & Magazines"
"Gray codes for partial match and range queries","C. Faloutsos","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA","IEEE Transactions on Software Engineering","","1988","14","10","1381","1393","It is suggested that Gray codes be used to improve the performance of methods for partial match and range queries. Specifically, the author illustrates the improved clustering of similar records that Gray codes can achieve with multiattribute hashing. Gray codes are used instead of binary codes to map record signatures to buckets. In Gray codes, successive codewords differ in the value of exactly one bit position; thus, successive buckets hold records with similar record signatures. The proposed method achieves better clustering of similar records, thus reducing the I/O time. A mathematical model is developed to derive formulas giving the average performance of both methods, and it is shown that the proposed method achieves 0-50% relative savings over the binary codes. The author also discusses how Gray codes could be applied to some retrieval methods designed for range queries, such as the grid file and the approach based on the so-called z-ordering. Gray codes are also used to design good distance-preserving functions, which map a k-dimensional (k-D) space into a one-dimensional one, in such a way that points are close in the k-D space are likely to be close in the 1-D space.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6184","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6184","","Reflective binary codes;Binary codes;Design automation;Mathematical model;Design methodology;Fractals;Frequency;Artificial intelligence;Computer science;Multidimensional systems","database theory;file organisation","partial match;range queries;Gray codes;multiattribute hashing;record signatures;buckets;I/O time;mathematical model;retrieval methods;grid file;distance-preserving functions","","67","","32","","","","","","IEEE","IEEE Journals & Magazines"
"Knowledge Representation of Software Component Interconnection Information for Large-Scale Software Modifications","S. S. Yau; J. J. Tsai","Department of Electrical Engineering and Computer Science, Northwestern University; NA","IEEE Transactions on Software Engineering","","1987","SE-13","3","355","361","Logic can be used to precisely express human thoughts and inferences. In this paper, an approach using first-order logic for knowledge representation of software component interconnection information to facilitate the validity and integrity checking of the interconnection among software components during software development or modification is presented. Directed graphs are first used to model the structure and behavior of a large-scale software system, and a first-order theory of directed graphs (the DG theory) is established. The interconnection behavior among software components in a large-scale software system is a directed graph which is called software component interconnection graph (CIG). The behavior of the CIG is interpreted using the DG theory and translated into logic representation. The translated logic representation is a set of logic clauses and can be considered as a set of axioms. Automated reasoning techniques based on these axioms can be used to perform the validity and integrity checking of software properties in the software development or maintenance phase.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233166","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702221","Automated reasoning;first-order logic;integrity checking;software component interconnection;software development and maintenance;software' modification;validity checks","Knowledge representation;Large-scale systems;Logic;Software systems;Software maintenance;LAN interconnection;Programming;Software performance;Vocabulary;Humans","","Automated reasoning;first-order logic;integrity checking;software component interconnection;software development and maintenance;software' modification;validity checks","","7","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Trie hashing with controlled load","W. A. Litwin; N. Roussopoulos; G. Levy; W. Hong","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; NA; NA","IEEE Transactions on Software Engineering","","1991","17","7","678","691","Trie hashing (TH), a primary key access method for storing and accessing records of dynamic files, is discussed. The key address is computed through a trie. A key search usually requires only one disk access when the trie is in core and two disk accesses for very large files when the trie must be on disk. A refinement to trie hashing, trie hashing with controlled load (THCL), is presented. It is designed to control the load factor of a TH file as tightly as that of a B-tree file, allows high load factor of up to 100% for ordered insertions, and increases the load factor for random insertions from 70% to over 85%. It is shown that these properties make trie hashing preferable to a B-tree.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.83904","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=83904","","Military computing;Computer science;Tree data structures;Protocols;Predictive models;Databases","file organisation;information retrieval systems;trees (mathematics)","primary key access method;dynamic files;key search;disk access;trie hashing;controlled load;THCL;load factor;TH file;B-tree file;high load factor;ordered insertions;load factor;random insertions","","5","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Implementing Language Support in High-Level Languages","M. S. McKendry; R. H. Campbell","School of Information and Computer Science, Georgia Institute of Technology, Atlanta, GA 30332.; Department of Computer Science, University of Illinois, Urbana, IL 61801.","IEEE Transactions on Software Engineering","","1984","SE-10","3","227","236","One of the requirements for building an operating system in a high-level operating system language, such as Ada, Concurrent Pascal, or Modula, is the construction of a language support system, or kernel. This paper presents a model that generalizes the concept of a kernel, and defines a kernel and the processes it supports to be at different levels of abstraction. A high-level language mechanism, the Execute statement, is then proposed as the basis of the interface between a kernel and the processes it supports. Software capabilities control access between levels and the Execute statement controls processor context switching between levels. The mechanisms rely on data typing for reliability and protection. They encourage systems that are well protected and exhibit an explicit hierarchical structure. Software capabilities and the Execute statement are illustrated with a pilot implementation on the Prime 650. An experimental operating system that encompasses their use is discussed. Extensions are presented which manage interrupts, timeslicing and preemption, and hardware protection mechanisms.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010231","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010231","Capabilities;context switching;high-level languages;operating systems;Pascal;run-time kernel","High level languages;Operating systems;Kernel;Protection;Concurrent computing;Hardware;Assembly systems;Runtime environment;Buildings;Modular construction","","","","3","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Bidding against competitors","C. -. Chang","Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA","IEEE Transactions on Software Engineering","","1990","16","1","100","104","Consideration is given to a system of n competitors, where if a competitor selects its bids equally likely from a given set of bid values, its probability of winning is guaranteed to be 1/n, regardless of the bid values selected by other competitors in the system. A discussion is presented of several variations of this basic scheme, namely, bidding with unequal weights, bidding with more than one winner, and bidding with an unknown number of competitors. Two economical, but approximate, bidding schemes are discussed. In the first scheme, the competitors select their bids from a set with a constant size, and in the second, each competitor selects only one bid even though the total number of competitors is not known a priori. It is shown how to use these bidding schemes to construct solutions to several problems in distributed systems, including the mutual exclusion problem and the dining philosophers problem.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44368","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44368","","Distributed computing;Random number generation;Centralized control;Control systems;Protection","distributed processing;probability;software engineering","software engineering;probability of winning;bidding;mutual exclusion problem","","","","13","","","","","","IEEE","IEEE Journals & Magazines"
"A Queuing Model of a Time-Sliced Priority-Driven Task Dispatching Algorithm","P. S. Kritzinger; A. E. Krzesinski; P. Teunissen","Department of Computer Science, University of Stellenbosch; NA; NA","IEEE Transactions on Software Engineering","","1980","SE-6","2","219","225","A queuing analysis of a preemptive, priority-driven, time-sliced dispatcher algorithm, typical of those found in many time-sharing systems, is presented. A distinctive feature of the system being modeled is that a preempted task, when readmitted to the dispatcher, is reallocated a full time slice rather than the residual. The combination of preemption, time-slice renewal and class-dependent arrival and service rates places the analysis beyond that of the well-known FBN algorithms. The model is used to predict the behavior of the dispatcher algorithm under various workloads. The model reveals that, at high arrival rates, the time-slice renewal policy prevents processor bound tasks from being relegated to the lower priority queues, thereby severely degrading the throughput of tasks with short processor requirements.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230472","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702718","Computer performance modeling;dispatcher algorithms;multilevel feedback queue;priority preemption;time slicing","Dispatching;Time sharing computer systems;Operating systems;Feedback;Throughput;Control systems;Delay;Queueing analysis;Algorithm design and analysis;Predictive models","","Computer performance modeling;dispatcher algorithms;multilevel feedback queue;priority preemption;time slicing","","1","","6","","","","","","IEEE","IEEE Journals & Magazines"
"Algebraic Specifications as Solutions of Implementation Equations","N. Y. Foo","Department of Computer Science, University of Sydney","IEEE Transactions on Software Engineering","","1987","SE-13","12","1364","1369","Algebraic specifications for datatypes are shown to be easy to write if succinct implementation descriptions are available. The method proposed solves out the implementation details, leaving behind the specification required. A number of examples illustrate the method. However it is also shown that in general the solution is not algorithmic. A connection to the correctness problem for implementations is made.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233146","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702185","Abstraction;algebraic specification;datatype;implementation correctness;unification","Equations;Writing;Software reliability;Algebra;Programming profession;Concrete;Data structures;Mathematical model;Computer science","","Abstraction;algebraic specification;datatype;implementation correctness;unification","","","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Properties of control-flow complexity measures","K. B. Lakshmanan; S. Jayaprakash; P. K. Sinha","Dept. of Comput. Sci., State Univ. of New York, Brockport, NY, USA; NA; NA","IEEE Transactions on Software Engineering","","1991","17","12","1289","1295","The authors attempt to formalize some properties which any reasonable control-flow complexity measure must satisfy. Since large programs are often built by sequencing and nesting of simpler constructs, the authors explore how control-flow complexity measures behave under such compositions. They analyze five existing control flow complexity measures-cyclomatic number, total adjusted complexity, scope ratio, MEBOW, and NPATH. The analysis reveals the strengths and weaknesses of these control flow complexity measures.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.106989","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=106989","","Fluid flow measurement;Software maintenance;Size measurement;Computer science;Flow graphs;Software metrics;Phase measurement;Software measurement;Software testing;Size control","programming theory;software metrics","control-flow complexity measure;sequencing;nesting;cyclomatic number;total adjusted complexity;scope ratio;MEBOW;NPATH","","29","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Managing and Predicting the Costs of Real-Time Software","R. D. H. Warburton","JAYCOR","IEEE Transactions on Software Engineering","","1983","SE-9","5","562","569","The Putnam model can be used to predict and manage software development projects. It is a management tool that takes, as input, easily obtained manpower data and produces cost and schedule estimates. This paper examines data from two real-time software projects and analyzes the applicability of the Putnam model. We propose a variation ation of the model which more reliably follows the staffing curve of real-time software applications. A critical analysis of the assumptions is presented and the parameters are reinterpreted so that they reflect the environment of embedded applications. Two projects are analyzed from actual data. It is shown how management decisions are reflected in the model. Even erratic and incomplete data can yield valuable conclusions. It is also shown that the model is appropriate to software developed with modern practices. We show how valuable management information can be obtained by laying out the data in a systematic manner.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.235115","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703096","Cost prediction;Putnam model;Rayleigh curve;realtime time software;software management","Costs;Predictive models;Application software;Scheduling;Project management;Programming;Testing;Software development management;Data analysis;Information management","","Cost prediction;Putnam model;Rayleigh curve;realtime time software;software management","","6","","","","","","","","IEEE","IEEE Journals & Magazines"
"Managing Software Development Projects for Maximum Productivity","N. R. Howes","Brown &amp; Root, Inc., P. O. Box 3, Houston, TX 77001.","IEEE Transactions on Software Engineering","","1984","SE-10","1","27","35","In the area of software development, data processing management often focuses more on coding techniques and system architecture than on how to manage the development. In recent years, ``structured programming'' and ``structured analysis'' have received more attention than the techniques software managers employ to manage. Moreover, these coding and architectural considerations are often advanced as the key to a smooth running, well managed project. This paper documents a philosophy for software development and the tools used to support it. Those management techniques deal with quantifying such abstract terms as ``productivity,'' ``performance,'' and ``progress,'' and with measuring these quantities and applying management controls to maximize them. The paper also documents the application of these techniques on a major software development effort.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010195","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010195","Performance evaluation;productivity analysis;progress measurement;software development methodologies;work breakdown structure","Project management;Software development management;Programming;Productivity;Job design;Packaging;Software performance;Software measurement;Engineering management;Automatic testing","","","","8","","3","","","","","","IEEE","IEEE Journals & Magazines"
"A general framework for concurrent simulation on neural network models","G. L. Heileman; M. Georgiopoulos; W. D. Roome","Dept. of Electr. & Comput. Eng., New Mexico Univ., Albuquerque, NM, USA; NA; NA","IEEE Transactions on Software Engineering","","1992","18","7","551","562","The analysis of complex neural network models via analytical techniques is often quite difficult due to the large numbers of components involved and the nonlinearities associated with these components. The authors present a framework for simulating neural networks as discrete event nonlinear dynamical systems. This includes neural network models whose components are described by continuous-time differential equations or by discrete-time difference equations. Specifically, the authors consider the design and construction of a concurrent object-oriented discrete event simulation environment for neural networks. The use of an object-oriented language provides the data abstraction facilities necessary to support modification and extension of the simulation system at a high level of abstraction. Furthermore, the ability to specify concurrent processing supports execution on parallel architectures. The use of this system is demonstrated by simulating a specific neural network model on a general-purpose parallel computer.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.148474","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=148474","","Neural networks;Object oriented modeling;Discrete event simulation;Computational modeling;Analytical models;Nonlinear dynamical systems;Differential equations;Difference equations;Parallel architectures;Computer simulation","data structures;discrete event simulation;neural nets;object-oriented programming;parallel languages","concurrent simulation;neural network models;nonlinearities;discrete event nonlinear dynamical systems;continuous-time differential equations;discrete-time difference equations;concurrent object-oriented discrete event simulation;object-oriented language;data abstraction;parallel architectures;general-purpose parallel computer","","10","","28","","","","","","IEEE","IEEE Journals & Magazines"
"A fault-tolerant scheduling problem","A. L. Liestman; R. H. Campbell","School of Computing Science, Simon Fraser University, Burnaby, B.C., Canada V5A 1S6; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL 61801","IEEE Transactions on Software Engineering","","1986","SE-12","11","1089","1095","A real-time system must be reliable if a failure to meet its timing specifications might endanger human life, damage equipment, or waste expensive resources. A deadline mechanism has been previously proposed to provide fault tolerance in real-time software systems. The mechanism trades the accuracy of the results of a service for timing precision. Two independent algorithms are provided for each service subject to a deadline. The primary algorithm produces a good quality service, although its real-time reliability may not be assured. The alternate algorithm is reliable and produces an acceptable response. An algorithm to generate an optimal schedule for the deadline mechanism is introduced, and a simple and efficient implementation is discussed. The schedule ensures the timely completion of the alternate algorithm despite a failure to complete the primary algorithm within real time.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312999","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312999","Real-time systems;scheduling;software fault tolerance;software reliability","Schedules;Real-time systems;Heuristic algorithms;Timing;Vegetation;Protocols;Software algorithms","fault tolerant computing;real-time systems;scheduling;software engineering","fault-tolerant scheduling problem;real-time system;timing specifications;deadline mechanism;timing precision","","68","","","","","","","","IEEE","IEEE Journals & Magazines"
"Representation and presentation of requirements knowledge","W. L. Johnson; M. S. Feather; D. R. Harris","Inf. Sci. Inst., Univ. of Southern California, Marina del Rey, CA, USA; Inf. Sci. Inst., Univ. of Southern California, Marina del Rey, CA, USA; NA","IEEE Transactions on Software Engineering","","1992","18","10","853","869","The approach to representation and presentation of knowledge used in ARIES, an environment to experiment with support for analysts in modeling target domains and in entering and formalizing system requirements, is described. To effectively do this, ARIES must manage a variety of notations so that analysts can enter information in a natural manner, and ARIES can present it back in different notations and from different viewpoints. To provide this functionality, a single, highly expressive internal representation is used for all information in the system. The system architecture separates representation and presentation, in order to localize consistency and propagation issues. The presentation architecture is tailored to be flexible enough so that new notations can be easily introduced on top of the underlying representation. Presentation knowledge is coupled to specification evolution knowledge thereby leveraging common representations for both in order to provide automated focusing support to users who need informative guidance in creating and modifying specifications.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.163603","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=163603","","Feathers;Information analysis;Software engineering;Formal specifications;System testing;US Government;Signal processing;Marine technology;Knowledge representation","formal specification;knowledge based systems;knowledge representation;software reusability","requirements knowledge;representation;presentation;ARIES;target domains;formalizing system requirements;system architecture;consistency;propagation;evolution knowledge;automated focusing support;specifications","","52","","43","","","","","","IEEE","IEEE Journals & Magazines"
"Direct Implementation of Algebraic Specification of Abstract Data Types","A. Moitra","National Centre for Software Development and Computing Techniques, Tata Institute of Fundamental Research","IEEE Transactions on Software Engineering","","1982","SE-8","1","12","20","Algebraic specification is now an established way of formally defining abstract data types. For its practical use, however, a segment of program which conforms with the specification has to be generated. Such program segments can be manually produced and must then be verified. Code generation can also be automated, as achieved by the ""direct implementation"" in [8] where any data type is treated as if its functions produce, manipulate, and access tree structures. We extend these results by formalizing the choice of the appropriate data type (e.g., a tree structure) required to ""implement"" any given data type. This allows us to consider the formal implementation of a data type in terms of a concrete model.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.234770","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702901","Abstract data types;algebraic specification;automatic implementation;concrete model;rewriting rules","Tree data structures;Concrete;Algebra;Programming;Computer languages","","Abstract data types;algebraic specification;automatic implementation;concrete model;rewriting rules","","3","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Efficient distributed detection of conjunctions of local predicates","M. Hurfin; M. Mizuno; M. Raynal; M. Singhal","IRISA, Rennes, France; NA; NA; NA","IEEE Transactions on Software Engineering","","1998","24","8","664","677","Global predicate detection is a fundamental problem in distributed systems and finds applications in many domains such as testing and debugging distributed programs. This paper presents an efficient distributed algorithm to detect conjunctive-form global predicates in distributed systems. The algorithm detects the first consistent global state that satisfies the predicate even if the predicate is unstable. Unlike previously proposed run-time predicate detection algorithms, our algorithm does not require the exchange of control messages during the normal computation. All the necessary information to detect predicates is piggybacked on computation messages of application programs. The algorithm is distributed because the predicate detection efforts as well as the necessary information are equally distributed among the processes. We prove the correctness of the algorithm and compare its performance with respect to message, storage and computational complexities with that of the previously proposed run-time predicate detection algorithms.","0098-5589;1939-3520;2326-3881","","10.1109/32.707701","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=707701","","Distributed computing;Lattices;Detection algorithms;Runtime;Computer Society;Application software;System testing;Debugging;Distributed algorithms;Computer applications","distributed algorithms;computational complexity;program testing;program debugging;software engineering","distributed systems;local predicate conjunctions;conjunctive-form global predicate detection;distributed program testing;distributed program debugging;distributed algorithm;consistent global state;application program computation messages;piggybacked data;algorithm correctness;algorithm performance;message complexity;storage complexity;computational complexity;run-time predicate detection algorithms;on-the-fly global predicate detection","","19","","20","","","","","","IEEE","IEEE Journals & Magazines"
"The domain theory for requirements engineering","A. Sutcliffe; N. Maiden","Sch. of Inf., City Univ., London, UK; NA","IEEE Transactions on Software Engineering","","1998","24","3","174","196","Retrieval, validation, and explanation tools are described for cooperative assistance during requirements engineering and are illustrated by a library system case study. Generic models of applications are reused as templates for modeling and critiquing requirements for new applications. The validation tools depend on a matching process which takes facts describing a new application and retrieves the appropriate generic model from the system library. The algorithms of the matcher, which implement a computational theory of analogical structure matching, are described. A theory of domain knowledge is proposed to define the semantics and composition of generic domain models in the context of requirements engineering. A modeling language and a library of models arranged in families of classes are described. The models represent the basic transaction processing or 'use case' for a class of applications. Critical difference rules are given to distinguish between families and hierarchical levels. Related work and future directions of the domain theory are discussed.","0098-5589;1939-3520;2326-3881","","10.1109/32.667878","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=667878","","Libraries;Application software;Software engineering;Knowledge engineering;Context modeling;Software tools;Computer aided software engineering;Software design;Design engineering;Buildings","formal specification;software reusability;computer aided software engineering;software tools;case-based reasoning;transaction processing","domain theory;requirements engineering;explanation tools;validation tools;retrieval tools;cooperative assistance;library system;generic application models;templates;critiquing requirements;modeling requirements;matching process;matcher algorithms;computational theory;analogical structure matching;semantics;modeling language;transaction processing;difference rules;hierarchical level;families","","47","","72","","","","","","IEEE","IEEE Journals & Magazines"
"SPD: A Humanized Documentation Technology","M. Azuma; T. Tabata; Y. Oki; S. Kamiya","NEC Corporation; NA; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","9","945","953","The SPD (Structured Programming Diagram) is a documentation technology used to design well structured programs. With SPD, designers can easily express functional structure, control structure, and physical layout of a program on one sheet of paper. Its straightforward expression appeals to both document writers and readers. SPD concept and conventions are introduced in this paper. SPD usage is then explained with a program design example. Other documentation technologies used in coordination with SPD are briefly touched upon. Finally, SPD reputation and evolution in the last ten years are reviewed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232828","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702113","Documentation;software development;Structured Programming Design","Documentation;Switches;Error correction;Programming;Productivity;Communication switching;Investments;National electric code;Software engineering;Research and development","","Documentation;software development;Structured Programming Design","","3","","26","","","","","","IEEE","IEEE Journals & Magazines"
"A high level language-based computing environment to support production and execution of reliable programs","H. Tsubotani; N. Monden; M. Tanaka; T. Ichikawa","Hiroshima University, Shitami, Saijo-cho, Higashi-Hiroshima 724, Japan; Hiroshima University, Shitami, Saijo-cho, Higashi-Hiroshima 724, Japan; Hiroshima University, Shitami, Saijo-cho, Higashi-Hiroshima 724, Japan; Hiroshima University, Shitami, Saijo-cho, Higashi-Hiroshima 724, Japan","IEEE Transactions on Software Engineering","","1986","SE-12","1","134","146","The authors present an environment which involves a debugging tool to aid in the detection and removal at logic errors. The debugging tool is supported by a special architecture, named SPRING, which was originally developed for reliable execution of Ada or Pascal programs. Following an overview of the system backed up by SPRING, the details of SPRING architecture are described, and the implementation of high level debugging on the SPRING architecture is discussed. In conclusion, the trial could be seen as a step toward providing an advanced programming environment for the development of reliable software.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312927","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312927","Ada;debugging;high level language architecture;programming language;software reliability","Springs;Debugging;Software reliability;Computer architecture;Software;Runtime","program debugging;programming environments;software reliability","computing environment;production;execution;reliable programs;debugging tool;logic errors;SPRING;SPRING architecture;high level debugging;programming environment","","1","","","","","","","","IEEE","IEEE Journals & Magazines"
"Block access estimation for clustered data using a finite LRU buffer","F. Grandi; M. R. Scalas","Dipartimento di Elettron. Inf. e Sistemistica, Bologna Univ., Italy; Dipartimento di Elettron. Inf. e Sistemistica, Bologna Univ., Italy","IEEE Transactions on Software Engineering","","1993","19","7","641","660","Data access cost evaluation is fundamental in the design and management of database systems. When some data items have duplicates, a clustering effect that can heavily influence access costs is observed. The availability of a finite amount of buffer memory in real systems has an even more dramatic impact. A comprehensive cost model for clustered data retrieval by an index using a finite buffer is presented. The approach combines and extends previous models based either on finite buffer or on uniform data clustering assumptions. The computational costs of the formulas proposed are independent of the data size or of the query cardinality and need only a single statistics per search key, the clustering factor, to be maintained by the system. The predictive power and the accuracy of the model are shown in comparison with actual costs resulting from simulations.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.238566","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=238566","","Costs;Relational databases;Database systems;Information retrieval;Predictive models;Indexes;Query processing;State estimation;Computational efficiency;Statistics","buffer storage;database management systems;information retrieval systems;query processing","block access estimation;data access cost evaluation;clustered data;finite LRU buffer;database systems;clustering effect;buffer memory;real systems;comprehensive cost model;clustered data retrieval;uniform data clustering assumptions;computational costs;predictive power","","4","","21","","","","","","IEEE","IEEE Journals & Magazines"
"A Concurrent General Purpose Operator Interface","N. B. Corrigan; J. D. Starkey","Department of Computer Science, Washington State University, Pullman, WA 99164.; Westinghouse Hanford Company, Richland, WA 99352.; Department of Computer Science, Washington State University, Pullman, WA 99164.; Department of Computer Science, Montana State University, Bozeman, MT 59717.","IEEE Transactions on Software Engineering","","1984","SE-10","6","738","748","Compact interactive control consoles are rephcing traditional control rooms as operator interfaces for physical processes. In the irust major application of concurrent programming outside the area of operating systems, this paper presents a design for a general purpose operator interface which uses a color graphics terminal with a touch-sensitive screen as the control console. Operators interact with a process through a collection of application-dependent displays generated interactively by users familiar with the physical process. The use of concurrent programming results in a straightforward and reliable design which may easily be extended to support multiple devices of varying types in the control console. An implementation of the Operator Interface in Concurrent Pascal currently in progress is also discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010302","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010302","Computer graphics;Concurrent Pascal;concurrent programming;interactive system;man-machine interface;operator interface;process control","Graphics;Control systems;Process control;Color;Computer interfaces;Computer science;Computer displays;Application software;Keyboards;Interactive systems","","","","1","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Reusing software: issues and research directions","H. Mili; F. Mili; A. Mili","Dept. d'Inf., Quebec Univ., Montreal, Que., Canada; NA; NA","IEEE Transactions on Software Engineering","","1995","21","6","528","562","Software productivity has been steadily increasing over the past 30 years, but not enough to close the gap between the demands placed on the software industry and what the state of the practice can deliver; nothing short of an order of magnitude increase in productivity will extricate the software industry from its perennial crisis. Several decades of intensive research in software engineering and artificial intelligence left few alternatives but software reuse as the (only) realistic approach to bring about the gains of productivity and quality that the software industry needs. In this paper, we discuss the implications of reuse on the production, with an emphasis on the technical challenges. Software reuse involves building software that is reusable by design and building with reusable software. Software reuse includes reusing both the products of previous software projects and the processes deployed to produce them, leading to a wide spectrum of reuse approaches, from the building blocks (reusing products) approach, on one hand, to the generative or reusable processor (reusing processes), on the other. We discuss the implication of such approaches on the organization, control, and method of software development and discuss proposed models for their economic analysis. Software reuse benefits from methodologies and tools to: (1) build more readily reusable software and (2) locate, evaluate, and tailor reusable software, the last being critical for the building blocks approach. Both sets of issues are discussed in this paper, with a focus on application generators and OO development for the first and a thorough discussion of retrieval techniques for software components, component composition (or bottom-up design), and transformational systems for the second. We conclude by highlighting areas that, in our opinion, are worthy of further investigation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.391379","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=391379","","Software reusability;Productivity;Computer industry;Software tools;Software quality;Buildings;Software engineering;Artificial intelligence;Production;Programming","software reusability;object-oriented programming","software productivity;software engineering;technical challenges;reusable software;building blocks approach;reusable processor;managerial aspects;software reuse measurements;software component retrieval;reusable components","","233","","163","","","","","","IEEE","IEEE Journals & Magazines"
"Capacity of voting systems","S. Rangarajan; P. Jalote; S. K. Tripathi","Dept. of Electr. & Comput. Eng., Northeastern Univ., Boston, MA, USA; NA; NA","IEEE Transactions on Software Engineering","","1993","19","7","698","706","Data replication is often used to increase the availability of data in a database system. Voting schemes can be used to manage this replicated data. The authors use a simple model to study the capacity of systems using voting schemes for data management. Capacity of a system is defined as the number of operations the system can perform successfully, on an average, per unit time. The capacity of a system using voting is examined and compared with the capacity of a system using a single node. It is shown that the maximum increase in capacity by the use of majority voting is bounded by 1/p, where p is the steady-state probability of a node being alive. It is also shown that for a system employing majority voting, if the reliability of nodes is high, increasing the number of nodes to more than three gives only a marginal increase in capacity. Similar analyses are performed for three other voting schemes.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.238570","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=238570","","Voting;Computer science;Database systems;Capacity planning;Steady-state;Performance analysis;Scalability;Availability;Military computing","database theory;distributed databases;probability","data replication;voting systems;database system;replicated data;data management;majority voting;steady-state probability;reliability","","6","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Expert Systems and the ""Myth"" of Symbolic Reasoning","J. Doyle","Department of Computer Science, Carnegie-Mellon University","IEEE Transactions on Software Engineering","","1985","SE-11","11","1386","1390","Elements of the artificial intelligence approach to expert systems offer great productivity advantages over traditional approaches to application systems development, even though the end result may be a program employing no AI techniques. These productivity advantages are the hidden truths behind the ""myth"" that symbolic reasoning programs are better than ordinary ones.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231886","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701954","Automatic programming;expert systems;Lisp;programmer productivity;Prolog;prototypes;specifications;symbolic reasoning","Expert systems;Productivity;Artificial intelligence;Prototypes;Computer science;Application software;Automatic programming;Biographies;Programming profession;Computerized monitoring","","Automatic programming;expert systems;Lisp;programmer productivity;Prolog;prototypes;specifications;symbolic reasoning","","7","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Theory-W software project management principles and examples","B. W. Boehm; R. Ross","Dept. of Comput. Sci., California Univ., Los Angeles, CA, USA; Dept. of Comput. Sci., California Univ., Los Angeles, CA, USA","IEEE Transactions on Software Engineering","","1989","15","7","902","916","A software project management theory is presented called Theory W: make everyone a winner. The authors explain the key steps and guidelines underlying the Theory W statement and its two subsidiary principles: plan the flight and fly the plan; and, identify and manage your risks. Theory W's fundamental principle holds that software project managers will be fully successful if and only if they make winners of all the other participants in the software process: superiors, subordinates, customers, users, maintainers, etc. Theory W characterizes a manager's primary role as a negotiator between his various constituencies, and a packager of project solutions with win conditions for all parties. Beyond this, the manager is also a goal-setter, a monitor of progress towards goals, and an activist in seeking out day-to-day win-lose or lose-lose project conflicts confronting them, and changing them into win-win situations. Several examples illustrate the application of Theory W. An extensive case study is presented and analyzed: the attempt to introduce new information systems to a large industrial corporation in an emerging nation. The analysis shows that Theory W and its subsidiary principles do an effective job both in explaining why the project encountered problems, and in prescribing ways in which the problems could have been avoided.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.29489","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=29489","","Project management;Software maintenance;Software development management;Programming;Computer science;Guidelines;Risk management;Application software;Information analysis;Management information systems","project engineering;software engineering","Theory-W software project management;case study;information systems","","186","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Notes on Type Abstraction (Version 2)","J. Guttag","Laboratory for Computer Science, Massachusetts Institute of Technology","IEEE Transactions on Software Engineering","","1980","SE-6","1","13","23","This paper, which was initially prepared to accompany a series of lectures given at the 1978 NATO International Summer School on Program Construction, is primarily tutorial in nature. It begins by discussing in a general setting the role of type abstraction and the need for formal specifications of type abstractions. It then proceeds to examine in some detail two approaches to the construction of such specifications: that proposed by Hoare in his 1972 paper ""Proofs of Correctness of Data Representations,"" and the author's own version of algebraic specifications. The Hoare approach is presented via a discussion of its embodiment in the programming language Euclid. The discussion of the algebraic approach includes material abstracted from earlier papers as well as some new material that has yet to appear. This new material deals with parameterized types and the specification of restrictions. The paper concludes with a brief discussion of the relative merits of the two approaches to type abstraction.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230209","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702690","Abstract data types;abstraction;algebraic axioms;program verification;proof rules","Algorithms;Computer languages;Formal specifications;Computerized monitoring;Computer science;Programming profession","","Abstract data types;abstraction;algebraic axioms;program verification;proof rules","","46","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Formal Specification of User Interfaces: A Comparison and Evaluation of Four Axiomatic Approaches","U. H. Chi","Department of Computer Science, University of Washington","IEEE Transactions on Software Engineering","","1985","SE-11","8","671","685","Few examples of formal specification of the semantics of user interfaces exist in the literature. This paper presents a comparison of four axiomatic approaches which we have applied to the specification of a commercial user interfacethe line editor for the Tandy PC-1 Pocket Computer. These techniques are shown to result in complete and relatively concise descriptions. A number of useful and nontrivial properties of the interface are formally deduced from one of the specifications. In addition, a direct implementation of the interface is constructed from a formal specification. Limitations of these specification examples are discussed along with future research work.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232517","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702077","Algebraic specifications;formal specifications;formal verification;set-theoretic specifications;software design;specification implementation;user interfaces","Formal specifications;User interfaces;Computer interfaces;Costs;Formal verification;Software design;Buildings;Computer science;Hardware;Protocols","","Algebraic specifications;formal specifications;formal verification;set-theoretic specifications;software design;specification implementation;user interfaces","","9","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Scheduling Tasks with Resource Requirements in Hard Real-Time Systems","Wei Zhao; K. Ramamritham; J. A. Stankovic","Department of Computer and Information Science, University of Massachusetts; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","5","564","577","This paper describes a heuristic approach for solving the problem of dynamically scheduling tasks in a real-time system where tasks have deadlines and general resource requirements. The crux of our approach lies in the heuristic function used to select the task to be scheduled next. The heuristic function is composed of three weighted factors. These factors explicitly consider information about real-time constraints of tasks and their utilization of resources. Simulation studies show that the weights for the various factors in the heuristic function have to be fine-tuned in order to obtain a degree of success in the range of 75-88 percent of that obtained via exhaustive search. However, modifying the approach to use limited backtracking improves the degree of success substantially to as high as 99.5 percent. This improvement is observed even when the initial set of weights are not tailored for a particular set of tasks. Simulation studies also show that in most cases the schedule determined by the heuristic algorithm is optimal or close to optimal.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233201","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702256","Deadlines;real-time;resource requirements;scheduling;simulation studies","Real time systems;Scheduling algorithm;Military computing;Dynamic scheduling;Heuristic algorithms;Power generation;Process control;Multiprocessing systems;Distributed computing;Information science","","Deadlines;real-time;resource requirements;scheduling;simulation studies","","106","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Experiences with a Feedback Version Development Methodology","F. B. Bastani","Department of Computer Science, University of Houston","IEEE Transactions on Software Engineering","","1985","SE-11","8","718","723","In the development of programs for novel applications, a series of design-implementation phases may be necessary in order to acquire a deeper understanding of the problem. This paper develops a feedback version development approach incorporating systematic knowledge integration techniques. Our experiences in applying these methods to various projects are also discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232521","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702081","Design methods;design representation;design sequence;knowledge integration;translation grammars;version development","Design methodology;Robots;Earthquakes;Software libraries;Sorting;Computer science;Data structures;Output feedback","","Design methods;design representation;design sequence;knowledge integration;translation grammars;version development","","1","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Inferring declarative requirements specifications from operational scenarios","A. van Lamsweerde; L. Willemet","Dept. d'Ingenierie Inf., Univ. Catholique de Louvain, Belgium; NA","IEEE Transactions on Software Engineering","","1998","24","12","1089","1114","Scenarios are increasingly recognized as an effective means for eliciting, validating, and documenting software requirements. The paper focuses on the use of scenarios for requirements elicitation and explores the process of inferring formal specifications of goals and requirements from scenario descriptions. Scenarios are considered as typical examples of system usage; they are provided in terms of sequences of interaction steps between the intended software and its environment. Such scenarios are in general partial, procedural, and leave required properties about the intended system implicit. In the end such properties need to be stated in explicit, declarative terms for consistency/completeness analysis to be carried out. A formal method is proposed for supporting the process of inferring specifications of system goals and requirements inductively from interaction scenarios provided by stakeholders. The method is based on a learning algorithm that takes scenarios as examples/counterexamples and generates a set of goal specifications in temporal logic that covers all positive scenarios while excluding all negative ones. The output language in which goals and requirements are specified is the KAOS goal based specification language. The paper also discusses how the scenario based inference of goal specifications is integrated in the KAOS methodology for goal based requirements engineering. In particular, the benefits of inferring declarative specifications of goals from operational scenarios are demonstrated by examples of formal analysis at the goal level, including conflict analysis, obstacle analysis, the inference of higher level goals, and the derivation of alternative scenarios that better achieve the underlying goals.","0098-5589;1939-3520;2326-3881","","10.1109/32.738341","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=738341","","Object oriented modeling;Humans;Software agents;Formal specifications;Logic;Specification languages;Problem-solving;Interconnected systems;Concrete;Terminology","formal specification;systems analysis;program verification;inference mechanisms;learning (artificial intelligence);temporal logic;specification languages;bibliographies","declarative requirements specification inference;operational scenarios;software requirements;requirements elicitation;formal specifications;scenario descriptions;system usage;interaction steps;consistency/completeness analysis;formal method;system goals;interaction scenarios;stakeholders;learning algorithm;examples/counterexamples;goal specifications;temporal logic;positive scenarios;output language;KAOS goal based specification language;scenario based inference;KAOS methodology;goal based requirements engineering;formal analysis;conflict analysis;obstacle analysis;higher level goals;alternative scenarios","","95","","74","","","","","","IEEE","IEEE Journals & Magazines"
"Shortest Semijoin Schedule for a Local Area Distributed Database System","S. Masuyama; T. Ibaraki; S. Nishio; T. Hasegawa","Department of Applied Mathematics and Physics, Faculty of Engineering, Kyoto University; NA; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","5","602","606","The semijoin provides a means of reducing the amount of data transmission among sites in a distributed database system. Previously the semijoin has been studied mainly for reducing communication cost in an environment with global public communication networks. In a local area system, however, wide bandwidth is usually available and the communication cost is virtually negligible. In view of this, we adopt a simplified model of a local area network, imposing no constraint on the transmission line capacity and the communication processing capability at each site. For this model, an efficient algorithm for obtaining the shortest semijoin schedule, in the sense of minimizing the total number of semijoin transmissions, is developed. It is based on a schedule diagram newly introduced to represent the semijoin schedule.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233465","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702260","Distributed database;local area network;query optimization;relational database;semijoin","Database systems;Costs;Local area networks;Relational databases;Data communication;Communication networks;Bandwidth;Transmission lines;Hardware;Scheduling algorithm","","Distributed database;local area network;query optimization;relational database;semijoin","","3","","9","","","","","","IEEE","IEEE Journals & Magazines"
"A generalized expert system for database design","A. Dogac; B. Yuruten; S. Spaccapietra","Dept. of Comput. Eng., Middle East Tech. Univ., Ankara, Turkey; Dept. of Comput. Eng., Middle East Tech. Univ., Ankara, Turkey; NA","IEEE Transactions on Software Engineering","","1989","15","4","479","491","Generalized Expert System for Database Design (GESDD) is a compound expert system made up of two parts: (1) an expert system for generating methodologies for database design, called ESGM; and (2) an expert system for database design, called ESDD. ESGM provides a tool for the database design expert to specify different design methodologies or to modify existing ones. The database designer uses ESDD in conjunction with one of these methodologies to design a database starting from the requirement specification phase and producing a logical schema in one of the well-known data models, namely, the hierarchical data model, the network data model, or the relational data model. The system is evolutive in the sense that an existing methodology can be modified or a novel methodology can be added to the existing ones. GESDD is a menu-driven system and it is coded in Prolog.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.16607","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=16607","","Expert systems;Relational databases;Transaction databases;Data models;Database systems;Machinery;Educational institutions;Computer science;Design methodology;Algebra","database management systems;expert systems;software tools","database design;Generalized Expert System for Database Design;ESGM;requirement specification phase;logical schema;hierarchical data model;network data model;relational data model;GESDD;menu-driven system","","24","","30","","","","","","IEEE","IEEE Journals & Magazines"
"An Expansive View of Reusable Software","E. Horowitz; J. B. Munson","Department of Computer Science, University of Southern California, Los Angeles, CA.; System Development Corporation, Camarillo, CA 93010.","IEEE Transactions on Software Engineering","","1984","SE-10","5","477","487","The present crisis in software development forces us to reconsider the fundamental ways in which programming is done. One often quoted solution is to exploit more fully the idea of reusable software. It is the purpose of this paper to examine this concept in all of its forms and to assess the current state of the art. In addition to its usual meaning of reusable code, reusability includes reusable design, various forms of specification systems. so-called application generators, and systems for prototyping. We examine each approach from the perspective of the practicing engineer, and we evaluate the work in terms of how it may ultimately improve the development process for large-scale software systems.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010270","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010270","Application generators;nonprocedural languages;prototyping;reusability;reusable software;specification;specification languages","Software reusability;Costs;Productivity;Life testing;Software testing;System testing;Software measurement;Programming;Software maintenance;Application software","","","","46","","33","","","","","","IEEE","IEEE Journals & Magazines"
"Software project control: an experimental investigation of judgment with fallible information","T. K. Abdel-Hamid; K. Sengupta; D. Ronan","Dept. of Adm. Sci., US Naval Postgraduate Sch., Monterey, CA, USA; Dept. of Adm. Sci., US Naval Postgraduate Sch., Monterey, CA, USA; Dept. of Adm. Sci., US Naval Postgraduate Sch., Monterey, CA, USA","IEEE Transactions on Software Engineering","","1993","19","6","603","612","Software project management is becoming an increasingly critical task in many organizations. While the macro-level aspects of project planning and control have been addressed extensively, there is a serious lack of research on the micro-empirical analysis of individual decision making behavior. The heuristics deployed to cope with the problems of poor estimation and poor visibility that hamper software project planning and control are investigated, and the implications for software project management are examined. A laboratory experiment in which subjects managed a simulated software development project is reviewed. The subjects were given project status information at different stages of the lifecycle and had to assess software productivity in order to dynamically readjust project plans. A conservative anchoring and adjustment heuristic is shown to explain the subjects' decisions quite well. Implications for software project planning and control are presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.232025","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=232025","","Project management;Costs;Decision making;Programming;Productivity;Job shop scheduling;Computer industry;Defense industry;Industrial control;Laboratories","project management;software engineering","macro-level aspects;micro-empirical analysis;software project planning;software project management;laboratory experiment;simulated software development project;software productivity","","29","","28","","","","","","IEEE","IEEE Journals & Magazines"
"A Tour Through Cedar","W. Teitelman","Sun Microsystems","IEEE Transactions on Software Engineering","","1985","SE-11","3","285","302","This paper<sup>l</sup>introduces the reader to many of the salient features of the Cedar programming environment, a state-of-the-art progrmming system that combines in a single integrated environment: high quality graphics, a sophisticated editor and document preparation facility, and a variety of tools for the programmer to use in the construction and debugging of his programs. The Cedar programming language [8] is a strongly typed, compiler-oriented language of the Pascal family. What is especially interesting about the Cedar project is that it is one of the few examples where an interactive, experimental programming environment has been built for this kind of language. In the past, such environments have been confined to dynamically typed languages like Lisp and Smalltalk.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232212","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702005","Cedar programming environment;Cedar programming languages;interactive programming environments;strongly typed languages","Programming environments;Programming profession;Computer languages;Displays;Microcomputers;Graphics;Debugging;Program processors;Sun;Time sharing computer systems","","Cedar programming environment;Cedar programming languages;interactive programming environments;strongly typed languages","","17","","17","","","","","","IEEE","IEEE Journals & Magazines"
"An intelligent image database system","S. K. Chang; C. W. Yan; D. C. Dimitroff; T. Arndt","Dept. of Comput. Sci., Pittsburgh Univ., PA, USA; Dept. of Comput. Sci., Pittsburgh Univ., PA, USA; Dept. of Comput. Sci., Pittsburgh Univ., PA, USA; Dept. of Comput. Sci., Pittsburgh Univ., PA, USA","IEEE Transactions on Software Engineering","","1988","14","5","681","688","A prototype intelligent image database system (IIDS) that is based on a novel pictorial data structure is presented. This prototype system supports spatial reasoning, flexible image information retrieval, visualization, and traditional image database operations. A pictorial data structure, based on 2-D strings, provides an efficient means for iconic indexing in image database systems and spatial reasoning. The modular design of IIDS facilitates its implementation. Further extensions of the prototype system are discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6147","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6147","","Intelligent systems;Deductive databases;Image databases;Prototypes;Data structures;Intelligent structures;Information retrieval;Image retrieval;Data visualization;Indexing","data structures;expert systems;query languages;user interfaces","intelligent image database system;IIDS;pictorial data structure;spatial reasoning;flexible image information retrieval;visualization;2-D strings;iconic indexing","","158","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Analysis of the periodic update write policy for disk cache","S. D. Carson; S. Setia","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA","IEEE Transactions on Software Engineering","","1992","18","1","44","54","A disk cache is typically used in file systems to reduce average access time for data storage and retrieval. The 'periodic update' write policy, widely used in existing computer systems, is one in which dirty cache blocks are written to a disk on a periodic basis. The average response time for disk read requests when the periodic update write policy is used is determined. Read and write load, cache-hit ratio, and the disk scheduler's ability to reduce service time under load are incorporated in the analysis, leading to design criteria that can be used to decide among competing cache write policies. The main conclusion is that the bulk arrivals generated by the periodic update policy cause a traffic jam effect which results in severely degraded service. Effective use of the disk cache and disk scheduling can alleviate this problem, but only under a narrow range of operating conditions. Based on this conclusion, alternate write packages that retain the periodic update policy's advantages and provide uniformly better service are proposed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.120315","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=120315","","File systems;Delay;Memory;Information retrieval;Processor scheduling;Degradation;Cache storage;Documentation;Computer science;Sprites (computer)","buffer storage;scheduling;storage allocation;storage management","periodic update write policy;file systems;average access time;data storage;computer systems;dirty cache blocks;average response time;disk read requests;cache-hit ratio;design criteria;competing cache write policies;bulk arrivals;traffic jam effect;degraded service;disk cache;disk scheduling;write packages","","9","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Software environment architectures and user interface facilities","M. Young; R. N. Taylor; D. B. Troup","Dept. of Inf. & Comput. Sci., California Univ., Irvine, CA, USA; Dept. of Inf. & Comput. Sci., California Univ., Irvine, CA, USA; Dept. of Inf. & Comput. Sci., California Univ., Irvine, CA, USA","IEEE Transactions on Software Engineering","","1988","14","6","697","708","The authors discuss the demands and constraints on a user interface management system for a software environment, and the relation between the architecture of the environment and the user interface management system. A model for designing user interface management systems for large extensible environments is presented. This model synthesizes several recent advances in user interfaces and specializes them to the domain of software environments. The model can be applied to a wide variety of environment contexts. A prototype implementation is described.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6151","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6151","","Computer architecture;User interfaces;Environmental management;Software systems;Software performance;Context modeling;Software prototyping;Prototypes;Assembly;Human factors","programming environments;user interfaces","software environment architectures;interactive program structures;user interface management system;user interfaces","","13","","33","","","","","","IEEE","IEEE Journals & Magazines"
"Client-access protocols for replicated services","C. T. Karamanolis; J. N. Magee","Dept. of Comput., Imperial Coll. of Sci., Technol. & Med., London, UK; NA","IEEE Transactions on Software Engineering","","1999","25","1","3","21","Addresses the problem of replicated service provision in distributed systems. Existing systems that follow the state machine approach concentrate on the synchronization of the server replicas and do not consider the problem of client interaction with the server group. This paper analyzes client interaction and identifies a number of access protocols to meet a range of client requirements and system models. The paper demonstrates that protocols for the ""open"" group model-clients external to the group of servers-satisfy the requirements of the state machine approach, even when replication is transparent to the clients. Experimental performance results indicate that the ""open"" model is clearly desirable when the service is used by a large, dynamically changing set of clients, a situation which pertains to Internet service provision.","0098-5589;1939-3520;2326-3881","","10.1109/32.748915","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=748915","","Access protocols;Synchronization;Programming profession;Availability;Web and internet services;Clocks;Intersymbol interference;Atomic layer deposition;Delay","access protocols;client-server systems;replicated databases;synchronisation;Internet","client-access protocols;replicated service provision;distributed systems;state machine approach;server replica synchronization;client interaction;open group model;performance;dynamically changing client set;Internet service provision;availability","","10","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Certification of software components","C. Wohlin; P. Runeson","Dept. of Commun. Syst., Lund Univ., Sweden; NA","IEEE Transactions on Software Engineering","","1994","20","6","494","499","Reuse is becoming one of the key areas in dealing with the cost and quality of software systems. An important issue is the reliability of the components, hence making certification of software components a critical area. The objective of this article is to try to describe methods that can be used to certify and measure the ability of software components to fulfil the reliability requirements placed on them. A usage modelling technique is presented, which can be used to formulate usage models for components. This technique will make it possible not only to certify the components, but also to certify the system containing the components. The usage model describes the usage from a structural point of view, which is complemented with a profile describing the expected usage in figures. The failure statistics from the usage test form the input of a hypothesis certification model, which makes it possible to certify a specific reliability level with a given degree of confidence. The certification model is the basis for deciding whether the component can be accepted, either for storage as a reusable component or for reuse. It is concluded that the proposed method makes it possible to certify software components, both when developing for and with reuse.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.295896","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=295896","","Certification;Object oriented modeling;Software testing;Costs;Software systems;Reliability engineering;Time measurement;Software measurement;Statistical analysis;Software reliability","software reliability;software reusability;software cost estimation;software quality","software component certification;software reuse;software cost;software quality;software reliability;usage modelling technique;failure statistics;hypothesis certification model;usage testing;usage modelling;usage profile","","38","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Design of knowledge-based systems with a knowledge-based assistant","E. Schoen; R. G. Smith; B. G. Buchanan","Schlumberger Palo Alto Res., CA, USA; Schlumberger Palo Alto Res., CA, USA; NA","IEEE Transactions on Software Engineering","","1988","14","12","1771","1791","The authors propose a model for an intelligent assistant to aid in building knowledge-based systems (KBSs) and discuss a preliminary implementation. The assistant participates in KBS construction, including acquisition of an initial model of a problem domain, acquisition of control and task-specific inference knowledge, testing and validation, and long-term maintenance of encoded knowledge. The authors present a hypothetical scenario in which the assistant and a KBS designer cooperate to create an initial domain model and then discuss five categories of knowledge the assistant requires to offer such help. They discuss two software technologies on which the assistant is based: an object-oriented programming language, and a user-interface framework.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9063","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9063","","Knowledge based systems;Knowledge engineering;Object oriented modeling;Knowledge acquisition;Intelligent structures;Buildings;Object oriented programming;Design engineering;System testing;User interfaces","high level languages;inference mechanisms;knowledge acquisition;knowledge based systems;object-oriented programming;program verification;programming environments;user interfaces","knowledge acquisition;knowledge-based systems;knowledge-based assistant;intelligent assistant;problem domain;inference knowledge;testing;validation;encoded knowledge;initial domain model;object-oriented programming language;user-interface","","11","","61","","","","","","IEEE","IEEE Journals & Magazines"
"Analysis of a conflict between aggregation and interface negotiation in Microsoft's Component Object Model","K. J. Sullivan; M. Marchukov; J. Socha","Dept. of Comput. Sci., Virginia Univ., Charlottesville, VA, USA; NA; NA","IEEE Transactions on Software Engineering","","1999","25","4","584","599","Many software projects today are based on the integration of independently designed software components that are acquired on the market, rather than developed within the projects themselves. A component standard, or integration architecture, is a set of design rules meant to ensure that such components can be integrated in defined ways without undue effort. The rules of a component standard define, among other things, component interoperability and composition mechanisms. Understanding the properties of such mechanisms and interactions between them is important for the successful development and integration of software components, as well as for the evolution of component standards. The paper presents a rigorous analysis of two such mechanisms: component aggregation and dynamic interface negotiation, which were first introduced in Microsoft's Component Object Model (COM). We show that interface negotiation does not function properly within COM aggregation boundaries. In particular, interface negotiation generally cannot be used to determine the identity and set of interfaces of aggregated components. This complicates integration within aggregates. We provide a mediator-based example, and show that the problem is in the sharing of interfaces inherent in COM aggregation.","0098-5589;1939-3520;2326-3881","","10.1109/32.799960","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=799960","","Computer architecture;Software design;Software standards;Standards development;Independent component analysis;Mechanical factors;Aggregates;Costs;Java;Interference","distributed object management;project management;open systems;application program interfaces","interface negotiation;Microsoft Component Object Model;software projects;independently designed software components;component standard;integration architecture;design rules;component interoperability;composition mechanisms;component standards;rigorous analysis;component aggregation;dynamic interface negotiation;COM aggregation boundaries;mediator-based example;COM aggregation","","12","","26","","","","","","IEEE","IEEE Journals & Magazines"
"The Design of a Cryptography Based Secure File System","E. Gudes","Wang Laboratories","IEEE Transactions on Software Engineering","","1980","SE-6","5","411","420","The design of a secure file system based on user controlled cryptographic (UCC) transformations is investigated. With UCC transformations, cryptography not only complements other protection mechanisms, but can also enforce protection specifications. Files with different access permissions are enciphered by different cryptographic keys supplied by authorized users at access time. Several classes of protection policies such as: compartmentalized, hierarchical, and data dependent are discussed. Several protection implementation schemes are suggested and analyzed according to criteria such as: security, efficiency, and user convenience. These schemes provide a versatile and powerful set of design alternatives.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230489","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702757","Access control;cryptography;file security;one way ciphers;protection specifications","Cryptography;File systems;User-generated content;Control systems;Data security;Power system protection;Communication system control;Permission;Power system security;Data communication","","Access control;cryptography;file security;one way ciphers;protection specifications","","10","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Where do operations come from? A multiparadigm specification technique","P. Zave; M. Jackson","AT&T Bell Labs., Murray Hill, NJ, USA; AT&T Bell Labs., Murray Hill, NJ, USA","IEEE Transactions on Software Engineering","","1996","22","7","508","528","Proposes a technique to help people organize and write complex specifications, exploiting the best features of several different specification languages. Z is supplemented, primarily with automata and grammars, to provide a rigorous and systematic mapping from input stimuli to convenient operations and arguments for the Z specification. Consistency analysis of the resulting specification is based on the structural rules. The technique is illustrated by two examples, a graphical human-computer interface and a telecommunications system.","0098-5589;1939-3520;2326-3881","","10.1109/32.538607","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=538607","","Mice;Specification languages;Telecommunication computing;Automata;Programming;Computer interfaces;Communication system control;Control systems;Context","specification languages;grammars;formal specification;graphical user interfaces;telecommunication computing;automata theory","operations;multiparadigm specification technique;specification languages;Z specification;automata;grammars;input stimuli;arguments;systematic mapping;consistency analysis;structural rules;graphical human-computer interface;telecommunications system","","18","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Global States of a Distributed System","M. J. Fischer; N. D. Griffeth; N. A. Lynch","Department of Computer Science, Yale university; NA; NA","IEEE Transactions on Software Engineering","","1982","SE-8","3","198","202","A global state of a distributed transaction system is consistent if no transactions are in progress. A global checkpoint is a transaction which must view a globally consistent system state for correct operation. We present an algorithm for adding global checkpoint transactions to an arbitrary distributed transaction system. The algorithm is nonintrusive in the sense that checkpoint transactions do not interfere with ordinary transactions in progress; however, the checkpoint transactions still produce meaningful results.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235418","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702936","Checkpoint;consistency;distributed system;global state;transaction","Transaction databases;Database systems;Interleaved codes;Banking;Computer science;Control systems;Concurrency control;Software systems;Computer errors;Operating systems","","Checkpoint;consistency;distributed system;global state;transaction","","55","","4","","","","","","IEEE","IEEE Journals & Magazines"
"Partition testing does not inspire confidence (program testing)","D. Hamlet; R. Taylor","Dept. of Comput. Sci., Portland State Univ., OR, USA; NA","IEEE Transactions on Software Engineering","","1990","16","12","1402","1411","Theoretical models are used to study partition testing in the abstract and to describe the circumstances under which it should perform well at failure detection. Partition testing is shown to be more valuable when the partitions are narrowly based on expected failures and there is a good chance that failures occur. It is concluded that for gaining confidence from successful tests, partition testing as usually practiced has little value.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.62448","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=62448","","Software testing;System testing;Programming profession;Data structures;Sampling methods;Performance evaluation;Reliability theory;Computer science;Genetic mutations","program testing;system recovery","theoretical models;program testing;partition testing;abstract;failure detection;expected failures","","197","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Managing process inconsistency using viewpoints","I. Sommerville; P. Sawyer; S. Viller","Dept. of Comput., Lancaster Univ., UK; NA; NA","IEEE Transactions on Software Engineering","","1999","25","6","784","799","Discusses the notion of software process inconsistency and suggests that inconsistencies in software processes are inevitable and sometimes desirable. We present an approach to process analysis that helps discover different perceptions of a software process and that supports the discovery of process inconsistencies and process improvements stimulated by these inconsistencies. By analogy with viewpoints for requirements engineering that allow multiple perspectives on a software system specification to be managed, we have developed the notion of process viewpoints that provide multi-perspective descriptions of software processes. A process viewpoint includes a statement of focus or ""world view"", a set of sources of process information, a process description and a set of organizational concerns that represent goals or constraints on the process analysis. We present a description and rationale of process viewpoints, discuss the process of applying process viewpoints for process understanding, and illustrate the overall approach using part of a case study drawn from industrial processes that are part of a safety-critical system development.","0098-5589;1939-3520;2326-3881","","10.1109/32.824395","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=824395","","Capability maturity model;Computer Society;Productivity;SPICE;Automation;Software systems;Software development management;Engineering management;Information analysis;Programming","software process improvement","software process inconsistency management;process viewpoints;software process analysis;software process perceptions;software process improvement;requirements engineering;multi-perspective descriptions;software system specification;focus statement;world view;process information sources;process description;organizational concerns;goals;constraints;software process understanding;case study;industrial processes;safety-critical system development","","23","","37","","","","","","IEEE","IEEE Journals & Magazines"
"A pattern recognition approach for software engineering data analysis","L. C. Briand; V. R. Basili; W. M. Thomas","Maryland Univ., College Park, MD, USA; Maryland Univ., College Park, MD, USA; Maryland Univ., College Park, MD, USA","IEEE Transactions on Software Engineering","","1992","18","11","931","942","In order to plan, control, and evaluate the software development process, one needs to collect and analyze data in a meaningful way. Classical techniques for such analysis are not always well suited to software engineering data. A pattern recognition approach for analyzing software engineering data, called optimized set reduction (OSR), that addresses many of the problems associated with the usual approaches is described. Methods are discussed for using the technique for prediction, risk management, and quality evaluation. Experimental results are provided to demonstrate the effectiveness of the technique for the particular application of software cost estimation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.177363","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=177363","","Pattern recognition;Software engineering;Data analysis;Programming;Costs;Application software;Predictive models;Productivity;Risk management;Machine learning","pattern recognition;project management;software cost estimation;software quality","pattern recognition;software engineering data analysis;optimized set reduction;prediction;risk management;quality evaluation;software cost estimation","","126","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Interactive State-Space Analysis of Concurrent Systems","E. T. Morgan; R. R. Razouk","Department of Information and Computer science, University of California; NA","IEEE Transactions on Software Engineering","","1987","SE-13","10","1080","1091","The introduction of concurrency into programs has added to the complexity of the software design process. This is most evident in the design of communications protocols where concurrency is inherent to the behavior of the system. The complexity exhibited by such software systems makes more evident the need for computer-aided tools for automatically analyzing behavior.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232850","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702148","Assertions;communications protocols;computer-aided design;concurrent programs;correctness;Petri net;reachability graph;software design","Concurrent computing;Protocols;Software systems;System recovery;Software design;Petri nets;Application software;Computational modeling;Mechanical factors;Hardware","","Assertions;communications protocols;computer-aided design;concurrent programs;correctness;Petri net;reachability graph;software design","","20","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Nonsensitive Data and Approximate Transactions","M. K. Sinha","National Centre for Software Development and Computing Techniques, Tata Institute of Fundamental Research","IEEE Transactions on Software Engineering","","1983","SE-9","3","314","322","A methodology has been proposed for solving database problems requiring only approximate solutions. Data items are classified as sensitive and nonsensitive. An approximate transaction modifies only the nonsensitive data items which need not satisfy strong consistency constraints, and provides results only up to a degree of approximation. Further, it is shown that such an approach improves the performance in situations where transaction conflicts are frequent. Additionally, the methodology provides users as well as data managers with mechanisms to control the precision of the computation, preserving the qualitative characteristics of the data items.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236867","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703059","Access synchronization;approximation;concurrency control;deadlock;decentralized system;locking;object model;time-stamp ordering","Transaction databases;System recovery;Quality management;Concurrency control;Programming","","Access synchronization;approximation;concurrency control;deadlock;decentralized system;locking;object model;time-stamp ordering","","2","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Symbolic Gray Code as a Perfect Multiattribute Hashing Scheme for Partial Match Queries","C. C. Chang; R. C. T. Lee; M. W. Du","Institute of Computer Engineering, National Chiao-Tung University; NA; NA","IEEE Transactions on Software Engineering","","1982","SE-8","3","235","249","In this paper, we shall show that the symbolic Gray code hashing mechanism is not only good for best matching, but also good for partial match queries. Essentially, we shall propose a new hashing scheme, called bucket-oriented symbolic Gray code, which can be used to produce any arbitrary Cartesian product file, which has been shown to be good for partial match queries. Many interesting properties of this new multiattribute hashing scheme, including the property that it is a perfect hashing scheme, have been discussed and proved.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235253","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702940","Bucket-oriented symbolic Gray code;Cartesian product file;multiattribute file organization;partial match query;perfect hashing;symbolic Gray code","Reflective binary codes;File systems","","Bucket-oriented symbolic Gray code;Cartesian product file;multiattribute file organization;partial match query;perfect hashing;symbolic Gray code","","1","","25","","","","","","IEEE","IEEE Journals & Magazines"
"PROTEAN: a high-level Petri net tool for the specification and verification of communication protocols","J. Billington; G. R. Wheeler; M. C. Wilbur-Ham","Comput. Lab., Cambridge Univ., UK; NA; NA","IEEE Transactions on Software Engineering","","1988","14","3","301","316","The PROTEAN protocol emulation and analysis computer aid is presented. It is based on a formal specification technique called numerical Petri nets (NPNs), and provides both graphical (color) and textual interfaces to the protocol designer. NPN specifications may be created, stored, appended to other NPNs, structured, edited, listed, displayed, and analyzed. Interactive simulation, exhaustive reachability analysis, and several directed graph analysis facilities are described. Specification languages are compared, with concentration on extended finite state machines and high-level Petri nets. Both the NPN and PROTEAN facilities are described and illustrated with a simple example. The application of PROTEAN to complex examples is mentioned briefly. Work towards a comprehensive protocol engineering workstation is also discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4651","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4651","","Protocols;Petri nets;Emulation;Formal specifications;Computational modeling;Analytical models;Reachability analysis;Specification languages;Automata;Workstations","directed graphs;finite automata;protocols;software tools","graphical interfaces;interactive simulation;specification languages;PROTEAN;high-level Petri net tool;specification;verification;communication protocols;numerical Petri nets;textual interfaces;exhaustive reachability analysis;directed graph analysis;finite state machines;engineering workstation","","83","","85","","","","","","IEEE","IEEE Journals & Magazines"
"Isomorphisms Between Petr Nets and Dataflow Graphs","K. M. Kavi; B. P. Buckles; U. N. Bhat","Department of Computer Science Engineering, University of Texas; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","10","1127","1134","Dataflow graphs are a generalized model of computation. Uninterpreted dataflow graphs with nondeterminism resolved via probabilities are shown to be isomorphic to a class of Petri nets known as free choice nets. Petri net analysis methods are readily available in the literature and this result makes those methods accessible to dataflow research. Nevertheless, combinatorial explosion can render Petri net analysis inoperative. Using a previously known technique for decomposing free choice nets into smaller components, it is demonstrated that, in principle, it is possible to determine aspects of the overall behavior from the particular behavior of components.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232854","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702152","Dataflow graphs;free choice nets;isomorphism;performance analysis;timed Petri nets","Petri nets;Computer architecture;Data analysis;Performance analysis;Parallel processing;Computer science;Power system modeling;Computational modeling;Explosions;Parallel algorithms","","Dataflow graphs;free choice nets;isomorphism;performance analysis;timed Petri nets","","20","","20","","","","","","IEEE","IEEE Journals & Magazines"
"A strategy for improving safety related software engineering standards","N. E. Fenton; M. Neil","Centre for Software Reliability, City Univ., London, UK; NA","IEEE Transactions on Software Engineering","","1998","24","11","1002","1013","There are many standards which are relevant for building safety- or mission-critical software systems. An effective standard is one that should help developers, assessors and users of such systems. For developers, the standard should help them build the system cost-effectively, and it should be clear what is required in order to conform to the standard. For assessors, it should be possible to objectively determine compliance to the standard. Users, and society at large, should have some assurance that a system developed to the standard has quantified risks and benefits. Unfortunately, the existing standards do not adequately fulfil any of these varied requirements. We explain why standards are the way they are, and then provide a strategy for improving them. Our approach is to evaluate standards on a number of key criteria that enable us to interpret the standard, identify its scope and check the ease with which it can be applied and checked. We also need to demonstrate that the use of a standard is likely either to deliver reliable and safe systems at an acceptable cost or to help predict reliability and safety accurately. Throughout the paper, we examine, by way of example, a specific standard for safety-critical systems (namely IEC 1508) and show how it can be improved by applying our strategy.","0098-5589;1939-3520;2326-3881","","10.1109/32.730547","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=730547","","Software safety;Software engineering;Software standards;Standards development;Software systems;Software quality;Computer Society;IEC standards;Best practices;Mission critical systems","safety-critical software;software standards;IEC standards;cost-benefit analysis","safety-related software engineering standards;standards improvement strategy;safety-critical software systems;mission-critical software systems;cost-effective system development;system assessors;standard compliance;quantified risks;quantified benefits;system users;key criteria;checking;systems reliability;cost;IEC 1508;safety measurement;safety prediction","","16","","19","","","","","","IEEE","IEEE Journals & Magazines"
"A Data Flow Oriented Program Testing Strategy","J. W. Laski; B. Korel","School of Engineering and Computer Science, Oakland University; NA","IEEE Transactions on Software Engineering","","1983","SE-9","3","347","354","Some properties of a program data flow can be used to guide program testing. The presented approach aims to exercise use-definition chains that appear in the program. Two such data oriented testing strategies are proposed; the first involves checking liveness of every definition of a variable at the point(s) of its possible use; the second deals with liveness of vectors of variables treated as arguments to an instruction or program block. Reliability of these strategies is discussed with respect to a program containing an error.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236871","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703063","Control flow;data context;data environment;data flow;data oriented testing;program testing;liveness;variable definition","Testing;Computer science;Data analysis;Information analysis;Runtime;Instruments;Data engineering;Reliability engineering;Control systems","","Control flow;data context;data environment;data flow;data oriented testing;program testing;liveness;variable definition","","176","","22","","","","","","IEEE","IEEE Journals & Magazines"
"A new structural induction theorem for rings of temporal Petri nets","Jianan Li; I. Suzuki; M. Yamashita","Dept. of Electr. Eng. & Comput. Sci., Wisconsin Univ., Milwaukee, WI, USA; Dept. of Electr. Eng. & Comput. Sci., Wisconsin Univ., Milwaukee, WI, USA; NA","IEEE Transactions on Software Engineering","","1994","20","2","115","126","Presents a new structural induction theorem for rings consisting of identical components that are modeled using a Petri net and a temporal logic formula. The theorem gives a condition in terms of the behavior of the rings of sizes k/spl minus/1 and k, k/spl ges/5, under which all rings of size k/spl minus/1 or greater exhibit ""similar"" behavior. Using the example of demand-driven token circulation, we show how the theorem can be applied to formally infer the correctness of a ring of any large size from that of a ring having fewer components.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.265633","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=265633","","Petri nets;Logic;Automata;Formal verification;Sufficient conditions;Cybernetics","Petri nets;temporal logic;temporal reasoning;formal verification","structural induction theorem;rings;temporal Petri nets;identical components;temporal logic formula;similar behavior;demand-driven token circulation;correctness;formal verification","","11","","27","","","","","","IEEE","IEEE Journals & Magazines"
"An approach to decentralized computer systems","J. N. Gray","Tandem Computers Incorporated, Cupertino, CA 95014","IEEE Transactions on Software Engineering","","1986","SE-12","6","684","692","The technology for distributed computing is available. However, it is argued that decentralized systems will always require more careful design, planning, and management than their centralized counterparts. The rationale for and against decentralization is given, and a technical approach to decentralized systems is sketched. This approach contrasts with the popular concept of a distributed integrated database which transparently provides remote IO against single system image. Rather, it proposes that functions be distributed as `servers' which abstract data as high-level operations on objects and communicate with `requestors' via a standard message protocol. This requestor-server approach has the advantages of modularity and performance.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312966","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312966","Database;network;requestor;server","Computers;Dictionaries;Databases;Organizations;Protocols;Servers;Availability","distributed processing","decentralized computer systems;distributed computing;technical approach;distributed integrated database;remote IO;single system image;standard message protocol;requestor-server approach","","23","","","","","","","","IEEE","IEEE Journals & Magazines"
"The feature and service interaction problem in telecommunications systems: a survey","D. O. Keck; P. J. Kuehn","Inst. of Commun. Networks & Comput. Eng., Stuttgart Univ., Germany; NA","IEEE Transactions on Software Engineering","","1998","24","10","779","796","Today's telecommunication systems are enhanced by a large and steadily growing number of supplementary services, each of which consists of a set of service features. A situation where a combination of these services behaves differently than expected from the single services' behaviors, is called service interaction. This interaction problem is considered as a major obstacle to the introduction of new services into telecommunications networks. We present a survey of the work carried out in this field during the last decade (1988-98). After a brief review of classification criteria that exist for feature interactions so far, we use a perspective called the emergence level view. This perspective pays respect to the fact that the sources for interactions can be of many different kinds, e.g., requirement conflicts or resource contentions. It is used to rationalize the impossibility of coping with the problem with one single approach. We also present a framework of four different criteria in order to classify the approaches dealing with the problem. The general kind of approach taken, a refinement of the well known detection, resolution, and prevention categories, serves as the main classification criterion. It is complemented by the method used, the stage during the feature lifecycle where an approach applies, and the system (network) context. The major results of the different approaches are then presented briefly using this classification framework. We finally draw some conclusions on the applicability of this framework and on possible directions of further research in this field.","0098-5589;1939-3520;2326-3881","","10.1109/32.729680","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=729680","","Telecommunication services;Interference;Information resources;Protocols;Telephony;Facsimile;Data communication;Terminology;Credit cards","bibliographies;telecommunication networks;telecommunication services;history;telecommunication computing","feature/service interaction problem;telecommunication systems;supplementary services;service features;telecommunications networks;emergence level view;requirement conflicts;resource contentions;classification criterion;feature lifecycle;classification framework;telecommunication service;service interference","","103","","141","","","","","","IEEE","IEEE Journals & Magazines"
"Implementing Distributed Read-Only Transactions","A. Chan; R. Gray","Computer Corporation of America, 4 Cambridge Center; NA","IEEE Transactions on Software Engineering","","1985","SE-11","2","205","212","This paper presents an efficient scheme for eliminating conflicts between distributed read-only transactions and distributed update transactions, thereby reducing synchronization delays. The scheme makes use of a multiversion mechanism in order to guarantee that distributed read-only transactions see semantically consistent snap-shots of the database, that they never have to be rolled-back due to their late arrival at retrieval sites, and that they inflict minimal synchronization delays on concurrent update transactions. Proof that the presented scheme guarantees semantic consistency is provided. Two important by-products of this scheme are that the recovery from transaction and system failures is greatly simplified and the taking of database dumps also can be accommodated while leaving the database on-line.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232196","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701989","Concurrency control;multiversion;read-only transactions;transaction recovery;two-phase locking","Transaction databases;Delay;Image databases;Database systems;System recovery;Concurrent computing;Distributed databases;Information retrieval;Contracts;Concurrency control","","Concurrency control;multiversion;read-only transactions;transaction recovery;two-phase locking","","52","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Reconfiguration models and algorithms for stateful interactive processes","T. A. Varvarigou; M. E. Anagnostou; S. R. Ahuja","Dept. of Electr. Eng. & Comput. Sci., Nat. Tech. Univ. of Athens, Greece; NA; NA","IEEE Transactions on Software Engineering","","1999","25","3","401","415","We present new results in the area of reconfiguration of stateful interactive processes in the presence of faults. More precisely, we consider a set of servers/processes that have the same functionality, i.e., are able to perform the same tasks and provide the same set of services to their clients. In the case when several of them turn out to be faulty, we want to reconfigure the system so that the clients of the faulty servers/processes are served by some other, fault-free, servers of the system in a way that is transparent to all the system clients. We propose a novel method for reconfiguring in the presence of faults: compensation paths. Compensation paths are an efficient way of shifting spare resources from where they are available to where they are needed. We also present optimal and suboptimal simple reconfiguration algorithms of low polynomial time complexity O(nmlog(n/sup 2//m)) for the optimal and O(m) for the suboptimal algorithms, where n is the number of processes and m is the number of primary-backup relationships. The optimal algorithms compute the way to reconfigure the system whenever the reconfiguration is possible. The suboptimal algorithms may sometimes fail to reconfigure the system, although reconfiguration would be possible by using the optimal centralized algorithms. However, suboptimal algorithms have other competitive advantages over the centralized optimal algorithms with regard to time complexity and communication overhead.","0098-5589;1939-3520;2326-3881","","10.1109/32.798328","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=798328","","Polynomials;Checkpointing;File systems;Computer networks;LAN interconnection;Wide area networks;Fault tolerant systems;File servers;Contamination","interactive systems;fault tolerant computing;computational complexity;client-server systems;system recovery;configuration management","reconfiguration models;stateful interactive processes;servers/processes;faulty servers/processes;fault-free servers;system clients;compensation paths;spare resources;suboptimal simple reconfiguration algorithms;polynomial time complexity;optimal reconfiguration algorithms;primary-backup relationships;optimal centralized algorithms;communication overhead","","","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Sofiware Partitioning for Distributed, Sequential, Pipelined Applications","V. R. Iyer; H. A. Sholl","Cadware Group Ltd., 869 Whalley Avenue, New Haven, CT 06405.; NA","IEEE Transactions on Software Engineering","","1989","15","10","1270","1279","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1989.559779","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=559779","","Delay;Software performance;Real time systems;Throughput;Application software;Software safety;Process design;Algorithm design and analysis;Performance analysis;Power system modeling","","Distributed Systems;response time;sequential pipelines;software partitioning;throughput","","3","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Abstract Data Type Development and Implementation: An Example","R. Ford; K. Miller","Department of Computer Science, University of Iowa; NA","IEEE Transactions on Software Engineering","","1985","SE-11","10","1033","1037","Data abstraction is an effective tool in the design of complex systems, and the representation independence it provides is a key factor in the maintenance and adaptation of software systems. This paper describes a system development methodology based on the development of hierarchies of abstract data types (ADT's). The methodology preserves a high degree of representation independence throughout both the design and implementation of complex systems. The methodology is illustrated with examples from the design and implementation of a Vision Research Programming System. These examples include ADT specifications, ADT interface specifications, and partial implementation code for the system in two different programming languages, Ada1 and Fortran.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231549","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701917","Abstract data type;computer vision;implementation of data abstraction;software development methodology","Prototypes;Software systems;Software prototyping;Computer languages;Pixel;Geometry;Solid modeling;Machine vision;Computer vision;Programming","","Abstract data type;computer vision;implementation of data abstraction;software development methodology","","1","","12","","","","","","IEEE","IEEE Journals & Magazines"
"An overview of the Nexus distributed operating system design","A. R. Tripathi","Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA","IEEE Transactions on Software Engineering","","1989","15","6","686","695","Nexus is a distributed operating system designed to support experimental research in fault-tolerance techniques and object-oriented programming in distributed systems. The Nexus programming environment consists of objects, which are instances of abstract data types. Inheritance of types and multiple implementations for a type are supported by the system. Operations on objects are invoked, based on the remote-procedure-call paradigm and executed as atomic actions with provisions for application-controlled checkpointing and restart within actions. Nexus also supports parallel remote procedure calls. Interobject communication and location transparency in accessing objects is supported by the Nexus kernel.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24722","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24722","","Operating systems;Kernel;Workstations;Fault tolerant systems;Object oriented programming;Computer networks;Distributed computing;Sun;Checkpointing;Local area networks","computer communications software;data structures;distributed processing;fault tolerant computing;object-oriented programming;operating systems (computers);programming environments","interobject communication;object access;inheritance;Nexus distributed operating system design;experimental research;fault-tolerance techniques;object-oriented programming;Nexus programming environment;abstract data types;multiple implementations;remote-procedure-call paradigm;atomic actions;application-controlled checkpointing;restart;parallel remote procedure calls;location transparency;Nexus kernel","","14","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Tidier Drawings of Trees","E. M. Reingold; J. S. Tilford","Department of Computer Science, University of Illinois; NA","IEEE Transactions on Software Engineering","","1981","SE-7","2","223","228","Various algorithms have been proposed for producing tidy drawings of trees&#8211;drawings that are aesthetically pleasing and use minimum drawing space. We show that these algorithms contain some difficulties that lead to aesthetically unpleasing, wider than necessary drawings. We then present a new algorithm with comparable time and storage requirements that produces tidier drawings. Generalizations to forests and m-ary trees are discussed, as are some problems in discretization when alphanumeric output devices are used.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234519","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702828","Data structures;trees;tree structures","Tree data structures;Printing;Binary trees;Computer science;Software algorithms;Engineering drawings","","Data structures;trees;tree structures","","228","","7","","","","","","IEEE","IEEE Journals & Magazines"
"SPiCE: a system for translating Smalltalk programs into a C environment","K. Yasumatsu; N. Doi","Syst. Practices Lab., Fuji Xerox Co. Ltd., Kanagawa, Japan; NA","IEEE Transactions on Software Engineering","","1995","21","11","902","912","Smalltalk-80 (hereafter referred to as Smalltalk), which is one of the most productive programming languages/environments, is very well suited for prototyping of applications but it is less well suited for delivering applications because applications can neither run in isolation from the Smalltalk environment nor be combined with other programs written in other languages. One way to make Smalltalk suitable for delivering applications is to translate Smalltalk into a compiler language such as C. By translating Smalltalk code into portable and interoperable C code, it is possible to deliver a stand-alone version of Smalltalk applications, and to develop an application partly in Smalltalk and partly in C. However, there are some difficulties in translating Smalltalk code into such a C code. First, the execution model of Smalltalk, which creates activation records as objects, is very different from that of C, and second, Smalltalk and C have very different approaches to storage management. We have implemented SPiCE, a system for translating Smalltalk into C. Our approach to the translation is to create runtime replacement classes implementing the same functionality of Smalltalk classes that are inherently part of the Smalltalk execution model, and to provide semi-conservative real-time compacting garbage collection that works without language support.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.473219","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=473219","","SPICE;Virtual machining;Computer languages;Object oriented modeling;Prototypes;Runtime;Robustness;Programming profession;Memory management","program interpreters;Smalltalk;C language;software portability;storage management;program compilers","SPiCE;Smalltalk;C;programming language translation;Smalltalk-80;prototyping;compiler language;interoperable code;portable code;execution model;activation records;storage management;runtime replacement classes;garbage collection;real-time","","11","","21","","","","","","IEEE","IEEE Journals & Magazines"
"On multisystem coupling through function request shipping","D. W. Cornell; D. M. Dias; P. S. Yu","IBM Thomas J. Watson Research Center, Yorktown Heights, NY 10598; IBM Thomas J. Watson Research Center, Yorktown Heights, NY 10598; IBM Thomas J. Watson Research Center, Yorktown Heights, NY 10598","IEEE Transactions on Software Engineering","","1986","SE-12","10","1006","1017","In a multisystem database system with a function request shipping approach, the databases are partitioned among the multiple systems and a facility is provided to support the shipping of database requests among the systems. This is in contrast to a data sharing multisystem approach in which all systems have direct access to the shared database. The performance of the two approaches is compared, emphasizing generic issues that affect the function shipping approach. A methodology is presented for partitioning the databases and routing transactions among the systems so as to minimize the fraction of remote function calls, while balancing the load among systems. Estimates of the resulting remote function calls, mirror transaction setups, and multisystem two-phase commits are obtained. Results of simulation and approximate analysis are presented.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313017","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313017","Database systems;data sharing;locking;multiprocessor systems;partitioning;performance analysis","Mirrors;Couplings;Database systems;Routing;Linear programming;Load modeling","database management systems","multisystem coupling;function request shipping;database system;data sharing;remote function calls;mirror transaction setups;multisystem two-phase commits;simulation;approximate analysis","","30","","","","","","","","IEEE","IEEE Journals & Magazines"
"Evaluating Software Engineering Technologies","D. N. Card; F. E. Mc Garry; G. T. Page","Computer Sciences Corporation, System Sciences Division; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","7","845","851","Many new software development practices, tools, and techniques have been introduced in recent years. Few, however, have been empirically evaluated. The objectives of this study were to measure technology use in a production environment, develop a statistical model for evaluating the effectiveness of technologies, and evaluate the effects of some specific technologies on productivity and reliability. A carefully matched sample of 22 projects from the Software Engineering Laboratory database was studied using an analysis-of-covariance procedure. Limited use of the technologies considered in the analysis produced approximately a 30 percent increase in software reliability. These technologies did not demonstrate any direct effect on development productivity.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233495","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702295","Modern programming practices;productivity;reliability software engineering;Software Engineering Laboratory;software measurement;technology evaluation","Software engineering;Productivity;Laboratories;Software measurement;Costs;Programming profession;Production;Databases;Space technology;Software reliability","","Modern programming practices;productivity;reliability software engineering;Software Engineering Laboratory;software measurement;technology evaluation","","21","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Formal verification for fault-tolerant architectures: prolegomena to the design of PVS","S. Owre; J. Rushby; N. Shankar; F. von Henke","Comput. Sci. Lab., SRI Int., Menlo Park, CA, USA; Comput. Sci. Lab., SRI Int., Menlo Park, CA, USA; Comput. Sci. Lab., SRI Int., Menlo Park, CA, USA; Comput. Sci. Lab., SRI Int., Menlo Park, CA, USA","IEEE Transactions on Software Engineering","","1995","21","2","107","125","PVS is the most recent in a series of verification systems developed at SRI. Its design was strongly influenced, and later refined, by our experiences in developing formal specifications and mechanically checked verifications for the fault-tolerant architecture, algorithms, and implementations of a model ""reliable computing platform"" (RCP) for life-critical digital flight-control applications, and by a collaborative project to formally verify the design of a commercial avionics processor called AAMP5. Several of the formal specifications and verifications performed in support of RCP and AAMP5 are individually of considerable complexity and difficulty. But in order to contribute to the overall goal, it has often been necessary to modify completed verifications to accommodate changed assumptions or requirements, and people other than the original developer have often needed to understand, review, build on, modify, or extract part of an intricate verification. We outline the verifications performed, present the lessons learned, and describe some of the design decisions taken in PVS to better support these large, difficult, iterative, and collaborative verifications.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.345827","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=345827","","Formal verification;Fault tolerance;Aerospace control;Aerospace electronics;Redundancy;Application software;Algorithm design and analysis;Computer architecture;Collaboration;Formal specifications","fault tolerant computing;reliability;formal verification;formal specification;aerospace control;computer architecture;safety-critical software","formal verification;fault-tolerant architectures;PVS;verification systems;formal specifications;fault-tolerant architecture;reliable computing platform;life-critical digital flight-control applications;collaborative project;commercial avionics processor;AAMP5;collaborative verifications","","243","","84","","","","","","IEEE","IEEE Journals & Magazines"
"The infeasibility of quantifying the reliability of life-critical real-time software","R. W. Butler; G. B. Finelli","NASA Langley Res. Center, Hampton, VA, USA; NASA Langley Res. Center, Hampton, VA, USA","IEEE Transactions on Software Engineering","","1993","19","1","3","12","This work affirms that the quantification of life-critical software reliability is infeasible using statistical methods, whether these methods are applied to standard software or fault-tolerant software. The classical methods of estimating reliability are shown to lead to exorbitant amounts of testing when applied to life-critical software. Reliability growth models are examined and also shown to be incapable of overcoming the need for excessive amounts of testing. The key assumption of software fault tolerance-separately programmed versions fail independently-is shown to be problematic. This assumption cannot be justified by experimentation in the ultrareliability region, and subjective arguments in its favor are not sufficiently strong to justify it as an axiom. Also, the implications of the recent multiversion software experiments support this affirmation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.210303","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=210303","","Software reliability;Application software;Hardware;Software systems;Control systems;Software testing;Fault tolerance;Software design;Computer errors;Costs","fault tolerant computing;real-time systems;safety;software reliability","reliability;life-critical real-time software;statistical methods;fault-tolerant software;growth models;software fault tolerance;multiversion software experiments","","177","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Efficient Support of Statistical Operations","S. N. Khoshafian; D. M. Bates; D. J. De Witt","MCC Corporation; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","10","1058","1070","Most research in statistical databases has concentrated on retrieval, sampling, and aggregation type statistical queries. Data management issues associated with computational statistical operations have been ignored. As a first step towards integrating database management support of statistical operations, we have analyzed the performance of X'X, the QR decomposition, and the Singular Value Factorization. Alternative implementation strategies with respect to the relational and transposed storage organizations are developed. Implementation strategies corresponding to vector building block, vector-matrix, and direct algorithms with explicit buffer management are compared in terms of efficiency in performance.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231853","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701921","Buffer management;database management systems;linear least squares;QR decomposition;secondary storage;singular value factorization;statistical databases","Performance analysis;Statistical analysis;Information retrieval;Relational databases;Database systems;Least squares methods;Transaction databases;Sampling methods;Vectors;Statistics","","Buffer management;database management systems;linear least squares;QR decomposition;secondary storage;singular value factorization;statistical databases","","2","","38","","","","","","IEEE","IEEE Journals & Magazines"
"The Use of Software Complexity Metrics in Software Maintenance","D. Kafura; G. R. Reddy","Department of Computer Science, Virginia Polytechnic Institute; NA","IEEE Transactions on Software Engineering","","1987","SE-13","3","335","343","This paper reports on a modest study which relates seven different software complexity metrics to the experience of maintenance activities performed on a medium size software system. Three different versions of the system that evolved over a period of three years were analyzed in this study. A major revision of the system, while still in its design phase, was also analyzed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233164","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702219","Complexity metrics;design analysis;maintenance;software metrics","Software maintenance;Costs;Software metrics;Software systems;Performance analysis;Computer science;Software performance;Software design;Maintenance engineering;Process control","","Complexity metrics;design analysis;maintenance;software metrics","","55","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Methodology for validating software metrics","N. F. Schneidewind","Naval Postgrad. Sch., Monterey, CA, USA","IEEE Transactions on Software Engineering","","1992","18","5","410","422","A comprehensive metrics validation methodology is proposed that has six validity criteria, which support the quality functions assessment, control, and prediction, where quality functions are activities conducted by software organizations for the purpose of achieving project quality goals. Six criteria are defined and illustrated: association, consistency, discriminative power, tracking, predictability, and repeatability. The author shows that nonparametric statistical methods such as contingency tables play an important role in evaluating metrics against the validity criteria. Examples emphasizing the discriminative power validity criterion are presented. A metrics validation process is defined that integrates quality factors, metrics, and quality functions.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.135774","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=135774","","Software metrics;Software measurement;Q factor;Statistical analysis;Software quality;Phase measurement;Time measurement;Power engineering and energy;Quality assessment;Performance analysis","program verification;quality control;software metrics;software reliability","software metrics;comprehensive metrics validation methodology;validity criteria;quality functions;software organizations;project quality goals;discriminative power;tracking;predictability;repeatability;nonparametric statistical methods;contingency tables;discriminative power validity criterion;metrics validation process","","173","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Testing and debugging distributed programs using global predicates","S. Venkatesan; B. Dathan","Comput. Sci. Program, Texas Univ., Richardson, TX, USA; NA","IEEE Transactions on Software Engineering","","1995","21","2","163","177","Testing and debugging programs are more involved in distributed systems than in uniprocessor systems because of the presence of the communication medium and the inherent concurrency. Past research has established that predicate testing is an approach that can alleviate some of the problems in this area. However, checking whether a general predicate is true in a particular distributed execution appears to be a computationally hard problem. This paper considers a class of predicates called conjunctive form predicates (CFP) that is quite useful in distributed program development, but can be tested efficiently. We develop fully-distributed algorithms to test CFP's, prove that these algorithms are correct, and analyze them for their message complexity. The analysis shows that our techniques incur a fairly low overhead on the distributed system.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.345831","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=345831","","Debugging;Software engineering;Computer science;Clouds;Concurrent computing;Distributed computing;Algorithm design and analysis;System testing;Computer networks;Communication networks","parallel programming;program testing;program debugging;programming theory;distributed algorithms","distributed program testing;distributed program debugging;global predicates;distributed systems;uniprocessor systems;concurrency;predicate testing;computationally hard problem;conjunctive form predicates;distributed program development;fully-distributed algorithms;message complexity;low overhead","","33","","31","","","","","","IEEE","IEEE Journals & Magazines"
"A prototyping language for real-time software","Luqi; V. Berzins; R. Yeh","Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA; Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA; NA","IEEE Transactions on Software Engineering","","1988","14","10","1409","1423","PSDL is a language for describing prototypes of real-time software systems. It is most useful for requirements analysis, feasibility studies, and the design of large embedded systems. PSDL has facilities for recording and enforcing timing constraints, and for modeling the control aspects of real-time systems using nonprocedural control constraints, operator abstractions, and data abstractions. The language has been designed for use with an associated prototyping methodology. PSDL prototypes are executable if supported by a software base containing reusable software components in an underlying programming language (e.g. Ada).<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6186","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6186","","Software prototyping;Prototypes;Real time systems;Software reusability;Software systems;Software quality;Computer science;Embedded system;Timing;Control systems","data structures;real-time systems;software reusability;specification languages","specification languages;prototyping language;real-time software;PSDL;requirements analysis;feasibility studies;embedded systems;timing constraints;real-time systems;nonprocedural control constraints;operator abstractions;data abstractions;reusable software components","","76","","32","","","","","","IEEE","IEEE Journals & Magazines"
"A framework for evaluating specification methods for reactive systems-experience report","M. A. Ardis; J. A. Chaves; L. J. Jagadeesan; P. Mataga; C. Puchol; M. G. Staskauskas; J. Von Olnhausen","Bell Labs., Naperville, IL, USA; Bell Labs., Naperville, IL, USA; Bell Labs., Naperville, IL, USA; Bell Labs., Naperville, IL, USA; Bell Labs., Naperville, IL, USA; Bell Labs., Naperville, IL, USA; Bell Labs., Naperville, IL, USA","IEEE Transactions on Software Engineering","","1996","22","6","378","389","Numerous formal specification methods for reactive systems have been proposed in the literature. Because the significant differences between the methods are hard to determine, choosing the best method for a particular application can be difficult. We have applied several different methods, including Modechart, VFSM, ESTEREL, Basic LOTOS, Z, SDL, and C, to an application problem encountered in the design of software for AT&T's 5ESS telephone switching system. We have developed a set of criteria for evaluating and comparing the different specification methods. We argue that the evaluation of a method must take into account not only academic concerns, but also the maturity of the method, its compatibility with the existing software development process and system execution environment, and its suitability for the chosen application domain.","0098-5589;1939-3520;2326-3881","","10.1109/32.508312","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=508312","","Application software;Telephony;Protocols;Switching systems;Programming;Formal specifications;Software design;Specification languages;System testing;Design methodology","formal specification;specification languages;telecommunication computing;telecommunication switching","specification methods;reactive systems;formal specification methods;Modechart;VFSM;ESTEREL;Basic LOTOS;Z;SDL;C;telephone switching system;software development process;system execution environment;specification languages;industrial applications;technology assessment","","26","","33","","","","","","IEEE","IEEE Journals & Magazines"
"Queueing Analysis of Fault-Tolerant Computer Systems","V. F. Nicola; V. G. Kulkarni; K. S. Trivedi","Department of Computer Science, Duke University; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","3","363","375","In this paper we consider the queueing analysis of a fault-tolerant computer system. The failure/repair behavior of the server is modeled by an irreducible continuous-time Markov chain. Jobs arrive in a Poisson fashion to the system and are serviced according to FCFS discipline. A failure may cause the loss of the work already done on the job in service, if any; in this case the interrupted job is repeated as soon as the server is ready to deliver service. In addition to the delays due to failures and repairs, jobs suffer delays due to queueing. We present an exact queueing analysig of the system and study the steady-state behavior of the number of jobs in the system. As a numerical example, we consider a system with two processors subject to failures and repairs.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233168","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702223","Fault-tolerant systems;performance models;queueing theory;reliability analysis","Queueing analysis;Fault tolerant systems;Delay;Performance analysis;Steady-state;Availability;Electric breakdown;Reliability theory;Predictive models;Computer aided manufacturing","","Fault-tolerant systems;performance models;queueing theory;reliability analysis","","10","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Analyzing partition testing strategies","E. J. Weyuker; B. Jeng","Dept. of Comput. Sci., New York Univ., NY, USA; Dept. of Comput. Sci., New York Univ., NY, USA","IEEE Transactions on Software Engineering","","1991","17","7","703","711","Partition testing strategies, which divide a program's input domain into subsets with the tester selecting one or more elements from each subdomain, are analyzed. The conditions that affect the efficiency of partition testing are investigated, and comparisons of the fault detection capabilities of partition testing and random testing are made. The effects of subdomain modifications on partition testing's ability to detect faults are studied.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.83906","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=83906","","Software testing;Fault detection;Performance evaluation;Helium;Guidelines;Computer science;Genetic mutations","program testing","input domain;partition testing;fault detection capabilities;random testing;subdomain modifications","","130","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Dataflow Resource Managers and Their Synthesis from Open Path Expressions","A. E. Oldehoeft; S. F. Jennings","Department of Computer Science, Iowa State University, Ames, IA 50010.; Department of Computer Science, Colorado State University, Ft. Collins, CO 80521.; Advanced Systems Group, Burroughs Corporation, Boulder, CO 80301.","IEEE Transactions on Software Engineering","","1984","SE-10","3","244","257","The control of concurrent access to shared resources is an important feature of both centralized and distributed operating systems. In conventional systems, exclusive access is the rule while concurrent access is the exception. Dataflow computer systems, along with an applicative style of programming, provide an execution environment in which this philosophy is reversed. In these latter systems, it is necessary to reexamine the manner in which synchronization of access to shared resources is specified and implemented. A basic design for a dataflow resource manager is reviewed, illustrating the clear separation between access mechanism and scheduling policy. The semantics of the access mechanism is based solely on the principle of data dependency. Specifications are presented for a general scheduler to further constrain or order accesses to the resource. Using ``open path expressions'' as a very high-level specification language for synchronization, it is shown how to automatically synthesize a scheduler as a distributed network of communicating modules.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010233","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010233","Applicative programming;concurrent access;dataflow computers;open path expressions;operating systems;parallel processing;resource managers","Resource management;Operating systems;Functional programming;Concurrent computing;Automatic programming;Parallel processing;Control system synthesis;Centralized control;Memory management;Specification languages","","","","2","","40","","","","","","IEEE","IEEE Journals & Magazines"
"A strategy for comparing alternative software development life cycle models","A. M. Davis; E. H. Bersoff; E. R. Comer","BTG Inc., Vienna, VA, USA; BTG Inc., Vienna, VA, USA; NA","IEEE Transactions on Software Engineering","","1988","14","10","1453","1461","It is difficult to compare and contrast models of software development because their proponents often use different terminology, and the models often have little in common except their beginnings (marked by a recognition that a problem exists) and ends (marked by the existence of a software solution). A framework is provided that can serve: as a basis for analyzing the similarities and differences among alternate life-cycle models; as a tool for software engineering researchers to help describe the probable impacts of a life-cycle mode; and as a means to help software practitioners decide on an appropriate life-cycle model to utilize on a particular project or in a particular application area.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6190","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6190","","Programming;Algorithm design and analysis;Software reusability;Software prototyping;Software performance;Software tools;Project management;Software engineering;Productivity;Software design","software engineering","software development life cycle models;software engineering","","78","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Xception: a technique for the experimental evaluation of dependability in modern computers","J. Carreira; H. Madeira; J. G. Silva","Dept. de Engenharia Inf., Coimbra Univ., Portugal; NA; NA","IEEE Transactions on Software Engineering","","1998","24","2","125","136","An important step in the development of dependable systems is the validation of their fault tolerance properties. Fault injection has been widely used for this purpose, however with the rapid increase in processor complexity, traditional techniques are also increasingly more difficult to apply. This paper presents a new software-implemented fault injection and monitoring environment, called Xception, which is targeted at modern and complex processors. Xception uses the advanced debugging and performance monitoring features existing in most modern processors to inject quite realistic faults by software, and to monitor the activation of the faults and their impact on the target system behavior in detail. Faults are injected with minimum interference with the target application. The target application is not modified, no software traps are inserted, and it is not necessary to execute the target application in special trace mode (the application is executed at full speed). Xception provides a comprehensive set of fault triggers, including spatial and temporal fault triggers, and triggers related to the manipulation of data in memory. Faults injected by Xception can affect any process running on the target system (including the kernel), and it is possible to inject faults in applications for which the source code is not available. Experimental, results are presented to demonstrate the accuracy and potential of Xception in the evaluation of the dependability properties of the complex computer systems available nowadays.","0098-5589;1939-3520;2326-3881","","10.1109/32.666826","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=666826","","Application software;Hardware;Monitoring;Computer errors;Fault tolerant systems;Concurrent computing;Reduced instruction set computing;Physics computing;Telecommunication computing;Debugging","fault tolerant computing;performance evaluation;computer debugging;real-time systems;reduced instruction set computing;system monitoring","Xception;computer dependability evaluation;fault tolerance property validation;processor complexity;software-implemented environment;fault injection environment;fault monitoring environment;debugging;performance monitoring;fault activation;target system behavior;target application;trace-mode execution;fault triggers;data manipulation;kernel;accuracy;RISC processors;real-time systems","","191","","49","","","","","","IEEE","IEEE Journals & Magazines"
"Estimating the speedup in parallel parsing","D. Sarkar; N. Deo","Dept. of Math. & Comput. Sci., Miami Univ., Coral Gables, FL, USA; NA","IEEE Transactions on Software Engineering","","1990","16","7","677","683","A method for estimating the speedup for asynchronous bottom-up parallel parsing is presented. Two models for bottom-up parallel parsing are proposed, and the speedup for each of the two models is estimated. The speedup obtained for model A is a very close to the simulation result already available in literature; however, the model is restrictive because it can only communicate with its immediate left and right neighbors. This increases the processor coordination and interprocessor communication times. Model B, while showing a greater speedup time, is expensive to construct when the number of processors is large.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.56094","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=56094","","Parallel processing;Computer architecture;Pipelines;Computational modeling;Operating systems;Mathematics;Computer science;Parallel programming;Parallel machines;Arithmetic","grammars;parallel algorithms;program compilers","speedup estimation;parallel parsing;asynchronous bottom-up;models;simulation result;processor coordination;interprocessor communication","","1","","18","","","","","","IEEE","IEEE Journals & Magazines"
"A Specification Method for Specifying Data and Procedural Abstractions","B. G. Claybrook","MITRE Corporation","IEEE Transactions on Software Engineering","","1982","SE-8","5","449","459","A specifilcation method designed primarily for specifying data abstractions, but suitable for specifying procedural abstractions as well, is described. The specification method is based on the abstract model approach to specifying abstractions. Several data abstractions and procedural abstractions are specified and a proof of implementation correctness is given for one of the data abstractions&#8211;a symbol table.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235735","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702975","Data abstraction;formal specification;implementation correctness;procedural abstraction","Formal specifications;Databases;Design methodology;Problem-solving;Programming profession","","Data abstraction;formal specification;implementation correctness;procedural abstraction","","","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Abstract requirements specification: A new approach and its application","C. L. Heitmeyer; J. D. McLean","Computer Science and Systems Branch, Naval Research Laboratory; NA","IEEE Transactions on Software Engineering","","1983","SE-9","5","580","589","An abstract requirements specification states system requirements precisely without describing a real or a paradigm implementation. Although such specifications have important advantages, they are difficult to produce for complex systems and hence are seldom seen in the ""real"" programming world. This paper introduces an approach to producing abstract requirements specifications that applies to a significant class of real-world systems, including any system that must reconstruct data that have undergone a sequence of transformations. tions. It also describes how the approach was used to produce a requirements document for SCP, a small, but nontrivial Navy communications system. The specification techniques used in the SCP requirements document are introduced and illustrated with examples.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.235117","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703098","Abstract specification;communications system;formal specifications;requirements document;requirements specification;specifications","Formal specifications;Contracts;Measurement standards;Standards development;Computer science;Software maintenance;Personnel;Software algorithms;Data structures","","Abstract specification;communications system;formal specifications;requirements document;requirements specification;specifications","","27","","24","","","","","","IEEE","IEEE Journals & Magazines"
"The Software Engineering Shortage: A Third Choice","J. P. McGill","Lockheed Missiles and Space Company, Inc., Department 62-M4, Building 581, P.O. Box 504, Sunnyvale, CA 94086.","IEEE Transactions on Software Engineering","","1984","SE-10","1","42","49","As interest in the concepts and methods of software engineering increases, many companies, particularly in aerospace, find it difficult to acquire software developers with the desired skills. The option of full-time, company-based training is discussed with suggestions for implementation. Lessons learned from the actual implementation of such a program are discussed along with possible directions for future evolution.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010197","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010197","DSDD;industrial training;software engineering;software life cycle","Software engineering;Programming;Acoustical engineering;Industrial training;Computer industry;Software maintenance;Aerospace engineering;Educational institutions;Construction industry;Design engineering","","","","7","","8","","","","","","IEEE","IEEE Journals & Magazines"
"A software environment for studying computational neural systems","E. Mesrobian; J. Skrzypek","Dept. of Comput. Sci., California Univ., Los Angeles, CA, USA; Dept. of Comput. Sci., California Univ., Los Angeles, CA, USA","IEEE Transactions on Software Engineering","","1992","18","7","575","589","UCLA-SFINX is a neural network simulation environment that enables users to simulate a wide variety of neural network models at various levels of abstraction. A network specification language enables users to construct arbitrary network structures. Small, structurally irregular networks can be modeled by explicitly defining each neuron and can be modeled by explicitly defining each neuron and corresponding connections. Very large networks with regular connectivity patterns can be implicitly specified using array constructs. Graphics support, based on X Windows System, is provided to visualize simulation results. Details of the simulation environment are described, and simulation examples are presented to demonstrate SFINX's capabilities.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.148476","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=148476","","Computational modeling;Biomembranes;Neurons;Computer networks;Neural networks;Biological neural networks;Computer science;Neuroscience;Buildings;Specification languages","digital simulation;formal specification;neural nets;programming environments;specification languages","graphics supports;software environment;computational neural systems;UCLA-SFINX;simulation environment;network specification language;arbitrary network structures;array constructs;X Windows System","","6","","34","","","","","","IEEE","IEEE Journals & Magazines"
"Representing software engineering models: the TAME goal oriented approach","M. Oivo; V. R. Basili","Tech. Res. Centre of Finland, Oulu, Finland; NA","IEEE Transactions on Software Engineering","","1992","18","10","886","898","A methodology and a knowledge representation and reasoning framework for top-down goal-oriented characterization, modeling, and execution of software engineering activities is presented. A prototype system (ES-TAME) which demonstrates the underlying knowledge representation and reasoning principles is described. ES-TAME provides an object-oriented metamodel concept that provides support for tailorable and reusable software engineering models (SEMs). It provides the basic mechanisms, functions, and attributes for all the other models. It is based on interobject relationships, dynamic viewpoints, and selective inheritance in addition to traditional object-oriented mechanisms. Descriptive SEMs include representations for basic software engineering activities. They are controlled and made operational by active GQM (goal-question-metric paradigm) models which are built by a systematic mechanism for defining and evaluating project and corporate goals and using measurement to provide feedback in real-time.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.163605","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=163605","","Software engineering;Object oriented modeling;Software quality;Software measurement;Feedback;Programming;Data analysis;Information analysis;Knowledge representation;Software prototyping","artificial intelligence;knowledge representation;object-oriented programming;software engineering;software reusability","software engineering models representation;TAME goal oriented approach;knowledge representation;reasoning framework;top-down goal-oriented characterization;modeling;prototype system;ES-TAME;object-oriented metamodel concept;reusable software engineering models;dynamic viewpoints;selective inheritance;goal-question-metric paradigm","","68","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Optimal Insertion of Software Probes in Well-Delimited Programs","R. L. Probert","Department of Computer Science, University of Ottawa","IEEE Transactions on Software Engineering","","1982","SE-8","1","34","42","A standard technique for monitoring software testing activities is to instrument the module under test with counters or probes before testing begins; then, during testing, data generated by these probes can be used to identify portions of as yet unexercised code. In this paper the effect of the disciplined use of language features for explicitly delimiting control flow constructs is investigated with respect to the corresponding ease of software instrumentation. In particular, assuming all control constructs are explicitly delimited, for example, by END IF or equivalent statements, an easily programmed method is given for inserting a minimum number of probes for monitoring statement and branch execution counts without disrupting source code structure or paragraphing. The use of these probes, called statement probes, is contrasted with the use of standard (branch) probes for execution monitoring. It is observed that the results apply to well-delimited modules written in a wide variety of programming languages, in particular, Ada.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.234772","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702903","Branch execution;control structures;execution count;flowgraphs;graph theory;monitors;probe basis;program instrumentation;programming language design;software probes;spanning trees;structured programs;testing","Probes;Software testing;Instruments;System testing;Monitoring;Computer languages;Code standards;Software standards;Counting circuits;Graph theory","","Branch execution;control structures;execution count;flowgraphs;graph theory;monitors;probe basis;program instrumentation;programming language design;software probes;spanning trees;structured programs;testing","","3","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Semantics guided regression test cost reduction","D. Binkley","Dept. of Comput. Sci., Loyola Coll., Baltimore, MD, USA","IEEE Transactions on Software Engineering","","1997","23","8","498","516","Software maintainers are faced with the task of regression testing: retesting a modified program on an often large number of test cases. The cost of regression testing can be reduced if the size of the program is reduced and if old test cases and results can be reused. Two complimentary algorithms for reducing the cost of regression testing are presented. The first produces a program called Differences that captures the semantic change between Certified, a previously tested program, and Modified, a changed version of Certified. It is more efficient to test Differences, because it omits unchanged computations. The program Differences is computed using a combination of program slices. The second algorithm identifies test cases for which Certified and Modified produce the same output and existing test cases that test new components in Modified. The algorithm is based on the notion of common execution patterns. Program components with common execution patterns have the same execution pattern during some call to their procedure. They are computed using a calling context slice. Whereas an interprocedural slice includes the program components necessary to capture all possible executions of a statement, a calling context slice includes only those program components necessary to capture the execution of a statement in a particular calling context. Together with Differences, it is possible to test Modified by running Differences on a smaller number of test cases. This is more efficient than running Modified on a large number of test cases. A prototype implementation has been built to examine and illustrate these algorithms.","0098-5589;1939-3520;2326-3881","","10.1109/32.624306","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=624306","","Costs;Automatic testing;Software testing;Software debugging;Software maintenance;Software tools;Computer Society;Software prototyping;Prototypes;Software engineering","program testing;software maintenance;subroutines;software cost estimation","semantics-guided regression test cost reduction;software maintenance;modified program retesting;old test cases;semantic change;program differences;certified program;program slices;common execution patterns;procedure calls;calling context slice;interprocedural slice;program components;program statement executions","","97","","43","","","","","","IEEE","IEEE Journals & Magazines"
"The x-Kernel: an architecture for implementing network protocols","N. C. Hutchinson; L. L. Peterson","Dept. of Comput. Sci., Arizona Univ., Tucson, AZ, USA; Dept. of Comput. Sci., Arizona Univ., Tucson, AZ, USA","IEEE Transactions on Software Engineering","","1991","17","1","64","76","A description is given of an operating system kernel, called the x-Kernel, that provides an explicit architecture for constructing and composing network protocols. The authors' experience implementing and evaluation several protocols in the x-Kernel shows that this architecture is general enough to accommodate a wide range of protocols, yet efficient enough to perform competitively with less-structured operating systems. Experimental results demonstrating the architecture's generality and efficiency are provided. The explicit structure provided by the x-Kernel has the following advantages. First, the architecture simplifies the process of implementing protocols in the kernel, making it easier to build and test novel protocols. Second, the uniformity of the interface between protocols avoids the significant cost of changing abstractions and makes protocol performance predictable. Third, it is possible to write efficient protocols by tuning the underlying architecture rather than heavily optimizing protocols themselves.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.67579","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=67579","","Operating systems;Kernel;Access protocols;Hardware;Application software;Sockets;Computer architecture;Performance evaluation;Heart;Encoding","network operating systems;protocols","x-Kernel;architecture;network protocols;operating system kernel;interface","","334","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Compound-Poisson software reliability model","M. Sahinoglu","Middle East Tech. Univ., Ankara, Turkey","IEEE Transactions on Software Engineering","","1992","18","7","624","630","The probability density estimation of the number of software failures in the event of clustering or clumping of the software failures is considered. A discrete compound Poisson (CP) prediction model is proposed for the random variable X/sub rem/, which is the remaining number of software failures. The compounding distributions, which are assumed to govern the failure sizes at Poisson arrivals, are respectively taken to be geometric when failures are forgetful and logarithmic-series when failures are contagious. The expected value ( mu ) of X/sub rem/ is calculated as a function of the time-dependent Poisson and compounding distribution based on the failures experienced. Also, the variance/mean parameter for the remaining number of failures, q/sub rem/, is best estimated by q/sub past/ from the failures already experienced. Then, one obtains the PDF of the remaining number of failures estimated by CP( mu ,q). CP is found to be superior to Poisson where clumping of failures exists. Its predictive validity is comparable to the Musa-Okumoto log-Poisson model in certain cases.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.148480","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=148480","","Software reliability;Predictive models;Software quality;Reliability engineering;Random variables;Probability distribution;Software measurement;Time measurement;Software systems","software reliability","compound-Poisson software reliability model;discrete compound Poisson prediction model;probability density estimation;software failures;clustering;clumping;random variable;Poisson arrivals;predictive validity;Musa-Okumoto log-Poisson model","","56","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Adaptive File Allocation in Star Computer Network","C. T. Yu; Man-Keung Siu; K. Lam; C. H. Chen","Department of Electrical Engineering and Computer Science, University of Illinois; NA; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","9","959","965","In this paper, we study the allocation of files in a star network. Unlike previous algorithms which assume that files are independently accessed and independently assigned, the interaction of files during the processing of queries is directly incorporated into our cost model. We present an adaptive algorithm, which is much faster than existing algorithms on file allocation, obtains solutions which are on the average only 0.1 percent away from the optimal solutions, and possesses many desirable properties such as the satisfaction of some necessary and sufficient conditions for file allocation.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232830","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702115","File allocation;query processing;star network","Intelligent networks;Computer networks;Costs;Sufficient conditions;Query processing;Adaptive algorithm;Clustering algorithms;Partitioning algorithms;Mathematics;Statistics","","File allocation;query processing;star network","","5","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Priority queues and sorting methods for parallel simulation","M. D. Grammatikakis; S. Liesche","INTRACOM, Peania, Greece; NA","IEEE Transactions on Software Engineering","","2000","26","5","401","422","The authors examine the design, implementation, and experimental analysis of parallel priority queues for device and network simulation. They consider: 1) distributed splay trees using MPI; 2) concurrent heaps using shared memory atomic locks; and 3) a new, more general concurrent data structure based on distributed sorted lists, designed to provide dynamically balanced work allocation and efficient use of shared memory resources. We evaluate performance for all three data structures on a Cray-TSESOO system at KFA-Julich. Our comparisons are based on simulations of single buffers and a 64/spl times/64 packet switch which supports multicasting. In all implementations, PEs monitor traffic at their preassigned input/output ports, while priority queue elements are distributed across the Cray-TBE virtual shared memory. Our experiments with up to 60000 packets and two to 64 PEs indicate that concurrent priority queues perform much better than distributed ones. Both concurrent implementations have comparable performance, while our new data structure uses less memory and has been further optimized. We also consider parallel simulation for symmetric networks by sorting integer conflict functions and implementing a packet indexing scheme. The optimized message passing network simulator can process /spl sim/500 K packet moves in one second, with an efficiency that exceeds /spl sim/50 percent for a few thousand packets on the Cray-T3E with 32 PEs. All developed data structures form a parallel library. Although our concurrent implementations use the Cray-TSE ShMem library, portability can be derived from Open-MP or MP1-2 standard libraries, which will provide support for one-way communication and shared memory lock mechanisms.","0098-5589;1939-3520;2326-3881","","10.1109/32.846298","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=846298","","Sorting;Data structures;Libraries;Switches;Queueing analysis;Analytical models;Tree data structures;Resource management;Packet switching;Traffic control","parallel programming;message passing;application program interfaces;queueing theory;sorting;digital simulation;abstract data types;virtual storage;shared memory systems;Cray computers;packet switching;software libraries","priority queues;sorting methods;parallel simulation;parallel priority queues;network simulation;distributed splay trees;MPI;concurrent heaps;shared memory atomic locks;concurrent data structure;distributed sorted lists;dynamically balanced work allocation;shared memory resources;Cray-TSESOO system;single buffers;packet switch;multicasting;preassigned input/output ports;priority queue elements;Cray-TBE virtual shared memory;concurrent priority queues;concurrent implementations;data structure;symmetric networks;integer conflict functions;packet indexing scheme;optimized message passing network simulator;parallel library;Cray-TSE ShMem library;MPI-2 standard libraries;Open-MP;shared memory lock mechanisms","","11","","33","","","","","","IEEE","IEEE Journals & Magazines"
"Computational improvements in Prolog applications by predicate variable pointers","G. M. Karam","Dept. of Syst. & Comput. Eng., Carleton Univ., Ottawa, Ont., Canada","IEEE Transactions on Software Engineering","","1990","16","5","490","497","The programming tradeoffs between structure-oriented and clause-oriented operations on data structures in Prolog are limited in current implementations because the assertion of clauses that include uninstantiated variables destroys any binding between these variables and those with which they are unified in the execution of the program. Built-in predicates for Prolog that allow one to assert predicate variables pointers, which are constants, rather than uninstantiated variables, are presented. The author shows: the possible performance benefits of clause-oriented implementations of data structures over equivalent structure-oriented versions, the logical implications of the proposed built-in predicates, and their practical significance by integrating them in C-Prolog and evaluating the two different implementations of the symbol table dictionary in D.H.D. Warren's pseudo-Pascal compiler example.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.52772","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=52772","","Dictionaries;Data structures;Assembly;Reactive power;Computational complexity;Logic programming;Manipulator dynamics;Data mining;Computational efficiency;Programming profession","computational complexity;data structures;PROLOG","structure-oriented operations;Warren;computational improvements;Prolog applications;predicate variable pointers;clause-oriented operations;data structures;uninstantiated variables;performance benefits;logical implications;built-in predicates;C-Prolog;symbol table dictionary;pseudo-Pascal compiler","","","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Typestate: A programming language concept for enhancing software reliability","R. E. Strom; S. Yemini","IBM Thomas J. Watson Research Center, P.O. Box 218, Yorktown Heights, NY 10598; IBM Thomas J. Watson Research Center, P.O. Box 218, Yorktown Heights, NY 10598","IEEE Transactions on Software Engineering","","1986","SE-12","1","157","171","The authors introduce a new programming language concept, called typestate, which is a refinement of the concept of type. Whereas the type of a data object determines the set of operations over permitted on the object, typestate determines the subset of these operations which is permitted in a particular context. Typestate tracking is a program analysis technique which enhances program reliability by detecting at compile-time syntactically legal but semantically undefined execution sequences. These include reading a variable before it has been initialized and dereferencing a pointer after the dynamic object has been deallocated. The authors define typestate, give examples of its application, and show how typestate checking may be embedded into a compiler. They discuss the consequences of typestate checking for software reliability and software structure, and summarize their experience in using a high-level language incorporating typestate checking.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312929","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312929","Program analysis;program verification;security;software reliability;type checking;typestate","Computer languages;Context;Software reliability;Program processors;Law","data structures;program compilers;software reliability","programming language;software reliability;typestate;data object;program analysis technique;compile-time;undefined execution sequences;dynamic object;compiler;high-level language","","61","","","","","","","","IEEE","IEEE Journals & Magazines"
"Data structures for parallel resource management","J. Biswas; J. C. Browne","Inst. of Syst. Sci., Nat. Univ. of Singapore, Kent Ridge, Singapore; NA","IEEE Transactions on Software Engineering","","1993","19","7","672","686","The problem of resource management for many processor architectures can be viewed as the problem of simultaneously updating data structures that hold system state. An approach in which the possibility of using structures with weakened specifications is examined, is presented. Specifically, data structures that weaken the specification of a priority queue, permitting it to be updated simultaneously by multiple processes are introduced. Two structures, the concurrent heap and the software banyan are proposed, along with their associated algorithms for update. The algorithms are shown to possess attractive properties of simultaneous update and throughput. The results of simulation and actual implementations show that such data structures can improve the execution times of parallel algorithms quite significantly. These structures are proposed as possible basic building blocks for implementation of resource allocation in operating systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.238568","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=238568","","Data structures;Resource management;Software algorithms;Throughput;Parallel algorithms;Operating systems;Contracts","data structures;parallel algorithms;parallel programming;resource allocation","parallel resource management;processor architectures;data structures;system state;weakened specifications;priority queue;multiple processes;concurrent heap;software banyan;simultaneous update;parallel algorithms;resource allocation;operating systems","","1","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Real-Time Execution Monitoring","B. Plattner","Neu-Technikum Buchs, Buchs, Switzerland.; University of Zurich, 8057 Zurich, Switzerland.","IEEE Transactions on Software Engineering","","1984","SE-10","6","756","764","Today's programming methodology emphasizes the study of static aspects of programs. In practice, however, monitoring a program in execution, i.e., monitoring a process, is routinely done by any programmer whose task it is to produce a reliable piece of software. There are two reasons why one might want to examine the dynamic aspects of a program: first, to evaluate the performance of a program, and hence to assess its overall behavior; and second, to demonstrate the presence of programming errors, isolate erroneous program code, and correct it. This latter task is commonly called ``debugging a program'' and requires a detailed insight into the innards of a program being executed. Today, many computer systems are being used to measure and control real-world processes. The pace of execution of these systems and their control programs is therefore bound to timing constraints imposed by the real-world process. As a step towards solving the problems associated with execution monitoring of real-time programs, we develop a set of appropriate concepts and define the basic requirements for a real-time monitoring facility. As a test case for the theoretical treatment of the topic, we design hardware and software for an experimental real-time monitoring system and describe its implementation.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010304","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010304","Debugging;monitor;performance evaluation;process interaction;process monitor;real-time monitoring;timing","Dynamic programming;Control systems;Programming profession;Computer errors;Error correction codes;Debugging;Process control;Timing;Computerized monitoring;Software testing","","","","51","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Prudent engineering practice for cryptographic protocols","M. Abadi; R. Needham","Syst. Res. Center, Digital Equipment Corp., Palo Alto, CA, USA; NA","IEEE Transactions on Software Engineering","","1996","22","1","6","15","We present principles for designing cryptographic protocols. The principles are neither necessary nor sufficient for correctness. They are however helpful, in that adherence to them would have prevented a number of published errors. Our principles are informal guidelines; they complement formal methods, but do not assume them. In order to demonstrate the actual applicability of these guidelines, we discuss some instructive examples from the literature.","0098-5589;1939-3520;2326-3881","","10.1109/32.481513","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=481513","","Cryptographic protocols;Cryptography;Authentication;Guidelines;Design engineering;Security;Logic;Error analysis;Computer Society;Privacy","cryptography;protocols;distributed processing;message authentication;software engineering","cryptographic protocol design;prudent engineering practice;correctness;formal methods","","178","","36","","","","","","IEEE","IEEE Journals & Magazines"
"On the Selection of an Optimal Set of Indexes","M. Y. L. Ip; L. V. Saxton; V. V. Raghavan","Datatron Processing &amp; Systems Ltd.; NA; NA","IEEE Transactions on Software Engineering","","1983","SE-9","2","135","143","A problem of considerable interest in the design of a database is the selection of indexes. In this paper, we present a probabilistic model of transactions (queries, updates, insertions, and deletions) to a file. An evaluation function, which is based on the cost saving (in terms of the number of page accesses) attributable to the use of an index set, is then developed. The maximization of this function would yield an optimal set of indexes. Unfortunately, algorithms known to solve this maximization problem require an order of time exponential in the total number of attributes in the file. Consequently, we develop the theoretical basis which leads to an algorithm that obtains a near optimal solution to the index selection problem in polynomial time. The theoretical result consists of showing that the index selection problem can be solved by solving a properly chosen instance of the knapsack problem. A theoretical bound for the amount by which the solution obtained by this algorithm deviates from the true optimum is provided. This result is then interpreted in the light of evidence gathered through experiments.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236458","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703030","Approximation algorithm;attribute selection;complexity;knapsack problem;index selection;secondary index","Indexes;Transaction databases;Computer science;Cost function;Polynomials;Degradation;Database systems;Councils;Context modeling;Software algorithms","","Approximation algorithm;attribute selection;complexity;knapsack problem;index selection;secondary index","","24","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Software performance engineering: a case study including performance comparison with design alternatives","C. U. Smith; L. G. Williams","Performance Eng. Services, Santa Fe, NM, USA; NA","IEEE Transactions on Software Engineering","","1993","19","7","720","741","Software performance engineering (SPE) provides an approach to constructing systems to meet performance objectives. The authors illustrate the application of SPE to an example with some real-time properties and demonstrate how to compare performance characteristics of design alternatives. They show how SPE can be integrated with design methods and demonstrate that performance requirements can be achieved without sacrificing other desirable design qualities such as understandability, maintainability, and reusability.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.238572","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=238572","","Software performance;Design engineering;Computer aided software engineering;Application software;Performance analysis;Maintenance engineering;Programming;Delay;Design methodology;Real time systems","quality control;real-time systems;software quality;software reliability","software performance engineering;performance objectives;real-time properties;design alternatives;SPE;performance requirements;understandability;maintainability;reusability","","52","","65","","","","","","IEEE","IEEE Journals & Magazines"
"If Prolog is the Answer, What is the Question? or What it Takes to Support AI Programming Paradigms","D. G. Bobrow","Intelligent Systems Laboratory, Xerox Palo Alto Research Center","IEEE Transactions on Software Engineering","","1985","SE-11","11","1401","1408","Knowledge programming, which makes use of the explicit representation and interpretation of knowledge to create intelligent programs, requires specialized languages and tools to help programmers. Prolog, an implementation of a logic programing language, provides some of these tools; it and other languages have been argued to be the ""best"" way to do such knowledge programming. This paper raises questions which suggest that any single paradigm of programming (e.g., logic programming or object-oriented programming) benefits by being integrated in a single environment with other paradigms of programming. Integration of these paradigms with each other, and within a flexible, user-friendly computing environment is also necessary. Such an environment must provide source level debugging and monitoring facilities, analysis and performance tuning tools, and an extended set of user communication programs.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231888","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701956","Artificial intelligence;knowledge programming;logic programming;loops;object-oriented programming;programming environments;programming paradigms","Artificial intelligence;Logic programming;Object oriented programming;Programming environments;Programming profession;Debugging;Computerized monitoring;Performance analysis;Kernel;Computer languages","","Artificial intelligence;knowledge programming;logic programming;loops;object-oriented programming;programming environments;programming paradigms","","9","","23","","","","","","IEEE","IEEE Journals & Magazines"
"A Note on Synthesis of Inductive Assertions","S. K. Basu","Department of Computer Science, University of Nebraska","IEEE Transactions on Software Engineering","","1980","SE-6","1","32","39","One of the principal impediments to widespread use of automated program verification methodology is due to the user burden of creating appropriate inductive assertions. In this paper, we investigate a class of programs for which such inductive assertions can be mechanically generated from Input-output specifications. This class of programs, called accumulating programs, are iterative realizations of problems in which the required output information is accumulated during successive passes over the input data structures. Obtaining invariant assertions for such programs is shown to be equivalent to the problem of generalizations of specifications to that over an extended closed data domain. For this purpose, a set of basis data elements are to be conceived of as generating the extended domain. An arbitary data element would thus be considered as uniquely decomposable into a sequence of basis elements. The structural relations between the components of a data element are used to extend program behavior and thus obtain the desired invariant.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230460","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702692","Accumulating programs;inductive assertions;linear data domain;program verification","Data structures;Impedance;Computer science;Input variables;Binary trees","","Accumulating programs;inductive assertions;linear data domain;program verification","","6","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Extending State Transition Diagrams for the Specification of HumanComputer Interaction","A. I. Wasserman","Section of Medical Information Science, University of California","IEEE Transactions on Software Engineering","","1985","SE-11","8","699","713","User Software Engineering is a methodology for the specification and implementation of interactive information systems. An early step in the methodology is the creation of a formal executable description of the user interaction with the system, based on augmented state transition diagrams. This paper shows the derivation of the USE transition diagrams based on perceived shortcomings of the ""pure"" state transition diagram approach. In this way, the features of the USE specification notation are gradually presented and illustrated. The paper shows both the graphical notation and the textual equivalent of the notation, and briefly describes the automated tools that support direct execution of the specification.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232519","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702079","Executable specifications;interactive information systems;rapid prototyping;software development methodology;transition diagrams;user interfaces;User Software Engineering","User interfaces;Software engineering;Information systems;Software prototyping;Interactive systems;Design methodology;Programming;Command languages;Database languages;Information science","","Executable specifications;interactive information systems;rapid prototyping;software development methodology;transition diagrams;user interfaces;User Software Engineering","","18","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Why Programming Environments Need Dynamic Data Types","J. W. Goodwin","Software Systems Research Center, Link&#246;ping University","IEEE Transactions on Software Engineering","","1981","SE-7","5","451","457","Data abstraction is a powerful source of program structure and abstraction. There is nothing about it, or the reasons why it works, which restricts it to static applications. Programming environments (PE's) especially need to use data types dynamically, since it is their function to support the programmer in all phases of work with a program. Thus, the PE must proceed smoothly from definition to use to editing of a type.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230853","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702871","Compiler-oriented language;data abstraction;dynamic defining of types;Lisp;programming environments;strong typing","Programming environments;Dynamic programming;Runtime environment;Programming profession;Data structures;Software systems;Contracts;Stress;Program processors;Runtime library","","Compiler-oriented language;data abstraction;dynamic defining of types;Lisp;programming environments;strong typing","","2","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Fault-Tolerant SoFtware Reliability Modeling","R. K. Scott; J. W. Gault; D. F. McAllister","IBM Corporation, Research Triangle Park; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","5","582","592","In situations in which computers are used to manage life-critical situations, software errors that could arise due to inadequate or incomplete testing cannot be tolerated. This paper examines three methods of creating fault-tolerant software systems, Recovery Block, N-Version Programming, and Consensus Recovery Block, and it presents reliability models for each. The models are used to show that one method, the Consensus Recovery Block, is more reliable than the other two.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233463","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702258","Consensus recovery block;fault-tolerant software;N-version programming;recovery block","Fault tolerance;Software reliability;Software testing;Software systems;Costs;Computer errors;Life testing;Fault tolerant systems;System testing;Guidelines","","Consensus recovery block;fault-tolerant software;N-version programming;recovery block","","64","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Towards a Theory of Forward Error Recovery","A. Mili","Department of Informatics, Faculty of Sciences, University of Tunis","IEEE Transactions on Software Engineering","","1985","SE-11","8","735","748","When the state of a program in execution is accidentally altered, a recovery action may be needed before the execution can proceed on. Two approaches exist for the design of recovery actions: backward recovery consists of retrieving a previously saved correct state and restarting the computation; forward recovery consists of generating  (sufficiently) correct state from the current (not too) contaminated state. This paper presents a tentative framework for the study of forward error recovery and then discusses some preliminary results and some future research within the proposed framework.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232523","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702083","Error recovery;exception handling;forward error recovery;program fault-tolerance;while statements","Error correction;Mathematics;Fault tolerance;Councils;Cities and towns;Informatics;Redundancy;Information analysis;Calculus","","Error recovery;exception handling;forward error recovery;program fault-tolerance;while statements","","4","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Some design aspects of databases through Petri net modeling","G. S. Hura; H. Singh; N. K. Nanda","Department of Computer Science, Wright State University, Dayton, OH 45431; Department of Electrical and Computer Engineering, Wayne State University, Detroit, MI 48202; Department of Electronics and Communication Engineering, University of Roorkee, Roorkee 247672, India","IEEE Transactions on Software Engineering","","1986","SE-12","4","505","510","The authors exploit the concepts of Petri nets for the modeling of databases through a meaningful interpretation of various database structures. This has been achieved using, specifically, the reachability and conflict concepts of Petri nets. The concept of conflict has been given a mathematical interpretation to suit its applications to database structures. Starting with a network structure, a new class of application for the reachability equation has been proposed. Based upon this, an algorithm has been postulated to access the data paths between any two specified nodes in the database model. The goal is to provide useful data for the design of databases.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312897","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312897","Database structures;information retrieval decomposition;Petri nets  conflict and reachability concepts;state space representation of Petri nets","Databases;Firing;Petri nets;Mathematical model;Data models;Fires;Equations","database management systems;directed graphs","database design;databases;Petri net modeling;database structures;reachability;conflict;data paths","","6","","","","","","","","IEEE","IEEE Journals & Magazines"
"Comments, with reply, on ""Axiomatizing software test data adequacy"" by E.J. Weyuker","S. H. Zweben; J. S. Gourlay","Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA","IEEE Transactions on Software Engineering","","1989","15","4","496","501","E.J. Weyuker (ibid., vol.SE-12, p.1128-38, Dec. 1986) recently proposed a set of properties which should be satisfied by any reasonable criterion used to claim that a computer program has been adequately tested. The author called these properties 'axioms'. She also evaluated several well-known testing strategies with respect to these properties, and concluded that some of the commonly used strategies failed to satisfy several of the properties. The commenters question both the fundamental nature of the properties and the precision with which they are presented, and illustrate how a number of ideas in E.J. Weyuker's paper can be simplified and clarified through greater precision and a more consistent set of definitions. They also reanalyze the testing strategies after accounting for these inconsistencies. The strategies tend to work better as a result of this reanalysis. The author rebuts the commenter's arguments.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.16609","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=16609","","Software testing;Voting;Databases;Gaussian distribution;Operating systems;Robustness;Fault tolerant systems;Stochastic processes","program testing","software test data adequacy;program testing","","9","","1","","","","","","IEEE","IEEE Journals & Magazines"
"A rely and guarantee method for timed CSP: a specification and design of a telephone exchange","A. Kay; J. N. Reed","Comput. Lab., Oxford Univ., UK; Comput. Lab., Oxford Univ., UK","IEEE Transactions on Software Engineering","","1993","19","6","625","639","A rely and guarantee method for timed communicating sequential processes (TCPSs), by which the behavior of a component belonging to a composite system is specified in terms of what it guarantees to its neighbors and what it relies on from them, is described. The method is illustrated using an overview of the specification of a plain old telephone service together with part of a design that provably satisfies this specification. The specification and design deal with safety, liveness, and troublesome race conditions.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.232027","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=232027","","Telephony;Interconnected systems;Safety;Formal specifications;Switching systems;Protocols;Large-scale systems;Explosions;Europe;Concurrent computing","communicating sequential processes;formal specification;telecommunications computing;telephone exchanges","rely method;telephone exchange;guarantee method;timed communicating sequential processes;specification;telephone service;safety;liveness;troublesome race conditions","","16","","40","","","","","","IEEE","IEEE Journals & Magazines"
"On the optimal checkpointing of critical tasks and transaction-oriented systems","V. Grassi; L. Donatiello; S. Tucci","Dipartimento di Ingegeneria Elettronica, Rome Univ., Italy; NA; NA","IEEE Transactions on Software Engineering","","1992","18","1","72","77","The probability distribution of the overhead caused by the use of the checkpointing rollback recovery technique is evaluated in both cases of a single critical task and of an overall transaction-oriented system. This distribution is obtained in Laplace-Stieltjes transform form, from which all the moments can be easily calculated. Alternatively, inversion methods can be used to evaluate the distribution. The authors propose checkpointing strategies based on the above distribution in order to optimize performance criteria motivated, in the case of critical tasks, by real time constraints, and in the case of transaction-oriented systems, by the need of guaranteeing the users about the maximum system unavailability.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.120317","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=120317","","Checkpointing;Availability;Performance analysis;Database systems;Delay;Steady-state;Probability distribution;Constraint optimization;Real time systems;Resumes","database management systems;Laplace transforms;optimisation;real-time systems;transaction processing","optimal checkpointing;transaction-oriented systems;probability distribution;overhead;checkpointing rollback recovery technique;single critical task;Laplace-Stieltjes transform form;moments;inversion methods;checkpointing strategies;performance criteria;real time constraints;maximum system unavailability","","26","","12","","","","","","IEEE","IEEE Journals & Magazines"
"A structured approach to program optimization","P. Armenise","Eng.-Ingegneira Inf. SpA, Rome, Italy","IEEE Transactions on Software Engineering","","1989","15","2","101","108","Software engineering should provide software engineers with methodologies and tools suitable for use in that small number of applications where efficiency is really important. In order to do that, the optimization process should be a clearly visible phase of the software lifecycle (regardless of the particular software development paradigm adopted), so that it can be regulated, securing the production of good quality and efficient software. With this in mind, the author suggests an approach to program optimization based on a paradigm, a method, some principles and guidelines, and some well-known techniques.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21737","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21737","","Software engineering;Application software;Guidelines;Software quality;Costs;Optimization methods;Maintenance;Hardware;Production;Computer industry","software engineering","program optimization;software engineers;optimization process;software lifecycle;software development paradigm","","9","","33","","","","","","IEEE","IEEE Journals & Magazines"
"Software quality measurement based on fault-detection data","S. Weerahandi; R. E. Hausman","Bellcore, Piscataway, NJ, USA; Bellcore, Piscataway, NJ, USA","IEEE Transactions on Software Engineering","","1994","20","9","665","676","We develop a methodology to measure the quality levels of a number of releases of a software product in its evolution process. The proposed quality measurement plan is based on the faults detected in field operation of the software. We describe how fault discovery data can be analyzed and reported in a framework very similar to that of the QMP (quality measurement plan) proposed by B. Hoadley (1986). The proposed procedure is especially useful in situations where one has only very little data from the latest release. We present details of implementation of solutions to a class of models on the distribution of fault detection times. The conditions under which the families: exponential, Weibull, or Pareto distributions might be appropriate for fault detection times are discussed. In a variety of typical data sets that we investigated one of these families was found to provide a good fit for the data. The proposed methodology is illustrated with an example involving three releases of a software product, where the fault detection times are exponentially distributed. Another example for a situation where the exponential fit is not good enough is also considered.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.317425","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=317425","","Software quality;Software measurement;Fault detection;Area measurement;Data analysis;Surveillance;Switching systems;Software systems;Telephony;Time measurement","software quality;software metrics;software reliability","software quality measurement;fault-detection data;quality levels;software product;quality measurement plan;field operation;fault discovery data;QMP;exponential;Weibull;Pareto distribution;data sets","","5","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Generic lifecycle support in the ALMA environment","A. Van Lamsweerde; B. Delcourt; E. Delor; M. -. Schayes; R. Champagne","Inst. d'Inf., Namur Univ., Belgium; Inst. d'Inf., Namur Univ., Belgium; NA; NA; NA","IEEE Transactions on Software Engineering","","1988","14","6","720","741","ALMA is an environment kernel supporting the elaboration, analysis, documentation, and maintenance of the various products developed during an entire software lifecycle. Its central component is an environment database in which properties about software objects and relations are collected. Two kinds of tools are provided: high-level tools and syntax-directed tools. A basic feature of the ALMA kernel is its genericity. Tools of the first kind are parameterized on software lifecycle models while tools of the second kind are parameterized on formalisms. Versions of specific models and formalisms are generated by a meta-environment, which also generates the environment database structure tailored to the desired lifecycle model. The database support meta-system and the instatiated database support systems it generates are emphasized, including the architectural design decisions made and the mechanisms introduced for achieving parameterization on lifecycle models.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6153","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6153","","Software maintenance;Software tools;Object oriented modeling;Kernel;Spatial databases;Object oriented databases;Relational databases;Documentation;Data models;Productivity","database management systems;programming environments;software tools;system documentation;systems analysis","programming environments;system documentation;ALMA;environment kernel;software lifecycle;environment database;software objects;high-level tools;syntax-directed tools","","20","","38","","","","","","IEEE","IEEE Journals & Magazines"
"Performance of a composite attribute and join index","B. C. Desai","Dept. of Comput. Sci., Concordia Univ., Montreal, Que., Canada","IEEE Transactions on Software Engineering","","1989","15","2","142","152","The use of a composite index known as the B/sub c/-tree is presented; it is based on the concept of the B/sup +/-tree and serves the dual purpose of an attribute and join index and indirectly implements the link sets. The leaf node of the B/sub c/-tree incorporates in each leaf node a reference to all tuples in the database that share common data values of a shared domain. In addition to improving the performance of the join and selection operations, the composite index facilitate the enforcement of structural integrity constraints. The author also presents the results of simulations that compare the performance of this approach with the simple join technique. The proposed approach, in the case of the simulated database, is seen to provide better performance for an average domain value size of greater than between 2 and 4 bytes.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21741","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21741","","Relational databases;Data structures;Application software;Database languages;Data models;Dispersion;Artificial intelligence;Computer aided manufacturing;CADCAM","data structures;relational databases","attribute index;composite index;B/sub c/-tree;B/sup +/-tree;join index;tuples;database;common data values;structural integrity constraints","","10","","33","","","","","","IEEE","IEEE Journals & Magazines"
"The Problem of Equivalence for Entity-Relationship Diagrams","S. Jajodia; P. A. Ng; F. N. Springsteel","Department of Computer Science, University of Missouri; NA; NA","IEEE Transactions on Software Engineering","","1983","SE-9","5","617","630","We investigate the question of when two entity-relationship diagrams (ERD's) should be considered equivalent, in the sense of representing the same information. This question is very important for a database design process which uses the ERD model, and can be interpreted in various ways. We give three natural and increasingly stricter criteria for developing concepts of equivalence for ERD's. We first give a notion of ""domain data compatibility"" which ensures that the ERD's in question represent the same universe of data in an aggregate sense. Then we define the set of functional dependencies which are naturally embedded in each ERD, and use it to develop a concept of ""data dependency equivalence"" which ensures that the ERD's satisfy the same constraints (functional dependencies) among the represented data. Finally, we give our strongest criterion, instance data equivalence, which requires the ERD's to have the same power to represent instances of data. We develop several alternate forms of this third notion, including some giving efficient tableaux tests for its occurrence. Indeed, for each type of equivalence, we give a polynomial-time algorithm to test for it.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.235262","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703101","Codd normal form;entity-relationship diagram;entity-relationship model;functional dependency;natural join;relational database model;third normal form","Relational databases;Erbium;Testing;Computer science;Process design;Aggregates;Polynomials;Data processing;Missiles","","Codd normal form;entity-relationship diagram;entity-relationship model;functional dependency;natural join;relational database model;third normal form","","5","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Reviews, Walkthroughs, and Inspections","G. M. Weinberg; D. P. Freedman","Weinberg and Weinberg, Rural Route Two, Lincoln, NE 68505.; Ethnotech, Inc., P.O. Box 6627, Lincoln, NE 68506.","IEEE Transactions on Software Engineering","","1984","SE-10","1","68","72","Formal technical reviews supply the quality measurement to the ``cost effectiveness'' equation in a project management system. There are several unique formal technical review procedures, each applicable to particular types of technical material and to the particular mix of the Review Committee. All formal technical reviews produce reports on the overall quality for project management, and specific technical information for the producers. These reports also serve as an historic account of the systems development process. Historic origins and future trends of formal and informal technical reviews are discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010200","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010200","Project management;software development management;technical reviews","Inspection;Project management;Costs;Control systems;Software development management;Quality management;Equations;Resource management;Humans;Information management","","","","31","","1","","","","","","IEEE","IEEE Journals & Magazines"
"Knowledge representation and reasoning in the design of composite systems","S. Fickas; B. R. Helm","Dept. of Comput. Sci., Oregon Univ., Eugene, OR, USA; Dept. of Comput. Sci., Oregon Univ., Eugene, OR, USA","IEEE Transactions on Software Engineering","","1992","18","6","470","482","The design process that spans the gap between the requirements acquisition process and the implementation process, in which the basic architecture of a system is defined, and functions are allocated to software, hardware, and human agents. is studied. The authors call this process composite system design. The goal is an interactive model of composite system design incorporating deficiency-driven design, formal analysis, incremental design and rationalization, and design reuse. They discuss knowledge representations and reasoning techniques that support these goals for the product (composite system) that they are designing, and for the design process. To evaluate the model, the authors report on its use to reconstruct the design of two existing composite systems rationally.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.142870","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=142870","","Knowledge representation;Interconnected systems;Process design;Humans;Hardware;Computer architecture;Software design;Artificial intelligence;Elevators;Programming","formal specification;inference mechanisms;knowledge representation;software prototyping;software reusability","composite systems;requirements acquisition;implementation process;human agents;deficiency-driven design;formal analysis;incremental design;rationalization;design reuse;knowledge representations;reasoning techniques","","40","","49","","","","","","IEEE","IEEE Journals & Magazines"
"Analysis of real-time rule-based systems with behavioral constraint assertions specified in Estella","A. M. K. Cheng; J. C. Browne; A. K. Mok; Rwo-Hsi Wang","Dept. of Comput. Sci., Houston Univ., TX, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1993","19","9","863","885","Rule-based expert systems are increasingly used to monitor and control the operations of complex real-time systems which require intensive knowledge-decision processing and human expertise. These embedded AI systems must respond to events in the rapidly changing external environment so that the results of the expert system's computation in each monitor-respond cycle are valid in safely operating the real-time system. Determining how fast an expert system can respond under all possible situations is a difficult problem. We have developed an efficient analysis methodology for a large class of rule-based EQL programs to determine whether a program in this class has bounded response time. In particular, we have identified several sets of primitive behavioral constraint assertions: an EQL program which satisfies all constraints in one of these sets of assertions is guaranteed to have bounded response time. Here, we enhance the applicability of our analysis technique by introducing a facility with which the rule-based programmer can specify application-specific knowledge that is too difficult to be mechanically detected in the new language Estella in order to determine the performance of an even wider range of programs. We also describe efficient algorithms for implementing the analysis tools.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.241770","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=241770","","Real time systems;Knowledge based systems;Expert systems;Monitoring;Delay;Control systems;Humans;Artificial intelligence;Embedded computing;Performance analysis","constraint handling;expert systems;formal specification;knowledge representation;real-time systems","real-time rule-based systems;behavioral constraint assertions;Estella;rule-based expert systems;knowledge-decision processing;human expertise;monitor-respond cycle;bounded response time;rule-based programmer;application-specific knowledge","","24","","29","","","","","","IEEE","IEEE Journals & Magazines"
"A statistical approach to the inspection checklist formal synthesis and improvement","Y. Chernak","25 Zabriskie St., Hackensack, NJ, USA","IEEE Transactions on Software Engineering","","1996","22","12","866","874","Proposes a statistical approach to the formal synthesis and improvement of inspection checklists. The approach is based on defect causal analysis and defect modeling. The defect model is developed using IBM's Orthogonal Defect Classification. A case study describes the steps required and a tool for the implementation. The advantages and disadvantages of both empirical and statistical methods are discussed and compared. It is suggested that a statistical approach should be used in conjunction with the empirical approach. The main advantage of the proposed technique is that it allows us to tune a checklist according to the most recent project experience and to identify optimal checklist items even when a source document does not exist.","0098-5589;1939-3520;2326-3881","","10.1109/32.553635","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=553635","","Inspection;Software performance;Productivity;Computer Society;Cost benefit analysis;Performance analysis;Software testing;Performance evaluation;Computer industry;Information analysis","software engineering;formal specification;inspection;error analysis;classification;program testing;statistics","statistical approach;inspection checklist formal synthesis;inspection checklist improvement;defect causal analysis;defect modeling;IBM Orthogonal Defect Classification;case study;implementation;empirical approach;checklist tuning;recent project experience;optimal checklist items identification;source document;software inspection;software testing","","23","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Dataflow computing models, languages, and machines for intelligence computations","J. Herath; Y. Yamaguchi; N. Saito; T. Yuba","Dept. of Comput. Sci., George Mason Univ., Fairfax, VA, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1988","14","12","1805","1828","The authors compare dataflow computing models, languages, and dataflow computing machines for numerical and nonnumerical computations. The high-level-language-graph transformations that must be performed to achieve high performance for numerical and nonnumerical programs executed in a dataflow computing environment are described for Lisp, using the DCBL transformations. Some general problems of dataflow computing machines are discussed. Performance evaluation measurements obtained by executing benchmark programs in the ETL nonnumerical dataflow computing environment, the EM-3, are presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.9065","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=9065","","Machine intelligence;Concurrent computing;Parallel processing;Algorithm design and analysis;Hardware;Processor scheduling;Physics computing;Computer science education;Computational modeling;Parallel algorithms","high level languages;LISP;parallel machines;parallel programming;performance evaluation","performance evaluation;functional programming;dataflow languages;parallel programming;intelligence computations;dataflow computing models;dataflow computing machines;high-level-language-graph transformations;dataflow computing environment;Lisp;DCBL;benchmark programs;ETL;EM-3","","16","","65","","","","","","IEEE","IEEE Journals & Magazines"
"Trace-based load characterization for generating performance software models","C. E. Hrischuk; C. Murray Woodside; J. A. Rolia","Dept. of Electr. & Comput. Eng., Alberta Univ., Edmonton, Alta., Canada; NA; NA","IEEE Transactions on Software Engineering","","1999","25","1","122","135","Performance models of software designs can give early warnings of problems such as resource saturation or excessive delays. However models are seldom used because of the considerable effort needed to construct them. The ANGIOTRACE/sup TM/ was developed to gather the necessary information from an executable design and develop a model in an automated fashion. It applies to distributed and concurrent software with synchronous (send-reply or RPC) communications, developing a layered queuing network model. The trace-based load characterization (TLC) technique presented here extends the ANGIOTRACE/sup TM/ to handle software with both synchronous and asynchronous interactions. TLC also detects interactions which are effectively synchronous or partly-synchronous (forwarding) but are built up from asynchronous messages. These patterns occur in telephony software and in other systems. The TLC technique can be applied throughout the software life-cycle, even after deployment.","0098-5589;1939-3520;2326-3881","","10.1109/32.748921","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=748921","","Character generation;Software performance;Delay;Software design;Queueing analysis;Operating systems;Telephony;Failure analysis;Risk analysis;Performance analysis","software performance evaluation;computer telephony integration;system monitoring","performance models;software designs;trace-based load characterization;resource saturation;excessive delay;ANGIOTRACE;executable design;automated model development;concurrent software;distributed software;synchronous communication;layered queuing network model;asynchronous interactions;synchronous interactions;asynchronous messages;telephony software;software life-cycle","","28","","","","","","","","IEEE","IEEE Journals & Magazines"
"On Deadlock Detection in Distributed Systems","V. D. Gligor; S. H. Shattuck","Department of Computer Science, University of Maryland; NA","IEEE Transactions on Software Engineering","","1980","SE-6","5","435","440","A hierarchically organized and a distributed protocol for deadlock detection in distributed databases are presented in [1]. In this paper we show that the distributed protocol is incorrect, and present possible remedies. However, the distributed protocol remains impractical because ""condensations"" of ""transaction-wait-for"" graphs make graph updates difficult to perform. Delayed graph updates cause the occurrence of false deadlocks in this as well as in some other deadlock detection protocols for distributed systems. The performance degradation that results from false deadlocks depends on the characteristics of each protocol.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230491","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702759","Deadlock detection;delayed graph updates;distributed systems;false deadlocks;on-line protocols;ostensibly blocked transactions;out-of-order graph updates","System recovery;Protocols;Delay;Out of order;Distributed computing;Concurrent computing;Distributed databases;Transaction databases;Degradation;Multiprocessing systems","","Deadlock detection;delayed graph updates;distributed systems;false deadlocks;on-line protocols;ostensibly blocked transactions;out-of-order graph updates","","46","","7","","","","","","IEEE","IEEE Journals & Magazines"
"An accurate worst case timing analysis for RISC processors","Sung-Soo Lim; Young Hyun Bae; Gyu Tae Jang; Byung-Do Rhee; Sang Lyul Min; Chang Yun Park; Heonshik Shin; Kunsoo Park; Soo-Mook Moon; Chong Sang Kim","Dept. of Comput. Eng., Seoul Nat. Univ., South Korea; Dept. of Comput. Eng., Seoul Nat. Univ., South Korea; Dept. of Comput. Eng., Seoul Nat. Univ., South Korea; Dept. of Comput. Eng., Seoul Nat. Univ., South Korea; Dept. of Comput. Eng., Seoul Nat. Univ., South Korea; NA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1995","21","7","593","604","An accurate and safe estimation of a task's worst case execution time (WCET) is crucial for reasoning about the timing properties of real time systems. In RISC processors, the execution time of a program construct (e.g., a statement) is affected by various factors such as cache hits/misses and pipeline hazards, and these factors impose serious problems in analyzing the WCETs of tasks. To analyze the timing effects of RISC's pipelined execution and cache memory, we propose extensions to the original timing schema where the timing information associated with each program construct is a simple time bound. In our approach, associated with each program construct is worst case timing abstraction, (WCTA), which contains detailed timing information of every execution path that might be the worst case execution path of the program construct. This extension leads to a revised timing schema that is similar to the original timing schema except that concatenation and pruning operations on WCTAs are newly defined to replace the add and max operations on time bounds in the original timing schema. Our revised timing schema accurately accounts for the timing effects of pipelined execution and cache memory not only within but also across program constructs. The paper also reports on preliminary results of WCET analysis for a RISC processor. Our results show that tight WCET bounds (within a maximum of about 30% overestimation) can be obtained by using the revised timing schema approach.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.392980","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=392980","","Computer aided software engineering;Timing;Reduced instruction set computing;Real time systems;Cache memory;Moon;Pipelines;Hazards;Information analysis;Processor scheduling","reduced instruction set computing;instruction sets;cache storage;real-time systems;timing;pipeline processing","accurate worst case timing analysis;RISC processors;worst case execution time;timing properties;real time systems;program construct;cache hits/misses;pipeline hazards;pipelined execution;timing schema extension;worst case timing abstraction;worst case execution path;revised timing schema;tight WCET bounds;WCTA","","79","","31","","","","","","IEEE","IEEE Journals & Magazines"
"A New Method for Concurrency in B-Trees","Yat-Sang Kwong; D. Wood","MICOM Company; NA","IEEE Transactions on Software Engineering","","1982","SE-8","3","211","222","In this paper we study the problem of supporting concurrent operations in B-trees and their variants. A survey of previous work is given and two basic types of solutions to this problem are identified. A new solution with a greater degree of concurrency is proposed. As solutions are surveyed or presented we identify useful techniques which have wider applicability. In particular, we introduce the technique of side-branching in our new solution.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235251","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702938","B-trees;concurrent operations;lock-coupling;side-branching","Concurrent computing;Data structures;Databases;Particle separators;Concurrency control;System recovery;Interleaved codes;Costs;Councils;Computer science","","B-trees;concurrent operations;lock-coupling;side-branching","","34","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Seesoft-a tool for visualizing line oriented software statistics","S. C. Eick; J. L. Steffen; E. E. Sumner","AT&T Bell Lab., Naperville, IL, USA; AT&T Bell Lab., Naperville, IL, USA; AT&T Bell Lab., Naperville, IL, USA","IEEE Transactions on Software Engineering","","1992","18","11","957","968","The Seesoft software visualization system allows one to analyze up to 50000 lines of code simultaneously by mapping each line of code into a thin row. The color of each row indicates a statistic of interest, e.g., red rows are those most recently changed, and blue are those least recently changed. Seesoft displays data derived from a variety of sources, such as version control systems that track the age, programmer, and purpose of the code (e.g., control ISDN lamps, fix bug in call forwarding); static analyses, (e.g., locations where functions are called); and dynamic analyses (e.g., profiling). By means of direct manipulation and high interaction graphics, the user can manipulate this reduced representation of the code in order to find interesting patterns. Further insight is obtained by using additional windows to display the actual code. Potential applications for Seesoft include discovery, project management, code tuning, and analysis of development methodologies.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.177365","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=177365","","Software tools;Statistics;Displays;Control systems;Software systems;Data visualization;Simultaneous localization and mapping;Programming profession;ISDN;Lamps","configuration management;data visualisation;project management;software tools","Seesoft;tool;line oriented software statistics;software visualization system;version control systems;ISDN lamps;call forwarding;static analyses;dynamic analyses;direct manipulation;high interaction graphics;discovery;project management;code tuning;development methodologies","","234","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Design wizards and visual programming environments for GenVoca generators","D. Batory; Gang Chen; E. Robertson; Tao Wang","Dept. of Comput. Sci., Texas Univ., Austin, TX, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","2000","26","5","441","452","Domain-specific generators will increasingly rely on graphical languages for declarative specifications of target applications. Such languages will provide front-ends to generators and related tools to produce customized code on demand. Critical to the success of this approach will be domain-specific design wizards, tools that guide users in their selection of components for constructing particular applications. The authors present the P3 ContainerStore graphical language, its generator, and design wizard.","0098-5589;1939-3520;2326-3881","","10.1109/32.846301","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=846301","","Programming environments;Data structures;Application software;Java;Containers;DSL;Computer languages;Libraries;EMP radiation effects;Computer Society","application generators;programming environments;visual programming;visual languages;user interfaces","design wizards;visual programming environments;GenVoca generators;domain-specific generators;graphical languages;declarative specifications;target applications;front-ends;customized code;P3 ContainerStore graphical language","","35","","39","","","","","","IEEE","IEEE Journals & Magazines"
"Program correctness: on inductive assertion methods","J. C. King","IBM Research","IEEE Transactions on Software Engineering","","1980","SE-6","5","465","479","A study of several of the proof of correctness methods is presented. In particular, the form of induction used is explored in detail. A relational semantic model for programming languages is introduced and its relation to predicate transformers is explored. A rather elementary viewpoint is taken in order to expose, as simply as possible, the basic differences of the methods and the underlying principles involved. These results were obtained by attempting to thoroughly understand the ""subgoal induction"" method.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230787","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702763","Correctness assertions;predicate transformers;program correctness;program proofs;relational semantics;subgoal induction;weakest preconditions","Transformers;Artificial intelligence;Computer languages;Induction generators;Terminology;Displays","","Correctness assertions;predicate transformers;program correctness;program proofs;relational semantics;subgoal induction;weakest preconditions","","4","","6","","","","","","IEEE","IEEE Journals & Magazines"
"A software environment for the specification and analysis of problems of coordination and concurrency","S. Aggarwal; D. Barbara; K. Z. Meth","AT&T Bell Labs., Murray Hill, NJ, USA; NA; NA","IEEE Transactions on Software Engineering","","1988","14","3","280","290","The SPANNER software environment for the specification and analysis of concurrent process coordination and resource sharing coordination is described. In the SPANNER environment, one can formally produce a specification of a distributed computing problem, and then verify its validity through reachability analysis and simulation. SPANNER is based on a finite-state machine model called the selection/resolution model. The capabilities of SPANNER are illustrated by the analysis of two classical coordination problems: (1) the dining philosophers; and (2) Dijkstra's concurrent programming problem. In addition, some of the more recently implemented capabilities of the SPANNER system are discussed, such as process types and cluster variables.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4649","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4649","","Protocols;Automata;Distributed computing;Concurrent computing;Computational modeling;Resource management;Analytical models;Computer languages;Kalman filters;Parallel languages","distributed processing;parallel programming;programming environments","software environment;specification;coordination;concurrency;SPANNER software environment;distributed computing;reachability analysis;simulation;finite-state machine model;selection/resolution model;dining philosophers;concurrent programming;cluster variables","","15","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Understanding and Documenting Programs","V. R. Basili; H. D. Mills","Department of Computer Science, University of Maryland; NA","IEEE Transactions on Software Engineering","","1982","SE-8","3","270","283","This paper reports on an experiment in trying to understand an unfamiliar program of some complexity and to record the authors' understanding of it. The goal was to simulate a practicing programmer in a program maintenance environment using the techniques of program design adapted to program understanding and documentation; that is, given a program, a specification and correctness proof were developed for the program. The approach points out the value of correctness proof ideas in guiding the discovery process. Toward this end, a variety of techniques were used: direct cognition for smaller parts, discovering and verifying loop invariants for larger program parts, and functions determined by additional analysis for larger program parts. An indeterminate bounded variable was introduced into the program documentation to summarize the effect of several program variables and simplify the proof of correctness.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235255","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702942","Program analysis;program correctness;program documentation;proof techniques;software maintenance","Milling machines;Documentation;Programming profession;Cognition;Computer science;Software maintenance;Writing","","Program analysis;program correctness;program documentation;proof techniques;software maintenance","","22","","7","","","","","","IEEE","IEEE Journals & Magazines"
"PROSPEC: an interactive programming environment for designing and verifying communication protocols","C. -. Chow; S. S. Lam","Dept. of Comput. Sci., Texas Univ., Austin, TX, USA; Dept. of Comput. Sci., Texas Univ., Austin, TX, USA","IEEE Transactions on Software Engineering","","1988","14","3","327","338","The PROSPEC software environment for designing and verifying communication protocols is described. It integrates several tools that implement methods for protocol verification and construction (i.e., fair reachability analysis, multiphase construction, and protocol projection). The system provides a unified graphical interface to facilitate the application of these methods and creates an interactive environment for specifying, verifying, and designing communication protocols. PROSPEC was used successfully to design and verify versions of BSC, X.21, X.25, and Telnet document transfer protocols.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4653","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4653","","Programming environments;Protocols;Reachability analysis;Automata;Software design;Computer errors;Power system modeling;Application software;Formal specifications;Software tools","interactive programming;programming environments;protocols;software tools","communication protocols verification;specification;PROSPEC;interactive programming environment;fair reachability analysis;multiphase construction;protocol projection;graphical interface;BSC;X.21;X.25;Telnet document transfer protocols","","7","","40","","","","","","IEEE","IEEE Journals & Magazines"
"The Noisy Substring Matching Problem","R. L. Kashyap; B. J. Oommen","School of Electrical Engineering, Purdue University; NA","IEEE Transactions on Software Engineering","","1983","SE-9","3","365","370","Let T(U) be the set of words in the dictionary H which contains U as a substring. The problem considered here is the estimation of the set T(U) when U is not known, but Y, a noisy version of U is available. The suggested set estimate S*(Y) of T(U) is a proper subset of H such that its every element contains at least one substring which resembles Y most according to the Levenshtein metric. The proposed algorithm for-the computation of S*(Y) requires cubic time. The algorithm uses the recursively computable dissimilarity measure Dk(X, Y), termed as the kth distance between two strings X and Y which is a dissimilarity measure between Y and a certain subset of the set of contiguous substrings of X. Another estimate of T(U), namely SM(Y) is also suggested. The accuracy of SM(Y) is only slightly less than that of S*(Y), but the computation time of SM(Y) is substantially less than that of S*(Y). Experimental results involving 1900 noisy substrings and dictionaries which are subsets of 1023 most common English words [11] indicate that the accuracy of the estimate S*(Y) is around 99 percent and that of SM(Y) is about 98 percent.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.237018","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703065","Error correction in strings;Levenshtein metric;noisy substring matching;string dissimilarity in terms of the dissimilarity of their substrings;string set estimation;text editing","Dictionaries;Databases;Recursive estimation;Computer science;Information retrieval","","Error correction in strings;Levenshtein metric;noisy substring matching;string dissimilarity in terms of the dissimilarity of their substrings;string set estimation;text editing","","17","","11","","","","","","IEEE","IEEE Journals & Magazines"
"The effect of imperfect error detection on reliability assessment via life testing","P. E. Ammann; S. S. Brilliant; J. C. Knight","Dept. of Inf. & Software Syst. Eng., George Mason Univ., Fairfax, VA, USA; NA; NA","IEEE Transactions on Software Engineering","","1994","20","2","142","148","Measurement of software reliability by life testing involves executing the software on large numbers of test cases and recording the results. The number of failures observed is used to bound the failure probability even if the number of failures observed is zero. Typical analyses assume that all failures that occur are observed, but, in practice, failures occur without being observed. In this paper, we examine the effect of imperfect error detection, i.e. the situation in which a failure of the software may not be observed. If a conventional analysis associated with life testing is used, the confidence in the bound on the failure probability is optimistic. Our results show that imperfect error detection does not necessarily limit the ability of life testing to bound the probability of failure to the very low values required in critical systems. However, we show that the confidence level associated with a bound on failure probability cannot necessarily be made as high as desired, unless very strong assumptions are made about the error detection mechanism. Such assumptions are unlikely to be met in practice, and so life testing is likely to be useful only for situations in which very high confidence levels are not required.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.265635","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=265635","","Life testing;Software testing;Failure analysis;Life estimation;Software reliability;Hardware;Software measurement;Predictive models;NASA;Software systems","software reliability;error detection;life testing;probability","imperfect error detection;software reliability assessment;life testing;test cases;failure probability;unobserved failures;test oracles;critical systems;confidence level;software testing","","21","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Software congestion, mobile servers, and the hyperbolic model","M. L. Fontenot","AT&T Bell Labs., Denver, CO, USA","IEEE Transactions on Software Engineering","","1989","15","8","947","962","The phenomenon of software congestion is examined. The term refers to situations in which the performance bottleneck of a system is an element of software, rather than a hardware device. Software congestion can occur in any system which contains one or more elements of software whose services may be simultaneously desired by multiple clients, but which can service only one client at a time. It is shown that the use of models which ignore software congestion can produce results that are completely irrelevant to actual system behavior. Furthermore, software congestion is frequently invisible to conventional performance measurement tools. A notational scheme, called mobile servers representation, is introduced for describing those systems in which software congestion may be important. An approximate analytical model, called the hyperbolic model, is developed for analyzing systems with software congestion.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.31352","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=31352","","Software performance;Hardware;Software systems;Databases;Software tools;Measurement;Analytical models;Network servers;Performance analysis","fault tolerant computing;performance evaluation;specification languages","system performance bottleneck;system description;simultaneously desired software elements;irrelevant results;residual capacity model;software congestion system analysis;mobile servers;software congestion;multiple clients;system behavior;invisible;performance measurement tools;notational scheme;mobile servers representation;analytical model;hyperbolic model","","15","","18","","","","","","IEEE","IEEE Journals & Magazines"
"The last 10 percent","R. F. Mathis","9712 Ceralene Drive, Fairfax, VA 22032","IEEE Transactions on Software Engineering","","1986","SE-12","6","705","712","Following a brief summary of the background and goals of developments in software engineering, some of the major thrusts in the future of program development and maintenance are discussed. Various national level software initiatives are discussed in this context. This is not a comparative survey of their plans and activities. The central issues addressed relate to the understandability of programming, the reuse of software, and the general problem of working with and improving a program that is already almost the one desired. This is the phase of the process after the system is `90% done', hence the emphasis on the `last 10 percent'.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312968","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312968","Computer initiatives;programming environments;software maintenance;software reuse","Software;Programming;Computers;Hardware;Companies;US Department of Defense;Buildings","DP management;software engineering","program maintenance;software engineering;program development;national level software initiatives","","3","","","","","","","","IEEE","IEEE Journals & Magazines"
"Learning to detect and avoid run-time feature interactions in intelligent networks","S. Tsang; E. H. Magill","Signaling & Protocols Unit, BT&D Technol. Ltd., Ipswich, UK; NA","IEEE Transactions on Software Engineering","","1998","24","10","818","830","The Intelligent Network (IN) allows rapid changes in the services provisioned and their functionality. Services may be supplied by different service providers, making it unlikely that all service specifications will be available for examination by any single agency. Approaches to handle feature interaction problems must be able to operate within these constraints. Work by the authors has produced a generic run time feature interaction manager (FIM) concept to manage feature interactions in a live network. It monitors features as black boxes, learns their ""correct"" behavior and uses this to determine when feature interactions have occurred. The paper describes and compares experiences using three different techniques to realize the proposed approach. These are: state sequence monitoring, artificial neural networks (ANN), and rule based monitoring which also includes integrated generic resolution approaches. The paper explores the design alternatives with the various techniques, and reports on the results obtained from experimentation.","0098-5589;1939-3520;2326-3881","","10.1109/32.729682","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=729682","","Intelligent networks;Runtime;Artificial neural networks;Monitoring;Telecommunication control;Telecommunication network management;Telecommunication services;Process design;Telephony;Testing","intelligent networks;telecommunication computing;knowledge based systems;telecommunication services;neural nets;computerised monitoring","run time feature interactions;intelligent networks;service provisioning;service providers;service specifications;feature interaction problems;generic run time feature interaction manager;live network;black boxes;state sequence monitoring;artificial neural networks;rule based monitoring;integrated generic resolution approaches","","12","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Statistical and Scientific Database Issues","A. Shoshani; H. K. T. Wong","Lawrence Berkeley Laboratory, University of California; NA","IEEE Transactions on Software Engineering","","1985","SE-11","10","1040","1047","The purpose of this paper is to summarize the research issues of statistical and scientific databases (SSDB's). It organizes the issues into four major groups: physical organization and access methods, operators, logical organization and user interfaces, and miscellaneous issues. It emphasizes the differences between SSDB's and traditional database applications, and motivates the need for new and innovative techniques for the support of SSDB's. In addition to describing current work in this field, it discusses open research areas and proposes possible approaches to their solution.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231851","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701919","Database management;multidimensional data;scientific databases;statistical databases","Multidimensional systems;Business;Detectors;User interfaces;Database systems;Design automation;Computer aided manufacturing;CADCAM;Very large scale integration;Knowledge based systems","","Database management;multidimensional data;scientific databases;statistical databases","","15","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Performance considerations for an operating system transaction manager","A. Kumar; M. Stonebraker","Graduate Sch. of Manage., Cornell Univ., Ithaca, NY, USA; NA","IEEE Transactions on Software Engineering","","1989","15","6","705","714","Results of a previous comparison study (A. Kumar and M. Stonebraker, 1987) between a conventional transaction manager and an operating system (OS) transaction manager indicated that the OS transaction manager incurs a severe performance penalty and appears to be feasible only in special circumstances. Three approaches for enhancing the performance of an OS transaction manager are considered. The first strategy is to improve performance by reducing the cost of lock acquisition and by compressing the log. The second strategy explores the possibility of still further improvements from additional semantics to be built into an OS transaction system. The last strategy is to use a modified index structure that makes update operations less expensive to perform. The results show that the OS will have to implement essentially all of the specialized tactics for transaction management that are currently used by a database management system (DBMS) in order to match DBMS performance.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24724","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24724","","Operating systems;Protocols;Computer crashes;Database systems;Concurrency control;Proposals;Environmental management;Knowledge management;Costs;Indexing","data structures;database management systems;operating systems (computers);performance evaluation;software reliability;transaction processing","log compressing;performance;considerations;operating system transaction manager;conventional transaction manager;OS transaction manager;performance penalty;lock acquisition;additional semantics;OS transaction system;modified index structure;update operations;transaction management;database management system;DBMS performance","","5","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Decomposition and aggregation by class in closed queueing networks","A. E. Conway; N. D. Georganas","Department of Electrical Engineering, University of Ottawa, Ottawa, Ont., Canada; Department of Electrical Engineering, McGill University, Montreal, P.Q., Canada; Department of Electrical Engineering, University of Ottawa, Ottawa, Ont., Canada","IEEE Transactions on Software Engineering","","1986","SE-12","10","1025","1040","A method is described whereby a multiple-class closed network of first-come first-served (FCFS) queues can be analyzed exactly by a decomposition and aggregation procedure that proceeds class by class, rather than node by node. First, the FCFS network is transformed into an equivalent network of processor-sharing queues in which a hierarchy of subsystems associated with subsets of the classes may be identified. This decomposition and aggregation procedure reduces the multiple-class queuing networks into a hierarchy of single-class queueing network problems. The reduced system is constructed containing one particular class of customers. A parametric analysis of this class with respect to the routing can then be made. The time and space requirements of this parametric analysis technique are derived and compared to the requirements of a straightforward repetitive analysis of the network using the convolution algorithm. An example parametric analysis of a store-and-forward communication network model is given.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6313019","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6313019","Decomposition;exact aggregation;Markov chains;network of queues;parametric analysis;performance evaluation;queueing theory","Queueing analysis;Matrix decomposition;Routing;Computers;Servers;Markov processes;Vectors","computer networks;queueing theory","decomposition;aggregation;closed queueing networks;multiple-class closed network;processor-sharing queues;parametric analysis;convolution algorithm;store-and-forward communication network model","","","","","","","","","","IEEE","IEEE Journals & Magazines"
"A distributed scheme for detecting communication deadlocks","N. Natarajan","Department of Computer Science, the Pennsylvania State University, University Park, PA 16802","IEEE Transactions on Software Engineering","","1986","SE-12","4","531","537","A distributed system is an interconnected network of computing elements or nodes, each of which has its own storage. A distributed program is a collection of processes which execute asynchronously, possibly in different nodes of a distributed system, and they communicate with each other in order to realize a common goal. In such an environment, a group of processes may sometimes get involved in a communication deadlock. This is a situation in which each member process of the group is waiting for some member to communicate with it, but no member is attempting communication with it. The author presents an algorithm for detecting such communication deadlocks. The algorithm is distributed; i.e. processes detect deadlocks during the course of their communication, without the aid of a central controller. The detection scheme does not presume any a priori structure among processes, and detection is made `on the fly' without freezing normal activities. The scheme does not require any storage whose size is determined by the size of the network, and hence is suitable also for an environment where processes are created dynamically.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312900","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312900","Communication;computing agents;deadlock;distributed program;distributed system","System recovery;Synchronization;Detectors;Kernel;Detection algorithms;Educational institutions","computer networks;distributed processing;system recovery","on the fly detection;distributed scheme;communication deadlocks;interconnected network;computing elements;central controller","","22","","","","","","","","IEEE","IEEE Journals & Magazines"
"Data Integration in Distributed Databases","S. M. Deen; R. R. Amin; M. C. Taylor","Department of Computer Science, University of Keele; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","7","860","864","Data integration in a distributed database refers to the production of union-compatible views for similar information expressed dissimilarly in different nodes. Such a facility is needed for location transparency and for easier formulation of global queries over the apparently incompatible data aggregated from different nodes. This paper examines the issues in data integration within a relational context, and proposes a solution based on special relational constructs which produce union-compatible relations. The advantages of this approach over others have also been discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233497","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702297","","Distributed databases;Relational databases;Database systems;Data models;Production;Councils;Computer science","","","","19","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Literate Smalltalk programming using hypertext","K. Osterbye","Aalborg Univ., Denmark","IEEE Transactions on Software Engineering","","1995","21","2","138","145","The problem examined in this paper is: how and to what extent can hypertext support literate programming in Smalltalk? In order to examine this question we have created a hypertext system which allows us to write Smalltalk code and documentation, and to link code and documentation freely. The literate programs created in hypertext differ from those created with traditional literate programming tools. The main difference is that hypertext-based program exposition promotes description of program dependencies and is perhaps less suited for the detailed exposition of algorithms.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.345829","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=345829","","Hypertext systems;Documentation;Humans;Programming environments;Software engineering;Program processors;Project management;Software development management;Object oriented modeling;File systems","Smalltalk;object-oriented programming;programming environments;software tools;hypermedia;system documentation","Smalltalk programming;hypertext;literate programming;Smalltalk code;documentation;literate programming tools;program dependencies;programming environments;object oriented programming","","7","","20","","","","","","IEEE","IEEE Journals & Magazines"
"State-based model checking of event-driven system requirements","J. M. Atlee; J. Gannon","Dept. of Comput. Sci., Waterloo Univ., Ont., Canada; NA","IEEE Transactions on Software Engineering","","1993","19","1","24","40","It is demonstrated how model checking can be used to verify safety properties for event-driven systems. SCR tabular requirements describe required system behavior in a format that is intuitive, easy to read, and scalable to large systems (e.g. the software requirements for the A-7 military aircraft). Model checking of temporal logics has been established as a sound technique for verifying properties of hardware systems. An automated technique for formalizing the semiformal SCR requirements and for transforming the resultant formal specification onto a finite structure that a model checker can analyze has been developed. This technique was effective in uncovering violations of system invariants in both an automobile cruise control system and a water-level monitoring system.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.210305","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=210305","","Thyristors;Safety;Software systems;Military aircraft;Logic;Hardware;Formal specifications;Automobiles;Automatic control;Control systems","formal specification;formal verification","event-driven system requirements;model checking;SCR tabular requirements;software requirements;A-7 military aircraft;temporal logics;formal specification;system invariants;automobile cruise control system;water-level monitoring system","","102","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Antisampling for Estimation: An Overview","N. C. Rowe","Department of Computer Science","IEEE Transactions on Software Engineering","","1985","SE-11","10","1081","1091","We survey a new way to get quick estimates of the values of simple statistks (like count, mean, standard deviation, maximum, median, and mode frequency) on a large data set. This approach is a comprehensive attempt (apparently the first) to estimate statistics without any sampling. Our ""antisampling"" techniques have analogies to those of sampling, and exhibit similar estimation accuracy, but can be done much faster than sampling with large computer databases. Antisampling exploits computer science ideas from database theory and expert systems, building an auxiliary structure called a ""database abstract."" We make detailed comparisons to several different kinds of sampling.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231855","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701923","Estimation;expert systems;inequalities;parametric optimization;query processing;sampling;statistical computing;statistical databases","Sampling methods;Databases;Statistical distributions;Frequency estimation;Computer science;Expert systems;Parametric statistics;Costs;Buildings;Query processing","","Estimation;expert systems;inequalities;parametric optimization;query processing;sampling;statistical computing;statistical databases","","6","","27","","","","","","IEEE","IEEE Journals & Magazines"
"On parallel processing systems: Amdahl's law generalized and some results on optimal design","L. Kleinrock; J. -. Huang","Dept. of Comput. Sci., California Univ., Los Angeles, CA, USA; NA","IEEE Transactions on Software Engineering","","1992","18","5","434","447","The authors model a job in a parallel processing system as a sequence of stages, each of which requires a certain integral number of processors for a certain interval of time. They derive the speedup of the system for two cases: systems with no arrivals, and systems with arrivals. In the case with no arrivals, their speedup result is a generalization of Amdahl's law (G.M. Amdahl, 1967). They extend the notion of power as previously applied to general queuing and computer-communication systems to their case of parallel processing systems. They find the optimal job input and the optimal number of processors to use so that power is maximized. Many of the results for the case of arrivals are the same as for the case of no arrivals. It is found that the average number of jobs in the system with arrivals equals unity when power is maximized. They also model a job in such a way that the number of processors required continuously varies over time. The same performance indices and parameters studied in the discrete model are evaluated for this continuous model.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.135776","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=135776","","Parallel processing;Power system modeling;Job design;Delay;Computer science;Throughput;Concurrent computing;Process design","computer communications software;operating systems (computers);parallel processing;queueing theory","Amdahl law;optimal design;parallel processing system;speedup result;power;general queuing;computer-communication systems;optimal job input;performance indices;discrete model;continuous model","","19","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Foreword","V. D. Gligor; P. A. B. Ng","Department of Electrical Engineering University of Maryland; NA","IEEE Transactions on Software Engineering","","1985","SE-11","6","497","501","THE concepts of system reliability&#8211;generally defined as the ability of a system to meet its interface specifications-and of system availability&#8211;generally defined as the ability of a system to meet its interface specifications within a specified time limit&#8211;predate not only that of distributed computing but also that of the electronic computer itself. With the advent of the electronic computer and its ever increasing penetration of technological, social, and political developments, reliability and availability gained additional recognition as disciplines of serious intellectual challenge. Much of the development of new reliability techniques can be linked directly to the computer hardware developments of the last three decades. However, until relatively recently, the concept of software reliability did not receive significant attention and, when it did, it was rather narrowly focused on approaches to prevent failures; i.e., on software development and verification methodologies, and on languages and tools.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232241","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702046","","Availability;Redundancy;Distributed computing;Hardware;Software systems;Database systems;Algorithm design and analysis;Computer interfaces;Software reliability;Programming","","","","9","","18","","","","","","IEEE","IEEE Journals & Magazines"
"A class of inherently fault tolerant distributed programs","F. B. Bastani; I. -. Yen; I. -. Chen","Dept. of Comput. Sci., Houston Univ., TX, USA; Dept. of Comput. Sci., Houston Univ., TX, USA; Dept. of Comput. Sci., Houston Univ., TX, USA","IEEE Transactions on Software Engineering","","1988","14","10","1432","1442","Software for industrial process-control systems, such as nuclear power plant safety control systems and robots, can be very complex because of the large number of cases that must be considered. A design approach is proposed that uses decentralized control concepts, and is based on E.W. Dijkstra's concept of self-stabilizing systems (1974). This method greatly simplifies the software, so that its correctness can be verified more easily. A simple control system is described for a simulated robot that is tolerant of partial failure of controllers and mechanisms, and permits online repair and enhancement of the control functions.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6188","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6188","","Fault tolerance;Software safety;Computer industry;Electrical equipment industry;Industrial control;Power generation;Robot control;Control systems;Service robots;Distributed control","distributed processing;fault tolerant computing;industrial robots;program verification;programming theory;robot programming","fault tolerant distributed programs;industrial process-control;decentralized control concepts;self-stabilizing systems;correctness;robot","","28","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Supporting search for reusable software objects","T. Isakowitz; R. J. Kauffman","Stern Sch. of Bus., New York Univ., NY, USA; NA","IEEE Transactions on Software Engineering","","1996","22","6","407","423","Prior research has shown that achieving high levels of software reuse in the presence of repository and object-based computer-aided software engineering (CASE) development methods presents interesting human, managerial and technical challenges. This article presents research that seeks to enhanced software development performance through reuse. We propose automated support for developers who search large repositories for the appropriate reusable software objects. We characterize search for repository objects in terms of a multistage model involving screening, identification, and the subsequent choice between new object construction or reusable object implementation. We propose automated support tools, including ORCA, a software Object Reuse Classification Analyzer, and AMHYRST, an Automated HYpertext-based Reuse Search Tool, that are based on this model. ORCA utilizes a faceted classification approach that can be implemented using hypertext. We also describe an aspect of AMHYRST's architecture which can automatically create hypertext networks that represent and link objects in terms of a number of distinguishing features. We illustrate our approach with an example drawn from a real world object repository.","0098-5589;1939-3520;2326-3881","","10.1109/32.508314","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=508314","","Software reusability;Computer aided software engineering;Programming;Software tools;Software development management;Engineering management;Humans;Research and development management;Computer architecture;Crisis management","computer aided software engineering;object-oriented programming;software reusability","reusable software objects;object-based computer-aided software engineering;repository objects;multistage model;object construction;ORCA;software object reuse classification analyzer;AMHYRST;automated hypertext-based reuse search tool;hypertext;object repositories;object search;repository evaluation;CASE;development environments","","31","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Safety Analysis Using Petri Nets","N. G. Leveson; J. L. Stolzy","Department of Information and Computer Science, University of California; NA","IEEE Transactions on Software Engineering","","1987","SE-13","3","386","397","The application of Time Petri net modeling and analysis techniques to safety-critical real-time systems is explored and procedures described which allow analysis of safety, recoverability, and fault-tolerance.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233170","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702225","Fault-tolerance;Petri-nets;requirements;software reliability;software safety","Petri nets;Software safety;Humans;Real time systems;Hazards;Hardware;Aerospace safety;Timing;Application software;Air traffic control","","Fault-tolerance;Petri-nets;requirements;software reliability;software safety","","236","","19","","","","","","IEEE","IEEE Journals & Magazines"
"The influence of different workload descriptions on a heuristic load balancing scheme","T. Kunz","Illinois Univ., Urbana, IL, USA","IEEE Transactions on Software Engineering","","1991","17","7","725","730","A task scheduler based on the concept of a stochastic learning automation, implemented on a network of Unix workstations, is described. Creating an artificial, executable workload, a number of experiments were conducted to determine the effect of different workload descriptions. These workload descriptions characterize the load at one host and determine whether a newly created task is to be executed locally or remotely. Six one-dimensional workload descriptors are examined. Two workload descriptions that are more complex are also considered. It is shown that the best single workload descriptor is the number of tasks in the run queue. The use of the worst workload descriptor, the 1-min load average, resulted in an increase of the mean response time of over 32%, compared to the best descriptor. The two best workload descriptors, the number of tasks in the run queue and the system call rate, are combined to measure a host's load. Experimental results indicate that no performance improvements over the scheduler versions using a one-dimensional workload descriptor can be obtained.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.83908","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=83908","","Load management;Processor scheduling;Distributed computing;Delay;Costs;Learning automata;Stochastic processes;Workstations;Stochastic systems;Helium","learning systems;microcomputer applications;scheduling;stochastic processes;Unix","heuristic load balancing scheme;task scheduler;stochastic learning automation;Unix workstations;executable workload;workload descriptions;one-dimensional workload descriptors;1-min load average;run queue;system call rate","","99","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Intervention Schedules for Real-Time Programming","C. Abbott","Lucasfilm Ltd., P.O. Box 2009, San Rafael, CA 94912.","IEEE Transactions on Software Engineering","","1984","SE-10","3","268","274","A way of programming real-time systems is described which inverts the usual image of parallel processes: instead of processes which are ordinarily running and which wait occasionally in order to synchronize with other cooperating processes, ``intervention schedules'' are ordinarily waiting and run nonpreemptibly, triggered by events, which may be external (modeling hardware interrupts) or generated by other intervention schedules. In order for nonpreemptive scheduling to make sense, the maximum period of time for which any event in an intervention schedule runs must be carefully controlled. This and other aspects of the model are considered, and it is compared with more traditional models of parallel processes, and with message passing models. Programming language features to support this programmming model are discussed. Strengths and limitations of the model are discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010235","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010235","Concurrency;multiprogramming;nonpreemptive scheduling;parallel programming;programming models;real-time programming;real-time systems;systems implementation languages","Registers;Real time systems;Hardware;Computer interfaces;Parallel programming;Clocks;Processor scheduling;Concurrent computing;Process control;Programming profession","","","","2","","17","","","","","","IEEE","IEEE Journals & Magazines"
"A Simple and Efficient Randomized Byzantine Agreement Algorithm","B. Chor; B. A. Coan","Laboratory for Computer Science, Massachusetts Institute of Technology; NA","IEEE Transactions on Software Engineering","","1985","SE-11","6","531","539","A new randomized Byzantine agreement algorithm is presented. This algorithm operates in a synchronous system of n processors, at most t of which can fail. The algorithm reaches agreement in 0(t/log n) expected rounds and O(n2tf/log n) expected message bits independent of the distribution of processor failures. This performance is further improved to a constant expected number of rounds and O(n2) message bits if the distribution of processor failures is assumed to be uniform. In either event, the algorithm improves on the known lower bound on rounds for deterministic algorithms. Some other advantages of the algorithm are that it requires no cryptographic techniques, that the amount of local computation is small, and that the expected number of random bits used per processor is only one. It is argued that in many practical applications of Byzantine agreement, the randomized algorithm of this paper achieves superior performance.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232245","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702050","Byzantine agreement;fault-tolerance;randomized algorithms","Redundancy;Cryptography;Fault tolerance;Contracts;Computer science;Computational modeling;Costs;Hardware;Software algorithms","","Byzantine agreement;fault-tolerance;randomized algorithms","","14","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Using program slicing in software maintenance","K. B. Gallagher; J. R. Lyle","Dept. of Comput. Sci., Loyola Coll., Baltimore, MD, USA; NA","IEEE Transactions on Software Engineering","","1991","17","8","751","761","Program slicing is applied to the software maintenance problem by extending the notion of a program slice (that originally required both a variable and line number) to a decomposition slice, one that captures all computation on a given variable, i.e., is independent of line numbers. Using the lattice of single variable decomposition slices ordered by set inclusion, it is shown how a slice-based decomposition for programs can be formed. One can then delineate the effects of a proposed change by isolating those effects in a single component of the decomposition. This gives maintainers a straightforward technique for determining those statements and variables which may be modified in a component and those which may not. Using the decomposition, a set of principles to prohibit changes which will interfere with unmodified components is provided. These semantically consistent changes can then be merged back into the original program in linear time.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.83912","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=83912","","Software maintenance;Couplings;Programming profession;Software testing;Lattices;Software tools;Computer science","program testing;software maintenance","program slicing;software maintenance problem;program slice;line number;single variable decomposition slices;set inclusion;slice-based decomposition;unmodified components;semantically consistent changes;linear time","","232","","37","","","","","","IEEE","IEEE Journals & Magazines"
"Program Development as a Formal Activity","M. Broy; P. Pepper","Institut f&#252;r Informatik, Technische Universit&#228;t M&#252;nchen; NA","IEEE Transactions on Software Engineering","","1981","SE-7","1","14","22","A methodology of program development by transformations is outlined. In particular, ways of representing the transformation rules are discussed, and the relationship between notions of their correctness and the semantic definition of programming languages is studied. How transformation techniques are complemented by the use of abstract data types and assertions is described. In the resulting calculus of transformations, the single rules not only represent design or optimization techniques, but they also incorporate verification principles. To illustrate this approach, the Warshall algorithm is developed by successive applications of transformations.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230815","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702798","Abstract data types;correctness of transformation rules;program transformations;transformational semantics","Network address translation;Computer languages;Calculus;Design optimization;Application software;Writing;Shape;Software engineering;Programming profession;Catalogs","","Abstract data types;correctness of transformation rules;program transformations;transformational semantics","","8","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Module allocation of real-time applications to distributed systems","C. E. Houstics","Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA","IEEE Transactions on Software Engineering","","1990","16","7","699","709","An allocation model for mapping a real-time application to certain k-processor multiprocessor systems is developed and analyzed. Its objective is minimizing the total processing time of the application by exploiting the parallelism of the application-architecture pair. The model is formulated in terms of the performance characteristics of the system and the resource requirements of the computation involved. Experience with the model suggests that it can be used effectively for the performance evaluation of application-distributed system pairs.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.56096","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=56096","","Real time systems;Application software;Parallel processing;Heuristic algorithms;Distributed computing;Computer architecture;Computer science;Hardware;Concurrent computing;Computer networks","distributed processing;multiprocessing systems;performance evaluation;real-time systems","module allocation;real-time applications;distributed systems;mapping;k-processor multiprocessor systems;parallelism;application-architecture pair;performance characteristics;performance evaluation","","35","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Program Specification Applied to a Text Formatter","M. S. Feather","Information Sciences Institute, University of Southern California","IEEE Transactions on Software Engineering","","1982","SE-8","5","490","498","Presentation of the fonnal specification of a small text formatter illustrates an approach to the construction of formal specifications. The key features of this approvach are described, and their beneficial influence on the construction and organization of specifications of tasks, especially those for which no concise descriptions are possible, are discussed. The intent is that in addition to serving as formal descriptions of tasks, such specifications will be of use in the processes of verification, development, and maintenance of their implementations.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235737","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702977","Applicative programming;program reliability;program specification;programming techniques;program transfornation","Formal specifications;Feathers;Maintenance;Equations;Computer languages;Councils;Artificial intelligence;Books","","Applicative programming;program reliability;program specification;programming techniques;program transfornation","","4","","24","","","","","","IEEE","IEEE Journals & Magazines"
"The cost of data flow testing: an empirical study","E. J. Weyuker","Dept. of Comput. Sci., New York Univ., NY, USA","IEEE Transactions on Software Engineering","","1990","16","2","121","128","A family of test data adequacy criteria employing data-flow information was previously proposed, and a theoretical complexity analysis was performed. The author describes an empirical study to determine the actual cost of using these criteria. The aim is to establish the practical usefulness of these criteria in testing software and provide a basis for predicting the amount of testing needed for a given program. The first goal of the study is to confirm the belief that the family of software testing criteria considered is practical to use. An attempt is made to show that even as the program size increases, the amount of testing, expressed in terms of the number of test cases sufficient to satisfy a given criterion, remains modest. Several ways of evaluating this hypothesis are explored. The second goal is to provide the prospective user of these criteria with a way of predicting the number of test cases that will be needed to satisfy a given criterion for a given program. This provides testers with a basis for selecting the most comprehensive criterion that they can expect to satisfy. Several plausible bases for such a prediction are considered.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44376","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44376","","Costs;Software testing;Performance analysis;Performance evaluation;Contracts;Computer science","parallel programming;program testing","data flow testing;empirical study;test data adequacy criteria;data-flow information;theoretical complexity analysis;cost;software testing criteria","","64","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Making Software Visible, Operational, and Maintainable in a Small Project Environment","W. Bryan; S. Siegel","CTEC, Inc., 6862 Elm Street, McLean, VA 22101.; CTEC, Inc., 6862 Elm Street, McLean, VA 22101.","IEEE Transactions on Software Engineering","","1984","SE-10","1","59","67","Practical suggestions are presented for effectively managing software development in small-project environments (i.e., no more than several million dollars per year). The suggestions are based on an approach to product development using a product assurance group that is independent from the development group. Within this check-and-balance management/development/product assurance structure, a design review process is described that effects an orderly transition from customer needs statement to software code. The testing activity that follows this process is then explained. Finally, the activities of a change control body (called a configuration control board) and supporting functions geared to maintaining delivered software are described. The suggested software management practices result from the experience of a small (approximately 100 employees) software engineering company that develops and maintains computer systems supporting real-time interactive commercial, industrial, and military applications.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010199","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010199","Configuration control board;design review;product assurance;project management;testing","Software maintenance;Software development management;Military computing;Environmental management;Programming;Product development;Process design;Testing;Engineering management;Software engineering","","","","4","","6","","","","","","IEEE","IEEE Journals & Magazines"
"A framework for neural net specification","L. S. Smith","Dept. of Comput. Sci., Stirling Univ., UK","IEEE Transactions on Software Engineering","","1992","18","7","601","612","A notation for the specification of neural nets is proposed. The aim is to produce a simple mathematical framework for use in specifying neural nets essentially by defining their transfer functions and connections. Nets are specified as interacting processing elements (nodes), communicating via instant links. Dynamics and adaptation are defined at the processing elements themselves, and all interaction is explicitly specified by directed arcs. Specifications can be built up hierarchically by turning a specification into a generator for a node, or they can be developed top-down. The use of the system is illustrated.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.148478","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=148478","","Neural networks;Transfer functions;Turning;Neurons;Equations;Packaging;Writing;Circuits;Network topology;Nerve fibers","formal specification;neural nets","framework;neural net specification;mathematical framework;transfer functions;connections;interacting processing elements","","13","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Composite programs: hierarchical construction, circularity, and deadlocks","W. A. Muhanna","Fac. of Manage. Inf. Syst., Ohio State Univ., Columbus, OH, USA","IEEE Transactions on Software Engineering","","1991","17","4","320","333","A graph-oriented, nonprocedural development environment in which composite programs are constructed by coupling a collection of existing component programs, the interfaces of which are defined by a fixed number of input ports and output ports, is discussed. It is shown that when the coupling graph is cyclic there is the possibility of a deadlock. A system that permits hierarchical construction of programs while testing, using a simple algebraic procedure, the resulting composite programs for communication deadlocks is presented. A decomposition-based approach to cycle enumeration is described. A formal graph-theoretic model of communication behavior for a class of atomic programs is presented. The model is then used to derive necessary and sufficient conditions for a deadlock to arise in a cycle. Techniques for dealing with deadly cycles (once identified) and improving the efficiency of their execution, once the cycles have been resolved, are described.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.90432","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=90432","","System recovery;System testing;Sufficient conditions;Predictive models;Safety;Concurrent computing;Distributed computing;Physics computing;Design methodology;Programming profession","concurrency control;graph theory;programming environments;programming theory","decomposition;graph theory;hierarchical construction;circularity;nonprocedural development environment;composite programs;interfaces;input ports;output ports;coupling graph;cyclic;communication deadlocks;cycle enumeration;communication behavior;atomic programs;necessary and sufficient conditions;deadly cycles","","3","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Architecture-directed refinement","G. -. Roman; C. D. Wilcox","Dept. of Comput. Sci., Washington Univ., St. Louis, MO, USA; Dept. of Comput. Sci., Washington Univ., St. Louis, MO, USA","IEEE Transactions on Software Engineering","","1994","20","4","239","258","As critical computer systems continue to grow in complexity, the task of showing that they execute correctly becomes more difficult. For this reason, research in software engineering has turned to formal methods, i.e., rigorous approaches to demonstrating the correctness of software systems. Unfortunately, the formal methods currently used in the design of concurrent systems do not provide any mechanisms for specifying and reasoning about the mapping of software to hardware. As a result, architectural constraints, even though they play an important role in the design process, are left out of the formal framework. We show how to state architectural constraints in a formal notation, how to prove that programs are allocated correctly to the underlying architecture, and how to factor architectural considerations into a program derivation process which uses a mixture of specification and program refinements. The approach is illustrated by the derivation of two related programs that solve the same problem but are designed to work on distinct architectures.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.277573","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=277573","","Computer architecture;Software systems;Hardware;Process design;Concurrent computing;Control systems;Software testing;System testing;Formal specifications;Concrete","parallel programming;parallel architectures;formal specification","software engineering;formal methods;correctness;concurrent systems;architectural constraints;design process;program derivation process;specification;program refinements;architecture-directed refinement","","3","","24","","","","","","IEEE","IEEE Journals & Magazines"
"A Domain Strategy for Computer Program Testing","L. J. White; E. I. Cohen","Department of Computer and Information Science, Ohio State University; NA","IEEE Transactions on Software Engineering","","1980","SE-6","3","247","257","This paper presents a testing strategy desiged to detect errors in the control flow of a computer program, and the conditions under which this strategy is reliable are given and characterized. The control flow statements in a computer progam partition the input space into a set of mutually exclusive domains, each of which corresponds to a particular program path and consists of input data points which cause that path to be executed. The testing strategy generates test points to examine the boundaries of a domain to detect whether a domain error has occurred, as either one or more of these boundaries will have shifted or else the corresponding predicate relational operator has changed. If test points can be chosen within e of each boundary, under the appropriate assumptions, the strategy is shown to be reliable in detecting domain errons of magnitude greater than . Moreover, the number of test points required to test each domain grows only linearly with both the dimensionality of the input space and the number of predicates along the path being tested.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234486","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702726","Control structure;domain errors;path-oriented testing;software reliability;software testing;test data generation","Computer errors;Error correction;Software testing;Automatic testing;Data flow computing;Software reliability;Automatic control;Military computing;Information science;System testing","","Control structure;domain errors;path-oriented testing;software reliability;software testing;test data generation","","192","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Software effort models for early estimation of process control applications","T. Mukhopadhyay; S. Kekre","Graduate Sch. of Ind. Adm., Carnegie Mellon Univ., Pittsburgh, PA, USA; Graduate Sch. of Ind. Adm., Carnegie Mellon Univ., Pittsburgh, PA, USA","IEEE Transactions on Software Engineering","","1992","18","10","915","924","Models are developed to estimate lines of code and function counts directly from user application features of process control systems early in the software development lifecycle. Since the application features are known with reasonable degree of confidence during early stages of development, it is possible to extend the use of the constructive cost model (COCOMO) and function-points-based approach for early software cost estimation. Alternative feature-based models that estimate size and effort using application features and productivity factors are developed. The feature-based models have been shown to estimate software effort with the least error.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.163607","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=163607","","Process control;Application software;Lab-on-a-chip;Programming;Manufacturing processes;Position control;Cost function;Motion control;Life estimation;Productivity","process computer control;software cost estimation;software engineering","early estimation;process control applications;lines of code;function counts;user application features;process control systems;software development lifecycle;constructive cost model;function-points-based approach;software cost estimation;feature-based models;application features;productivity factors;software effort;least error","","32","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Analysis of a Hybrid Access Scheme for Buffered Users-Probabilistic Time Division","A. Ephremides; O. A. Mowafi","Department of Electrical Engineering, University of Maryland; NA","IEEE Transactions on Software Engineering","","1982","SE-8","1","52","61","A new multiple access scheme is proposed and evaluated. The proposed scheme combines desirable features of the ordinary time-division (TDMA) and the random access (RA) schemes. It is shown that by adjusting the value of a single parameter a, the proposed access method can vary continuously from one extreme (TDMA) to the other (RA). The average delay per packet and the throughput can be improved for intermediate values of the load factor. Furthermore, the method can control the channel instability.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.234774","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702905","Delay;multiple access;packet switching;stability;throughput","Time division multiple access;Throughput;Delay;Stability;Traffic control;Queueing analysis;Packet switching;Laboratories;Computer architecture;Computer networks","","Delay;multiple access;packet switching;stability;throughput","","34","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Fault injection for dependability validation: a methodology and some applications","J. Arlat; M. Aguera; L. Amat; Y. Crouzet; J. -. Fabre; J. -. Laprie; E. Martins; D. Powell","Lab. d'Autom. et d'Anal. des Syst., CNRS, Toulouse, France; Lab. d'Autom. et d'Anal. des Syst., CNRS, Toulouse, France; Lab. d'Autom. et d'Anal. des Syst., CNRS, Toulouse, France; Lab. d'Autom. et d'Anal. des Syst., CNRS, Toulouse, France; Lab. d'Autom. et d'Anal. des Syst., CNRS, Toulouse, France; Lab. d'Autom. et d'Anal. des Syst., CNRS, Toulouse, France; Lab. d'Autom. et d'Anal. des Syst., CNRS, Toulouse, France; Lab. d'Autom. et d'Anal. des Syst., CNRS, Toulouse, France","IEEE Transactions on Software Engineering","","1990","16","2","166","182","The authors address the problem of validating the dependability of fault-tolerant computing systems, in particular, the validation of the fault-tolerance mechanisms. The proposed approach is based on the use of fault injection at the physical level on a hardware/software prototype of the system considered. The place of this approach in a validation-directed design process and with respect to related work on fault injection is clearly identified. The major requirements and problems related to the development and application of a validation methodology based on fault injection are presented and discussed. Emphasis is put on the definition, analysis, and use of the experimental dependability measures that can be obtained. The proposed methodology has been implemented through the realization of a general pin-level fault injection tool (MESSALINE), and its usefulness is demonstrated by the application of MESSALINE to the experimental validation of two systems: a subsystem of a centralized computerized interlocking system for railway control applications and a distributed system corresponding to the current implementation of the dependable communication system of the ESPRIT Delta-4 Project.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44380","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44380","","Application software;Fault tolerant systems;Hardware;Software prototyping;Process design;Fault diagnosis;Distributed computing;Rail transportation;Centralized control;Communication system control","computer communications software;distributed processing;fault tolerant computing;program verification;railways;software tools","dependability validation;fault-tolerant computing systems;fault-tolerance mechanisms;hardware/software prototype;validation-directed design process;validation methodology;general pin-level fault injection tool;MESSALINE;centralized computerized interlocking system;railway control applications;distributed system;dependable communication system;ESPRIT Delta-4 Project","","309","","43","","","","","","IEEE","IEEE Journals & Magazines"
"Negotiated interfaces for software reuse","G. S. Novak; F. N. Hill; M. -. Wan; B. G. Sayrs","Dept. of Comput. Sci., Texas Univ., Austin, TX, USA; Dept. of Comput. Sci., Texas Univ., Austin, TX, USA; Dept. of Comput. Sci., Texas Univ., Austin, TX, USA; Dept. of Comput. Sci., Texas Univ., Austin, TX, USA","IEEE Transactions on Software Engineering","","1992","18","7","646","653","A significant barrier to the reuse of software is the rigid interface presented by a subroutine. For nontrivial data structures, it is unlikely that the existing form of the data of an application will match the requirements of a separately written subroutine. The authors describe two methods of interfacing existing data to a subroutine: generation of a program to convert the data to the form needed by the subroutine, and rewriting the subroutine, through compilation, to fit the existing data. Both methods can be invoked through easily used menu-based negotiation with the user. These methods have been implemented using the GLISP language and compiler.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.148482","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=148482","","Application software;Data structures;Measurement units;Data conversion;Software algorithms;Costs;Production;Runtime","computer communications software;data structures;software reusability","software reuse;rigid interface;subroutine;nontrivial data structures;menu-based negotiation;GLISP language;compiler","","9","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Augmenting Ada for SIMD Parallel Processing","C. L. Cline; H. J. Siegel","PASM Parallel Processing Laboratory, School of Electrical Engineering, Purdue University; NA","IEEE Transactions on Software Engineering","","1985","SE-11","9","970","977","In order to program SIMD (single instruction stream-multiple data stream) parallel machines used for tasks such as speech and image processing, a language with explicit parallel constructs is often desirable. The language Ada, developed by the Department of Defense, is used here as a basis for such a language. Extensions of Ada, which allow the user to specify such operations as interprocessor communications and activation of processors, are proposed. These features are demonstrated by showing their use in a common speech processing algorithm, the parallel FFT.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232832","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702117","Ada;FFT;parallel processing;programming languages;SIMD machines","Parallel processing;Parallel languages;Speech processing;Concurrent computing;Streaming media;Parallel machines;Image processing;Computer architecture;Parallel algorithms;Natural languages","","Ada;FFT;parallel processing;programming languages;SIMD machines","","5","","36","","","","","","IEEE","IEEE Journals & Magazines"
"Syntax-Directed Pretty PrintingA First Step Towards a Syntax-Directed Editor","L. F. Rubin","Prime Computer, Inc.","IEEE Transactions on Software Engineering","","1983","SE-9","2","119","127","A language-independent syntax-directed pretty printer has been implemented as the first step towards building a language-independent syntax-directed editor. The syntax-directed pretty printer works in two phases: the grammar processing phase and the program processing phase. In the grammar processing stage, a grammar which contains a context-free grammar and information for the parser and pretty printer is processed and all files needed by the second phase are written. With these files, the syntax-directed pretty printer works for the language of the grammar. The syntax-directed editor would use the same grammar processing phase to construct the files needed to make it work for a specific language. In the program processing phase, programs in the language of the grammar are parsed and parse trees are built. If syntax errors are found, error messages are produced and error recovery is done. The parse trees are pretty printed according to the pretty printer specifications given in the grammar, resulting in well-indented, syntactically clear programs.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236456","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703028","Editor generator;formatter;language-independence;pretty printer;programming environments;syntax-directed editor","Printers;Switches;Programming environments;Software tools;Computer languages;Software engineering","","Editor generator;formatter;language-independence;pretty printer;programming environments;syntax-directed editor","","8","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Software size estimation of object-oriented systems","L. A. Laranjeira","Dept. of Electr. & Comput. Eng., Texas Univ., Austin, TX, USA","IEEE Transactions on Software Engineering","","1990","16","5","510","522","The strengths and weaknesses of existing size estimation techniques are discussed. The nature of software size estimation is considered. The proposed method takes advantage of a characteristic of object-oriented systems, the natural correspondence between specification and implementation, in order to enable users to come up with better size estimates at early stages of the software development cycle. Through a statistical approach the method also provides a confidence interval for the derived size estimates. The relation between the presented software sizing model and project cost estimation is also considered.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.52774","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=52774","","Object oriented modeling;Costs;Software engineering;Programming;Software systems;Delay estimation;Scheduling;Personnel;Equations;Phase estimation","object-oriented programming;software engineering","object-oriented systems;software size estimation;natural correspondence;specification;implementation;software development cycle;statistical approach;confidence interval;project cost estimation","","59","","41","","","","","","IEEE","IEEE Journals & Magazines"
"Concurrent Maintenance of Binary Search Trees","U. Manber","Department of Computer Science, University of Wisconsin, Madison, WI 53706.","IEEE Transactions on Software Engineering","","1984","SE-10","6","777","784","The problem of providing efficient concurrent access for independent processes to a dynamic search structure is the topic of this paper. We develop concurrent algorithms for search, update, insert, and delete in a simple variation of binary search trees, called external trees. The algorithm for deletion, which is usually the most difficult operation, is relatively easy in this data structure. The advantages of the data structure and the algorithms are that they are simple, flexible, and efficient, so that they can be used as a part in the design of more complicated concurrent algorithms where maintaining a dynamic search structure is necessary. In order to increase the efficiency of the algorithms we introduce maintenance processes that independently reorganize the data structure and relieve the user processes of nonurgent operations. We also discuss questions of transactions in a dynamic environment and replicated copies of the data structure.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010306","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010306","Concurrent algorithms;data structures;distributed algorithms;locking;transactions;trees","Binary search trees;Data structures;Tree data structures;Operating systems;Computer science;Application software;Process design","","","","11","","17","","","","","","IEEE","IEEE Journals & Magazines"
"A secure group membership protocol","M. K. Reiter","AT&T Bell Labs., Murray Hill, NJ, USA","IEEE Transactions on Software Engineering","","1996","22","1","31","42","A group membership protocol enables processes in a distributed system to agree on a group of processes that are currently operational. Membership protocols are a core component of many distributed systems and have proved to be fundamental for maintaining availability and consistency in distributed applications. We present a membership protocol for asynchronous distributed systems that tolerates the malicious corruption of group members. Our protocol ensures that correct members control and consistently observe changes to the group membership, provided that in each instance of the group membership, fewer than one-third of the members are corrupted or fail benignly. The protocol has many potential applications in secure systems and, in particular, is a central component of a toolkit for constructing secure and fault-tolerant distributed services that we have implemented.","0098-5589;1939-3520;2326-3881","","10.1109/32.481515","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=481515","","Electronic switching systems;Cryptographic protocols;Fault tolerant systems;Intrusion detection;Communication system security;Marine vehicles;Information security;Cryptography;Maintenance engineering","protocols;security of data;distributed processing;software fault tolerance;software tools","secure group membership protocol;distributed system processes;currently operational processes;availability;consistency;asynchronous distributed systems;malicious corruption tolerance;group members;group membership change observation;group membership change control;secure systems;toolkit;secure distributed service construction;fault-tolerant distributed service construction","","30","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Rajdoot: a remote procedure call mechanism supporting orphan detection and killing","F. Panzieri; S. K. Shrivastava","Dept. of Comput. Sci., Pisa Univ., Italy; NA","IEEE Transactions on Software Engineering","","1988","14","1","30","37","Rajdoot is a remote procedure call (RPC) mechanism with a number of fault tolerance capabilities. A discussion is presented of the reliability-related issues and how these issues have been dealt with in the RPC design. Rajdoot supports exactly-once semantics with call nesting capability, and incorporates effective measures for orphan detection and killing. Performance figures show that the reliability measures of Rajdoot impose little overhead.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4620","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4620","","Computer crashes;Fault detection;Telecommunication network reliability;Fault tolerant systems;Protocols;Ethernet networks;Radar;Councils;Computer science;Laboratories","fault tolerant computing;operating systems (computers);software reliability","Rajdoot;remote procedure call mechanism;orphan detection;killing;fault tolerance capabilities;exactly-once semantics;call nesting;reliability","","24","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Software Science Revisited: A Critical Analysis of the Theory and Its Empirical Support","V. Y. Shen; S. D. Conte; H. E. Dunsmore","Department of Computer Sciences, Purdue University; NA; NA","IEEE Transactions on Software Engineering","","1983","SE-9","2","155","165","The theory of software science was developed by the late M. H. Halstead of Purdue University during the early 1970's. It was first presented in unified form in the monograph Elements of Software Science published by Elsevier North-Holland in 1977. Since it claimed to apply scientific methods to the very complex and important problem of software production, and since experimental evidence supplied by Halstead and others seemed to support the theory, it drew widespread attention from the computer science community.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236460","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703032","Software complexity;software engineering;software management;software measurement;software metrics;software science","Software measurement;Software metrics;Books;Production;Programming profession;Military computing;Software tools;Computer science;Software engineering;Engineering management","","Software complexity;software engineering;software management;software measurement;software metrics;software science","","60","","50","","","","","","IEEE","IEEE Journals & Magazines"
"Data structured programming: Program design without arrays and pointers","H. D. Mills; R. C. Linger","IBM Corporation, Bethesda, MD 20817; Department of Computer Science, University of Maryland, College Park, MD 20742; IBM Corporation, Bethesda, MD 20817","IEEE Transactions on Software Engineering","","1986","SE-12","2","192","197","Structured programming introduced a new discipline for accessing the instructions of a program. In suitable programming languages, this discipline can be described in terms of program design without gotos. It can be shown, for example, that any functional result achievable in a programming language with gotos can be achieved in that same language without gotos if sequence, selection, and iteration control constructs are present. The gotos permit random access to the instructions while sequence, selection, and iteration provide much more limited and disciplined access. The authors introduce a new discipline for accessing the data of a program. Any functional result achievable in a programming language with arrays and pointers can be achieved in that same language without arrays and pointers if set, stack, and queue data types are present. The arrays and pointers permit random access to the data while sets, stacks, and queues provide much more limited and disciplined access.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312935","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312935","Correctness proofs;data structures;program correctness;program design;software engineering;structured programming","Arrays;Programming;Cognition;Memory;Explosions;Algorithm design and analysis","data structures;structured programming","software engineering;structured programming;program design;programming languages;random access;sequence;selection;iteration;arrays;pointers;set;stack;queue data types","","17","","","","","","","","IEEE","IEEE Journals & Magazines"
"Selectors: High-Level Resource Schedulers","D. W. Leinbaugh","Department of Computer and Information Science, The Ohio State University, Columbus, OH 43210.; AT&T Bell Laboratories, Columbus, OH 43213.","IEEE Transactions on Software Engineering","","1984","SE-10","6","810","825","Resource sharing problems can be described in three basically independent modular components.  The constraints the resource places upon sharing because of physcal limitations and consistency requirements.  The desired ordering of resource requests to achieve efficiency-either efficiency of resource utilization or efficiency of processes making the requests.  Modifications to the ordering to prevent starvation of processes waiting for requests which might otherwise never receive service. A high-level nonprocedural language to specify these components of resource sharing problems is described. General deadlock and starvation properties of selectors are proven. Solutions to several classic resource sharing problems are shown to illustrate the expressiveness of this language. Proof techniques for this high-level language are introduced to show how to prove particular selectors are or are not deadlock and starvation free.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010310","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010310","Deadlock;nonprocedural language;process synchronization;protected resource;resource scheduling;resource sharing;starvation","Resource management;System recovery;Protection;Concurrent computing;Writing;Process control;High level languages;Computer displays;Information science;Software quality","","","","2","","11","","","","","","IEEE","IEEE Journals & Magazines"
"An Incremental Programming Environment","R. Medina-Mora; P. H. Feiler","Department of Computer Science, Carnegie-Mellon University; NA","IEEE Transactions on Software Engineering","","1981","SE-7","5","472","482","This paper describes an incremental programming environment (IPE) based on compilation technology, but providing facilities traditionally found only in interpretive systems. IPE provides a comfortable environment for a single programmer working on a single program.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.231109","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702873","Ada environments;incremental compilation;incremental program construction;interactive debugging;programming environments;programming methodology;software development environments;syntax-directed editing","Programming environments;Programming profession;Debugging;Computer science;Computer languages;Automatic control;User interfaces;Software engineering;Cities and towns;Program processors","","Ada environments;incremental compilation;incremental program construction;interactive debugging;programming environments;programming methodology;software development environments;syntax-directed editing","","31","","17","","","","","","IEEE","IEEE Journals & Magazines"
"The Qualified Function Approach to Analysis of Program Behavior and Performance","A. Gabrielian; L. P. McNamee; D. J. Trawick","Command and Control Systems Division, Ground Systems Group, Hughes Aircraft Company; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","8","758","773","The notion of a qualified function is introduced as a general means of representing the parameters of dynamic systems. Two specific types of qualified functions are defined for the analysis of the behavior and performance of structured programs. Transformation functions represent the values of variables during execution and timing algorithms express the execution times of programs symbolically. Complete rules of derivation for transformation functions and timing algorithms are given for the control mechanisms of sequence, selection, fixed loop, and while statement. Deterministic and stochastic simplification of transformation functions and timing algorithms are investigated and methods of eliminating recursion for expressions corresponding to while statements are studied.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232525","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702085","Difference equations;performance evaluation;program execution times;qualified function;symbolic evaluation;symbolic execution;system modeling;timing algorithm","Performance analysis;Timing;Computational modeling;Command and control systems;Aerospace control;Aircraft propulsion;Real time systems;Emulation;Stochastic processes;Equations","","Difference equations;performance evaluation;program execution times;qualified function;symbolic evaluation;symbolic execution;system modeling;timing algorithm","","3","","15","","","","","","IEEE","IEEE Journals & Magazines"
"The use of cooperation scenarios in the design and evaluation of a CSCW system","O. Stiemerling; A. B. Cremers","Dept. of Comput. Sci. III, Bonn Univ., Germany; NA","IEEE Transactions on Software Engineering","","1998","24","12","1171","1181","Design and evaluation of groupware systems raise questions which do not have to be addressed in the context of single user systems. The designer has to take into account not only the interaction of a single user with the computer, but also the computer-supported interaction of several users with each other. In this article we describe the use of cooperation scenarios in the design and evaluation of an innovative access control system for a concrete groupware application developed in the PoLITeam project. We have used informal textual scenarios to capture a rich description of the particularities of access to cooperatively used documents in three different organizations. Based on these scenarios, we have developed an access control system, which not only allows specification of access rights in advance but also allows involvement of third persons at the actual time of access, using negotiation and notification mechanisms. We describe our evaluation strategy which again employs the cooperation scenarios developed in the empirical phase. After relating our approach to other work, we summarize and discuss our experiences and the advantages (and disadvantages) of using scenarios for the design and evaluation of computer systems cooperative work (CSCW) systems. Finally, we give a brief outlook on future work.","0098-5589;1939-3520;2326-3881","","10.1109/32.738345","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=738345","","Collaborative work;Collaborative software;Access control;Permission;Control systems;Communication system control;Concrete;Application software;Design methodology;Computer science","groupware;authorisation;software engineering","groupware system evaluation;groupware system design;CSCW system evaluation;CSCW system design;cooperation scenarios;single user interaction;computer-supported user interaction;access control system;PoLITeam project;informal textual scenarios;cooperatively used documents;access rights specification;third persons;negotiation mechanisms;notification mechanisms;empirical phase;computer systems cooperative work","","12","","27","","","","","","IEEE","IEEE Journals & Magazines"
"A decomposition solution to a queueing network model of a distributed file system with dynamic locking","A. Ha","Department of Electrical Engineering and Computer Science, The Johns Hopkins University, Baltimore, MD 21218","IEEE Transactions on Software Engineering","","1986","SE-12","4","521","530","The author presents a new approach to modeling file systems using queueing networks. The delays due to locking the files are modeled using service centers whose service times and probabilities of access are estimated from the values of measurable quantities. The model of a lock is based on the analysis of execution of transactions in the system. The lock for every file is modeled as a sequence of service centers. The decomposition method can be used to solve the model, which allows multiple classes of transactions and shared files to be represented. An example involving measurement data collected in a small business installation is given to compare performance measures provided by the simulation and analytic models.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312899","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312899","Concurrency control;distributed systems;file systems;hierarchical decomposition;locking mechanisms;queueing networks","Delay;Servers;Analytical models;File systems;Load modeling;Probability;Business","database management systems;database theory;distributed processing;queueing theory","DBMS;decomposition solution;queueing network model;distributed file system;dynamic locking;delays;service centers;measurable quantities;shared files;measurement data;small business installation","","3","","","","","","","","IEEE","IEEE Journals & Magazines"
"Some Experiences in Promoting Reusable Software: Presentation in Higher Abstract Levels","Y. Matsumoto","Toshiba Corporation, Tokyo 183, Japan.","IEEE Transactions on Software Engineering","","1984","SE-10","5","502","513","In the Toshiba software factory, quality control and productivity improvements are primary concerns. Emphasis is placed on reusing existing software modules that have been proven correct through actual operation. To achieve a substantial degree of reuse, the software design process is viewed at several levels of abstraction. In this paper, these levels of abstraction are defined, and examples of the specification for these defined levels are given. This paper proposes a ``presentation'' of each existing module at the highest level of abstraction. Traceability between the presentation and the reusable program modules which implement it is established to simplify reusability. The paper concludes with an example showing reuse of a presentation for a different application.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010274","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010274","Ada design;productivity;requirements;reusability;software factory;software life cycle;software production","Software reusability;Productivity;Production facilities;Algorithm design and analysis;High level languages;Software quality;Quality control;Process design;Application software;Character generation","","","","32","","10","","","","","","IEEE","IEEE Journals & Magazines"
"RSF: a formalism for executable requirement specifications","M. Degl'Innocenti; G. L. Ferrari; G. Pacini; F. Turini","Syst. & Mangae., Vocolo S Pierini, Pisa, Italy; NA; NA; NA","IEEE Transactions on Software Engineering","","1990","16","11","1235","1246","RSF is a formalism for specifying and prototyping systems with time constraints. Specifications are given via a set of transition rules. The application of a transition rule is dependent upon certain events. The occurrence times of the events and the data associated with them must satisfy given properties. As a consequence of the application of a rule, some events are generated and others are scheduled to occur in the future, after given intervals of time. Specifications can be queried, and the computation of answers to queries provides a generalized form of rapid prototyping. Executability is obtained by mapping the RSF rules into logic programming. The rationale, a definition of the formalism, the execution techniques which support the general notion of rapid prototyping and a few examples of its use are presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.60312","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=60312","","Prototypes;Software prototyping;Time factors;Logic programming;Specification languages;Processor scheduling;Production systems;Software systems;Power system management;Functional programming","software prototyping","RSF;formalism;executable requirement specifications;time constraints;transition rules;events;occurrence times;answers;queries;rapid prototyping;logic programming","","8","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Design of Analyzers for Selective Program Analysis","J. Arthur; J. Ramanathan","Department of Computer Science, Purdue University; NA","IEEE Transactions on Software Engineering","","1981","SE-7","1","39","51","The need for programming environments which support different phases of the software life cycle using responsive tools is well established. This paper presents a method for developing automatic analyzers which analyze programs and provide programmers with a variety of messages for the purpose of validating these programs in the early stages of program development. We show using an example, that such analyzers can be systematically constructed using an extension of the Attribute Grammar model which reflects the fact that a program analyzer should perform a static analysis of the program as well as monitor its dynamic behavior efficiently. One of the advantages of the model is that a systematic interaction is allowed between the static and dynamic attributes of the program. We illustrate that an advantage of this interaction is selective program instrumentation. That is, the analyzer is responsive to the programmer's needs by providing a selective analysis of the program's behavior rather than an exhaustive analysis which is difficult to comprehend.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230818","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702801","Attribute grammars;instrumentation;program validation;translators","Instruments;Programming environments;Performance analysis;Dynamic programming;Software tools;Software systems;Testing;Programming profession;Monitoring;Computer science","","Attribute grammars;instrumentation;program validation;translators","","4","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Approximate throughput computation of stochastic marked graphs","J. Campos; J. M. Colom; H. Jungnitz; M. Silva","Dept. de Ingenieria Electr. e Inf., Zaragoza Univ., Spain; Dept. de Ingenieria Electr. e Inf., Zaragoza Univ., Spain; Dept. de Ingenieria Electr. e Inf., Zaragoza Univ., Spain; Dept. de Ingenieria Electr. e Inf., Zaragoza Univ., Spain","IEEE Transactions on Software Engineering","","1994","20","7","526","535","A general iterative technique for approximate throughput computation of stochastic strongly connected marked graphs is presented. It generalizes a previous technique based on net decomposition through a single input-single output cut, allowing the split of the model through any cut. The approach has two basic foundations. First, a deep understanding of the qualitative behavior of marked graphs leads to a general decomposition technique. Second, after the decomposition phase, an iterative response time approximation method is applied for the computation of the throughput. Experimental results on several examples generally have an error of less than 3%. The state space is usually reduced by more than one order of magnitude; therefore, the analysis of otherwise intractable systems is possible.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.297941","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=297941","","Throughput;Stochastic processes;Delay;Iterative methods;Performance analysis;Approximation methods;State-space methods;Computational modeling;Proposals;Queueing analysis","Petri nets;stochastic processes;performance evaluation","approximate throughput computation;stochastic marked graphs;iterative technique;stochastic strongly connected marked graphs;net decomposition;single input-single output cut;qualitative behavior;general decomposition technique;iterative response time approximation method;error;state space;intractable systems;stochastic Petri net models","","25","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Performance analysis of mass storage service alternatives for distributed systems","K. K. Ramakrishnan; J. S. Emer","Digital Equipment Corp., Littleton, MA, USA; Digital Equipment Corp., Littleton, MA, USA","IEEE Transactions on Software Engineering","","1989","15","2","120","133","The authors consider the performance of alternative mass-storage services for a client-server-style distributed system. Some qualitative arguments are presented on the ramifications of implementations of mass-storage services at various levels of the storage semantics hierarchy. The authors concentrate, in particular, on contrasting disk and file services. The functionalities of disk and file services are distinguished by their primitive operations: individual disk-block access for the disk service, and individual file-block access for the file service. This difference results in different partitionings of the computation between the client and server, as well as different network communication requirements. To understand the ramifications of such differences between the services, the authors present performance estimates for basic disk and file services. Performance estimates for several design alternatives are presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21739","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21739","","Performance analysis;Prototypes;Network servers;Computer networks;Performance evaluation;Network interfaces;Costs;Time measurement;Throughput;Parameter estimation","distributed processing;file organisation;network operating systems;performance evaluation;storage management","LAN;mass storage service alternatives;distributed systems;client-server-style distributed system;storage semantics hierarchy;file services;disk;individual disk-block access;file-block access;network communication requirements;design alternatives","","13","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Passive-space and time view: vector clocks for achieving higher performance, program correction, and distributed computing","M. Ahuja; T. Carlson; A. Gahlot","Dept. of Comput. Sci. & Eng., California Univ., San Diego, La Jolla, CA, USA; NA; NA","IEEE Transactions on Software Engineering","","1993","19","9","845","855","We have noticed two problems with viewing a process as a sequence of events. The first problem is the complete loss of information about potential intra-process concurrency for both sequential and distributed computations, and partial loss of information about potential inter-process concurrency for distributed computations. The second problem is that the resulting reasoning framework does not lend itself to refinement (from sequential computing or a given set of distributed processes) to a preferable set of distributed processes. We argue that it is more natural to view a computation, either distributed or sequential, as a partially ordered set of events. Doing so leads to a view, called passive-space and time view, which we propose. To aid users of the relation ""Affects"" in developing algorithms, we define vector clocks, that are global logical clocks, so that the relation ""Affects"", and hence all potential concurrency, between events can be identified from their timestamps assigned.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.241768","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=241768","","Clocks;Concurrent computing;Distributed computing;Costs;Performance loss;High performance computing;Process design;Parallel processing;Debugging;Computer science","concurrency control;distributed processing;program debugging","time view;passive-space view;vector clocks;high performance;program correction;distributed computing;intraprocess concurrency;distributed computations;sequential computations;global logical clocks;timestamps;debugging","","6","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Parsing nonlinear languages","M. Tucci; G. Vitiello; G. Costagliola","Dipartimento di Inf. ed Applicazioni, Salerno Univ., Italy; Dipartimento di Inf. ed Applicazioni, Salerno Univ., Italy; Dipartimento di Inf. ed Applicazioni, Salerno Univ., Italy","IEEE Transactions on Software Engineering","","1994","20","9","720","739","The diagrammatic approach to user interfaces for computer-aided software development toolkits, visual query systems, and visual programming environments, is based on the use of diagrams and charts traditionally drawn on paper. In particular, the VLG system (Visual Language Generator) has been proposed to generate icon-oriented visual languages customized for given applications. The syntactical model underlying the interpretation of a visual language in VLG has been designed to describe icon-oriented visual languages. In order to enable the VLG system to apply to any kind of graphical languages, like diagrammatic ones, it is necessary to find a more general syntactical model able to support both their generation and interpretation. This paper addresses the comprehension of the features that a grammatical formalism for nonlinear languages must have to match any requirement for an efficient parsing. To this aim, relation grammars support an easy implementation of a general parsing algorithm for multidimensional languages, parametric with respect to the rewriting rules of the grammar. We compare the expressive power of relation grammars to grammatical formalisms for graph grammars.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.317427","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=317427","","Programming environments;User interfaces;Computer interfaces;Application software;Multidimensional systems;Power system modeling;Costs;Petri nets;Design for quality;Human computer interaction","visual programming;visual languages;diagrams;programming environments;graphical user interfaces;grammars;software tools","nonlinear language parsing;diagrammatic approach;user interfaces;computer-aided software development toolkits;visual query systems;visual programming environments;diagrams;charts;VLG system;Visual Language Generator;icon-oriented visual languages;syntactical model;visual language;graphical languages;nonlinear languages;parsing;relation grammars;general parsing algorithm;multidimensional languages;rewriting rules;graph grammars","","10","","42","","","","","","IEEE","IEEE Journals & Magazines"
"Providing customized assistance for software lifecycle approaches","J. Ramanthan; S. Sarkar","Univ. Energy Syst., Dublin, OH, USA; NA","IEEE Transactions on Software Engineering","","1988","14","6","749","757","The authors describe a tightly coupled environment architecture centered around a customized software development assistant, that uses underlying representations of the software development process, the objects and relationships being manipulated, the functionalities of the tools, and the roles of the various project members to provide automated support for this discipline. The assistant facilitates the interconnection of all the components of the environment. Features of a conceptual modeling language for specifying such representations and using them to generate customized assistants are emphasized.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6155","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6155","","Programming;Computer architecture;Software standards;Standards development;Large-scale systems;Software tools;Databases;Project management;Software development management;Standards organizations","high level languages;programming environments;software tools","software tools;programming environments;tightly coupled environment;customized software development assistant;software development;conceptual modeling language","","17","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Anonymous remote computing: a paradigm for parallel programming on interconnected workstations","R. K. Joshi; D. J. Ram","Dept. of Comput. Sci. & Eng., Indian Inst. of Technol., Bombay, India; NA","IEEE Transactions on Software Engineering","","1999","25","1","75","90","Parallel computing on interconnected workstations is becoming a viable and attractive proposition due to the rapid growth in speeds of interconnection networks and processors. In the case of workstation clusters, there is always a considerable amount of unused computing capacity available in the network. However, heterogeneity in architectures and operating systems, load variations on machines, variations in machine availability, and failure susceptibility of networks and workstations complicate the situation for the programmer. In this context, new programming paradigms that reduce the burden involved in programming for distribution, load adaptability, heterogeneity and fault tolerance gain importance. This paper identifies the issues involved in parallel computing on a network of workstations. The anonymous remote computing (ARC) paradigm is proposed to address the issues specific to parallel programming on workstation systems. ARC differs from the conventional communicating process model by treating a program as one single entity consisting of several loosely coupled remote instruction blocks instead of treating it as a collection of processes. The ARC approach results in distribution transparency and heterogeneity transparency. At the same time, it provides fault tolerance and load adaptability to parallel programs on workstations. ARC is developed in a two-tiered architecture consisting of high level language constructs and low level ARC primitives. The paper describes an implementation of the ARC kernel supporting ARC primitives.","0098-5589;1939-3520;2326-3881","","10.1109/32.748919","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=748919","","Concurrent computing;Parallel programming;Workstations;Parallel processing;Fault tolerance;Multiprocessor interconnection networks;Computer networks;Computer architecture;Operating systems;Load management","parallel programming;workstation clusters;software fault tolerance","anonymous remote computing;parallel programming paradigm;interconnected workstations;interconnection networks;processors;workstation clusters;load adaptability;distribution;heterogeneity;fault tolerance;parallel computing;workstation network;communicating process model;loosely coupled remote instruction blocks;distribution transparency;heterogeneity transparency;two-tiered architecture;high level language constructs;low level primitives;kernel","","13","","42","","","","","","IEEE","IEEE Journals & Magazines"
"Formal program construction by transformations-computer-aided, intuition-guided programming","F. L. Bauer; B. Moller; H. Partsch; P. Pepper","Inst. for Inf., Tech. Univ. of Munich, West Germany; Inst. for Inf., Tech. Univ. of Munich, West Germany; NA; NA","IEEE Transactions on Software Engineering","","1989","15","2","165","180","Formal program construction by transformations is a method of software development in which a program is derived from a formal problem specification by manageable, controlled transformation steps which guarantee that the final product meets the initial specification. This methodology has been investigated in the Munich project CIP (computer-aided intuition-guided programming). The research includes the design of a wide-spectrum language specifically tailored to the needs of transformational programming, the construction of a transformation system to support the methodology, and the study of transformation rules and other methodological issues. Particular emphasis has been laid on developing a sound theoretical basis for the overall approach.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21743","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21743","","Formal specifications;Programming;Software engineering;Software development management;Bridges;Computer science;Mathematics;Life testing;Formal languages","formal specification;software engineering","program construction by transformations;software development;formal problem specification;Munich project CIP;computer-aided intuition-guided programming;wide-spectrum language;transformational programming;transformation rules","","81","","88","","","","","","IEEE","IEEE Journals & Magazines"
"Elements of Software Configuration Management","E. H. Bersoff","BTG, Inc., 1945 Gallows Rd., Vienna, VA 22180.","IEEE Transactions on Software Engineering","","1984","SE-10","1","79","87","Software configuration management (SCM) is one of the disciplines of the 1980's which grew in response to the many failures of the software industry throughout the 1970's. Over the last ten years, computers have been applied to the solution of so many complex problems that our ability to manage these applications has all too frequently failed. This has resulted in the development of a series of ''new'' disciplines intended to help control the software process. This paper will focus on the discipline of SCM by first placing it in its proper context with respect to the rest of the software development process, as well as to the goals of that process. It will examine the constituent components of SCM, dwelling at some length on one of those components, configuration control. It will conclude with a look at what the 1980's might have in store.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010202","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010202","Configuration management;management;product assurance;software","Software development management;Computer industry;Application software;Programming;Roads;Process control;Cost function;Software measurement;Project management","","","","30","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Supporting systems development by capturing deliberations during requirements engineering","B. Ramesh; V. Dhar","US Naval Postgraduate Sch., Monterey, CA, USA; NA","IEEE Transactions on Software Engineering","","1992","18","6","498","510","Support for various stakeholders involved in software projects (designers, maintenance personnel, project managers and executives, end users) can be provided by capturing the history about design decisions in the early stages of the system's development life cycle in a structured manner. Much of this knowledge, which is called the process knowledge, involving the deliberation on alternative requirements and design decisions, is lost in the course of designing and changing such systems. Using an empirical study of problem-solving behavior of individual and groups of information systems professionals, a conceptual model called REMAP (representation and maintenance of process knowledge) that relates process knowledge to the objects that are created during the requirements engineering process has been developed. A prototype environment that provides assistance to the various stakeholders involved in the design and management of large systems has been implemented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.142872","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=142872","","Software maintenance;Software design;Personnel;Project management;Software development management;History;Problem-solving;Management information systems;Design engineering;Knowledge engineering","formal specification;knowledge acquisition","issue based information systems method;knowledge capture;systems development;deliberations;requirements engineering;software projects;history;design decisions;development life cycle;process knowledge;problem-solving behavior;information systems professionals;conceptual model;REMAP","","149","","45","","","","","","IEEE","IEEE Journals & Magazines"
"Modeling and analysis of concurrent maintenance policies for data structures using pointers","Ing-Ray Chen; S. A. Banawan","Dept. of Comput. & Inf. Sci., Mississippi Univ., MS, USA; NA","IEEE Transactions on Software Engineering","","1993","19","9","902","911","We present a state reduction method that effectively reduces a two-dimensional Markov model to a one-dimensional Markov model for the performance analysis of a class of concurrent data structure maintenance policies. The reduced model allows the derivation of a closed form expression for the average service time per operation and facilitates the identification of priority allocation functions under which: the system is stable; and the service time per operation is minimized. The applicability of the model is exemplified with a binary tree data structure and the conditions under which concurrent maintenance strategies are better than a conventional incremental maintenance strategy are determined.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.241772","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=241772","","Data structures;Delay;Performance analysis;Binary trees;Tree data structures;Database systems;Degradation;Concurrent computing;Computational modeling","Markov processes;performance evaluation;software maintenance;tree data structures","concurrent maintenance policies;data structures;pointers;state reduction method;two-dimensional Markov model;one-dimensional Markov model;performance analysis;concurrent data structure maintenance policies;closed form expression;service time per operation;priority allocation functions;binary tree data structure;1D Markov model;2D Markov model","","2","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Predicting fault-prone software modules in telephone switches","N. Ohlsson; H. Alberg","Dept. of Comput. & Inf. Sci., Linkoping Univ., Sweden; NA","IEEE Transactions on Software Engineering","","1996","22","12","886","894","An empirical study was carried out at Ericsson Telecom AB to investigate the relationship between several design metrics and the number of function test failure reports associated with software modules. A tool, ERIMET, was developed to analyze the design documents automatically. Preliminary results from the study of 130 modules showed that: based on fault and design data one can satisfactorily build, before coding has started, a prediction model for identifying the most fault-prone modules. The data analyzed show that 20 percent of the most fault-prone modules account for 60 percent of all faults. The prediction model built in this paper would have identified 20 percent of the modules accounting for 47 percent of all faults. At least four design measures can alternatively be used as predictors with equivalent performance. The size (with respect to the number of lines of code) used in a previous prediction model was not significantly better than these four measures. The Alberg diagram introduced in this paper offers a way of assessing a predictor based on historical data, which is a valuable complement to linear regression when prediction data is ordinal. Applying the method described in this paper makes it possible to use measures at the design phase to predict the most fault-prone modules.","0098-5589;1939-3520;2326-3881","","10.1109/32.553637","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=553637","","Telephony;Predictive models;Fault diagnosis;Switches;Telecommunication switching;Software testing;Data analysis;Size measurement;Linear regression;Phase measurement","telephony;telecommunication computing;software fault tolerance;software metrics;statistical analysis;program testing;diagrams;electronic switching systems","fault-prone software module prediction;telephone switches;Ericsson Telecom AB;design metrics;function test failure reports;ERIMET tool;design documents;prediction model;design measures;performance;Alberg diagram;historical data;linear regression;software reliability","","173","","32","","","","","","IEEE","IEEE Journals & Magazines"
"Performance characterization of optimizing compilers","R. H. Saavedra; A. J. Smith","Dept. of Comput. Sci., Univ. of Southern California, Los Angeles, CA, USA; NA","IEEE Transactions on Software Engineering","","1995","21","7","615","628","Optimizing compilers have become an essential component in achieving high levels of performance. Various simple and sophisticated optimizations are implemented at different stages of compilation to yield significant improvements, but little work has been done in characterizing the effectiveness of optimizers, or in understanding where most of this improvement comes from. We study the performance impact of optimization in the context of our methodology for CPU performance characterization based on the abstract machine model. The model considers all machines to be different implementations of the same high level language abstract machine; in previous research, the model has been used as a basis to analyze machine and benchmark performance. We show that our model can be extended to characterize the performance improvement provided by optimizers and to predict the run time of optimized programs, and measure the effectiveness of several compilers in implementing different optimization techniques.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.392982","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=392982","","Optimizing compilers;Predictive models;Central Processing Unit;Computer science;Time measurement;Application software;Computer aided manufacturing;Context modeling;High level languages;Performance analysis","optimising compilers;program compilers;software performance evaluation;performance evaluation","abstract machine model;optimizing compilers;performance impact;CPU performance characterization;high level language abstract machine;performance improvement;optimized programs;optimization techniques","","14","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Predictive modeling techniques of software quality from software measures","T. M. Khoshgoftaar; J. C. Munson; B. B. Bhattacharya; G. D. Richardson","Dept. of Comput. Sci. & Eng., Florida Atlantic Univ., Boca Raton, FL, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1992","18","11","979","987","The objective in the construction of models of software quality is to use measures that may be obtained relatively early in the software development life cycle to provide reasonable initial estimates of the quality of an evolving software system. Measures of software quality and software complexity to be used in this modeling process exhibit systematic departures of the normality assumptions of regression modeling. Two new estimation procedures are introduced, and their performances in the modeling of software quality from software complexity in terms of the predictive quality and the quality of fit are compared with those of the more traditional least squares and least absolute value estimation techniques. The two new estimation techniques did produce regression models with better quality of fit and predictive quality when applied to data obtained from two software development projects.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.177367","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=177367","","Software quality;Predictive models;Software measurement;Software systems;Programming;Software metrics;Application software;Software safety;Computer science;Statistics","software metrics;software quality;statistical analysis","predictive modelling process;software quality;software measures;software development life cycle;software system;software complexity;regression modeling;least squares;least absolute value estimation;predictive quality","","53","","22","","","","","","IEEE","IEEE Journals & Magazines"
"SWSL: a synthetic workload specification language for real-time systems","D. L. Kiskis; K. G. Shin","Dept. of Electr. Eng. & Comput. Sci., Michigan Univ., Ann Arbor, MI, USA; Dept. of Electr. Eng. & Comput. Sci., Michigan Univ., Ann Arbor, MI, USA","IEEE Transactions on Software Engineering","","1994","20","10","798","811","We discuss the issues that must be addressed in the specification and generation of synthetic workloads for distributed real-time systems. We describe a synthetic workload specification language (SWSL) that defines a workload in a form that can be compiled by a synthetic workload generator (SWG) to produce an executable synthetic workload. The synthetic workload is then downloaded to the target machine and executed while performance and dependability measurements are made. SWSL defines the workload at the task level using a data flow graph, and at the operation level using control constructs and synthetic operations taken from a library. It is intended to be easy to use, flexible, and capable of creating synthetic workloads that are representative of real-time workloads. It provides a compact, parameterized notation. It supports automatic replication of objects to facilitate the specification of large workloads for distributed real-time systems. It also provides extensive support for the experimentation process.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.328992","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=328992","","Specification languages;Real time systems;Laboratories;Application software;Reluctance generators;Flow graphs;Automatic control;Libraries;NASA;Software engineering","specification languages;formal specification;distributed processing;real-time systems;performance evaluation","SWSL;synthetic workload specification language;real-time systems;distributed real-time systems;synthetic workload generator;executable synthetic workload;performance;dependability measurements;data flow graph;operation level;control constructs;synthetic operations;real-time workloads","","7","","37","","","","","","IEEE","IEEE Journals & Magazines"
"An Approach to Formal Specification of Control Modules","W. H. Leung; C. V. Ramamoorthy","Bell Laboratories; NA","IEEE Transactions on Software Engineering","","1980","SE-6","5","485","489","This paper is concerned with the formal specification of program modules which control access to resources shared among concurrent proceses. The concept of state space is defined for such program modules and the formal specification is given in terms of a program module invariant and input-output assertions defined on the state space. Examples are provided to ilustrate the construction of sDecifications with this approach.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230789","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702765","Concurrent processes;control modules;input-output assertion;invariant assertion;program specification;resource sharing;state space model","Formal specifications;State-space methods;Process control;Laboratories;Resource management;Programming profession;Monitoring;Protection","","Concurrent processes;control modules;input-output assertion;invariant assertion;program specification;resource sharing;state space model","","","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Achieving Distributed Termination without Freezing","N. Francez; M. Rodeh","Department of Computer Science, Technion&#8211;Israel Institute of Technology; NA","IEEE Transactions on Software Engineering","","1982","SE-8","3","287","292","An efficient algorithm for achieving distributed termination without introducing new communicaton channels and without delaying the basic computations (""freezing"") is presented. The algorithm is related to the methodology of designing distributed programs where the programmer is relieved from the problem of distributed termination. An informal correctness proof and complexity analysis are included.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235257","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702944","Communication;concurrency;CSP;distributed programs;distributed termination","Stability;State-space methods;Bismuth;Delay;Distributed computing;Design methodology;Algorithm design and analysis;Programming profession;Concurrent computing;Computer science","","Communication;concurrency;CSP;distributed programs;distributed termination","","51","","18","","","","","","IEEE","IEEE Journals & Magazines"
"An entropy-based measure of software complexity","W. Harrison","PSU Center for Software Quality Res., Portland State Univ., OR, USA","IEEE Transactions on Software Engineering","","1992","18","11","1025","1029","It is proposed that the complexity of a program is inversely proportional to the average information content of its operators. An empirical probability distribution of the operators occurring in a program is constructed, and the classical entropy calculation is applied. The performance of the resulting metric is assessed in the analysis of two commercial applications totaling well over 130000 lines of code. The results indicate that the new metric does a good job of associating modules with their error spans (averaging number of tokens between error occurrences).<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.177371","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=177371","","Software measurement;Entropy;Software quality;Computer errors;Programming profession;Software testing;Information theory;Probability distribution;Performance analysis;Application software","probability;software metrics","entropy-based measure;software complexity;average information content;empirical probability distribution;classical entropy calculation;performance","","70","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Protocol conversion","S. S. Lam","Dept. of Comput. Sci., Texas Univ., Austin, TX, USA","IEEE Transactions on Software Engineering","","1988","14","3","353","362","The problem of achieving communication between two processes across a network or an internetwork is considered. The notion of logical connectivity between processes in a protocol is formalized. The problem of constructing a protocol converter to achieve interoperability between processes that implement different protocols is addressed. A formal model is presented, based on the theory of protocol projection, for reasoning about the semantics of different protocols and conversions between them. Two kinds of converters are presented: memoryless converters and finite-state converters. The construction of some finite-state converters is illustrated, and examples are given.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4655","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4655","","Protocols;Image converters;Computer architecture;IP networks;TCPIP;Computer networks;Software standards;Open systems;Internetworking;Communication standards","computer networks;protocols","logical connectivity;protocol;converter;formal model;memoryless converters;finite-state converters","","76","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Language constructs for specifying concurrency in CDL","R. K. Shyamasundar; J. W. Thatcher","Dept. of Comput. Sci., Pennsylvania State Univ., University Park, PA, USA; NA","IEEE Transactions on Software Engineering","","1989","15","8","977","993","A description is given of language constructs for specifying concurrency in CDL*. The main goals in designing the language have been: modular specification, data integrity, and expressiveness. The language constructs are presented, and it is shown through examples how the constructs mirror the goals. The major advantages of the constructs are as follows: (1) data integrity is achieved without resorting to mutual exclusion unnecessarily, (2) dynamic resource management is achieved safely guaranteeing the anonymity of the dynamically allocating resources, and (3) similar components can be packaged together without resorting to sequential access. Various features of the language are illustrated through examples. In short, the language provides a step towards integrating abstraction mechanisms and specification techniques. Some of the features in CDL* are compared to some of the features available in other languages, including distributed programming languages.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.31354","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=31354","","Concurrent computing;Resource management;Computer languages;Mirrors;Packaging;Interference;Parallel processing;Electrical capacitance tomography;Logic programming;Contracts","data integrity;parallel programming;specification languages","CDL* concurrency specification;language constructs;modular specification;data integrity;expressiveness;mutual exclusion;dynamic resource management;anonymity;dynamically allocating resources;abstraction mechanisms;specification techniques;CDL*;distributed programming languages","","2","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Essential Elements of Software Engineering Education Revisited","P. Freeman","Department of Information and Computer Science, University of California","IEEE Transactions on Software Engineering","","1987","SE-13","11","1143","1148","A basis for software engineering education proposed in 1976 is reviewed and found to still be valid today, although needing more emphasis on design and better delivery mechanisms. Specific recommendations are made.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232862","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702160","Curriculum;design education;education;intellectual basis of software engineering;software engineering;technology transfer","Software engineering;Computer science;Engineering management;Computer science education;Proposals;Educational programs;Technology transfer;Problem-solving;Buildings;Knowledge engineering","","Curriculum;design education;education;intellectual basis of software engineering;software engineering;technology transfer","","19","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Automated software synthesis: an application in mechanical CAD","S. Bhansali; T. J. Hoar","Semantic Designs, Austin, TX, USA; NA","IEEE Transactions on Software Engineering","","1998","24","10","848","862","Automated program synthesis has not gained widespread acceptance among software practitioners despite considerable efforts by several researchers. We outline some of the difficulties in applying program synthesis for practical problems and argue that a careful analysis of the cost vs. benefit tradeoff is essential when considering such an approach. We describe a successful application of automated program generation for synthesizing geometric constraint satisfaction routines in the domain of mechanical CAD. We present a general framework for modeling and solving the problem, illustrate the framework using examples from the geometric constraint satisfaction domain, and describe experimental results on productivity increase using this approach. We also discuss characteristics of the problem domain and our approach that were critical for success.","0098-5589;1939-3520;2326-3881","","10.1109/32.729684","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=729684","","Application software;Costs;Productivity;Design automation;Robotic assembly;Solid modeling;Synthesizers;Kinematics;Shape;Programming profession","mechanical engineering computing;CAD;automatic programming;constraint handling","automated software synthesis;mechanical CAD;automated program synthesis;software practitioners;automated program generation;geometric constraint satisfaction routines;geometric constraint satisfaction domain;productivity increase","","4","","32","","","","","","IEEE","IEEE Journals & Magazines"
"Whether software engineering needs to be artificially intelligent","H. A. Simon","Department of Psychology, Carnegie-Mellon University, Pittsburgh, PA 15213","IEEE Transactions on Software Engineering","","1986","SE-12","7","726","732","The author discusses the roles that humans now play versus the roles that could be taken over by artificial intelligence in developing computer systems. Also discussed is how the intelligent part of the automatic system can communicate effectively with humans. Topics covered include an artificial intelligence overview; weak methods; the heuristic search; the problem space; the knowledge base; expert systems; and conclusions drawn from a description of the general artificial intelligence paradigm.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312974","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312974","","Humans;Programming;Computers;Software;Software engineering;Expert systems","artificial intelligence;expert systems;software engineering","software engineering;artificial intelligence;developing computer systems;automatic system;weak methods;heuristic search;problem space;knowledge base;expert systems","","17","","","","","","","","IEEE","IEEE Journals & Magazines"
"The Raid distributed database system","B. Bhargava; J. Riedl","Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA; Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA","IEEE Transactions on Software Engineering","","1989","15","6","726","736","Raid, a robust and adaptable distributed database system for transaction processing, is described. Raid is a message-passing system, with server processes on each site. The servers manage concurrent processing, consistent replicated copies during site failures and atomic distributed commitment. A high-level, layered communications package provides a clean, location-independent interface between servers. The latest design of the communications package delivers messages via shared memory in a high-performance configuration in which several servers are linked into a single process. Raid provides the infrastructure to experimentally investigate various methods for supporting reliable distributed transaction processing. Measurements on transaction processing time and server CPU time are presented. Data and conclusions of experiments in three categories are also presented: communications software, consistent replicated copy control during site failures, and concurrent distributed checkpointing. A software tool for the evaluation of transaction processing algorithms in an operating system kernel is proposed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24726","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24726","","Database systems;Packaging;Robustness;Atomic layer deposition;Time measurement;Communication system control;Checkpointing;Software tools;Software algorithms;Operating systems","computer communications software;concurrency control;distributed databases;software packages;transaction processing","Raid distributed database system;adaptable distributed database system;message-passing system;concurrent processing;consistent replicated copies;site failures;atomic distributed commitment;layered communications package;location-independent interface;shared memory;high-performance configuration;infrastructure;reliable distributed transaction processing;transaction processing time;server CPU time;consistent replicated copy control;concurrent distributed checkpointing;software tool;transaction processing algorithms;operating system kernel","","21","","27","","","","","","IEEE","IEEE Journals & Magazines"
"The effects of layering and encapsulation on software development cost and quality","S. H. Zweben; S. H. Edwards; B. W. Weide; J. E. Hollingsworth","Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA; NA","IEEE Transactions on Software Engineering","","1995","21","3","200","208","Software engineers often espouse the importance of using abstraction and encapsulation in developing software components. They advocate the ""layering"" of new components on top of existing components, using only information about the functionality and interfaces provided by the existing components. This layering approach is in contrast to a ""direct implementation"" of new components, utilizing unencapsulated access to the representation data structures and code present in the existing components. By increasing the reuse of existing components, the layering approach intuitively should result in reduced development costs, and in increased quality for the new components. However, there is no empirical evidence that indicates whether the layering approach improves developer productivity or component quality. We discuss three controlled experiments designed to gather such empirical evidence. The results support the contention that layering significantly reduces the effort required to build new components. Furthermore, the quality of the components, in terms of the number of defects introduced during their development, is at least as good using the layered approach. Experiments such as these illustrate a number of interesting and important issues in statistical analysis. We discuss these issues because, in our experience, they are not well known to software engineers.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.372147","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=372147","","Encapsulation;Programming;Costs;Software quality;Data structures;Productivity;Software systems;Computer languages;Statistical analysis;Computerized monitoring","software cost estimation;software quality;data encapsulation;data structures;object-oriented programming;software reusability","software development cost;software quality;encapsulation;abstraction;layering approach;developer productivity;component quality;controlled experiments;statistical analysis;empirical evidence;software engineers;abstract data types;software reuse","","27","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Development of a debugger for a concurrent language","F. Baiardi; N. De Francesco; G. Vaglini","Dipartimento di Informatica, Universit&#x00E0; di Pisa, Corso Italia 40, 56100 Pisa, Italy; Dipartimento di Informatica, Universit&#x00E0; di Pisa, Corso Italia 40, 56100 Pisa, Italy; Dipartimento di Informatica, Universit&#x00E0; di Pisa, Corso Italia 40, 56100 Pisa, Italy","IEEE Transactions on Software Engineering","","1986","SE-12","4","547","553","The authors discuss issues related to the debugging of concurrent programs. A set of desirable characteristics for a debugger for concurrent languages is deduced from a review of the differences between the debugging of concurrent programs and that of sequential ones. A debugger for concurrent language based upon CSP is then described. The debugger makes it possible to compare a description of the expected program behavior to the actual behaviour. The description of the behavior is given in terms of expressions composed by events and/or assertions on the process state. The developed formalism is able to describe behaviors at various levels of abstraction. Lastly, some guidelines for the implementation of the debugger are given and a detailed example of program debugging is analyzed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312902","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312902","Concurrent programming;debugging;programming environment;program specifications;tool transparency","Debugging;Radiation detectors;Delay;Process control;Runtime;Semantics;Parallel processing","parallel processing;program debugging","debugger;concurrent language;concurrent programs;CSP;expected program behavior;assertions;abstraction","","21","","","","","","","","IEEE","IEEE Journals & Magazines"
"Stepwise design of real-time systems","R. Kurki-Suonio","Software Syst. Lab., Tampere Univ. of Technol., Finland","IEEE Transactions on Software Engineering","","1993","19","1","56","69","The joint action approach to modeling of reactive systems is presented and augmented with real time. This leads to a stepwise design method where temporal logic of actions can be used for formal reasoning, superposition is the key mechanism for transformations, the advantages of closed-system modularity are utilized, logical properties are addressed before real-time properties, and real-time properties are enforced without any specific assumptions on scheduling. As a result, real-time modeling is made possible already at early stages of specification, and increased insensitivity is achieved with respect to properties imposed by implementation environments.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.210307","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=210307","","Real time systems;Design methodology;Mechanical factors;Solids;Logic design;Interleaved codes;Time factors;Concurrent computing;Safety","formal specification;real-time systems;temporal logic","real-time systems;reactive systems;stepwise design method;temporal logic;formal reasoning;closed-system modularity;real-time properties;scheduling","","8","","37","","","","","","IEEE","IEEE Journals & Magazines"
"An Optimal Algorithm for Processing Distributed Star Queries","A. L. P. Chen; V. O. K. Li","System Development Corporation; NA","IEEE Transactions on Software Engineering","","1985","SE-11","10","1097","1107","The problem of optimal query processing in distributed database systems was shown to be NP-hard. However, for a special type of queries called star queries, we have developed a polynomial optimal algorithm. Semijoin tactics are applied for query processing. An execution graph is introduced to represent the semijoin programs associated with the distributed processing of the queries. We then identify optimality properties of semijoin programs for star queries, and use these properties to derive the optimal semijoin program. We have shown that the optimal semijoin program can be found from serial semijoin strategies, defined as serial semijoin programs which include each semijoin associated with the query exactly once. By making certain assumptions on the file sizes and the semijoin selectivities, we can obtain the optimal semijoin program from these strategies in polynomial time. Our assumption on selectivites is consistent in the sense that we consider the selectivity of a semijoin based on the current database state, i.e., we take into consideration the reduction effects of all prior semijoins.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231857","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701925","Distributed database systems;optimal algorithms;query optimization;relational data model;semijoin programs;semijoin selectivity;star queries","Query processing;Qualifications;Database systems;Tree graphs;Polynomials;Data models;Distributed computing;Costs;Distributed processing;Relational databases","","Distributed database systems;optimal algorithms;query optimization;relational data model;semijoin programs;semijoin selectivity;star queries","","12","","21","","","","","","IEEE","IEEE Journals & Magazines"
"EQL: the language and its implementation","B. Jayaraman; G. Gupta","Dept. of Comput. Sci., Univ. of North Carolina, Chapel Hill, NC, USA; Dept. of Comput. Sci., Univ. of North Carolina, Chapel Hill, NC, USA","IEEE Transactions on Software Engineering","","1989","15","6","771","779","EqL, a general-purpose language that combines the capabilities of functional and logic programming languages, is described. A program in EqL consists of a collection of conditional, pattern-directed rules, where the conditions are expressed as a conjunction of equations, and the patterns are terms built up of data-constructors and basic values. The computational paradigm in EqL is equation solving. Examples illustrating the major features of the language, nondeterminism, deferred evaluation of primitives, and logical variables are presented. The aspects of a sequential implementation for EqL, such as compile-time flattening of equations, run-time equation-delaying, and last-equation optimization, are also described.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24730","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24730","","Equations;Logic programming;Functional programming;Runtime;Computer languages;Software engineering;Programming profession;Computer science;Concrete","equations;functional programming;high level languages;logic programming;mathematics computing","conditional rules;functional programming;general-purpose language;logic programming languages;EqL;pattern-directed rules;data-constructors;basic values;computational paradigm;equation solving;nondeterminism;deferred evaluation;logical variables;sequential implementation;compile-time flattening;run-time equation-delaying;last-equation optimization","","","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Integrating multiple paradigms within the blackboard framework","S. Vranes; M. Stanojevic","Dept. of Comput. Sci., Mihajlo Pupin Inst., Belgrade, Serbia; Dept. of Comput. Sci., Mihajlo Pupin Inst., Belgrade, Serbia","IEEE Transactions on Software Engineering","","1995","21","3","244","262","The complexity and diversity of real world applications have forced researchers in the AI field to focus more on the integration of diverse knowledge representation and reasoning techniques for solving challenging, real world problems. Our development environment, BEST (Blackboard based Expert Systems Toolkit), is aimed to provide the ability to produce large scale, evolvable, heterogeneous intelligent systems. BEST incorporates the best of multiple programming paradigms in order to avoid restricting users to a single way of expressing either knowledge or data. It combines rule based programming, object oriented programming, logic programming, procedural programming and blackboard modelling in a single architecture for knowledge engineering, so that the user can tailor a style of programming to his application, using any or arbitrary combinations of methods to provide a complete solution. The deep integration of all these techniques yields a toolkit more effective even for a specific single application than any technique in isolation or collections of multiple techniques less fully integrated. Within the basic, knowledge based programming paradigm, BEST offers a multiparadigm language for representing complex knowledge, including incomplete and uncertain knowledge. Its problem solving facilities include truth maintenance, inheritance over arbitrary relations, temporal and hypothetical reasoning, opportunistic control, automatic partitioning and scheduling and both blackboard and distributed problem solving paradigms.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.372151","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=372151","","Logic programming;Object oriented programming;Problem-solving;Artificial intelligence;Knowledge representation;Expert systems;Large-scale systems;Intelligent systems;Object oriented modeling;Knowledge engineering","expert system shells;expert systems;blackboard architecture;logic programming;object-oriented programming;problem solving","multiple programming paradigms;blackboard framework;real world applications;development environment;BEST;Blackboard based Expert Systems Toolkit;heterogeneous intelligent systems;rule based programming;object oriented programming;logic programming;procedural programming;blackboard modelling;knowledge engineering;knowledge based programming paradigm;multiparadigm language;truth maintenance;uncertain knowledge;distributed problem solving;hypothetical reasoning;opportunistic control;automatic partitioning;scheduling","","27","","47","","","","","","IEEE","IEEE Journals & Magazines"
"Ordering Actions for Visibility","M. S. Mckendry","Department of Computer Science, Carnegie-Mellon University","IEEE Transactions on Software Engineering","","1985","SE-11","6","509","519","Several research projects are studying architectures for distributed computing that are founded on the notion of atomic actions operating on objects (instances of abstract data types). Such projects as Clouds at Georgia Tech and Archons at Carnegie-Mellon University are evaluating this approach as the foundation for constructing distributed operating systems. Objects are not new to operating systems. They provide substantial benefits in such dimensions as protection and synchronization, as well as their inherent organizational characteristics. This paper is concerned with synchronization to control ordering, a function often associated with objects. Conventional approaches require substantial extension for the action environment. Typically, they are based on (or equivalent to) general semaphores. Semaphores take no account of the visibility requirements of actions however, and consequently they can allow an action to progress beyond the point at which its effects can be undone. Also, they do not account for failures.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232243","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702048","Abstract data types;actions;concurrency control;distributed systems;objects;synchronization","Operating systems;Protection;Database systems;Costs;Computer science;Computer languages;Computer architecture;Distributed computing;Clouds;Concurrency control","","Abstract data types;actions;concurrency control;distributed systems;objects;synchronization","","","","25","","","","","","IEEE","IEEE Journals & Magazines"
"LRAutomatic Parser Generator and LR(1) Parser","C. Wetherell; A. Shannon","Bell Laboratories; NA","IEEE Transactions on Software Engineering","","1981","SE-7","3","274","278","LR is an LR(1) parser generation system. It is written entirely in portable ANS1 standard Fortran 66 and has been successfully operated on a number of computers. LR uses a powerful algorithm of Pager's to generate a space efficient parser for any LR(1) grammar. Generated parsers have been used in a variety of compilers, utility programs, and applications packages.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230837","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702840","Compiler construction;LR(1) parsing;programming languages","Production;Laboratories;Portable computers;Power generation;Program processors;Utility programs;Application software;Packaging;Government;Subcontracting","","Compiler construction;LR(1) parsing;programming languages","","1","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Streets of Byzantium: Network Architectures for Fast Reliable Broadcasts","O. Babaoglu; R. Drummond","Department of Computer Science, Cornell University; NA","IEEE Transactions on Software Engineering","","1985","SE-11","6","546","554","A site broadcasting its local value to all other sites ina fault-prone environment is a fundamental paradigm in constructing reliable distributed systems. Time complexity lower bounds and network connectivity requirements for reliable broadcast protocols in point-to-point communication networks are well known. In this paper, we consider the reliable broadcast problem in distributed systems with broadcast networks (for example, Ethernets) as the basic communication architecture. We show how properties of such network architectures can be used to effectively restrict the externally visible behavior of faulty processors. We use these techniques to derive simple protocols that implement reliable broadcast in only two rounds, independent of the failure upper bounds.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232247","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702052","Byzantine agreement;distributed computing;Ethernet;fault-tolerance;network partitions","Broadcasting;Protocols;Telecommunication network reliability;Transmitters;Distributed computing;Fault tolerant systems;Computer architecture;Computer science;Upper bound;Communication networks","","Byzantine agreement;distributed computing;Ethernet;fault-tolerance;network partitions","","47","","22","","","","","","IEEE","IEEE Journals & Magazines"
"An applicable family of data flow testing criteria","P. G. Frankl; E. J. Weyuker","Dept. of Electr. Eng. & Comput. Sci., Polytech. Univ., New York, NY, USA; NA","IEEE Transactions on Software Engineering","","1988","14","10","1483","1498","The authors extend the definitions of the previously introduced family of data flow testing criteria to apply to programs written in a large subset of Pascal. They then define a family of adequacy criteria called feasible data flow testing criteria, which are derived from the data-flow testing criteria. The feasible data flow testing criteria circumvent the problem of nonapplicability of the data flow testing criteria by requiring the test data to exercise only those definition-use associations which are executable. It is shown that there are significant differences between the relationships among the data flow testing criteria and the relationships among the feasible data flow testing criteria. The authors discuss a generalized notion of the executability of a path through a program unit. A script of a testing session using their data flow testing tool, ASSET, is included.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6194","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6194","","Software testing;Flow graphs;Computer science;Computer errors;Data analysis","program testing;software reliability","program testing;data flow testing;Pascal;adequacy criteria;definition-use associations;ASSET","","249","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Invariant-based verification of a distributed deadlock detection algorithm","A. D. Kshemkalyani; M. Singhal","Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA; Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA","IEEE Transactions on Software Engineering","","1991","17","8","789","799","It is argued that most previous proposals for distributed deadlock detection are incorrect because they have used informal/intuitive arguments to prove the correctness of their algorithms. Informal and intuitive arguments are prone to errors because of the highly complex nature of distributed deadlock detection/resolution algorithms. The priority-based probe algorithm for distributed deadlock detection and resolution of A.L. Choudhary et al. (1989) is corrected, and it is formally proven that the modified algorithm is correct (i.e., that it does detect all deadlocks and does not report phantom deadlocks). The proof technique is novel in that the authors first abstract the properties of the deadlock detection and resolution algorithm by invariants, and then show that the invariants imply the desired correctness of the algorithm.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.83914","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=83914","","System recovery;Detection algorithms;Probes;Error correction;Proposals;Imaging phantoms;Distributed algorithms;Distributed databases;Information science","algorithm theory;distributed processing;program verification;system recovery;theorem proving","invariant-based verification;distributed deadlock detection algorithm;informal/intuitive arguments;distributed deadlock detection/resolution algorithms;priority-based probe algorithm;correctness","","24","","17","","","","","","IEEE","IEEE Journals & Magazines"
"A Note on Denial-of-Service in Operating Systems","V. D. Gligor","Department of Electrical Engineering, University of Maryland, College Park, MD 20742.","IEEE Transactions on Software Engineering","","1984","SE-10","3","320","324","A simple and general definition of denial-of-service in operating systems is presented. It is argued that no current protection mechanism nor model resolves this problem in any demonstrable way. The notion of interuser dependency is introduced and identified as the common cause for all problem instances. Decomposition of operating systems into hierarchies of services is assumed for the discovery of denial-of-service instances.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010241","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010241","Denial-of-service;interuser dependencies;maximum waiting time;service hierarchy;service specifications","Computer crime;Operating systems;Protection;Hardware;Time sharing computer systems;Control systems;Information retrieval;Formal verification;Authorization;Computer aided instruction","","","","44","","14","","","","","","IEEE","IEEE Journals & Magazines"
"A critical analysis of incremental iterative data flow analysis algorithms","M. G. Burke; B. G. Ryder","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; NA","IEEE Transactions on Software Engineering","","1990","16","7","723","728","A model of data flow analysis and fixed point iteration solution procedures is presented. The faulty incremental iterative algorithm is introduced. Examples of the imprecision of restarting iteration from the intraprocedural and interprocedural domains are given. Some incremental techniques which calculate precise data flow information are summarized.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.56098","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=56098","","Algorithm design and analysis;Data analysis;Iterative algorithms;Information analysis;Flow graphs;Performance analysis;Optimizing compilers;Program processors;Software systems;Software algorithms","parallel algorithms;parallel programming","intraprocedural domains;critical analysis;incremental iterative data flow analysis algorithms;model;fixed point iteration solution;interprocedural domains","","14","","32","","","","","","IEEE","IEEE Journals & Magazines"
"On Horizontally Microprogrammed Microarchitecture Description Techniques","J. L. Gieser","JRS Research Laboratories, Inc.","IEEE Transactions on Software Engineering","","1982","SE-8","5","513","525","In automatically generating microcode starting from a highlevel source language, a significant issue is the description of the target microengine architecture. The techniques and methodologies used to accomplish this address the practical issues of: 1) a detailed description of all microprogram controJled haudware elements of the microengine, the microinstruction, the rules for valid use of all microprogrammed features, and the behavior of microprogrammed operations; and 2) the use of this description to interpret and decode higher level source intermediate languages to form microoperations and ultimately microinstructions. This work is a step in conceptually defining the techniques and methodologies for microarchitecture descriptions to accomplish the above. Its objective is to identify the techniques that appear to have the most promise for use in interjecting the target microarchitecture characteristics into the high-level language-to-microcode compilation process.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.235739","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702979","Automatic microcode generation;high-level microprogramming languages;microengine description techniques;microprogrammed architectures;microprogramming","Microarchitecture;Microprogramming;Decoding;Software standards;Standards development;Software tools;Production;Current measurement;Compaction;High level languages","","Automatic microcode generation;high-level microprogramming languages;microengine description techniques;microprogrammed architectures;microprogramming","","5","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Defining Database Views as Data Abstractions","B. G. Claybrook; A. -. Claybrook; J. Williams","EnMasse Computer Corporation; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","1","3","14","The concept of data abstraction is utilized in database systems to define user interfaces via database views in database application languages and to describe the architecture of database systems. Differences between the specification and use of database views and other data abstractions realized as abstract data types are discussed. Database views are formally specified using both the algebraic specification method and the abstract model specification method. The use of database views is demonstrated via the EXT_Pascal database application language.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231532","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701893","Data abstraction;database view;formal specification","Database systems;User interfaces;Formal specifications;Application software","","Data abstraction;database view;formal specification","","4","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Reliability analysis of large software systems: defect data modeling","Y. Levendel","AT&T Bell Lab., Naperville, IL, USA","IEEE Transactions on Software Engineering","","1990","16","2","141","152","The author analyzes and models the software development process, and presents field experience for large distributed systems. Defect removal is shown to be the bottleneck in achieving the appropriate quality level before system deployment in the field. The time to defect detection, the defect repair time and a factor reflecting the introduction of new defects due to imperfect defect repair are some of the constants in the laws governing defect removal. Test coverage is a measure of defect removal effectiveness. A birth-death mathematical model based on these constants is developed and used to model field failure report data. The birth-death model is contrasted with a more classical decreasing exponential model. Both models indicate that defect removal is not a cost-effective way to achieve quality. As a result of the long latency of software defects in a system, defect prevention is suggested to be a far more practical solution to quality than defect removal.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44378","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44378","","Software systems;Military computing;Telecommunication computing;Programming;Mathematical model;Software testing;Distributed computing;Availability;Communication industry;Reliability","distributed processing;large-scale systems;program testing;software reliability","reliability analysis;defect data modeling;software development;large distributed systems;bottleneck;defect removal;birth-death mathematical model;field failure report data;quality","","48","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Software reliability allocation based on structure, utility, price, and cost","F. Zahedi; N. Ashrafi","Dept. of Manage. Sci., Massachusetts Univ., Boston, MA, USA; Dept. of Manage. Sci., Massachusetts Univ., Boston, MA, USA","IEEE Transactions on Software Engineering","","1991","17","4","345","356","A software reliability allocation model is developed. This model determines how reliable software modules and programs must be in order to maximize the user's utility, while taking into account the financial and technical constraints of the system. The model is shown to provide a unified approach in which the user's requirements and preferences are formally integrated with the technical structure of the software and its module and program reliabilities. The model determines reliability goals at the planning and design stages of the software project, making reliability a singular measure for performance evaluation and project control. An example for the application of the model is provided.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.90434","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=90434","","Software reliability;Costs;Power system reliability;Software testing;Guidelines;Software performance;Software measurement;Power system modeling;Control systems;Programming profession","reliability theory;software reliability","structure;utility;price;cost;software reliability allocation;reliability goals;performance evaluation;project control","","76","","60","","","","","","IEEE","IEEE Journals & Magazines"
"Implementing atomicity in two systems: techniques, tradeoffs, and experience","L. -. Cabrera; J. A. McPherson; P. M. Schwarz; J. C. Wyllie","Dept. of Comput. Sci., IBM Almaden Res. Center, San Jose, CA, USA; Dept. of Comput. Sci., IBM Almaden Res. Center, San Jose, CA, USA; Dept. of Comput. Sci., IBM Almaden Res. Center, San Jose, CA, USA; Dept. of Comput. Sci., IBM Almaden Res. Center, San Jose, CA, USA","IEEE Transactions on Software Engineering","","1993","19","10","950","961","This paper presents our experience with implementing atomicity in two systems: the QuickSilver distributed file system and the Starburst relational database manager. Each of these systems guarantees that certain collections of operations done on behalf of their clients execute atomically, despite process, machine, or network failures. In this paper we describe the atomic properties implemented by each system, present the algorithms and mechanisms used, examine the similarities and differences between the two systems, and give the rationale for different design decisions. We demonstrate that the support of atomicity with high performance requires a variety of techniques carefully chosen to balance the amount of data logged, the level of concurrency allowed, and the mutual consistency requirements of sets of objects, The main goal is to help others implement efficient systems that support atomicity.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.245737","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=245737","","File systems;Relational databases;Mechanical factors;Algorithm design and analysis;Data structures;Computer crashes;Database systems;Operating systems;Buildings","distributed databases;network operating systems;relational databases;transaction processing","atomicity;QuickSilver distributed file system;Starburst relational database manager;atomic properties;concurrency;mutual consistency;client-server transactions;transaction systems;recoverable data structures;shadow copies;stable storage","","6","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Software development cost estimation using function points","J. E. Matson; B. E. Barrett; J. M. Mellichamp","Dept. of Ind. Eng., Alabama Univ., Tuscaloosa, AL, USA; Dept. of Ind. Eng., Alabama Univ., Tuscaloosa, AL, USA; Dept. of Ind. Eng., Alabama Univ., Tuscaloosa, AL, USA","IEEE Transactions on Software Engineering","","1994","20","4","275","287","This paper presents an assessment of several published statistical regression models that relate software development effort to software size measured in function points. The principal concern with published models has to do with the number of observations upon which the models were based and inattention to the assumptions inherent in regression analysis. The research describes appropriate statistical procedures in the context of a case study based on function point data for 104 software development projects and discusses limitations of the resulting model in estimating development effort. The paper also focuses on a problem with the current method for measuring function points that constrains the effective use of function points in regression models and suggests a modification to the approach that should enhance the accuracy of prediction models based on function points in the future.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.277575","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=277575","","Programming;Cost function;Size measurement;Software measurement;Regression analysis;Predictive models;Lab-on-a-chip;Environmental factors;Lifting equipment;Context modeling","statistical analysis;software cost estimation","software development cost estimation;function points;statistical regression models;regression analysis;development effort;prediction models","","143","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Anomaly Detection in Concurrent Software by Static Data Flow Analysis","R. N. Taylor; L. J. Osterweil","Space and Military Applications Division, Boeing Computer Services Company; NA","IEEE Transactions on Software Engineering","","1980","SE-6","3","265","278","Algorithms are presented for detecting errors and anomalies in programs which use synchronization constructs to implement concurrency. The algorithms employ data flow analysis techniques. First used in compiler object code optimization, the techniques have more recently been used in the detection of variable usage errors in dngle process programs. By adapting these existing algorithms, the sane classes of variable usage errors can be detected in concurrent process programs. Important classes of errors unique to concurrent process programs are also described, and algorithms for their detection are presented.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234488","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702728","Concurrent software;data flow analysis;error detection;HAL/S;process synchronization errors;uninitialized variables","Data analysis;Concurrent computing;Computer languages;Military computing;Displays;Algorithm design and analysis;Program processors;Optimizing compilers;Object detection;Error analysis","","Concurrent software;data flow analysis;error detection;HAL/S;process synchronization errors;uninitialized variables","","26","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Extending the Noninterference Version of MLS for SAT","J. T. Haigh; W. D. Young","Honeywell Secure Computing and Technology Center; NA","IEEE Transactions on Software Engineering","","1987","SE-13","2","141","150","A noninterference formulation of MLS applicable to the Secure Ada Target (SAT) Abstract Model is developed. An analogous formulation is developed to handle the SAT type enforcement policy. Unwinding theorems are presented for both MLS and Multidomain Security (MDS) and the SAT Abstract Model is shown to satisfy both MLS and MDS. Generalizations and extensions are also considered.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.226478","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702195","Access control;assured pipeline;covert channel analysis;multilevel security;noninterference;security policy model;type enforcement","Multilevel systems;Power system modeling;Pipelines;Certification;Power system security;Access control;Signal analysis;Computer applications;Trademarks;Protection","","Access control;assured pipeline;covert channel analysis;multilevel security;noninterference;security policy model;type enforcement","","30","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Adaptive Routing Using a Virtual Waiting Time Technique","A. K. Agrawala; S. K. Tripathi; G. Ricart","Department of Computer Science, University of Maryland; NA; NA","IEEE Transactions on Software Engineering","","1982","SE-8","1","76","81","The virtual waiting time technique is introduced as a solution to the problem of a controller distributing work to servers of different speeds. The servers are considered to be part of a distributed system without feedback. The virtual waiting time technique is shown to minimize the average completion time for a job distributed by the controller. The virtual waiting time technique does not depend on any arrival distribution and is applicable to any service time distribution. The performance of the technique is examined for different arrival and service time distributions.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1982.234942","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702907","Load sharing;routing;virtual waiting time","Routing;Communication system control;Feedback;Network servers;Distributed computing;Bandwidth;Delay;Control systems;Distributed control;Processor scheduling","","Load sharing;routing;virtual waiting time","","16","","6","","","","","","IEEE","IEEE Journals & Magazines"
"A hybrid monitor for behavior and performance analysis of distributed systems","D. Haban; D. Wybranietz","Int. Comput. Sci. Inst., Berkeley, CA, USA; NA","IEEE Transactions on Software Engineering","","1990","16","2","197","211","The authors describe a hybrid monitor for measuring the performance and observing the behavior of distributed systems during execution. They emphasize data collection, analysis and presentation of execution data. A special hardware support, which consists of a test and measurement processor (TMP), was designed and has been implemented in the nodes of experimental multicomputer system consisting of eleven nodes. The operations of the TMP are completely transparent with a minimal, less than 0.1%, overhead to the measured system. In the experimental system, all the TMPs were connected with a central monitoring station, using an independent communication network, in order to provide a global view of the monitored system. The central monitoring station displayed the resulting information in easy-to-read charts and graphs. Experience with the TMP shows that it promotes an improved understanding of run-time behavior and performance measurements, which aids in deriving qualitative and quantitative assessments of distributed systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44382","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44382","","Performance analysis;Computerized monitoring;Hardware;Control systems;Displays;Debugging;Computer science;Interference;Centralized control;System testing","distributed processing;performance evaluation;program testing","behaviour analysis;qualitative assessments;performance analysis;distributed systems;hybrid monitor;data collection;execution data;hardware support;test and measurement processor;TMP;experimental multicomputer system;communication network;quantitative assessments","","72","","28","","","","","","IEEE","IEEE Journals & Magazines"
"A three-dimensional iconic environment for image database querying","A. Del Bimbo; M. Campanai; P. Nesi","Dipartimento di Sistemi e Inf., Firenze Univ., Italy; Dipartimento di Sistemi e Inf., Firenze Univ., Italy; Dipartimento di Sistemi e Inf., Firenze Univ., Italy","IEEE Transactions on Software Engineering","","1993","19","10","997","1011","Retrieval by contents of images from pictorial databases can be effectively performed through visual icon-based systems. In these systems, the representation of pictures with 2D strings, which are derived from symbolic projections, provides an efficient and natural way to construct iconic indexes for pictures and is also an ideal representation for the visual query. With this approach, retrieval is reduced to matching two symbolic strings. However, using 2D-string representations, spatial relationships between the objects represented in the image might not be exactly specified. Ambiguities arise for the retrieval of images of 3D scenes. In order to allow the unambiguous description of object spatial relationships, in this paper, following the symbolic projections approach, images are referred to by considering spatial relationships in the 3D imaged scene. A representation language is introduced that expresses positional and directional relationships between objects in three dimensions, still preserving object spatial extensions after projections. Iconic retrieval from pictorial databases with 3D interfaces is discussed and motivated. A system for querying by example with 3D icons, which supports this language, is also presented.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.245741","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=245741","","Image databases;Information retrieval;Image retrieval;Content based retrieval;Visual databases;Layout;Spatial databases;Graphics;Database languages;Displays","graphical user interfaces;query processing;visual databases","three-dimensional iconic environment;image database querying;pictorial databases;visual icon-based systems;2D strings;symbolic projections;visual query;object spatial relationships;spatial relationships;object spatial extensions;3D interfaces;querying by example;3D icons","","26","","31","","","","","","IEEE","IEEE Journals & Magazines"
"Subsystems of Processes with Deadlock Avoidance","D. B. Lomet","IBM T. J. Watson Research Center","IEEE Transactions on Software Engineering","","1980","SE-6","3","297","304","A graph-oriented approach to deadlock avoidance, which treates both shared and exclusive locking, has been described [6]. The method is particularly suited for database systems. With enhancements introduced here, the problem of indefimite delay, i.e., the possibility that a process will not run to completion (will be delayed indefinitely) can be eliminated. The approach taken is to partition the resource system into subsystems, each of which can be scheduled independently. Indefinite delay is avoided by the construction of subsystems that guarantee the completion of a process or the granting of a resource request. Further, we show how the subsystem approach can be applied systematically so as to approximate FIFO scheduling of resource requests, while avoiding deadlock and indefmite delay. Other scheduling disciplines can also be realized. A lock manager program utilizing the FIFO method has been implemented.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230476","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702732","Database systems;deadlock;deadlock avoidance;indefinite delay;lockdng;resource allocation;starvation","System recovery;Delay;Database systems;Resource management;Operating systems;Councils;Scheduling algorithm;Frequency;Safety;Testing","","Database systems;deadlock;deadlock avoidance;indefinite delay;lockdng;resource allocation;starvation","","7","","8","","","","","","IEEE","IEEE Journals & Magazines"
"Function point analysis: difficulties and improvements","C. R. Symons","Nolan, Norton & Co., London, UK","IEEE Transactions on Software Engineering","","1988","14","1","2","11","The method of function point analysis was developed by A. J. Albrecht (1979) to help measure the size of a computerized business information system. Such sizes are needed as a component of the measurement of productivity in system development and maintenance activities, and as a component of estimating the effort needed for such activities. Close examination of the method shows certain weaknesses, and the author proposes a partial alternative. A description is given of the principles of this Mark II approach. The results are presented of some measurements of actual systems to calibrate the Mark II approach, and conclusions are drawn on the validity and applicability of function point analysis generally.<<ETX>></ETX>","0098-5589;1939-3520;2326-3881","","10.1109/32.4618","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4618","","Productivity;Information systems;Information processing;Size measurement;Environmental factors;Information analysis;Gain measurement;Information technology;Project management","management information systems;systems analysis","function point analysis;computerized business information system;productivity;system development;maintenance;Mark II","","167","","7","","","","","","IEEE","IEEE Journals & Magazines"
"Autonomous Vehicle Control Using Al Techniques","D. Keirsey; J. Mitchell; B. Bullock; T. Nussmeir; D. Y. Tseng","Hughes Research Laboratory; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","9","986","992","A review of early work on a project to develop autonomous vehicle control technology is presented. The primary goal of this effort is the development of a generic capability that can be specialized to a wide range of DoD applications. The emphasis in this project is development of the fundamental Al-based technology required by autonomous systems and the implementation of a testbed environment to evaluate and demonstrate the system capabilities.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232552","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702119","Artificial intelligence;autonomous vehicles;planning","Remotely operated vehicles;Mobile robots;Control systems;Intelligent vehicles;Intelligent sensors;Performance analysis;Navigation;Robotics and automation;System testing;Laboratories","","Artificial intelligence;autonomous vehicles;planning","","3","","11","","","","","","IEEE","IEEE Journals & Magazines"
"An insider's evaluation of PAISLey","P. Zave","AT&T Bell Lab., Murray Hill, NJ, USA","IEEE Transactions on Software Engineering","","1991","17","3","212","225","An executable specification language called PAISLey is evaluated. The language is accompanied by specification methods, analysis techniques, and software tools. The actual results of the PAISLey project are summarized. Research methods, how the results were obtained, and how the project might have been improved are discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.75412","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=75412","","Specification languages;Software tools;Investments;Writing;Chaos;Heart;Software systems;Testing","formal specification;software tools;specification languages","PAISLey;executable specification;specification methods;analysis techniques;software tools","","32","","35","","","","","","IEEE","IEEE Journals & Magazines"
"On criteria for module interfaces","D. Hoffman","Dept. of Comput. Sci., Victoria Univ., BC, Canada","IEEE Transactions on Software Engineering","","1990","16","5","537","542","While the benefits of modular software development are widely acknowledged, there is little agreement as to what constitutes a good module interface. Computational complexity techniques allow evaluation of algorithm time and space costs but offer no guidance in the design of the interface to an implementation. Yet, interface design decisions often have a critical effect on the development and maintenance costs of large software systems. Criteria that have led to simple, elegant interfaces are presented in detail. These criteria have been developed and refined through repeated practical application. The use of the criteria is illustrated with concrete examples.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.52776","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=52776","","Costs;Software systems;Programming;Computational complexity;Algorithm design and analysis;Application software;Concrete;Software engineering;Control systems;Hardware","software engineering","module interfaces;modular software development","","9","","16","","","","","","IEEE","IEEE Journals & Magazines"
"On Required Element Testing","S. C. Ntafos","Computer Science Program, University of Texas at Dallas, Richardson, TX 75080.","IEEE Transactions on Software Engineering","","1984","SE-10","6","795","803","In this paper we introduce two classes of program testing strategies that consist of specifying a set of required elements for the program and then covering those elements with appropriate test inputs. In general, a required element has a structural and a functional component and is covered by a test case if the test case causes the features specified in the structural component to be executed under the conditions specified in the functional component. Data flow analysis is used to specify the structural component and data flow interactions are used as a basis for developing the functional component. The strategies are illustrated with examples and some experimental evaluations of their effectiveness are presented.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010308","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010308","Data flow analysis;required element testing;testing strategies","Software testing;Data analysis;Genetic mutations;Error correction;Performance evaluation;Costs","","","","100","","23","","","","","","IEEE","IEEE Journals & Magazines"
"A simulation study of two distributed task allocation procedures","V. M. Milutinovic; J. J. Crnkovic; C. E. Houstis","Sch. of Electr. Eng., Purdue Univ., West Lafayette, IN, USA; NA; NA","IEEE Transactions on Software Engineering","","1988","14","1","54","61","The authors concentrate on the simulation study of two distributed task allocation procedures: the load balancing and the LOCO procedure. The first is widely used in general-purpose processing. The second was recently introduced and analyzed in the processing environment corresponding to the complex multitask jobs typical of some supercomputing and artificial-intelligence-oriented systems. Both procedures are simulated and compared in realistic situations, where both processing resources and interconnection network may represent the system bottleneck. Both were tested using carrier-sense multiple-access communications protocols. The CSMA/CD protocol performed better than TDMA with load balancing, but no difference was found with the LOCO procedure. For a large number of special-purpose processing resources and a large number of jobs in the system, LOCO produced better results than load balancing.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4622","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4622","","Computer architecture;Artificial intelligence;Load management;Computational modeling;Distributed computing;Computer science;Intelligent systems;Multiprocessor interconnection networks;Engines;Queueing analysis","multiprogramming;protocols;virtual machines","distributed task allocation procedures;simulation study;load balancing;LOCO procedure;general-purpose processing;complex multitask jobs;supercomputing;artificial-intelligence-oriented systems;interconnection network;system bottleneck;carrier-sense multiple-access;communications protocols;CSMA/CD;TDMA","","4","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Some Properties Derived from Structural Analysis of Program Graph Models","R. M. Negrini; M. Sami","Dipartimento di Elettronica, Politecnico di Milano; NA","IEEE Transactions on Software Engineering","","1983","SE-9","2","172","178","It is considered interesting to identify, from the structure of control flow and of relationships among variables in a program, some properties allowing to point out possible sources of errors or of faulty behavior. In particular, it is found that information about termination of loops and about meaningfulness of acceptance tests in recopery block strategy can be extracted from such structural analysis. Criteria for applying this analysis to programs with arbitrary structures are presented.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236462","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703034","Program graph models;program testing;structural dependence;structural termination","Circuit testing;Fault diagnosis;Circuit faults;Error correction;Data mining;Information analysis;Performance analysis;Performance evaluation;Runtime;Software reliability","","Program graph models;program testing;structural dependence;structural termination","","2","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Object-oriented development","G. Booch","Rational, Mountain View, CA 94043","IEEE Transactions on Software Engineering","","1986","SE-12","2","211","221","Object-oriented development is a partial-lifecycle software development method in which the decomposition of a system is based upon the concept of an object. This method is fundamentally different from traditional functional approaches to design and serves to help manage the complexity of massive software-intensive systems. The author examines the process of object-oriented development as well as the influences upon this approach from advances in abstraction mechanisms, programming languages, and hardware. The concept of an object is central to object-oriented development and so the properties of an object are discussed. The mapping of object-oriented techniques to Ada using a design case study is considered.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312937","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312937","Abstract data type;Ada;object;object-oriented development;software development method","Object oriented modeling;Object recognition;Software;Hardware;Abstracts;Engines;Wheels","software engineering","partial-lifecycle software development method;decomposition;software-intensive systems;object-oriented development;abstraction mechanisms;programming languages;hardware;Ada","","205","","","","","","","","IEEE","IEEE Journals & Magazines"
"Adaptive Optimization of a System's Load","G. Serazzi; M. Calzarossa","Istituto di Analisi Numerica, Consiglio Nazionale delle Ricerche (CNR), Pavia, Italy; Dipartimento di Informatica e Sistemistica, Universit di Pavia, Pavia, Italy.; Istituto di Analisi Numerica, Consiglio Nazionale delle Ricerche (CNR), Pavia, Italy; Dipartimento di Informatica e Sistemistica, Universit di Pavia, Pavia, Italy.","IEEE Transactions on Software Engineering","","1984","SE-10","6","837","845","Applications of modeling techniques based on queueing theory to computer system performance analysis normally assume the existence of steady-state conditions. However, these conditions are often violated since the unpredictable composition of workload causes peaks having highly variable intensities and durations. Furthermore, computer system performance is highly dependent on how the system reacts to workload fluctuations. Automatic control mechanisms are required to take care of the high variance of resource demands. Real-time optimization of the overall performance of a computer system requires the introduction of adaptive control on the controlled functions, An adaptive scheduling algorithm which controls the input of the system in order to maximize a given performance criterion, such as the system throughput, is presented. The system load is adjusted depending on the characteristics of both the mix of jobs in execution and the mix of jobs submitted to the system and waiting in the input queue. The asymptotic analysis of the performance bounds provides useful information about the limits on the performance indexes that can be achieved with a multiclass workload. The evaluation of the adaptive control system is performed through simulation experiments using data collected from two real workloads. This technique could be used to optimize the throughput of a centralized system as well as for the automatic load balancing in a distributed environment.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010312","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010312","Adaptive control;adaptive scheduling algorithm;asymptotic bound analysis;load balancing;real-time performance optimization","Performance analysis;Automatic control;System performance;Adaptive control;Control systems;Throughput;Application software;Load modeling;Queueing analysis;Steady-state","","","","3","","21","","","","","","IEEE","IEEE Journals & Magazines"
"The Amulet environment: new models for effective user interface software development","B. A. Myers; R. G. McDaniel; R. C. Miller; A. S. Ferrency; A. Faulring; B. D. Kyle; A. Mickish; A. Klimovitski; P. Doane","Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA; NA; NA; NA; NA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1997","23","6","347","365","The Amulet user interface development environment makes it easier for programmers to create highly interactive, graphical user interface software for Unix, Windows and the Macintosh. Amulet uses new models for objects, constraints, animation, input, output, commands, and undo. The object system is a prototype instance model in which there is no distinction between classes and instances or between methods and data. The constraint system allows any value of any object to be computed by arbitrary code and supports multiple constraint solvers. Animations can be attached to existing objects with a single line of code. Input from the user is handled by ""interactor"" objects which support reuse of behavior objects. The output model provides a declarative definition of the graphics and supports automatic refresh. Command objects encapsulate all of the information needed about operations, including support for various ways to undo them. A key feature of the Amulet design is that all graphical objects and behaviors of those objects are explicitly represented at run time, so the system can provide a number of high level built-in functions, including automatic display and editing of objects, and external analysis and control of interfaces. Amulet integrates these capabilities in a flexible and effective manner.","0098-5589;1939-3520;2326-3881","","10.1109/32.601073","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=601073","","User interfaces;Animation;Programming profession;Graphical user interfaces;Software prototyping;Prototypes;Graphics;Displays;Control system analysis;Automatic control","user interface management systems;programming environments;computer animation;graphical user interfaces;object-oriented programming","graphical user interface software;effective user interface software development;Amulet user interface development environment;animation;object system;prototype instance model;constraint system;arbitrary code;multiple constraint solvers;interactor objects;behavior object reuse;output model;declarative definition;automatic refresh;command objects;graphical objects;automatic display","","64","","32","","","","","","IEEE","IEEE Journals & Magazines"
"A recommended practice for describing software designs: IEEE standards project 1016","H. J. Barnard; R. F. Metz; A. L. Price","AT&T Information Systems, Denver, CO 80234; AT&T Information Systems, Denver, CO 80234; AT&T Information Systems, Denver, CO 80234","IEEE Transactions on Software Engineering","","1986","SE-12","2","258","263","The method outlined presumes that a design is completely described when the information needs of each design user are satisfied. The minimum set of design users and their specific information requirements are discussed. An information model is used to describe the needed design information through a set of 15 standard design entity attributes. To simplify the access and assimilation of design information, an organization of the entity attributes into four distinct design views is proposed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312941","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312941","Design documentation;IEEE Standards;software design","Software design;IEEE standards;Software systems;Organizations;Algorithm design and analysis","software engineering;standards","software engineering;software designs;IEEE Standards Project 1016;design users;information requirements;information model;design entity attributes","","3","","","","","","","","IEEE","IEEE Journals & Magazines"
"A case history development of a foolproofing interface documentation system","T. Nakajo; I. Azuma; M. Tada","Dept. of Ind. & Syst. Eng., Chuo Univ., Tokyo, Japan; NA; NA","IEEE Transactions on Software Engineering","","1993","19","8","765","773","The authors discuss information transmission errors occurring between design engineers involved in software development and describe an interface design documentation system that can prevent them. The equivalence of human errors in software design and hardware manufacturing activities is established. The characteristics that must be included in an interface documentation system to prevent communication errors in software design activities, based on foolproofing principles that were identified for hardware manufacturing, are discussed. Utilizing these characteristics, an example of an interface documentation system for software products which control measuring equipment is presented. Its effects on the resultant number of communication errors between hardware and software engineers is subsequently experimentally evaluated.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.238580","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=238580","","History;Computer errors;Documentation;Hardware;Software design;Manufacturing;Design engineering;Programming;Humans;Software systems","computerised control;fault tolerant computing;human factors;system documentation;user interfaces","measurement equipment control;foolproofing interface documentation system;information transmission errors;design engineers;software development;interface design documentation system;human errors;software design;hardware manufacturing activities;foolproofing principles;measuring equipment","","1","","19","","","","","","IEEE","IEEE Journals & Magazines"
"Working Sets Past and Present","P. J. Denning","Department of Computer Science, Purdue University","IEEE Transactions on Software Engineering","","1980","SE-6","1","64","84","A program's working set is the collection of segments (or pages) recently referenced. This concept has led to efficient methods for measuring a program's intrinsic memory demand; it has assisted in undetstanding and in modeling program behavior; and it has been used as the basis of optimal multiprogrammed memory management. The total cost of a working set dispatcher is no larger than the total cost of other common dispatchers. This paper outlines the argument why it is unlikely that anyone will find a cheaper nonlookahead memory policy that delivers significantly better performance.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.230464","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702696","Dispatchers;lifetime curves;memory management;memory space-time product;multiprogrammed load controllers;multiprogramming;optimal multiprogramming;phase/transition behavior;program behavior;program locality;program measurement;stochastic program models;virtual memory;working set dispatchers;working sets","Memory management;Costs;Processor scheduling;Optimal control;Phase measurement;Stochastic processes;Space technology;Operating systems;Computer science;Adaptive control","","Dispatchers;lifetime curves;memory management;memory space-time product;multiprogrammed load controllers;multiprogramming;optimal multiprogramming;phase/transition behavior;program behavior;program locality;program measurement;stochastic program models;virtual memory;working set dispatchers;working sets","","137","","128","","","","","","IEEE","IEEE Journals & Magazines"
"A Statistical Method for Software Quality Control","K. Okumoto","AT&amp;T Bell Laboratories","IEEE Transactions on Software Engineering","","1985","SE-11","12","1424","1430","This paper proposes a statistical method that can be used to monitor, control, and predict the quality (measured in terms of the failure intensity) of a software system being tested. The method consists of three steps: estimation of the failure intensity (failures per unit of execution time) based on groups of failures, fitting the logarithmic Poisson model to the estimated failure intensity data, and constructing confidence limits for the failure intensity process. The proposed estimation method is validated through a simulation study. A method for predicting the additional execution time required to achieve a failure intensity objective is also discussed. A set of failure data collected from a real-time command and control system is used to demonstrate the proposed method.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232178","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701964","Additional software test time;logarithmic Poisson model;software reliability model;software quality control","Statistical analysis;Software quality;Condition monitoring;Control systems;Software measurement;Software systems;Software testing;System testing;Real time systems;Command and control systems","","Additional software test time;logarithmic Poisson model;software reliability model;software quality control","","13","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Real-Time Behavior of Programs","V. H. Haase","Department of Computer Science, Technical University of Graz","IEEE Transactions on Software Engineering","","1981","SE-7","5","494","501","Verification and compile-time checking of the behavior of programs in real time is an important issue in many applications, e.g., process control, lab automation, and monitoring of missiles and vehicles. Present day programming languages and compilers lack the facilities of calculating execution times of programs.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.231111","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702875","Deadline scheduling;guarded commands;parallel processes;process control;real-time programming","Process control;Computerized monitoring;Transformers;Aerospace electronics;Hardware;State-space methods;Application software;Automation;Missiles;Vehicles","","Deadline scheduling;guarded commands;parallel processes;process control;real-time programming","","16","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Symbolic Semantics and Program Reduction","V. Ambriola; F. Giannotti; D. Pedreschi; F. Turini","Dipartimento di Informatica, Universit&#224; di Pisa; NA; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","8","784","794","A class of transformations of functional programs based on symbolic execution and simplification of conditionals is presented. The operational symbolic semantics of a family of functional languages is defined exploiting a set-theoretic notion of symbolic constants. An effective transformation able to simplify a functional program via removal of conditionals is discussed. Finally, it is shown that a structural approach, based on abstract data type specifications, provides a suitable representation for symbolic constants.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232527","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702087","Abstract data type specifications;functional programming languages;program reduction;program transformations;rewriting systems;symbolic evaluation","Constraint optimization;Input variables;Functional programming;Proposals;Testing;Performance analysis;Constraint theory;Concrete;Robustness","","Abstract data type specifications;functional programming languages;program reduction;program transformations;rewriting systems;symbolic evaluation","","1","","17","","","","","","IEEE","IEEE Journals & Magazines"
"A characterization of the stochastic process underlying a stochastic Petri net","G. Ciardo; R. German; C. Lindemann","Dept. of Comput. Sci., Coll. of William & Mary, Williamsburg, VA, USA; NA; NA","IEEE Transactions on Software Engineering","","1994","20","7","506","515","Stochastic Petri nets (SPN's) with generally distributed firing times can model a large class of systems, but simulation is the only feasible approach for their solution. We explore a hierarchy of SPN classes where modeling power is reduced in exchange for an increasingly efficient solution. Generalized stochastic Petri nets (GSPN's), deterministic and stochastic Petri nets (DSPN's), semi-Markovian stochastic Petri nets (SM-SPN's), timed Petri nets (TPN's), and generalized timed Petri nets (GTPN's) are particular entries in our hierarchy. Additional classes of SPN's for which we show how to compute an analytical solution are obtained by the method of the embedded Markov chain (DSPN's are just one example in this class) and state discretization, which we apply not only to the continuous-time case (PH-type distributions), but also to the discrete case.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.297939","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=297939","","Stochastic processes;Petri nets;Stochastic systems;Power system modeling;Embedded computing;Markov processes;Delay;Steady-state;Fires;Distributed computing","Petri nets;stochastic processes;Markov processes","stochastic process;stochastic Petri net;distributed firing times;simulation;SPN classes;modeling power;generalized stochastic Petri nets;stochastic Petri nets;deterministic Petri nets;semiMarkovian stochastic Petri nets;timed Petri nets;generalized timed Petri nets;embedded Markov chain;state discretization;continuous-time case;PH-type distributions","","102","","25","","","","","","IEEE","IEEE Journals & Magazines"
"A disciplined approach to office analysis","V. De Antonellis; B. Zonta","Dipartimento di Sci. dell'Inf., Milano Univ., Italy; NA","IEEE Transactions on Software Engineering","","1990","16","8","822","828","To define office requirements, the authors propose a disciplined language in which a good portion of conventionality and known and concrete concepts are associated with a minimum formalism. The language can be used in analyzing an office for the purpose of designing a computer-based office support system. Given the language, the designer can organize information obtained by people working in the office and state the office requirements that will be the basis for developing a suitable system. The features of the language are illustrated and its morphology and syntax are explained.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.57621","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=57621","","Natural languages;Concrete;Software engineering;AC generators;Guidelines","computational linguistics;formal languages;formal specification;office automation;programming languages","office requirements;disciplined language;conventionality;concrete concepts;minimum formalism;computer-based office support system;designer;morphology;syntax","","15","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Experience with Traits in the Xerox Star Workstation","G. A. Curry; R. M. Ayers","Sequent Corporate Systems, Portland, OR.; Xerox Office Systems Division, Palo Alto, CA 94304.","IEEE Transactions on Software Engineering","","1984","SE-10","5","519","527","The Xerox Star (8010) is an integrated office workstation. Its software is written in an object-oriented style. Often, different applications will impose slightly different requirements on nominally similar objects which they use. Customization of object definitions for different applications is achieved by attaching modifiers called traits to pre-existing object defintions. This paper describes the approach and recounts our experience with traits.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010276","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010276","Human interface;multiple inheritance;object orientation;reusability;software engineering;subclassing;traits","Workstations;Software design;Application software;Software systems;Joining processes;Software engineering;Printers;Postal services;Graphics","","","","9","","9","","","","","","IEEE","IEEE Journals & Magazines"
"The object-oriented functional data language","M. V. Mannino; J. J. Choi; D. S. Batory","Texas Univ., Austin, TX, USA; Texas Univ., Austin, TX, USA; Texas Univ., Austin, TX, USA","IEEE Transactions on Software Engineering","","1990","16","11","1258","1272","The object-oriented functional data language (O/sup 2/FDL) is an interactive strongly typed database programming language that integrates the object-oriented and functional programming paradigms. It was designed for advanced applications that require a powerful and uniform database programming language supporting the software engineering principles of these tow paradigms. To this end, the O/sup 2/FDL supports inheritance and encapsulation of object-oriented languages, and an equational notation and strong typing of functional programming. Strong typing is extended with type restrictions to constrain the instantiations of type variables in function interfaces, while inheritance is augmented with a monotonic subtype rule for function redefinition. The O/sup 2/FDL also supports novel features. For the core of the O/sup 2/FDL, a denotational semantics based on an extended lambda -calculus is provided. For selected system-defined functions, operational semantics are provided and it is demonstrated that a subset of the O/sup 2/FDL is at least as expressive as the relational algebra.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.60314","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=60314","","Object oriented databases;Spatial databases;Relational databases;Transaction databases;Functional programming;Computer languages;Application software;Design automation;Encapsulation;Database systems","high level languages;object-oriented programming;software engineering","object oriented programming;object-oriented functional data language;interactive strongly typed database programming language;functional programming;software engineering;O/sup 2/FDL;inheritance;encapsulation;object-oriented languages;equational notation;strong typing;type restrictions;type variables;function interfaces;monotonic subtype rule;function redefinition;denotational semantics;extended lambda -calculus;operational semantics;relational algebra","","10","","42","","","","","","IEEE","IEEE Journals & Magazines"
"Qualified Data Flow Problems","L. H. Holley; B. K. Rosen","IBM Cambridge Scientific Center; NA","IEEE Transactions on Software Engineering","","1981","SE-7","1","60","78","It is known that not aU paths are possible in the run time control flow of many programs. It is also known that data flow analysis cannot restrict attention to exactly those paths that are possible. It is, therefore, usual for analytic methods to consider aU paths. Sharper information can be obtained by considering a recursive set of paths that is large enough to include aUl possible paths, but smaU enough to exclude many of the impossible ones. This paper presents a simple uniform methodology for sharpening data flow information by considering certain recursive path sets of practical importance. Associated with each control flow arc there is a relation on a finite set Q. The paths that qualify to be considered are (essentially) those for which the composition of the relations encountered is nonempty. For example, Q might be the set of all assignments of values to each of several bit variables used by a program to remember some facts about the past and branch accordingly in the future. Given any data-flow problem together with qualifying relations on Q associated with the control flow arcs, we construct a new problem. Considering all paths in the new problem is equivalent to considering only qualifying paths in the old one. Preliminary experiments (with a smaUl set of real programs) indicate that qualified analysis is feasible and substantialy more informative than ordinary analysis.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234509","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702803","Data flow analysis;global variable;interprocedural analysis;label variable;symbolic execution","Testing;Data analysis;Computer languages;Feedback;Assembly;Flowcharts;Constraint optimization;Operating systems;Algorithm design and analysis;Availability","","Data flow analysis;global variable;interprocedural analysis;label variable;symbolic execution","","11","","25","","","","","","IEEE","IEEE Journals & Magazines"
"Reflexive Incidence Matrx (RIM) Representation of Petri Nets","S. K. Das; V. K. Agrawal; D. Sarkar; L. M. Patnaik; P. S. Goel","Department of Computer Science, University of Central Florida; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","6","643","653","Although incidence matrix representation has been used to analyze the Petri net based models of a system, it has the limitation that it does not preserve reflexive properties (i.e., the presence of self-loops) of Petri nets. But in many practical applications self-loops play very important roles. This paper proposes a new representation scheme for general Petri nets. This scheme defines a matrix called ""reflexive incidence matrix (RIM) C<sup>r</sup>,"" which is a combination of two matrices, a ""base matrix C<sup>b</sup>,"" and a ""power matrix C<sup>p</sup>."" This scheme preserves the reflexive and other properties of the Petri nets. Through a detailed analysis it is shown that the proposed scheme requires less memory space and less processing time for answering commonly encountered net queries compared to other schemes. Algorithms to generate the RIM from the given net description and to decompose RIM into input and output function matrices are also given. The proposed Petri net representation scheme is very useful to model and analyze the systems having shared resources, chemical processes, network protocols, etc., and to evaluate the performance of asynchronous concurrent systems.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233202","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702270","Incidence matrix;Petri net;reflexivity;self-loop;space complexity;time complexity","Petri nets;Matrix decomposition;Power system modeling;Computer science;Matrix converters;Chemical analysis;Performance analysis;Chemical processes;Protocols","","Incidence matrix;Petri net;reflexivity;self-loop;space complexity;time complexity","","1","","14","","","","","","IEEE","IEEE Journals & Magazines"
"A relational notation for state transition systems","S. S. Lam; A. U. Shankar","Dept. of Comput. Sci., Texas Univ., Austin, TX, USA; NA","IEEE Transactions on Software Engineering","","1990","16","7","755","775","A relational notation for specifying state transition systems is presented. Several refinement relations between specifications are defined. To illustrate the concepts and methods, three specifications of the alternating-bit protocol are given. The theory is applied to explain auxiliary variables. Other applications of the theory to protocol verification, composition, and conversion are discussed. The approach is compared with previously published approaches.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.56101","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=56101","","Protocols;Computer languages;Petri nets;Logic programming;Probability;Space vehicles;History;Computer science;Equations","formal specification;protocols","relational notation;specifying state transition systems;refinement relations;alternating-bit protocol;composition","","32","","38","","","","","","IEEE","IEEE Journals & Magazines"
"The Draco Approach to Constructing Software from Reusable Components","J. M. Neighbors","Department of Information and Computer Science, University of California, Irvine, CA 92717.; CXC Corporation, Irvine, CA 92714.","IEEE Transactions on Software Engineering","","1984","SE-10","5","564","574","This paper discusses an approach called Draco to the construction of software systems from reusable software parts. In particular we are concerned with the reuse of analysis and design information in addition to programming language code. The goal of the work on Draco has been to increase the productivity of software specialists in the construction of similar systems. The particular approach we have taken is to organize reusable software components by problem area or domain. Statements of programs in these specialized domains are then optimized by source-to-source program transformations and refined into other domains. The problems of maintaining the representational consistency of the developing program and producing efficient practical programs are discussed. Some examples from a prototype system are also given.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010280","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010280","Analysis;automatic programming;design;module interconnection languages;program generation;program refinement;program transformations;reusable software;software components","Software reusability;Information analysis;Software systems;Software prototyping;Prototypes;Computer languages;Productivity;Automatic programming;Tellurium;Humans","","","","185","","17","","","","","","IEEE","IEEE Journals & Magazines"
"Automated derivation of time bounds in uniprocessor concurrent systems","G. S. Avrunin; J. C. Corbett; L. K. Dillon; J. C. Wileden","Massachusetts Univ., Amherst, MA, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1994","20","9","708","719","The successful development of complex real-time systems depends on analysis techniques that can accurately assess the timing properties of those systems. This paper describes a technique for deriving upper and lower bounds on the time that can elapse between two given events in an execution of a concurrent software system running on a single processor under arbitrary scheduling. The technique involves generating linear inequalities expressing conditions that must be satisfied by all executions of such a system and using integer programming methods to find appropriate solutions to the inequalities. The technique does not require construction of the state space of the system and its feasibility has been demonstrated by using an extended version of the constrained expression toolset to analyze the timing properties of some concurrent systems with very large state spaces.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.317429","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=317429","","Optimal scheduling;Real time systems;Timing;Processor scheduling;Scheduling algorithm;Software systems;State-space methods;Lifting equipment;Linear programming;Runtime","integer programming;real-time systems;scheduling;systems analysis;concurrency control","time bound derivation;uniprocessor concurrent systems;complex real-time systems;timing properties;lower bounds;upper bounds;concurrent software system;single processor;arbitrary scheduling;linear inequalities;integer programming methods;constrained expression toolset;very large state spaces;concurrent systems;timing analysis;finite state systems","","8","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Identifying Error-Prone SoftwareAn Empirical Study","V. Y. Shen; Tze-jie Yu; S. M. Thebaut; L. R. Paulsen","Department of Computer Sciences, Purdue University; NA; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","4","317","324","A major portion of the effort expended in developing commercial software today is associated with program testing. Schedule and/ or resource constraints frequently require that testing be conducted so as to uncover the greatest number of errors possible in the time allowed. In this paper we describe a study undertaken to assess the potential usefulness of various product-and process-related measures in identifying error-prone software. Our goal was to establish an empirical basis for the efficient utilization of limited testing resources using objective, measurable criteria. Through a detailed analysis of three software products and their error discovery histories, we have found simple metrics related to the amount of data and the structural complexity of programs to be of value for this purpose.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232222","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702015","Defect density;error-prone modules;probability of errors;program testing;software errors;software metrics","Error correction;Software testing;Software measurement;Costs;Software systems;Laboratories;Performance evaluation;System testing;History;Software metrics","","Defect density;error-prone modules;probability of errors;program testing;software errors;software metrics","","102","","16","","","","","","IEEE","IEEE Journals & Magazines"
"An overview of a graphical multilanguage applications environment","G. Fisher","Div. of Comput. Sci., California Univ., Davis, CA, USA","IEEE Transactions on Software Engineering","","1988","14","6","774","786","A programming environment to support the development and use of engineering applications is presented. The environment provides uniform support for a set of Pascal-class languages in which engineering and scientific applications are commonly written. The environment includes a dynamically multilanguage interpreter debugger to aid in the interactive development of applications. For the application and user, the environment provides a graphical program interface based on the concept of a software control panel. Through a control panel, the user may interactively modify program parameters and exercise fine-grain control over program execution. The environment also includes a graphical design tool for constructing executable block diagrams based on standard application programs. The control-panel tool is integrated with the design tool, to provide a uniform interface to all levels of program execution.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6157","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6157","","Application software;Image processing;Graphics;Programming environments;Laboratories;User interfaces;Algorithm design and analysis;Software algorithms;Aging;Operating systems","engineering graphics;program debugging;program interpreters;programming environments;software tools;user interfaces","software tools;user interfaces;engineering graphics;program debugging;graphical multilanguage applications environment;programming environment;engineering applications;Pascal-class languages;multilanguage interpreter;interactive development;graphical program interface;software control panel;program execution;graphical design tool;executable block diagrams","","6","","34","","","","","","IEEE","IEEE Journals & Magazines"
"Constructing specifications by combining parallel elaborations","M. S. Feather","Inf. Sci. Inst., Univ. of Southern California, Marina del Rey, CA, USA","IEEE Transactions on Software Engineering","","1989","15","2","198","208","An incremental approach to construction is proposed, with the virtue of offering considerable opportunity for mechanized support. Following this approach one builds a specification through a series of elaborations that incrementally adjust a simple initial specification. Elaborations perform both refinements, adding further detail, and adaptations, retracting oversimplifications and tailoring approximations to the specifics of the task. It is anticipated that the vast majority of elaborations can be concisely described to a mechanism that will then perform them automatically. When elaborations are independent, they can be applied in parallel, leading to diverging specifications that must later be recombined. The approach is intended to facilitate comprehension and maintenance of specifications, as well as their initial construction.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21745","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21745","","Formal specifications;Specification languages;Vocabulary;Software maintenance;Feathers;Programming;Production;Feedback;Software prototyping;User interfaces","formal specification;software engineering","parallel elaborations;incremental approach;specification;comprehension;maintenance","","45","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Performance Improvement of Abstractions Through Context Dependent Transformations","F. B. Bastani","Department of Computer Science, University of Houston, Houston, TX 77004.","IEEE Transactions on Software Engineering","","1984","SE-10","1","100","116","The use of abstractions enhances several aspects of a software system, especially its maintainability, reusability, and comprehensibility. However, it decreases the performance of the software. Context dependent transformations can effectively remove the performance loss of abstractions while preserving all their advantages. We state the conditions which the transformations should satisfy and develop four general transformation rules. Language mechanisms are proposed which permit the transformation directives to be embedded in the source code. This can be used to automate the transformations. It also facilitates an approach to incremental performance improvement.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010204","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010204","Context dependent transformations;data abstractions;performance improvement;semantic equivalence;software quality;source code transformation;transformation rules","Software design;System testing;Software performance;Software quality;Software systems;Software maintenance;Hierarchical systems;Design methodology;Software testing","","","","3","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Knowledge representation and reasoning in a software synthesis architecture","D. E. Setliff; R. A. Rutenbar","Dept. of Electr. & Comput. Eng., Carnegie Mellon Univ., Pittsburgh, PA, USA; Dept. of Electr. & Comput. Eng., Carnegie Mellon Univ., Pittsburgh, PA, USA","IEEE Transactions on Software Engineering","","1992","18","6","523","533","The knowledge representation and reasoning strategies in an automatic program synthesis architecture called ELF are described. ELF synthesizes computer-aided design (CAD) tools that automatically route wires in VLSI circuits. The design space ELF confronts, requires it to understand various physical technologies, to select an appropriate procedure-level decomposition, to choose algorithms and data structures, to manage any interdependencies, and to generate efficient code. ELF manages the design space using a variety of knowledge sources, including domain-specific knowledge. The manner in which knowledge is used determines the representation method of choice. The effectiveness of these ideas is illustrated via a tour through the synthesis steps for a specific routing tool, and a brief discussion of the performance of the resulting synthetic router as measured against an industrial tool.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.142874","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=142874","","Knowledge representation;Ground penetrating radar;Geophysical measurement techniques;Circuit synthesis;Space technology;Design automation;Wires;Very large scale integration;Algorithm design and analysis;Appropriate technology","automatic programming;circuit layout CAD;inference mechanisms;knowledge representation","software synthesis architecture;knowledge representation;reasoning strategies;automatic program synthesis architecture;ELF;computer-aided design;VLSI circuits;procedure-level decomposition;data structures;design space;domain-specific knowledge;synthetic router","","10","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Engineering and analysis of fixed priority schedulers","D. I. Katcher; H. Arakawa; J. K. Strosnider","Dept. of Electr. & Comput. Eng., Carnegie Mellon Univ., Pittsburgh, PA, USA; NA; NA","IEEE Transactions on Software Engineering","","1993","19","9","920","934","Scheduling theory holds great promise as a means to a priori validate timing correctness of real-time applications. However, there currently exists a wide gap between scheduling theory and its implementation in operating system kernels running on specific hardware platforms. The implementation of any particular scheduling algorithm introduces overhead and blocking components which must be accounted for in the timing correctness validation process. This paper presents a methodology for incorporating the costs of scheduler implementation within the context of fixed priority scheduling algorithms. Both event-driven and timer-driven scheduling implementations are analyzed. We show that for the timer-driven scheduling implementations the selection of the timer interrupt rate can dramatically affect the schedulability of a task set, and we present a method for determining the optimal timer rate. We analyzed both randomly generated and two well-defined task sets and found that their schedulability can be significantly degraded by the implementation costs. Task sets that have ideal breakdown utilization over 90% may not even be schedulable when the implementation costs are considered. This work provides a first step toward bridging the gap between real-time scheduling theory and implementation realities. This gap must be bridged for any meaningful validation of timing correctness properties of real-time applications.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.241774","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=241774","","Job shop scheduling;Timing;Kernel;Costs;Processor scheduling;Operating systems;Hardware;Scheduling algorithm;Testing;Degradation","operating systems (computers);real-time systems;scheduling","fixed priority schedulers;timing correctness;real-time applications;scheduling theory;operating system kernels;hardware platforms;validation process;blocking components;fixed priority scheduling algorithms;timer-driven scheduling;event-driven scheduling;schedulability;optimal timer rate","","99","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Archetype: a unified method for the design and implementation of protocol architectures","B. Meandzija","Dept. of Comput. Sci. & Eng., Southern Methodist Univ., Dallas, TX, USA","IEEE Transactions on Software Engineering","","1988","14","6","822","837","A method for the automated design, specification, and implementation of protocol architectures is introduced. A natural-language-like protocol architecture specification technique, called Archetype, is formulated. This technique aids the design by enabling an unambiguous specification of the protocol architecture on the level of the communications technologies used, without involvement in the complex implementation details of these technologies. The author defines a data-driven concurrent execution model and specifies the generation of executable specifications from abstract protocol architecture specifications. The exploitation of parallelism in the execution model enables the fulfilment of performance constraints placed on protocol architectures. An architecture based on a single X.25-level 3-like protocol is used as an illustrative example.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6161","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6161","","Design methodology;Protocols;Computer architecture;Communications technology;Parallel processing;Computer networks;Proposals;Computer science;Automata;Petri nets","automatic programming;data structures;multiprocessing programs;protocols;simulation languages","natural languages;protocol design;automatic programming;data structures;protocol architectures;automated design;specification technique;Archetype;data-driven concurrent execution model;abstract protocol architecture specifications;performance constraints;X.25-level 3-like protocol","","3","","31","","","","","","IEEE","IEEE Journals & Magazines"
"A practical view of software measurement and implementation experiences within Motorola","M. K. Daskalantonakis","Motorola, Arlington Heights, IL, USA","IEEE Transactions on Software Engineering","","1992","18","11","998","1010","A practical view of software measurement that formed the basis for a companywide software metrics initiative within Motorola is described. A multidimensional view of measurement is provided by identifying different dimensions (e.g., metric usefulness/utility, metric types or categories, metric audiences, etc.) that were considered in this companywide metrics implementation process. The definitions of the common set of Motorola software metrics, as well as the charts used for presenting these metrics, are included. The metrics were derived using the goal/question metric approach to measurement. A distinction is made between the use of metrics for process improvement over time across projects and the use of metrics for in-process project control. Important experiences in implementing the software metrics initiative within Motorola are also included.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.177369","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=177369","","Software measurement;Software metrics;Multidimensional systems;Companies;Guidelines;Engineering management;Process planning;Productivity;Computer industry","project management;software metrics;software quality;software reliability","software measurement;implementation experiences;Motorola;software metrics initiative;multidimensional view;metric usefulness;utility;metric types;categories;metric audiences;process improvement;in-process project control","","115","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Prototyping a process monitoring experiment","M. G. Bradac; D. E. Perry; L. G. Votta","AT&T Bell Labs., Naperville, IL, USA; NA; NA","IEEE Transactions on Software Engineering","","1994","20","10","774","784","Features are often the basic unit of development for a very large software system and represent long-term efforts, spanning up to several years from inception to actual use. Developing an experiment to monitor (by means of sampling) such lengthy processes requires a great deal of care in order to minimize casts and to maximize benefits. Just as prototyping is often a necessary auxiliary step in a large-scale, long-term development effort, so, too, is prototyping a necessary step in the development of a large-scale, long-term process monitoring experiment. Therefore, we have prototyped our experiment using a representative process and reconstructed data from a large and rich feature development. This approach has yielded three interesting sets of results. First, we reconstructed a 30-month time diary for the lead engineer of a feature composed of both hardware and software. These data represent the daily state (where the lead engineer spent the majority of his time) for a complete cycle of the development process. Second, we found that we needed to modify our experimental design. Our initial set of states did not represent the data as well as we had hoped. This is exemplified by the fact that the ""Other"" category is too large. Finally, the data provide evidence for both a waterfall view and an interactive, cyclic view of software development. We conclude that the prototyping effort is a necessary part of developing and installing any large-scale process monitoring experiment.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.328994","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=328994","","Prototypes;Monitoring;Software prototyping;Large-scale systems;Software systems;Sampling methods;Design engineering;Hardware;Data engineering;Design for experiments","software prototyping;process computer control;computerised monitoring","process monitoring experiment;prototyping;very large software system;large-scale long-term development;long-term process monitoring;hardware;software;experimental design;waterfall view;interactive cyclic view;software development;large-scale process monitoring experiment","","17","","29","","","","","","IEEE","IEEE Journals & Magazines"
"Correspondence visualization techniques for analyzing and evaluating software measures","C. Ebert","Inst. of Control Eng. & Ind. Autom., Stuttgart Univ., Germany","IEEE Transactions on Software Engineering","","1992","18","11","1029","1034","One-dimensional statistical methods of scaling have been employed to present a distinct subjective criterion that is related to a measurable aspect of a software component. However, different aspects being measured and different software components being analyzed usually have some characteristics in common. Selected techniques for graphical representation permit a brief but nevertheless thorough view of complex relations among complicated sets of data. Several methods of visualizing and analyzing multidimensional data sets are presented and discussed. The underlying goals of such techniques are to find unknown structures and dependencies among measures, to represent different data sets in order to improve communication and comparability of distinct analyses, and to decrease visual complexity. For improved understandability of the statistical and related graphical concepts, a small set of design aspects from a real-world example is introduced. The techniques illustrated are applied to the same set of data and compared.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.177373","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=177373","","Software measurement;Data visualization;Multidimensional systems;Statistical analysis;Data analysis;Computer displays;Gaussian processes;Data processing;Humans;Control engineering","data visualisation;software metrics;statistical analysis","correspondence visualisation;software measures;statistical methods;scaling;distinct subjective criterion;graphical representation;multidimensional data sets;dependencies;visual complexity","","16","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Entity structure based design methodology: a LAN protocol example","S. Sevinc; B. P. Zeigler","Dept. of Electr. & Comput. Eng., Arizona Univ., Tucson, AZ, USA; Dept. of Electr. & Comput. Eng., Arizona Univ., Tucson, AZ, USA","IEEE Transactions on Software Engineering","","1988","14","3","375","383","An application of the system entity structure is illustrated: a frame-like knowledge representation scheme is used to design local area networks (LANs). An entity structure for a data-link-layer protocol that illustrates many possible applications is introduced. The main concepts of the design methodology are illustrated using this example entity structure, and the underlying simulation environment is briefly discussed. The methodology aims to facilitate evaluation of a wide family of design alternatives and component combinations.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4657","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4657","","Design methodology;Local area networks;Protocols;Knowledge representation;Computational modeling;Discrete event simulation;Process design;Packet switching;Communication switching;Data communication","local area networks;packet switching;protocols","entity structure based design methodology;LAN protocol;frame-like knowledge representation scheme;data-link-layer protocol;simulation environment","","15","","38","","","","","","IEEE","IEEE Journals & Magazines"
"On optimal site assignment for relations in the distributed database environment","D. W. Cornell; P. S. Yu","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; NA","IEEE Transactions on Software Engineering","","1989","15","8","1004","1009","In a distributed database environment, the site assignment of relations is a critical issue. When the joint operations in a query involve relations over multiple sites, the site to carry out the joint operation can have a significant impact on the performance. Based on the query descriptions and arrival frequency to each site, a methodology is developed to assign relations and determine joint sites simultaneously. The methodology first decomposes queries into relation steps and then makes site assignments based on either a linear integer programming technique to minimize the amount of intersystem communication while balancing resource utilizations across systems, or a heuristic technique to minimize average response time under similar resource constraints.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.31356","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=31356","","Distributed databases;Cost function;Query processing;Linear programming;Hardware;Resource management;Delay;Network topology;Frequency measurement;Time measurement","distributed databases;heuristic programming;information retrieval;linear programming","relation assignment;joint site determination;query decomposition;average response minimization;optimal site assignment;distributed database environment;relations;joint operations;multiple sites;query descriptions;arrival frequency;relation steps;site assignments;linear integer programming technique;intersystem communication;balancing resource utilizations;heuristic technique;resource constraints","","14","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Teaching a Software Design Methodology","D. M. Weiss","Software Productivity Consortium","IEEE Transactions on Software Engineering","","1987","SE-13","11","1156","1163","This paper describes an approach to teaching a software design methodology used at The Wang Institute of Graduate Studies. The approach is general enough to be used with any of the currently popular design methodologies. Students are first taught the principles underlying the methodology, and the standards used with it. This phase is done in a series of lectures. In the second phase, students are presented with a real design problem, and asked to solve it using the methodology. They are monitored in this process by an expert in the methodology whose job is to assure that the students adhere to the methodology, but who makes no design decisions.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232864","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702162","Software design;software engineering education;teaching software design","Education;Software design;Design methodology;Software engineering;Programming;Monitoring;Job design;Productivity;Laboratories;Application software","","Software design;software engineering education;teaching software design","","1","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Automatic support for usability evaluation","A. Lecerof; F. Paterno","Ist. CNUCE, CNR, Pisa, Italy; NA","IEEE Transactions on Software Engineering","","1998","24","10","863","888","The main goal of the work is to propose a method to evaluate user interfaces using task models and logs generated from a user test of an application. The method can be incorporated into an automatic tool which gives the designer information useful to evaluate and improve the user interface. These results include an analysis of the tasks which have been accomplished, those which failed and those never tried, user errors and their type, time related information, task patterns among the accomplished tasks, and the available tasks from the current state of the user session. This information is also useful to an evaluator checking whether the specified usability goals have been accomplished.","0098-5589;1939-3520;2326-3881","","10.1109/32.729686","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=729686","","Usability;User interfaces;Testing;Human computer interaction;Performance evaluation;Information analysis;Application software;Design engineering;Process design;Failure analysis","user interfaces;task analysis;software performance evaluation;automatic programming;human factors;interactive systems;program testing","automatic support;usability evaluation;user interface evaluation;task models;user test;automatic tool;user interface;user errors;time related information;task patterns;user session;usability goals","","69","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Software Structure for Display Management Systems","E. D. Carlson; J. R. Rhyne; D. L. Weller","Convergent Technologies, Inc.; NA; NA","IEEE Transactions on Software Engineering","","1983","SE-9","4","385","394","Display management software usually provides support for: creating displays on a CRT (cathode ray tube) or other output device; handling user inputs from keyboards, light-pens, and other input devices; and communicating with an application program in terms of these outputs and inputs. We propose a design for a family of display management systems which provide device-independent, high-level support for applications programming. The design involves structuring the display management software as a set of modules, with three levels of interfaces. The key features of this design include: 1) separation of display specifications from the actual data to be displayed; 2) structured output and input specifications; 3) asynchronous, message passing inter-faces; and 4) a software structure based on hiding details of data structures, algorithms and device orders.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.237026","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703073","Display management;graphics software;software engineering","Displays;Engineering management;Keyboards;Cathode ray tubes;Application software;Graphics;Software engineering;Laboratories;Communication system software;Algorithm design and analysis","","Display management;graphics software;software engineering","","","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Advances in software inspections","M. E. Fagan","IBM Thomas J. Watson Research Center, York-town Heights, NY 10598","IEEE Transactions on Software Engineering","","1986","SE-12","7","744","751","Software inspection is a method of static testing to verify that software meets its requirements. It engages the developers and others in a formal process of investigation that usually detects more defects in the product-and at lower cost-than does machine testing. Studies and experiences are presented which enhance the use of the inspection process and improve its contribution to development of defect-free software on time and at lower cost. Examples of benefits are cited followed by descriptions of the inspection process and some methods of obtaining the enhanced results. Users of the method report very significant improvements in quality that are accompanied by lower development costs and greatly reduced maintenance efforts. Excellent results have been obtained by small and large organizations in all aspects of new development as well as in maintenance. There is some evidence that developers who participate in the inspection of their own product actually create fewer defects in subsequent work. Because inspections formalize the development process, productivity-enhancing and quality-enhancing tools can be adopted more easily and rapidly.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312976","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312976","Defect detection;inspection;project management;quality assurance;software development;software engineering;software quality;testing;walkthru","Inspection;Testing;Maintenance engineering;Software quality;Process control;Standards","program testing;software reliability","software inspections;static testing;defect-free software;development costs;maintenance","","142","","","","","","","","IEEE","IEEE Journals & Magazines"
"Designing masking fault-tolerance via nonmasking fault-tolerance","A. Arora; S. S. Kulkarni","Dept. of Comput. Sci., Ohio State Univ., Columbus, OH, USA; NA","IEEE Transactions on Software Engineering","","1998","24","6","435","450","Masking fault-tolerance guarantees that programs continually satisfy their specification in the presence of faults. By way of contrast, nonmasking fault-tolerance does not guarantee as much: it merely guarantees that when faults stop occurring, program executions converge to states from where programs continually (re)satisfy their specification. We present in this paper a component based method for the design of masking fault-tolerant programs. In this method, components are added to a fault-intolerant program in a stepwise manner, first, to transform the fault-intolerant program into a nonmasking fault-tolerant one and, then, to enhance the fault-tolerance from nonmasking to masking. We illustrate the method by designing programs for agreement in the presence of Byzantine faults, data transfer in the presence of message loss, triple modular redundancy in the presence of input corruption, and mutual exclusion in the presence of process fail-stops. These examples also serve to demonstrate that the method accommodates a variety of fault-classes. It provides alternative designs for programs usually designed with extant design methods, and it offers the potential for improved masking fault-tolerant programs.","0098-5589;1939-3520;2326-3881","","10.1109/32.689401","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=689401","","Fault tolerance;Fault tolerant systems;Design methodology;Detectors;Fault detection;Redundancy;Costs;Interconnected systems","software fault tolerance;formal specification","masking fault-tolerance;nonmasking fault-tolerance;program executions;specification;masking fault-tolerant programs;fault-intolerant program;Byzantine faults;triple modular redundancy;process fail-stops","","20","","26","","","","","","IEEE","IEEE Journals & Magazines"
"An evaluation of expert systems for software engineering management","C. L. Ramsey; V. R. Basili","US Naval Res. Lab., Washington, DC, USA; NA","IEEE Transactions on Software Engineering","","1989","15","6","747","759","The development of four separate, prototype expert systems to aid in software engineering management is described. Given the values for certain metrics, these systems provide interpretations which explain any abnormal patterns of these values during the development of a software project. The four expert systems which solve the same problem, were built using two different approaches to knowledge acquisition, a bottom-up approach and a top-down approach and two different expert system methods, rule-based deduction and frame-based abduction. In a comparison to see which methods might better suit the needs of this field, it was found that the bottom-up approach led to better results that did the top-down approach, and the rule-based deduction systems using simple rules provided more complete and correct solutions than did the frame-based abduction systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24728","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24728","","Expert systems;Software engineering;Engineering management;Software development management;Medical expert systems;Research and development management;Project management;Programming;Military computing;Computer science","expert systems;knowledge acquisition;performance evaluation;software engineering","expert systems evaluation;prototype expert systems;software engineering management;abnormal patterns;software project;knowledge acquisition;bottom-up approach;top-down approach;expert system methods;rule-based deduction;frame-based abduction;simple rules","","17","","30","","","","","","IEEE","IEEE Journals & Magazines"
"Optimal test distributions for software failure cost estimation","W. J. Gutjahr","Dept. of Stat., Oper. Res. & Comput. Sci., Wien Univ., Austria","IEEE Transactions on Software Engineering","","1995","21","3","219","228","We generalize the input domain based software reliability measures by E.C. Nelson (1973) and by S.N. Weiss and E.J. Weyuker (1988), introducing expected failure costs under the operational distribution as a measure for software unreliability. This approach incorporates in the reliability concept a distinction between different degrees of failure severity. It is shown how to estimate the proposed quantity by means of random testing, using the Importance Sampling technique from Rare Event Simulation. A test input distribution that yields an unbiased estimator with minimum variance is determined. The practical application of the presented method is outlined, and a detailed numerical example is given.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.372149","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=372149","","Software testing;Cost function;Software reliability;Software measurement;Application software;Fault detection;Reliability theory;Monte Carlo methods;Discrete event simulation;Yield estimation","software cost estimation;software reliability;software metrics;program testing","optimal test distributions;software failure cost estimation;input domain based software reliability measures;expected failure costs;operational distribution;software unreliability;failure severity;random testing;Importance Sampling technique;Rare Event Simulation;test input distribution;unbiased estimator;minimum variance","","25","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Combining queueing network and Generalized Stochastic Petri Net models for the analysis of some software blocking phenomena","G. Balbo; S. C. Bruell; S. Ghanta","Dipartimento di Informatica, Universit&#x00E1; di Tonno, Torino, Italy; Department of Computer Science, University of Iowa, Iowa City, IA 52242; Department of Computer Science, University of Minnesota, Minneapolis, MN 55455","IEEE Transactions on Software Engineering","","1986","SE-12","4","561","576","Much work has been done on the modeling of hardware resources; far fewer studies have been conducted on the impact of software systems on the underlying hardware. The authors address one such case in which blocking is present because of critical sections of code; this cannot be treated within the framework of product-form queuing network models. They show how a combination of generalized stochastic petri nets and queuing networks can easily model the situation under consideration. In addition, they show how a simple extension of this model can be applied to studying realistic systems with several domains.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312904","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312904","Class migration;critical sections;domains;Generalized Stochastic Petri Nets;queueing networks;serialization delays","Computational modeling;Analytical models;Markov processes;Servers;Software;Hardware","directed graphs;programming theory;queueing theory","queueing network;stochastic Petri net models;software blocking phenomena;hardware","","14","","","","","","","","IEEE","IEEE Journals & Magazines"
"Modeling of Software Partition for Distributed Real-Time Applications","J. P. Huang","Titan Systems, Incorporated","IEEE Transactions on Software Engineering","","1985","SE-11","10","1113","1126","The issue of software partition deals with the process of mapping the given set of logical modules, which reflect the user's point of view, into a set of software tasks, which reflect the software implementor's point of view. It is shown in this paper that the software partitioning problem can be modeled as one that maximizes the efficiency in resource utilization while observing the constraints on CPU throughput, memory space available, maximally allowed task execution time, and the order of module execution. The CPU and memory constraints are implementation dependent. The maximum task execution time constraint is due to considerations on the response time performance. The constraint on module execution order is a logical one, and it is shown to have significant performance impact. It is proven that by employing the module precedence relation, which reflects the sequence of module execution, the order of module execution can be properly maintained during the software partitioning process. And thus the defined tasks can be guaranteed to be completely executable, once properly activated With completely executable tasks, the operating overhead cost and the response time delay can be minimized. The following four module precedence relations are explored: precede, succeed, parallel, and precede as well as succeed. The validity of the selected partitioning criterion of maximizing the resource utilization efficiency is also assessed through simulation experiments. The results of simulation show that performance of the selected criterion is insensitive to the application environment, as well as to the application requirements.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231859","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701927","Distributed real-time applications;maximally allowed task execution time;order of module execution;partitioning efficiency;precedence relation;response time performance;software partition","Application software;Delay;Software performance;Software engineering;Resource management;Couplings;Real time systems;Memory management;Software maintenance;Costs","","Distributed real-time applications;maximally allowed task execution time;order of module execution;partitioning efficiency;precedence relation;response time performance;software partition","","19","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Dependability modeling and analysis of distributed programs","N. Lopez-Benitez","Dept. of Comput. Sci., Texas Tech. Univ., Lubbock, TX, USA","IEEE Transactions on Software Engineering","","1994","20","5","345","352","Presents a modeling approach based on stochastic Petri nets to estimate the reliability and availability of programs in a distributed computing system environment. In this environment, successful execution of programs is conditioned on the successful access of related files distributed throughout the system. The use of stochastic Petri nets is demonstrated by extending a basic reliability model to account for repair actions when faults occur. To this end, two possible models are discussed: the global repair model, which assumes a centralized repair team that restores the system to its original status when a failure state is reached, and the local repair model, which assumes that repairs are localized to the node where they occur. The former model is useful in evaluating the availability of programs (or the availability of the hardware support) subject to hardware faults that are repaired globally; therefore, the programs of interest can be interrupted. On the other hand, the latter model can be used to evaluate program reliability in the presence of hardware faults subject to repair, without interrupting the normal operation of the system.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.286421","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=286421","","Distributed control;Petri nets;Availability;Hardware;Stochastic systems;Distributed computing;Stochastic processes;Reliability theory;Graph theory;Tree graphs","distributed algorithms;Petri nets;program diagnostics;software reliability;system recovery;stochastic processes;programming theory;multiprocessing programs","dependability modeling;dependability analysis;distributed programs;stochastic Petri nets;program reliability;program availability;distributed computing system environment;program execution;repair actions;global repair mode;centralized repair team;system status restoration;failure state;local repair model;hardware support;hardware faults;program interruption;file distribution","","11","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Expressions for completely and partly unsuccessful batched search of sequential and tree-structured files","Y. Manolopoulos; J. G. Kollias","Dept. of Electr. Eng., Aristotelian Univ. of Thessaloniki, Greece; NA","IEEE Transactions on Software Engineering","","1989","15","6","794","799","A number of previous studies derived expressions for batched searching of sequential and tree-structured files on the assumption that all the keys in the batch exist in the file, i.e., all the searches are successful. Formulas for batched searching of sequential and tree-structured files are derived, but the assumption made is that either all or part of the keys in the batch do not exist in the file, i.e., the batched search is completely or partly unsuccessful.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24732","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24732","","Costs;Databases;Data security;Indexing;Delay;Computer vision;Computer science","batch processing (computers);database management systems;information retrieval","completely unsuccessful batched search;partly unsuccessful batched search;batched searching;tree-structured files","","2","","19","","","","","","IEEE","IEEE Journals & Magazines"
"ZPL: a machine independent programming language for parallel computers","B. L. Chamberlain; Sung-Eun Choi; C. Lewis; C. Lin; L. Snyder; W. D. Weathersby","Dept. of Comput. Sci. & Eng., Washington Univ., Seattle, WA, USA; NA; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","2000","26","3","197","211","The goal of producing architecture-independent parallel programs is complicated by the competing need for high performance. The ZPL programming language achieves both goals by building upon an abstract parallel machine and by providing programming constructs that allow the programmer to ""see"" this underlying machine. This paper describes ZPL and provides a comprehensive evaluation of the language with respect to its goals of performance, portability, and programming convenience. In particular, we describe ZPt's machine-independent performance model, describe the programming benefits of ZPL's region-based constructs, summarize the compilation benefits of the language's high-level semantics, and summarize empirical evidence that ZPL has achieved both high performance and portability on diverse machines such as the IBM SP-2, Cray T3E, and SGI Power Challenge.","0098-5589;1939-3520;2326-3881","","10.1109/32.842947","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=842947","","Computer languages;Concurrent computing;Parallel programming;Parallel machines;High performance computing;Hardware;Laboratories;Buildings;Programming profession;Parallel processing","parallel programming;parallel languages","ZPL;machine independent programming language;parallel computers;architecture-independent parallel programs;abstract parallel machine;programming constructs;performance;portability;programming convenience;programming benefits;high-level semantics","","26","","52","","","","","","IEEE","IEEE Journals & Magazines"
"A Distributed Drafting Algorithm for Load Balancing","L. M. Ni; Chong-Wei Xu; T. B. Gendreau","Department of Computer Science, Michigan State University; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","10","1153","1161","It is desirable for the load in a distributed system to be balanced evenly. A dynamic process migration protocol is needed in order to achieve load balancing in a user transparent manner. A distributed algorthim for load balancing which is network topology independent is proposed in this paper. Different network topologies and low-level communications protocols affect the choice of only some system design parameters. The ""drafting"" algorithm attempts to compromise two contradictory goals: maximize the processor utilization and minimize the communication overhead. The main objective of this paper is to describe the dynamic process migration protocol based on the proposed drafting algorithm. A sample distributed system is used to further illustrate the drafting algorithm and to show how to define system design parameters. The system performance is measured by simulation experiments based on the sample system.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231863","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701931","Bidding algorithm;computer network;distributed algorithm;distributed operation system;distributed system;load balancing;process migration;system performance","Technical drawing;Load management;Protocols;Operating systems;Delay;Network topology;System performance;Distributed algorithms;Computational modeling;Computer networks","","Bidding algorithm;computer network;distributed algorithm;distributed operation system;distributed system;load balancing;process migration;system performance","","77","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Extended K-d Tree Database Organization: A Dynamic Multiattribute Clustering Method","Jo-Mei Chang; King-Sun Fu","Bell Laboratories; NA","IEEE Transactions on Software Engineering","","1981","SE-7","3","284","290","The problem of performing multiple attribute clustering in a dynamic database is studied. The extended K-d tree method is presented. In an extended K-d tree organization, the basic k-d tree structure after modification is used as the structure of the directory which organizes the data records in the secondary storage. The discriminator value of each level of the directory determines the partitioning direction of the corresponding attribute subspace. When the record insertion causes the data page to overload, the attribute space will be further partitioned along the direction specified by the corresponding discriminator.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230839","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702842","Dynamic clustering method;multiattribute;partial match query;physical database design","Clustering methods;Information retrieval;Clustering algorithms;Tree data structures;Helium;Magnetic cores;Magnetic devices;Database systems;Degradation;Indexing","","Dynamic clustering method;multiattribute;partial match query;physical database design","","10","","9","","","","","","IEEE","IEEE Journals & Magazines"
"A Relational Representation of an Abstract Type System","D. L. Weller; B. W. York","IBM Research Laboratory, San Jose, CA 95193.; IBM Research Laboratory, San Jose, CA 95193.; Artificial Intelligence Technology Group, Digital Equipment Corporation, 77 Reed Rd., Hudson, MA 01749.","IEEE Transactions on Software Engineering","","1984","SE-10","3","303","309","Programming languages have traditionally had more data types than database systems. The flexibility of abstract types could make a database system more useful in supporting application development. Abstract types allow users to think about and manipulate data in terms and structures that they are familiar with. This paper proposes that databases have a type system interface and describes a representation of a type system in terms of relations. The type system model supports a variety of programming language constructs, such as user-defined parameterized data types and user-defined generic operations. The efficiency of the type system is compared to the access time of the database system.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010239","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010239","Abstract data types;database interface;programming languages;relational database;type system","Database systems;Computer languages;Relational databases;Laboratories;Power system modeling;Energy management;Power system management;Manipulator dynamics;Data systems;Artificial intelligence","","","","1","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Performance Modeling of Database Recovery Protocols","N. Griffyth; J. A. Miller","School of Information and Computer Science, Georgia Institute of Technology; NA","IEEE Transactions on Software Engineering","","1985","SE-11","6","564","572","The performance modeling described in this paper compares several protocols which ensure that a database can be recovered to a consistent state after a transaction failure or system crash. The contributions of the paper include a collection of simple analytic models, based on Markov processes, for these protocols and some surprising results on the relative performance of the protocols. We consider only two-stage transactions (all reads before writes) and ignore effects of serializing transactions. The most interesting performance result presented is that, for systems obeying the assumptions of this paper, the ""pessimistic"" policy of holding write locks to commit point is considerably less efficient than the ""optimistic"" policy which allows reading of uncommitted data, but risks cascading aborts. A multiversion policy introduced in [2] was also studied and found always to be nearly as good as the optimistic policy and sometimes much better.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232494","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702054","Atomic actions;concurrency control;database systems;Markov processes;performance modeling;queueing models;reliability;transaction systems","Transaction databases;Database systems;Access protocols;Performance analysis;Markov processes;Concurrency control;Predictive models;Computer science;Computer crashes;Indexes","","Atomic actions;concurrency control;database systems;Markov processes;performance modeling;queueing models;reliability;transaction systems","","6","","12","","","","","","IEEE","IEEE Journals & Magazines"
"An extended domain-based model of software reliability","S. N. Weiss; E. J. Weyuker","Courant Inst. of Math. Sci., New York Univ., NY, USA; Courant Inst. of Math. Sci., New York Univ., NY, USA","IEEE Transactions on Software Engineering","","1988","14","10","1512","1524","A definition of software reliability is proposed in which reliability is treated as a generalization of the probability of correctness of the software in question. A tolerance function is introduced as a method of characterizing an acceptable level of correctness. This in turn is used, together with the probability function defining the operational input distribution, as a parameter of the definition of reliability. It is shown that the definition can be used to provide many natural models of reliability by varying the tolerance function and that it may be reasonably approximated using well-chosen test sets. It is also shown that there is an inherent limitation to the measurement of reliability using finite test sets.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6196","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6196","","Software reliability;Software measurement;Time measurement;Software testing;Random variables;Lead;Computer science;Statistical analysis","probability;program testing;program verification;programming theory;software reliability","extended domain-based model;software reliability;correctness;tolerance function;probability function;operational input distribution;test sets","","38","","16","","","","","","IEEE","IEEE Journals & Magazines"
"Concurrent Certifications by Intervals of Timestamps in Distributed Database Systems","C. Boksenbaum; M. Cart; J. Ferrie; J. -. Pons","Centre de Recherche en Informatique, University of Montpellier; NA; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","4","409","419","This paper introduces, as an optimistic concurrency control method, a new certification method by means of intervals of timestamps, usable in a distributed database system. The main advantage of this method is that it allows a chronological commit order which differs from the serialization one (thus avoiding rejections or delays of transactions which occur in usual certification methods or in classical locking or timestamping ones). The use of the dependency graph permits both classifying this method among existing ones and proving it. The certification protocol is first presented under the hypothesis that transactions' certifications are processed in the same order on all the concerned sites; it is then extended to allow concurrent certifications of transactions.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233178","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702233","Certification;concurrency control;dependency graph;distributed databases;intervals of timestamps","Certification;Database systems;Concurrency control;Spatial databases;Transaction databases;Delay;Protocols;Distributed databases;Testing;System recovery","","Certification;concurrency control;dependency graph;distributed databases;intervals of timestamps","","22","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Specification and design of transactions in information systems: a formal approach","G. Babin; F. Lustman; P. Shoval","Dept. of Decision Sci. & Eng. Syst., Rensselaer Polytech. Inst., Troy, NY, USA; NA; NA","IEEE Transactions on Software Engineering","","1991","17","8","814","829","In conventional information systems development, consistency between requirements specifications and design is achieved by manual checking. The application of the transformational paradigm to the specification and design phases is proposed. Requirements are expressed in the ADISSA notation, using the ADISSA method, a transaction-oriented refinement of structured systems analysis. The control part of a transaction is transformed into a formal specification, the FSM (finite state machine) transaction, by applying a set of rules. The design stage is realized by an algorithm which compares the FSM transaction into simpler transactions and implements them with a hierarchical set of finite-state machines. Consistency between the formal specification and the result of the design is achieved by proving that the latter has the same behavior as the former.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.83916","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=83916","","Information systems;Formal specifications;Information analysis;Algorithm design and analysis;System analysis and design;System testing;Guidelines;Statistical analysis;Programming;Uncertainty","data integrity;finite automata;formal specification;structured programming;systems analysis;transaction processing","formal approach;conventional information systems development;requirements specifications;manual checking;transformational paradigm;ADISSA notation;transaction-oriented refinement;structured systems analysis;formal specification;FSM;finite state machine;hierarchical set","","3","","14","","","","","","IEEE","IEEE Journals & Magazines"
"A Rigorous Approach to Fault-Tolerant Programming","F. Cristian","IBM Research Laboratory","IEEE Transactions on Software Engineering","","1985","SE-11","1","23","31","The design of programs that are tolerant of hardware fault occurrences and processor crashes is investigated. Using a stable storage management system as a running example, a new approach is suggested for specifying, understanding, and verifying the correctness of fault-tolerant software. The approach extends previously developed axiomatic reasoning methods to the design of fault-tolerant systems by modeling faults as being operations that are performed at random time intervals on any computing system by the system's adverse environment.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231534","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701895","Availability;correctness;fault-tolerance;programming logic;reliability;stochastic modeling","Fault tolerance;Hardware;Logic programming;Stochastic processes;Computer crashes;Availability;Stochastic systems;Design methodology;Fault tolerant systems;Software systems","","Availability;correctness;fault-tolerance;programming logic;reliability;stochastic modeling","","21","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Structuring primitives for a dictionary of entity relationship data schemas","C. Batini; G. Di Battista; G. Santucci","Dipartimento di Inf. e Sistemistica, Roma Univ., Italy; Dipartimento di Inf. e Sistemistica, Roma Univ., Italy; Dipartimento di Inf. e Sistemistica, Roma Univ., Italy","IEEE Transactions on Software Engineering","","1993","19","4","344","365","The data dictionary contains the description of all types of data produced, managed, exchanged, and maintained in an organization. Data descriptions (very often hundreds of schemas) should be organized in such a way to allow all the users of the information system to understand the meaning of data and their relationships. To this end, a set of structuring primitives for a dictionary of entity relationship data schemas is presented. The formal properties of such structuring primitives are investigated, and the feasibility of their usage is shown by providing a methodology for dictionary design.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.223803","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=223803","","Dictionaries;Proposals;Software engineering;Management information systems;Associate members;Design methodology;Organizing;Information management;Resource management;Remuneration","entity-relationship modelling;relational databases","structuring primitives;data descriptions;entity relationship data schemas;information system","","24","","54","","","","","","IEEE","IEEE Journals & Magazines"
"The KAT (knowledge-action-transformation) approach to the modeling and evaluation of reliability and availability growth","J. -. Laprie; K. Kanoun; C. Beounes; M. Kaaniche","LAAS-CNRS, Toulouse, France; LAAS-CNRS, Toulouse, France; LAAS-CNRS, Toulouse, France; LAAS-CNRS, Toulouse, France","IEEE Transactions on Software Engineering","","1991","17","4","370","382","An approach for the modeling and evaluation of reliability and availability of systems using the knowledge of the reliability growth of their components is presented. Detailed models of reliability and availability for single-component systems are derived under much weaker assumption than usually considered. These models, termed knowledge models, enable phenomena to be precisely characterized, and a number of properties to be deduced. Since the knowledge models are too complex to be applied in real life for performing predictions, simplified models for practical purposes (action models) are discussed. The hyperexponential model is presented and applied to field data of software and hardware failures. This model is shown to be comparable to other models as far as reliability of single-component systems is concerned: in addition, it enables estimating and predicting the reliability of multicomponent systems, as well as their availability. The transformation approach enables classical Markov models to be transformed into other Markov models which account for reliability growth. The application of the transformation to multicomponent systems is described.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.90436","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=90436","","Hardware;Availability;Predictive models;Software systems;Performance evaluation;Physics computing;Fault tolerant systems;Filling","knowledge based systems;Markov processes;reliability theory;software reliability","KAT;knowledge-action-transformation;availability growth;single-component systems;knowledge models;action models;hyperexponential model;multicomponent systems;Markov models","","50","","61","","","","","","IEEE","IEEE Journals & Magazines"
"Meet real-time requirements of parallel programs and maximally utilize system resources","Bin Qin","IBM Canada Ltd., Toronto, Ont., Canada","IEEE Transactions on Software Engineering","","1993","19","10","976","981","The time-cost behavior of a program directly depends on its execution environment (i.e., the number of other programs in the system). We present techniques to analyze the time-cost behavior of programs that include the effect of their execution environment. It is assumed the underlying system has a shared memory architecture. The paper shows that one can analytically relate a parallel program's time cost to its execution environment. A direct benefit of the work is to let us meet the real-time requirement of a parallel program and utilize maximally a multiprocessor system's resource.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.245739","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=245739","","Real time systems;Costs;Multiprocessing systems;Performance analysis;Time sharing computer systems;Computational modeling;Memory architecture;Parallel processing;Control systems;Random variables","parallel programming;programming theory;real-time systems;software cost estimation","real-time requirements;parallel programs;system resources;time-cost behavior;execution environment;shared memory architecture;multiprocessor system;performance analysis","","3","","12","","","","","","IEEE","IEEE Journals & Magazines"
"Fixed-priority sensitivity analysis for linear compute time models","S. Vestal","Technol. Center, Honeywell Inc., Minneapolis, MN, USA","IEEE Transactions on Software Engineering","","1994","20","4","308","317","Several formal results exist that allow an analytic determination of whether a particular scheduling discipline can feasibly schedule a given set of hard real-time periodic tasks. In most cases, these results provide little more than a 'yes' or 'no' answer. In practice, it is also useful to know how sensitive scheduling feasibility is to changes in the characteristics of the task set. This paper presents algorithms that allow a system developer to determine, for fixed-priority preemptive scheduling of hard real-time periodic tasks on a uniprocessor, how sensitive schedule feasibility is to changes in the computation times of various software components. The algorithms allow a system developer to determine what changes in task computation times can be made while preserving schedule feasibility (or what changes are needed to achieve feasibility). Both changes to the computation time of a single task and changes to the computation times of a specified subset of the tasks are analyzable. The algorithms also allow a decomposition of tasks into modules, where a module may be a component of multiple tasks.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.277577","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=277577","","Sensitivity analysis;Processor scheduling;Scheduling algorithm;Software algorithms;Real time systems;Programming;Computer architecture;Runtime;Law","sensitivity analysis;scheduling;computational complexity;real-time systems;formal verification","fixed-priority sensitivity analysis;linear computation time models;scheduling discipline;hard real-time periodic tasks;task scheduling feasibility;fixed-priority preemptive scheduling;uniprocessor;software components;task decomposition;modules;real-time scheduling;rate monotonic scheduling;schedulability analysis;real-time verification;software development process;real-time benchmarking;real-time architectures","","49","","23","","","","","","IEEE","IEEE Journals & Magazines"
"An Experience Using Two Covert Channel Analysis Techniques on a Real System Design","J. T. Haigh; R. A. Kemmerer; J. Mchugh; W. D. Young","Honeywell Secure Computing Technology Center; NA; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","2","157","168","This paper examines the application of two covert channel analysis techniques to a high level design for a real system, the Honeywell Secure Ada Target (SAT). The techniques used were a version of the noninterference model of multilevel security due to Goguen and Meseguer and the shared resource matrix method of Kemmerer. Both techniques were applied to the Gypsy Abstract Model of the SAT. The paper discusses the application of the techniques and the nature of the covert channels discovered. The relative strengths and weaknesses of the two methods are discussed and criteria for an ideal covert channel tool are developed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.226479","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702197","Covert channels;formal specification;formal verification;multilevel security;noninterference security policies;shared resource matrix","System analysis and design;Multilevel systems;National security;Performance analysis;Computer science;Formal specifications;Formal verification;Computer security;Information analysis;Information security","","Covert channels;formal specification;formal verification;multilevel security;noninterference security policies;shared resource matrix","","5","","13","","","","","","IEEE","IEEE Journals & Magazines"
"A comprehensive evaluation of capture-recapture models for estimating software defect content","L. C. Briand; K. El Emam; B. G. Freimut; O. Laitenberger","Dept. of Syst. & Comput. Eng., Carleton Univ., Ottawa, Ont., Canada; NA; NA; NA","IEEE Transactions on Software Engineering","","2000","26","6","518","540","An important requirement to control the inspection of software artifacts is to be able to decide, based on more objective information, whether the inspection can stop or whether it should continue to achieve a suitable level of artifact quality. A prediction of the number of remaining defects in an inspected artifact can be used for decision making. Several studies in software engineering have considered capture-recapture models to make a prediction. However, few studies compare the actual number of remaining defects to the one predicted by a capture-recapture model on real software engineering artifacts. The authors focus on traditional inspections and estimate, based on actual inspections data, the degree of accuracy of relevant state-of-the-art capture-recapture models for which statistical estimators exist. In order to assess their robustness, we look at the impact of the number of inspectors and the number of actual defects on the estimators' accuracy based on actual inspection data. Our results show that models are strongly affected by the number of inspectors, and therefore one must consider this factor before using capture-recapture models. When the number of inspectors is too small, no model is sufficiently accurate and underestimation may be substantial. In addition, some models perform better than others in a large number of conditions and plausible reasons are discussed. Based on our analyses, we recommend using a model taking into account that defects have different probabilities of being detected and the corresponding Jackknife Estimator. Furthermore, we calibrate the prediction models based on their relative error, as previously computed on other inspections. We identified theoretical limitations to this approach which were then confirmed by the data.","0098-5589;1939-3520;2326-3881","","10.1109/32.852741","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=852741","","Inspection;Biological system modeling;Software quality;Software engineering;Predictive models;Robustness;Computer Society;State estimation;Decision making;Animals","software quality;software performance evaluation;inspection;probability;software development management","capture-recapture models;software defect content estimation;traditional inspections;objective information;artifact quality;software engineering;real software engineering artifacts;inspections data;statistical estimators;estimator accuracy;probabilities;Jackknife Estimator;relative error","","85","","42","","","","","","IEEE","IEEE Journals & Magazines"
"Grammars and relations","L. Mark; R. J. Cochrane","Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA","IEEE Transactions on Software Engineering","","1992","18","9","840","849","The potential benefits obtained when context-free grammars are used to define complex objects in the relational model are demonstrated. The grammar formalism facilitates relational queries on the hierarchical structure of these objects and promotes the use of grammar-based tools as front ends to relational database systems.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.159832","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=159832","","Relational databases;Data mining;Context modeling;Application software;Data models;Data engineering;Data structures;Military computing;Computer science;Buildings","context-free grammars;query processing;relational databases;user interfaces","context-free grammars;complex objects;relational model;grammar formalism;relational queries;hierarchical structure;grammar-based tools;front ends;relational database systems","","","","44","","","","","","IEEE","IEEE Journals & Magazines"
"Experimentally characterizing the behavior of multiprocessor memory systems: a case study","K. Gallivan; D. Gannon; W. Jalby; A. Malony; H. Wijshoff","Center for Supercomput. Res. & Dev., Illinois Univ., Urbana, IL, USA; Center for Supercomput. Res. & Dev., Illinois Univ., Urbana, IL, USA; Center for Supercomput. Res. & Dev., Illinois Univ., Urbana, IL, USA; Center for Supercomput. Res. & Dev., Illinois Univ., Urbana, IL, USA; Center for Supercomput. Res. & Dev., Illinois Univ., Urbana, IL, USA","IEEE Transactions on Software Engineering","","1990","16","2","216","223","It is demonstrated how the behavior of a cache-based multi-vector-processor memory system can be systematically characterized and its performance experimentally correlated with key features of the address stream. The approach is based on the definition of a family of parameterized kernels used to explore specific aspects of the memory system's performance. The empirical results from this kernel suite provide the data from which architectural or algorithmic characteristics can be studied. The results of applying the approach to an Alliant FX/8 are presented and evaluated.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.44384","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=44384","","Computer aided software engineering;Hardware;Random access memory;Performance analysis;Multiprocessing systems;Queueing analysis;Analytical models;Kernel","buffer storage;multiprocessing systems;program testing;storage management","behavior analysis;performance analysis;multiprocessor memory systems;cache-based multi-vector-processor;address stream;parameterized kernels;algorithmic characteristics;Alliant FX/8","","7","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Software requirements analysis for real-time process-control systems","M. S. Jaffe; N. G. Leveson; M. P. E. Heimdahl; B. E. Melhart","Hughes Aircraft Co., Fullerton, CA, USA; NA; NA; NA","IEEE Transactions on Software Engineering","","1991","17","3","241","258","A set of criteria is defined to help find errors in, software requirements specifications. Only analysis criteria that examine the behavioral description of the computer are considered. The behavior of the software is described in terms of observable phenomena external to the software. Particular attention is focused on the properties of robustness and lack of ambiguity. The criteria are defined using an abstract state-machine model for generality. Using these criteria, analysis procedures can be defined for particular state-machine modeling languages to provide semantic analysis of real-time process-control software requirements.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.75414","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=75414","","Real time systems;Control systems;Process control;Safety;Aircraft manufacture;Programming;Computer science;Software prototyping;Prototypes;Robustness","formal specification;process computer control;real-time systems","real-time process-control systems;software requirements specifications;observable phenomena;robustness;ambiguity;abstract state-machine model;semantic analysis;software requirements","","124","","27","","","","","","IEEE","IEEE Journals & Magazines"
"Mathemtical model of composite objects and its application for organizing engineering databases","M. A. Ketabchi; V. Berzins","Dept. of Electr. Eng. & Comput. Sci., Santa Clara Univ., CA, USA; NA","IEEE Transactions on Software Engineering","","1988","14","1","71","84","The authors introduce a clustering concept called component aggregation which considers assemblies having the same types of parts as equivalent objects. The notion of equivalent objects is used to develop a mathematical model of composite objects. It is shown that the set of equivalence classes of objects form a Boolean algebra whose minterms represent the objects that are not considered composite at the current viewing level. The algebraic structure of composite objects serves as a basis for developing a technique for organizing composite objects and supporting materialization of explosion views. The technique provides a clustering mechanism which partitions the database into meaningful and application-oriented clusters, and allows any desired explosion view to be materialized using a minimal set of stored views. A simplified relational database for design data and a set of frequent access patterns in design applications are outlined and used to demonstrate the benefits of database organizations based on the mathematical model of composite objects.<<ETX>></ETX>","0098-5589;1939-3520;2326-3881","","10.1109/32.4624","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4624","","Organizing;Data engineering;Explosions;Information retrieval;Application software;Relational databases;Object oriented databases;Assembly;Boolean algebra;Object oriented modeling","CAD;data structures;database theory;relational databases","database partitioning;composite objects;engineering databases;clustering concept;component aggregation;assemblies;equivalent objects;equivalence classes;Boolean algebra;minterms;stored views;relational database;design data;frequent access patterns","","20","","49","","","","","","IEEE","IEEE Journals & Magazines"
"Anatomy of a Small Pascal Compiler","P. Schulthess; C. Jacobi","Institute for Informatics, Swiss Federal Institute of Technology; NA","IEEE Transactions on Software Engineering","","1983","SE-9","2","185","191","An exceptionally compact Pascal Compiler was written. We explain how.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.236596","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703036","Small systems;Pascal compiler","Anatomy;Binary trees;Program processors;Statistics;Jacobian matrices;Informatics;Design optimization;Memory;Computer architecture;Writing","","Small systems;Pascal compiler","","2","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Functional programming, formal specification, and rapid prototyping","P. Henderson","Department of Computing Science, University of Stirling, Stirling FK9 4LA, Scotland","IEEE Transactions on Software Engineering","","1986","SE-12","2","241","250","Functional programming has enormous potential for reducing the high cost of software development. Because of the simple mathematical basis of functional programming, it is easier to design correct programs in a purely functional style than in a traditional imperative style. It is argued that functional programs combine the clarity required for the formal specification of software designs with the ability to validate the design by execution. As such they are ideal for rapidly prototyping a design as it is developed. An example is presented which is larger than those traditionally used to explain functional programming. This example is used to illustrate a method of software design which efficiently and reliably turns an informal description of requirements into an executable formal specification.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312939","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312939","Functional programming;software design;specification;validation","Prototypes;Functional programming;Software design;Formal specifications;Equations;Abstracts","programming;software engineering;specification languages","formal specification;rapid prototyping;software development;functional programming;correct programs;imperative style;formal specification;software designs;functional programming;formal specification","","28","","","","","","","","IEEE","IEEE Journals & Magazines"
"Measuring software dependability by robustness benchmarking","A. Mukherjee; D. P. Siewiorek","Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA; NA","IEEE Transactions on Software Engineering","","1997","23","6","366","378","Inability to identify weaknesses or to quantify advancements in software system robustness frequently hinders the development of robust software systems. Efforts have been made to develop benchmarks of software robustness to address this problem, but they all suffer from significant shortcomings. The paper presents the various features that are desirable in a benchmark of system robustness, and evaluates some existing benchmarks according to these features. A new hierarchically structured approach to building robustness benchmarks, which overcomes many deficiencies of past efforts, is also presented. This approach has been applied to building a hierarchically structured benchmark that tests part of the Unix file and virtual memory systems. The resultant benchmark has successfully been used to identify new response class structures that were not detected in a similar situation by other less organized techniques.","0098-5589;1939-3520;2326-3881","","10.1109/32.601075","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=601075","","Software measurement;Robustness;Benchmark testing;Operating systems;Software systems;System testing;Buildings;Application software;Software tools;Computer aided instruction","software metrics;software reliability;program testing;Unix;virtual storage;operating systems (computers)","software dependability measurement;robustness benchmarking;software system robustness;robust software systems development;hierarchically structured benchmark;hierarchically structured approach;robustness benchmarks;Unix file;virtual memory systems;response class structures","","43","","18","","","","","","IEEE","IEEE Journals & Magazines"
"A metaprogramming method and its economic justification","L. S. Levy","AT&T Bell Laboratories, Piscataway, NJ 08854","IEEE Transactions on Software Engineering","","1986","SE-12","2","272","277","Metaprogramming, defined as creating application programs by writing programs that produce programs, is presented as the basis of a method for reducing software costs and improving software quality. The method starts with a rapid prototyping phase in which selected representative parts of the application are prototyped; this is followed by a tooling up phase, during which the metaprogramming occurs. The final phase is the production of the application programs using the software tools and techniques of the metaprogramming phase. The author summarizes the experience of two projects that support the assertion that metaprogramming is an efficient way to produce programs, since these projects used metaprogramming in their development. An economic theory which justifies this approach is outlined. It is shown how to do a cost/benefit analysis of the method.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312943","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312943","Application generators;metaprogramming;methodology;software economics","Software;Productivity;Generators;Economics;Computational modeling;Prototypes","application generators","metaprogramming method;economic justification;application programs;software costs;software quality;rapid prototyping;tooling up phase;application programs;software tools;cost/benefit analysis","","9","","","","","","","","IEEE","IEEE Journals & Magazines"
"Specification and analysis of real-time problem solvers","B. Hamidzadeh; S. Shekhar","Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA; Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA","IEEE Transactions on Software Engineering","","1993","19","8","788","803","The authors provide a method for the specification of real-time artificial intelligence (AI) problem solvers. Using this method, a formal specification of a real-time problem is presented. In addition, a method for analyzing real-time AI problem solvers is examined using a case study of two real-time problem solvers, namely DYNORAII and RTA* for the real-time path planning problem. New results on worst-case and average-case complexity of the problem, and of the algorithms that solve it, and an experimental evaluation of DYNORAII and RTA* for deadline compliance and response-time minimization are provided.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.238582","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=238582","","Artificial intelligence;State-space methods;Control systems;Rivers;Time factors;Joining processes;Problem-solving;Delay;Formal specifications;Path planning","computational complexity;formal specification;path planning;problem solving;real-time systems","real-time artificial intelligence;formal specification;real-time problem;real-time AI problem solvers;DYNORAII;RTA*;real-time path planning problem;average-case complexity;deadline compliance;response-time minimization","","10","","39","","","","","","IEEE","IEEE Journals & Magazines"
"Using flat concurrent Prolog in system modeling","Y. Dotan; B. Arazi","Dept. of Electr. & Comput. Eng., Ben Gurion Univ., Beer Sheva, Israel; Dept. of Electr. & Comput. Eng., Ben Gurion Univ., Beer Sheva, Israel","IEEE Transactions on Software Engineering","","1991","17","6","493","512","The flat concurrent Prolog (FCP) language, which enables the implementation of synchronization through data flow, communication through shared variables, parallelism through the reduction of the AND components in the clause's body, and indeterminacy through guarded commands, is discussed. It is shown that FCP, used in conjunction with Petri net methods, forms a powerful tool in the modeling of parallel systems that involve concurrency. The simulation of systems represented by various types of Petri nets is achieved using the reduction process of FCP. AND parallelism supports free competition among conflicting enabled transitions. A structural analysis of systems is provided using the metaprogramming technique.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.87277","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=87277","","Modeling;Logic programming;Concurrent computing;Petri nets;Flexible manufacturing systems;Dynamic programming;Parallel processing;Phase detection;Data structures;Timing","logic programming;parallel programming;Petri nets;PROLOG;structured programming;virtual machines","system modeling;flat concurrent Prolog;synchronization;data flow;shared variables;parallelism;AND components;indeterminacy;guarded commands;FCP;Petri net methods;parallel systems;Petri nets;reduction process;free competition;conflicting enabled transitions;structural analysis;metaprogramming technique","","5","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Database Transformation, Query Translation, and Performance Analysis of a New Database Computer in Supporting Hierarchical Database Management","J. Banerjee; D. K. Hsiao; F. K. Ng","Advanced Systems and Technology, Sperry-Univac; NA; NA","IEEE Transactions on Software Engineering","","1980","SE-6","1","91","109","Database computers are special-purpose storage and processing devices which are intended to relieve the database management (software) systems running on the general-purpose computers and provide improved storage and processing capabilities (via hardware) for the existing and new database application. However, to support existing database applications, two steps must be followed. First, the existing database must be transformed into the storage format of the new database computer. This one-time tranformation, known as database transformation, is required to preserve the semantics of the database and to take advantage of the advanced hardware features of the new computer. Second, the database sublanguage used in the existing application programs must be supported in real time by the new database computer so that application programs may be executed in the new environment without the need of program conversion. Such real-time translation of sublanguage calls to the instructions of the new database computer, known as query translation, must be straightforward with minimal software support.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1980.234466","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702698","Database computer;database management system;database transformation;hierarchical data model;performance evaluation;storage analysis;transaction execution time analysis","Performance analysis;Transaction databases;Spatial databases;Application software;Relational databases;Hardware;Remuneration;Software performance;Software systems;Contracts","","Database computer;database management system;database transformation;hierarchical data model;performance evaluation;storage analysis;transaction execution time analysis","","2","","13","","","","","","IEEE","IEEE Journals & Magazines"
"A hookup theorem for multilevel security","D. McCullough","Odyssey Res. Associates, Ithaca, NY, USA","IEEE Transactions on Software Engineering","","1990","16","6","563","568","A security property for trusted multilevel systems, restrictiveness, is described. It restricts the inferences a user can make about sensitive information. This property is a hookup property, or composable, meaning that a collection of secure restrictive systems when hooked together form a secure restrictive composite system. It is argued that the inference control and composability of restrictiveness make it an attractive choice for a security policy on trusted systems and processes.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.55085","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=55085","","Multilevel systems;Information security;Invasive software;Control systems;Labeling;Interconnected systems;Personnel;Government;Information processing;Program processors","security of data;software engineering","user inferences;hookup theorem;multilevel security;security property;trusted multilevel systems;restrictiveness;sensitive information;hookup property;composable;secure restrictive composite system;inference control;security policy","","59","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Effect of System Workload on Operating System Reliability: A Study on IBM 3081","R. K. Iyer; D. J. Rossetti","Computer Systems Group, Coordinated Science Laboratory and the Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign; NA","IEEE Transactions on Software Engineering","","1985","SE-11","12","1438","1448","This paper presents an analysis of operating system failures on an IBM 3081 running VM/SP. We find three broad categories of software failures: error handling (ERH), program control or logic (CTL), and hardware related (HS); it is found that more than 25 percent of software failures occur in the hardware/software interface. Measurements show that results on software reliability cannot be considered representative unless the system workload is taken into account. For example, it is shown that the risk of a software failure increases in a nonlinear fashion with the amount of interactive processing, as measured by parameters such as the paging rate and the amount of overhead (operating system CPU time). The overall CPU execution rate, although measured to be close to 100 percent most of the time, is not found to correlate strongly with the occurrence of failures. The paper discusses possible reasons for the observed workload failure dependency based on detailed investigations of the failure data.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232180","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701966","Failure analysis;software reliability;system workload;VM/SP","Operating systems;Hardware;Software measurement;Time measurement;Failure analysis;Virtual manufacturing;Error correction;Control systems;Logic;Software reliability","","Failure analysis;software reliability;system workload;VM/SP","","52","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Software Structure Metrics Based on Information Flow","S. Henry; D. Kafura","Department of Computer Science, University of Wisconsin; NA","IEEE Transactions on Software Engineering","","1981","SE-7","5","510","518","Structured design methodologies provide a disciplined and organized guide to the construction of software systems. However, while the methodology structures and documents the points at which design decisions are made, it does not provide a specific, quantitative basis for making these decisions. Typically, the designers' only guidelines are qualitative, perhaps even vague, principles such as ""functionality,"" ""data transparency,"" or ""clarity."" This paper, like several recent publications, defines and validates a set of software metrics which are appropriate for evaluating the structure of large-scale systems. These metrics are based on the measurement of information flow between system components. Specific metrics are defined for procedure complexity, module complexity, and module coupling. The validation, using the source code for the UNIX operating system, shows that the complexity measures are strongly correlated with the occurrence of changes. Further, the metrics for procedures and modules can be interpreted to reveal various types of structural flaws in the design and implementation.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.231113","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702877","Complexity;design methodologies;information flow;software metrics;UNIX","Software quality;Design methodology;Software metrics;Costs;Software maintenance;Software systems;Software tools;Computer science;Software measurement;Guidelines","","Complexity;design methodologies;information flow;software metrics;UNIX","","343","","40","","","","","","IEEE","IEEE Journals & Magazines"
"A hybrid distributed centralized system structure for transaction processing","B. Ciciani; D. M. Dias; B. R. Iyer; P. S. Yu","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; NA; NA","IEEE Transactions on Software Engineering","","1990","16","8","791","806","A hybrid system structure comprised of distributed systems to take advantage of locality of reference and a central system to handle transactions that access non-local data is examined. Several transaction processing applications, such as reservation systems, insurance and banking have such regional locality of reference. A concurrency and coherency control protocol that maintains the integrity of the data and performs well for transactions that access local or non-local data is described. It is shown that the performance of the hybrid system is much less sensitive to the fraction of remote accesses than the distributed system and offers similar performance to the distributed system for local transactions.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.57619","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=57619","","Distributed databases;Transaction databases;Delay;Insurance;Banking;Computer networks;Concurrent computing;Distributed control;Performance analysis;Spatial databases","concurrency control;data integrity;distributed processing;transaction processing","hybrid distributed centralized system structure;distributed systems;locality;central system;non-local data;transaction processing applications;reservation systems;insurance;banking;concurrency;coherency control protocol;integrity;remote accesses;local transactions","","8","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Testability of software components","R. S. Freedman","Dept. of Comput. Sci., Polytech. Univ., Brooklyn, NY, USA","IEEE Transactions on Software Engineering","","1991","17","6","553","564","The concept of domain testability of software is defined by applying the concepts of observability and controllability to software. It is shown that a domain-testable program does not exhibit any input-output inconsistencies and supports small test sets in which test outputs are easily understood. Metrics that can be used to assess the level of effort required in order to modify a program so that it is domain-testable are discussed. Assessing testability from program specifications and an experiment which shows that it takes less time to build and test a program developed from a domain-testable specification than a similar program developed from a nondomain-testable specification are also discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.87281","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=87281","","Software testing;Controllability;Observability;Timing;Computer displays;Software engineering;Hardware;Programming;Computer science;Explosives","formal specification;program testing","software components;domain testability;observability;controllability;domain-testable program;input-output inconsistencies;small test sets;test outputs;program specifications;domain-testable specification;nondomain-testable specification","","101","","32","","","","","","IEEE","IEEE Journals & Magazines"
"An Image Processing Language with Icon-Assisted Navigation","Shi-Kuo Chang; E. Jungert; S. Levialdi; G. Tortora; T. Ichikawa","Department of Electrical and Computer Engineering, Illinois Institute of Technology; NA; NA; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","8","811","819","This paper describes a generic image processing language IPL, and a programming environment supporting the language primitives for an image information system. The central notion of IPL is that it allows the user to navigate through the image database and manipulate images using generalized icons. The image processing language IPL consists of three subsets: the logical image processing language LIPL, the interactive image processing language IIPL, and the physical image processing language PIPL. This paper presents the main concepts of this generic language, some examples, and a scenario.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232529","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702089","Image database;image icons;image information system;image processing language","Image processing;Navigation;Information systems;Image databases;Programming environments;Application software;Hardware;Software systems;Software design;Manufacturing","","Image database;image icons;image information system;image processing language","","8","","14","","","","","","IEEE","IEEE Journals & Magazines"
"Optimiizing Static Scope Lisp by Repetitive Interpretation of Recursive Function Calls","K. Felgentreu; W. -. Lippe; F. H. Simon","Department of Computer Science, Institut fiir Numerische und Instrumentelle Mathematik, University of Munster; NA; NA","IEEE Transactions on Software Engineering","","1987","SE-13","6","628","635","This paper presents some recent results in interpreter optimization. The techniques of shallow binding and repetitive interpretation of tail recursive functions are adapted to Lisp with static scoping as the binding method for-all identifiers. Then a new technique of interpreting"" covered tail recursive"" functions is proposed. The purpose of the paper is to show that the extra expense for static scoping can be kept small by combining these techniques.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233473","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702268","Applicative languages;covered tail recursion;interpreter;shallow binding;static scoping;tail recursion","Tail;Computer science;Instruments;Computer architecture;Registers","","Applicative languages;covered tail recursion;interpreter;shallow binding;static scoping;tail recursion","","","","10","","","","","","IEEE","IEEE Journals & Magazines"
"A theory of fault-based testing","L. J. Morell","Dept. of Comput. Sci., Hampton Univ., Hampton, VA, USA","IEEE Transactions on Software Engineering","","1990","16","8","844","857","A theory of fault-based program testing is defined and explained. Testing is fault-based when it seeks to demonstrate that prescribed faults are not in a program. It is assumed that a program can only be incorrect in a limited fashion specified by associating alternate expressions with program expressions. Classes of alternate expressions can be infinite. Substituting an alternate expression for a program expression yields an alternate program that is potentially correct. The goal of fault-based testing is to produce a test set that differentiates the program from each of its alternates. A particular form of fault-based testing based on symbolic execution is presented. In symbolic testing, the output from the system is an expression in terms of the input and the symbolic alternative. Equating this with the output from the original program yields a propagation equation whose solutions determine those alternatives which are not differentiated by this test. Since an alternative set can be infinite, it is possible that no finite test differentiates the program from all its alternates. Circumstances are described as to when this can be decided.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.57623","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=57623","","Testing;Differential equations;Performance evaluation;Information analysis;Performance analysis;Computer science","computational complexity;program verification;symbol manipulation","fault-based program testing;prescribed faults;alternate expressions;program expressions;test set;symbolic execution;symbolic alternative;propagation equation;alternative set;finite test","","129","","32","","","","","","IEEE","IEEE Journals & Magazines"
"Design of Ada Systems Yielding Reusable Components: An Approach Using Structured Algebraic Specification","S. D. Litvintchouk; A. S. Matsumoto","Raytheon Company, Portsmouth, RI 02871.; Mitre Corporation, Bedford, MA 07130.; ITT Advanced Technology Center, Stratford, CT 06497.","IEEE Transactions on Software Engineering","","1984","SE-10","5","544","551","Our experience with design of Ada<sup>1</sup> software has indicated that a methodology, based on formal algebra, can be developed which integrates the design and management of reusable components with Ada systems design. The methodology requires the use of a specification language, also based on formal algebra, to extend Ada's expressive power for this purpose. We show that certain requirements for the use of Ada packages which cannot be expressed in Ada can be expressed in algebraic specification languages, and that such specifications can then be implemented in Ada.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010278","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010278","Abstract data type;Ada;algebraic specification;category theory;component environment;initial algebra;parameterized module;reusable components","Algebra;Algorithms;Software systems;Software design;Power system management;Packaging;Software reusability;Computer languages;High level synthesis;Joining processes","","","","9","","16","","","","","","IEEE","IEEE Journals & Magazines"
"An ontological model of an information system","Y. Wand; R. Weber","Fac. of Commerce & Bus. Adm., British Columbia Univ., Vancouver, BC, Canada; NA","IEEE Transactions on Software Engineering","","1990","16","11","1282","1292","An ontological model of an information system that provides precise definitions of fundamental concepts like system, subsystem, and coupling is proposed. This model is used to analyze some static and dynamic properties of an information system and to examine the question of what constitutes a good decomposition of an information system. Some of the major types of information system formalisms that bear on the authors' goals and their respective strengths and weaknesses relative to the model are briefly reviewed. Also articulated are some of the fundamental notions that underlie the model. Those basic notions are then used to examine the nature and some dynamics of system decomposition. The model's predictive power is discussed.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.60316","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=60316","","Ontologies;Information systems;Computer science;Predictive models;Information analysis;Business;US Department of Commerce;Context modeling;Specification languages","software engineering","static properties;ontological model;information system;system;subsystem;coupling;dynamic properties;decomposition;predictive power","","219","","46","","","","","","IEEE","IEEE Journals & Magazines"
"Timing analysis for fixed-priority scheduling of hard real-time systems","M. G. Harbour; M. H. Klein; J. P. Lehoczky","Dept. de Electron., Cantabria Univ., Santander, Spain; NA; NA","IEEE Transactions on Software Engineering","","1994","20","1","13","28","This paper presents a timing analysis for a quite general hard real-time periodic task set on a uniprocessor using fixed-priority methods. Periodic tasks are composed of serially executed subtasks, where each subtask is characterized by an execution time, a fixed priority and a deadline. A method for determining the schedulability of each task and subtask is presented along with its theoretical underpinnings. This method can be used to analyze the schedulability of any task set on a uniprocessor whose priority structure can be modeled as serially executed subtasks, which can lead to a very complex priority structure. Important examples include task sets that involve interrupts, certain synchronization protocols, certain precedence constraints, nonpreemptible sections, and some message-passing systems. The method is illustrated by a robotics example.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.263752","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=263752","","Timing;Real time systems;Contracts;Dynamic scheduling;Electric breakdown;Protocols;Robots;Control systems;Life testing;System testing","real-time systems;interrupts;message passing;robots;scheduling","timing analysis;fixed-priority scheduling;hard real-time systems;periodic task set;uniprocessor;fixed-priority methods;periodic tasks;serially executed subtasks;execution time;schedulability;complex priority structure;interrupts;synchronization protocols;precedence constraints;nonpreemptible sections;message-passing systems;robotics","","84","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Further Analysis of the Entity-Relationship Approach to Database Design","P. A. Ng","Department of Computer Sciences, University of Missouri","IEEE Transactions on Software Engineering","","1981","SE-7","1","85","99","The nondeterministic or deterministic entity-relationship model of a database is formaRy defined as a user's view of that database in terms of a collection of time-varying relations: the regular or weak entity relations, or the regular or weak relationship relations. Both nondeterministic and deterministic entity-relationship models have the same strength to characterize information concerning entities and relationships which exist in our minds. An improved table form of the relations is introduced to provide a clear and concise user's view of databases. The basic concept of the entity-relationship approach to the logical database design is provided, and is used to derive 3NF relations. FinaUly, a method of representing physicaly these relations, which are generated by the use of the entity-relationship approach to the logical database design, is presented. Thus, the entity-relationship approach to the logical and physical database design can also be realized.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.234511","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702805","Determinism and nondeterminism;entity-relationship approach;functional dependency;logical and physical database design;normal forms;relational;hierarchical;network models","Relational databases;Transaction databases;Data models;System analysis and design;Application software","","Determinism and nondeterminism;entity-relationship approach;functional dependency;logical and physical database design;normal forms;relational;hierarchical;network models","","10","","15","","","","","","IEEE","IEEE Journals & Magazines"
"An Approach and Mechanism for Auditable and Testable Advanced Transaction Processing Systems","R. D. Schultz; A. F. Cardenas","Abacus Programming Corporation; NA","IEEE Transactions on Software Engineering","","1987","SE-13","6","666","676","An architectural approach and a software mechanism is presented to enhance the auditability and testability of advanced transaction processing EDP systems. A high degree of auditability can be achieved through integrated support of auditability mechanisms as opposed to the traditional after-the-fact, ad hoc, add-on audit and test approaches. A programmable audit evidence gathering mechanism called an audit probe is proposed. A generic model of the audit probe is presented and its major features outlined. Audit hooks are proposed as standard probe interfaces for audit software. An overview of a high level audit-oriented audit probe definition language (APDL) for specifying the evidence gathering requirements for audit is highlighted. Audit test concurrent with the normal operation of the system and the capability of filtering only selected audit data are advocated. An example is presented illustrating the use of APDL and its value to auditing and quality control.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233204","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702272","Audit;auditability;audit definition language;audit hook;audit probe;quality control;software testing;transaction processing system","System testing;Probes;Quality control;Software testing;Transaction databases;Database systems;Management information systems;Software standards;Filtering;Proposals","","Audit;auditability;audit definition language;audit hook;audit probe;quality control;software testing;transaction processing system","","","","26","","","","","","IEEE","IEEE Journals & Magazines"
"Reusability Through Program Transformations","T. E. Cheatham","Center for Research in Computing Technology, Harvard University, Cambridge, MA 02138 and Software Options, Inc., Cambridge, MA 02138.","IEEE Transactions on Software Engineering","","1984","SE-10","5","589","594","We describe a methodology and supporting programming environment that provide for reuse of abstract programs. Abstract programs are written using notations and constructs natural to the problem domain in a language realized by syntactic extension of a base language. Program transformations are employed to refine an abstract program into its concrete counterpart. We discuss the use of the methodology in the setting of rapid prototyping and custom tailoring.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1984.5010282","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=5010282","Programming environments;program transformations;rapid prototyping;reusability;specification languages","Concrete;Computer languages;Prototypes;Programming profession;Programming environments;Specification languages;Costs;Maintenance;Software systems","","","","35","","7","","","","","","IEEE","IEEE Journals & Magazines"
"A Meeting Scheduler for Office Automation","K. Sugihara; T. Kikuno; N. Yoshida","Department of Information and Computer Scienees, University of Hawaii at Manoa. Honolulu. HI; NA; NA","IEEE Transactions on Software Engineering","","1989","15","10","1141","1146","Scheduling of meetings is one of the basic functions demanded in office automation, since office workers spend much time on meetings. This paper discusses a schedufkng problem of meetings and presents a meeting scheduler for office automation which provides an automatic mechanism for updating a schedule of meetings.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1989.559760","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=559760","","Office automation;Processor scheduling;Productivity;Pervasive computing;Heuristic algorithms;Scheduling algorithm;Information systems;Hardware;Face;Algorithm design and analysis","","Office automation;office information systems;optimization;productivity;scheduling","","17","","4","","","","","","IEEE","IEEE Journals & Magazines"
"Performance Evaluation of Centralized Databases with Static Locking","A. Thomasian","Hawthorne Research Laboratory, IBM Thomas J. Watson Research Center","IEEE Transactions on Software Engineering","","1985","SE-11","4","346","355","The performance of transaction processing systems is determined by the contention for hardware as well as software resources (database locks), due to the concurrency control mechanism of the database being accessed by transactions. We consider a transaction processing system with a set of dominant transcation classes. Each class needs to acquire a certain subset of the locks in the database before it can be processed, i.e., predeclared lock requests with static locking. Straightforward application of the decomposition method requires the numerical solution of a two-dimensional Markov chain. Equivalently, a hierarchical simulation method, where the computer system is represented by a composite queue with exponential service rates, can be used to analyze the system. We propose an inexpensive analytic solution method, also based on hierarchical decomposition, such that the throughput of the computer system ic characterized by the number of active transactions (regardless of class). Numerical results are provided to show that the new method is adequately accurate compared to the other two rather costly methods. It can be used to determine the effect of granularity of locking on system performance. The solution method is also applicable to multiresource queueing systems with multiple contention points.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232224","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702017","Approximate solution;concurrency control;decomposition hierarchical simulation;Markov chain;multiprogramming;queueing network model;queueing systems with multiple contention points;static locking;two-phase locking","Transaction databases;Hardware;Software performance;Concurrency control;Application software;Computational modeling;Analytical models;Computer simulation;Queueing analysis;Throughput","","Approximate solution;concurrency control;decomposition hierarchical simulation;Markov chain;multiprogramming;queueing network model;queueing systems with multiple contention points;static locking;two-phase locking","","26","","36","","","","","","IEEE","IEEE Journals & Magazines"
"The realizable benefits of a language prototyping language","R. M. Herndon; V. A. Berzins","Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA; NA","IEEE Transactions on Software Engineering","","1988","14","6","803","809","The uses and advantages of a language tailored specifically for the description and construction of translators are considered. The major features of the Kodiyak language prototyping language are described. The Kodiyak language was designed to be a comprehensive translator development system. The language is intended to support a simple, unambiguous conceptual model of translation, to allow the construction of nontrivial translators, and, to be easy to use.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6159","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6159","","Prototypes;Computer science;Application software;Computer errors;Computer languages;Software tools;Computational modeling;Character recognition;Art","high level languages;program interpreters;programming environments","attribute grammars;programming environments;language prototyping language;translators;Kodiyak;translator development system;conceptual model","","18","","27","","","","","","IEEE","IEEE Journals & Magazines"
"A cost model for determining the optimal number of software test cases","D. B. Brown; S. Maghsoodloo; W. H. Deason","Dept. of Comput. Sci. & Eng., Auburn Univ., AL, USA; Dept. of Comput. Sci. & Eng., Auburn Univ., AL, USA; Dept. of Comput. Sci. & Eng., Auburn Univ., AL, USA","IEEE Transactions on Software Engineering","","1989","15","2","218","221","A probabilistic model is presented that demonstrates the optimal number of software test cases required in situations where the following can be estimated as independent parameters: (1) the cost per test; (2) the cost per error if undetected until field implementation; (3) the number of software executions over its lifetime; (4) the number of possible different executions; and (5) the number of faults embedded in the software. A formula is derived by the use of calculus and is solved by approximation techniques. Tables of the optimal number of tests over a range of parameter values are presented to illustrate the results. The model serves as a basis for further research efforts to improve the accuracy of input variable estimation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.21747","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=21747","","Cost function;Software testing;Computer aided software engineering;Embedded software;Software systems;Life testing;Error analysis;Life estimation;Lifetime estimation;Parameter estimation","DP management;software engineering","cost model;optimal number;software test cases;probabilistic model;cost per test;cost per error;input variable estimation","","19","","15","","","","","","IEEE","IEEE Journals & Magazines"
"Flex: A High-Level Language for Specifying Customized Microprocessors","D. E. Comer; N. H. Gehani","Department of Computer Sciences, Purdue University; NA","IEEE Transactions on Software Engineering","","1985","SE-11","4","387","396","Researchers at Bell Labs have recently developed a silicon compiler, named Plex, that automatically generates VLSI layouts of high performance and area efficient microprocessors. Plex takes as input a specification of the function to be executed and generates a complete mask-level layout of a customized microprocessor to execute that function. The Plex microprocessor interacts with the external world, via input and output wires, and interrupts. The dedicated function performed by a Plex microprocessor typically involves real-time handling of inputs and interrupts-and the real-time generation of output signals.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232228","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702021","Concurrent programming;customized chips;customized microprocessors;microprocessor design;real-time programming language;VLSI;wafer computers","High level languages;Microprocessors;Wires;Very large scale integration;Silicon compiler;Assembly;Specification languages;Fingers;Logic;Read only memory","","Concurrent programming;customized chips;customized microprocessors;microprocessor design;real-time programming language;VLSI;wafer computers","","1","","7","","","","","","IEEE","IEEE Journals & Magazines"
"PROVIDE: a process visualization and debugging environment","T. G. Moher","Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA","IEEE Transactions on Software Engineering","","1988","14","6","849","857","The author introduces PROVIDE, a source-level process visualization and debugging environment currently under development at the University of Illinois at Chicago. PROVIDE is a modern coding and debugging environment that is designed to allow the user to configure interaction at a desired level of abstraction. It emphasizes the use of interactive computer graphics for the illustration of program execution, with special attention to the requirements of program debugging. The major features of PROVIDE are presented, especially the concepts of deferred-binding program animation, which allows users to interactively change the depiction of program execution during the debugging task, and process history consistency maintenance, which guarantees a consistent (automatically updated) record of program execution in the face of changes to program instructions and run-time data values. The current PROVIDE prototype is implemented on Macintosh workstations networked to a VAX 11/780 running 4.2 BSD Unix.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.6163","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6163","","Debugging;Computer graphics;Vehicle dynamics;History;Runtime;Data visualization;Trademarks;Automatic control;Facial animation;Prototypes","computer graphics;program debugging;programming environments","process visualization environment;PROVIDE;debugging environment;University of Illinois;interactive computer graphics;program execution;program debugging;deferred-binding program animation;process history consistency maintenance;Macintosh workstations;VAX 11/780;4.2 BSD Unix","","40","","25","","","","","","IEEE","IEEE Journals & Magazines"
"On Access Checking in Capability-Based Systems","R. Y. Kain; C. E. Landwehr","Department of Electrical Engineering, University of Minnesota; NA","IEEE Transactions on Software Engineering","","1987","SE-13","2","202","207","Public descriptions of capability-based system designs often do not clarify the necessary details concerning the propagation of access rights within the systems. A casual reader may assume that it is adequate for capabilities to be passed in accordance with the rules for data copying. A system using such a rule cannot enforce either the military security policy or the Bell and LaPadula rules. The paper shows why this problem arises and provides a taxonomy of capability-based designs. Within the space of design options defined by the taxonomy we identify a class of designs that cannot enforce the Bell-LaPadula rules and two designs that do allow their enforcement.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232892","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702200","Access control;capabilities;capability-based architectures;security policy;*;taxonomy","Data security;Permission;Taxonomy;Access control;Information security;Computer security;Information management;Government;Contracts;Laboratories","","Access control;capabilities;capability-based architectures;security policy;*;taxonomy","","10","","9","","","","","","IEEE","IEEE Journals & Magazines"
"Simulating the behavior of software modules by trace rewriting","Yabo Wang; D. L. Parnas","Dept. of Electr. & Comput. Eng., McMaster Univ., Hamilton, Ont., Canada; Dept. of Electr. & Comput. Eng., McMaster Univ., Hamilton, Ont., Canada","IEEE Transactions on Software Engineering","","1994","20","10","750","759","The trace assertion method is a module interface specification method based on the finite state machine model. To support this method, we plan to develop a specification simulation tool, a trace simulator, that symbolically interprets trace assertions of trace specifications and simulates the externally observable behavior of the modules specified. We first present the trace assertion method. Then we formally define trace rewriting systems and show how trace rewriting, a technique similar to term rewriting, can be applied to implement trace simulation.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.328996","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=328996","","Computational modeling;Discrete event simulation;Automata;Formal specifications;Software systems;System testing;Equations;Software tools;Software development management;Programming","finite state machines;rewriting systems;formal specification;simulation;digital simulation","software module behavior simulation;trace rewriting;trace assertion method;module interface specification method;finite state machine model;specification simulation tool;trace simulator;trace specifications;trace rewriting systems;term rewriting;trace simulation","","17","","20","","","","","","IEEE","IEEE Journals & Magazines"
"An interactive protocol synthesis algorithm using a global state transition graph","Y. -. Zhang; K. Takahashi; N. Shiratori; S. Noguchi","Res. Inst. of Electr. Commun., Tohoku Univ., Sendai, Japan; Res. Inst. of Electr. Commun., Tohoku Univ., Sendai, Japan; Res. Inst. of Electr. Commun., Tohoku Univ., Sendai, Japan; Res. Inst. of Electr. Commun., Tohoku Univ., Sendai, Japan","IEEE Transactions on Software Engineering","","1988","14","3","394","404","An interactive synthesis algorithm, to construct two communicating finite-state machines (protocols), is presented. The machines exchange messages over two unidirectional FIFI (first-in first-out) channels when the function of the protocol has been given. The synthesis algorithm first constructs the global state transition graph (GSTG) of a protocol to be synthesized and then produces the protocol. It is based on a set of production rules and a set of deadlock avoidance rules, which guarantee that complete reception and deadlock freeness capabilities are provided in the interacting process. This synthesis algorithm prevents a designer from creating unspecified reception and nonexecutable transition, avoids the occurrence of deadlocks, and monitors for the presence of buffer overflow.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4659","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4659","","Protocols;System recovery;Algorithm design and analysis;Buffer overflow;Automata","finite automata;graph theory;interactive programming;protocols","interactive protocol synthesis algorithm;global state transition graph;finite-state machines;global state transition graph;production rules;deadlock avoidance rules;complete reception;deadlock freeness;buffer overflow","","27","","20","","","","","","IEEE","IEEE Journals & Magazines"
"Mean value analysis for blocking queueing networks","I. F. Akyildiz","Sch. of Inf. & Comput. Sci., Georgia Inst. of Technol., Atlanta, GA, USA","IEEE Transactions on Software Engineering","","1988","14","4","418","428","An approximation is introduced for the mean value analysis of queueing networks with transfer blocking. The blocking occurs when a job, after completing service at a station, wants to join a station which is full. The job resides in the server of the source station until a place becomes available in the destination station. The approximation is based on the modification of mean residence times, due to the blocking events that occur in the network. Several examples are executed that validate the approximate results.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.4663","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=4663","","Queueing analysis;Network servers;Computer networks;State-space methods;Communication networks;Throughput;Performance evaluation;Computer science;Job listing service;Analytical models","performance evaluation;queueing theory","performance evaluation;mean value analysis;queueing networks;transfer blocking;destination station;mean residence times","","39","","22","","","","","","IEEE","IEEE Journals & Magazines"
"Two Complementary Course Sequences on the Design and Implementation of Software Products","J. E. Burns; E. L. Robertson","School of Information and Computer Science, Georgia Institute of Technology; NA","IEEE Transactions on Software Engineering","","1987","SE-13","11","1170","1175","For many students, the first chance to produce software as part of a team comes with the first work experience outside a university. The difficulties of working with others are compounded by the problems of working in a new environment and for a client with ambiguous and changing goals. Although it is difficult to approximate the ""real world"" accurately in an academic course, we have implemented two full-year course sequences which apparently give our students some insight into the problems they will face when they leave the university. One course requires the development and implementation of a software product by a team of undergraduates, and the other requires experienced graduate students to act as supervisors for the undergraduate projects. We describe the content and structure of these two sequences, emphasizing how they support and enhance each other. We believe other curricula would benefit from similar courses.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.232866","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702164","Computer science education;software engineering;software engineering management;software products;team projects","Software engineering;Computer science;Computer science education;Computer industry;Programming;Product design;Educational products;Educational programs;Project management;Engineering management","","Computer science education;software engineering;software engineering management;software products;team projects","","4","","14","","","","","","IEEE","IEEE Journals & Magazines"
"A Paradigm for the Design of Parallel Algorithms with Applications","I. V. Ramakrishnan; J. C. Browne","Department of Computer Science, University of Texas at Austin; NA","IEEE Transactions on Software Engineering","","1983","SE-9","4","411","415","This paper proposes a model or paradigm for the development of parallel algorithms, gives an example of the proposed paradigm, and displays algorithms developed by application of the technique. The algorithm for the merge of two ordered lists developed through application of this technique is thought to be original. The paradigm proposed is to create composite unit operations which combine data movement between data structures with a conventional operation such as compare or add. The composite operation constructed for this study is based upon partitioning the data elements into two linear lists. Exchange of data between adjacent elements in each list are then combined with compares and adds to complete the composite operations. This composite operation can be implemented on at least the following computational architectures.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1983.234777","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1703075","Data structures;parallel algorithms;set processing algorithms;sorting and merging","Algorithm design and analysis;Parallel algorithms;Parallel processing;Costs;Data structures;Computer architecture;Sorting;Concurrent computing;Computer networks;Merging","","Data structures;parallel algorithms;set processing algorithms;sorting and merging","","","","11","","","","","","IEEE","IEEE Journals & Magazines"
"Computer-aided software development process design","C. Y. Lin; R. R. Levary","Jet Propulsion Lab., California Inst. of Technol., Pasadena, CA, USA; Jet Propulsion Lab., California Inst. of Technol., Pasadena, CA, USA","IEEE Transactions on Software Engineering","","1989","15","9","1025","1037","The authors describe an intelligent tool designed to aid managers of software development projects in planning, managing, and controlling the development process of medium- to large-scale software projects. Its purpose is to reduce uncertainties in the budget, personnel, and schedule planning of software development projects. It is based on dynamic models for the software development and maintenance life-cycle process. This dynamic process is composed of a number of time-varying, interacting developmental phases, each characterized by its intended functions and requirements. System dynamics is used as a modeling methodology. The resulting software life-cycle simulator (SLICS) and the hybrid expert simulation system of which it is a subsystem are described.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.31362","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=31362","","Programming;Process design;Project management;Software development management;Process planning;Process control;Large-scale systems;Software tools;Uncertainty;Personnel","software engineering;software tools","computer-aided software development process design;management;control;system dynamics;intelligent tool;software development projects;budget;personnel;schedule planning;dynamic models;maintenance;time-varying;interacting developmental phases;software life-cycle simulator;SLICS;hybrid expert simulation system","","17","","23","","","","","","IEEE","IEEE Journals & Magazines"
"Programming in the large","C. V. Ramamoorthy; V. Garg; A. Prakash","Department of Electrical Engineering and Computer Sciences, Computer Science Division, University of California, Berkeley, CA 94720; Department of Electrical Engineering and Computer Sciences, Computer Science Division, University of California, Berkeley, CA 94720; Department of Electrical Engineering and Computer Sciences, Computer Science Division, University of California, Berkeley, CA 94720","IEEE Transactions on Software Engineering","","1986","SE-12","7","769","783","It is asserted that ad-hoc programming techniques do not work in the development of big software systems. The programs faced in developing large software include starting from fuzzy and incomplete requirements; enforcing a methodology on the developers; coordinating multiple programmers and managers; achieving desired reliability and performance in the system; managing a multitude of resources in a meaningful way; and completing the system within a limited time frame. The authors examine some of the trends in requirement specification; life cycle modeling; programming environments; design tools; and other software engineering areas for tackling the above problems. The authors suggest several phase-independent and phase-dependent techniques for programming in the large. It is shown how research in automatic programming, knowledge-based systems, metrics, and programming environments can make a significant difference in the ability to develop large systems.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1986.6312978","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=6312978","Information abstraction;knowledge-based systems;metrics;programming environments;reusability;software life cycle","Software;Measurement;Complexity theory;Software engineering;Libraries;Databases;Programming","automatic programming;programming environments;software engineering;software tools","programming techniques;requirement specification;life cycle modeling;programming environments;design tools;software engineering;phase-independent;phase-dependent;automatic programming;knowledge-based systems;metrics","","17","","","","","","","","IEEE","IEEE Journals & Magazines"
"Covert flow trees: a visual approach to analyzing covert storage channels","R. A. Kemmerer; P. A. Porras","Dept. of Comput. Sci., California Univ., Santa Barbara, CA, USA; Dept. of Comput. Sci., California Univ., Santa Barbara, CA, USA","IEEE Transactions on Software Engineering","","1991","17","11","1166","1185","The authors introduce a technique for detecting covert storage channels using a tree structure called a covert flow tree (CFT). CFTs are used to perform systematic searches for operation sequences that allow information to be relayed through attributes and eventually detected by a listening process. When traversed, the paths of a CFT yield a comprehensive list of operation sequences which support communication via a particular resource attribute. These operation sequences are then analyzed and either discharged as benign or determined to be covert communication channels. Algorithms for automating the construction of CFTs and potential covert channel operation sequences are presented. To illustrate this technique, two example systems are analyzed and their results compared to two currently accepted analysis techniques performed on identical systems. This comparison shows that the CFT approach not only identified all covert storage channels found by the other analysis techniques, but discovered a channel not detected by the other techniques.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.106972","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=106972","","Bandwidth;Timing;Tree graphs;Communication channels;Relays;Information analysis;Performance analysis;Inspection;Tree data structures;Multilevel systems","security of data;trees (mathematics)","covert storage channels;tree structure;covert flow tree;attributes;listening process;resource attribute;covert channel operation sequences","","28","","13","","","","","","IEEE","IEEE Journals & Magazines"
"Use of sequencing constraints for specification-based testing of concurrent programs","R. H. Carver; Kuo-Chung Tai","Dept. of Comput. Sci., George Mason Univ., Fairfax, VA, USA; NA","IEEE Transactions on Software Engineering","","1998","24","6","471","490","This paper presents and evaluates a specification-based methodology for testing concurrent programs. This methodology requires sequencing constraints, which specify restrictions on the allowed sequences of synchronization events. Sequencing constraints for a concurrent program can be derived from the program's formal or informal specification. Details of the proposed testing methodology based on the use of Constraints on Succeeding and Preceding Events (CSPE) are given. How to achieve coverage and detect violations of CSPE constraints for a concurrent program, according to deterministic and nondeterministic testing of this program, are described. A coverage criterion for CSPE-based testing is defined and analyzed. The results of empirical studies of CSPE-based testing for four concurrent problems are reported. These results indicate that the use of sequencing constraints for specification-based testing of concurrent programs is a promising approach.","0098-5589;1939-3520;2326-3881","","10.1109/32.689403","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=689403","","Software testing;Automata;Explosions;Computer science;Sequential analysis;Fault detection;Protocols;Event detection","parallel programming;formal specification;program testing;multiprocessing programs","sequencing constraints;specification-based testing;concurrent programs;synchronization events;informal specification;formal specification;nondeterministic testing;deterministic testing","","55","","42","","","","","","IEEE","IEEE Journals & Magazines"
"Experience with an approach to comparing software design methodologies","Xiping Song; L. J. Osterweil","Siemens Corp. Res. Inc., Princeton, NJ, USA; NA","IEEE Transactions on Software Engineering","","1994","20","5","364","384","Introduces a systematic and defined process called ""comparison of design methodologies"" (CDM) for objectively comparing software design methodologies (SDMs). We believe that using CDM will lead to detailed, traceable, and objective comparisons. CDM uses process modeling techniques to model SDMs, classify their components, and analyze their procedural aspects. Modeling the SDMs entails decomposing their methods into components and analyzing the structure and functioning of the components. The classification of the components illustrates which components address similar design issues and/or have similar structures. Similar components then may be further modeled to aid in more precisely understanding their similarities and differences. The models of the SDMs are also used as the bases for conjectures and analyses about the differences between the SDMs. This paper describes three experiments that we carried out in evaluating CDM. The first uses CDM to compare Jackson System Development (JSD) and Booch's (1986) object-oriented design. The second uses CDM to compare two other pairs of SDMs. The last one compares some of our comparisons with other comparisons done in the past using different approaches. The results of these experiments demonstrate that process modeling is valuable as a powerful tool in analysis of software development approaches.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.286419","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=286419","","Software design;Object oriented modeling;Design methodology;Power system modeling;Guidelines;Programming;Process design;Large-scale systems;Power system reliability;Software systems","software engineering;object-oriented methods","software design methodologies comparison;traceable comparisons;objective comparisons;process modeling techniques;procedural aspects;method decomposition;components classification;Jackson System Development;JSD;Booch's (1986) object-oriented design;BOOD;software development approaches;modeling formalism;software process","","16","","46","","","","","","IEEE","IEEE Journals & Magazines"
"Synchronized Distributed Termination","B. Szymanski; Yuan Shi; N. S. Prywes","Department of Computer Science, Rensselear Polytechnic Institute; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","10","1136","1140","An efficient decentralized algorithm for synchronized termination of a distributed computation is presented. It is assumed that distributed processes are connected via unidirectional channels into a strongly connected network, in which no central controller exists. The number of processes and the network configuration are not known a priori. The number of steps required to terminate distributed computation after all processes met their local termination conditions is proportional to the diameter D of the network (D + 1 steps).","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231861","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701929","Decentralized algorithms;distributed programming;distributed systems;networks;termination detection","Computer networks;Communication channels;Distributed computing;Algorithm design and analysis;Information science;Centralized control;Computer science;Performance evaluation;Detection algorithms;Forward contracts","","Decentralized algorithms;distributed programming;distributed systems;networks;termination detection","","6","","10","","","","","","IEEE","IEEE Journals & Magazines"
"Hierarchical reachability graph of bounded Petri nets for concurrent-software analysis","M. Notomi; T. Murata","Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA; Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA","IEEE Transactions on Software Engineering","","1994","20","5","325","336","Petri nets have been proposed as a promising tool for modeling and analyzing concurrent-software systems such as Ada programs and communication protocol software. Among analysis techniques available for Petri nets, the most general approach is to generate all possible states (markings) of the system in a form of a so-called reachability graph. However, this conventional reachability graph approach is inefficient or intractable, even for a bounded Petri net, due to state explosion in many practical applications. To cope with this problem, this paper proposes a method for constructing a hierarchically organized state space called the hierarchical reachability graph (HRG). Using the HRG, we obtain necessary and sufficient conditions for reachability and deadlock, as well as algorithms to test whether a given state or marking is reachable from the initial state and whether there is a deadlock state (a state with no successor states).<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.286423","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=286423","","Petri nets;State-space methods;System recovery;Communication system software;Testing;Protocols;Explosions;Sufficient conditions;Software tools;Reachability analysis","Petri nets;state-space methods;multiprocessing programs;software engineering;hierarchical systems","hierarchical reachability graph;bounded Petri nets;concurrent-software analysis;Ada programs;communication protocol software;markings;state explosion;efficiency;tractability;hierarchically organized state space;deadlock state;successor states","","56","","24","","","","","","IEEE","IEEE Journals & Magazines"
"Time scale decomposition of a class of generalized stochastic Petri net models","H. H. Ammar; S. M. R. Islam","Dept. of Electr. & Comput. Eng., Clarkson Univ., Potsdam, NY, USA; Dept. of Electr. & Comput. Eng., Clarkson Univ., Potsdam, NY, USA","IEEE Transactions on Software Engineering","","1989","15","6","809","820","A time-scale decomposition (TSD) algorithm of a class of generalized stochastic Petri net (GSPN) models of systems comprising activities whose duration differ by orders of magnitude is presented. The GSPN model of a system can be decomposed into a hierarchical sequence of aggregated subnets, each of which is valid at a certain time scale. These smaller subnets are solved in isolation and their solutions are combined to get the solution of the whole system. A degradable multiprocessor system which would be intractable using conventional techniques, is analyzed using TSD. The complexity of the TSD algorithm can be orders of magnitude smaller without any significant loss in the accuracy of the result. In general, the error due to aggregation is proportional to the maximum degree of coupling between aggregates. An expression of the error due to aggregation is also given in terms of the ratio of fast and slow transitions in the GSPN model. The algorithm is easy to use and can be easily automated.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.24734","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=24734","","Stochastic processes;Stochastic systems;Fires;Degradation;Multiprocessing systems;Telecommunication network reliability;Performance analysis;Petri nets;Concurrent computing","multiprocessing systems;performance evaluation;Petri nets;stochastic processes","generalized stochastic Petri net models;time-scale decomposition;GSPN model;hierarchical sequence;aggregated subnets;degradable multiprocessor system;complexity;TSD algorithm;aggregation;coupling;slow transitions","","51","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Mapping the Interface Description Language type model into C","K. Shannon; R. Snodgrass","Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA; Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA","IEEE Transactions on Software Engineering","","1989","15","11","1333","1346","The Interface Description Language (IDL) is a notation for describing the characteristics of data structures passed among collections of cooperating processes in a programming environment. The authors discuss a mapping from IDL to C data structures and macro definitions that supports the full language and is type safe and run-time efficient, but is not particularly compile-time efficient nor easy to use. They then propose that the mapping be performed in a preprocessor, thereby achieving efficiency and ease of use as well.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.41327","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=41327","","Data structures;Runtime;Programming environments;Computer languages;Computer science;Programming profession;Application software;Computerized monitoring;Program processors","C language;data structures;high level languages;programming environments","Interface Description Language type model;cooperating processes;programming environment;mapping;IDL;C data structures;macro definitions;type safe;run-time efficient;preprocessor;efficiency;ease of use","","","","41","","","","","","IEEE","IEEE Journals & Magazines"
"Parallaxis-III: architecture-independent data parallel processing","T. Braunl","Dept. of Electr. & Electron. Eng., Western Australia Univ., Nedlands, WA, Australia","IEEE Transactions on Software Engineering","","2000","26","3","227","243","Parallaxis-III is an architecture-independent data parallel programming language based on Modula-2. It has been designed for teaching data parallel concepts and is in use at a large number of institutions. Compilers exist for data parallel systems, as well as for a sequential simulation system. A data parallel graphics debugger allows efficient source level analysis for parallel programs.","0098-5589;1939-3520;2326-3881","","10.1109/32.842949","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=842949","","Parallel processing;Parallel programming;Computational modeling;Concurrent computing;Education;Data visualization;Computer simulation;Computer languages;Iterative algorithms;Parallel languages","parallel programming;parallel languages;program debugging;data visualisation;virtual machines","Parallaxis-III;architecture-independent data parallel processing;data parallel programming language;Modula-2;compilers;sequential simulation system;data parallel graphics debugger;source level analysis;parallel programs","","1","","21","","","","","","IEEE","IEEE Journals & Magazines"
"Component based design of multitolerant systems","A. Arora; S. S. Kulkarni","Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA; NA","IEEE Transactions on Software Engineering","","1998","24","1","63","78","The concept of multitolerance abstracts problems in system dependability and provides a basis for improved design of dependable systems. In the abstraction, each source of undependability in the system is represented as a class of faults, and the corresponding ability of the system to deal with that undependability source is represented as a type of tolerance. Multitolerance thus refers to the ability of the system to tolerate multiple fault classes, each in a possibly different way. We present a component based method for designing multitolerance. Two types of components are employed by the method, namely detectors and correctors. A theory of detectors, correctors, and their interference free composition with intolerant programs is developed, which enables stepwise addition of components to provide tolerance to a new fault class while preserving the tolerances to the previously added fault classes. We illustrate the method by designing a fully distributed multitolerant program for a token ring.","0098-5589;1939-3520;2326-3881","","10.1109/32.663998","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=663998","","Detectors;Design methodology;Interference;Fault detection;Fault tolerant systems;Security;Abstracts;Token networks;Degradation;Safety","software fault tolerance;systems analysis;formal specification;token networks","component based design;multitolerant systems;undependability;system dependability;dependable systems design;undependability source;component based method;multitolerance;correctors;detectors;interference free composition;intolerant programs;stepwise addition;previously added fault classes;fully distributed multitolerant program;token ring","","41","","27","","","","","","IEEE","IEEE Journals & Magazines"
"An Analysis of the Effect of Network Parameters on the Performance of Distributed Database Systems","A. P. Sheth; A. Singhal; M. T. Liu","Department of Computer and Information Science, Ohio State University; NA; NA","IEEE Transactions on Software Engineering","","1985","SE-11","10","1174","1184","Performance analysis studies of distributed database systems in the past have assumed that the message transmission time between any two nodes of a network is constant. They disregard the effect of communication network parameters such as network traffic, network topology, and capacity of transmission channels. In this paper, an analytical model is used to estimate the delays in transmission channels of the long haul network supporting the distributed database system. The analysis shows that the constant transmission time assumption cannot be justified in many cases, and that the response time is sensitive to the parameters mentioned above. Extensions and performance analysis in the context of interconnection networks are also discussed.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.231865","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701933","Concurrency control;distributed databases;interconnection network;long haul network;network topology;queueing analysis;response time;utilization","Performance analysis;Database systems;Delay estimation;Communication networks;Telecommunication traffic;Traffic control;Network topology;Channel capacity;Analytical models;Multiprocessor interconnection networks","","Concurrency control;distributed databases;interconnection network;long haul network;network topology;queueing analysis;response time;utilization","","6","","21","","","","","","IEEE","IEEE Journals & Magazines"
"A Controlled Experiment Quantitatively Comparing Software Development Approaches","V. R. Basili; R. W. Reiter","Department of Computer Science, University of Maryland; NA","IEEE Transactions on Software Engineering","","1981","SE-7","3","299","320","A software engineering research study has been undertaken to empirically analyze and compare various software development approaches; its fundamental features and initial findings are presented in this paper. An experiment was designed and conducted to confirm certain suppositions concerning the beneficial effects of a particular disciplined methodology for software development. The disciplined methodology consisted of programming teams employing certain techniques and organizations commonly defined under the umbrella term structured programming. Other programming teams and individual programmers both served as control groups for comparison. The experimentally tested hypotheses involved a number of quantitative, objective, unobtrusive, and automatable measures of programming aspects dealing with the software development process and the developed software product. The experiment's results revealed several programming aspects for which statistically significant differences existed between the disciplined methodology and the control groups. The results were interpreted as confirmation of the original suppositions and evidence in favor of the disciplined methodology. This paper describes the specific features of the experiment; outlines the investigative approach used to plan, execute, and analyze it; reports its immediate results; and interprets them according to intuitions regarding the disciplined methodology.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1981.230841","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702844","Controlled experimentation;empirical study;programming measurement;programming methodology;programming teams;software development;software metrics;structured programming practices","Software measurement;Automatic control;Computer science;Software engineering;Programming profession;Production;Application software;Programming environments;Automatic testing;Software testing","","Controlled experimentation;empirical study;programming measurement;programming methodology;programming teams;software development;software metrics;structured programming practices","","42","","28","","","","","","IEEE","IEEE Journals & Magazines"
"Kit: a study in operating system verification","W. R. Bevier","Comput. Logic Inc., Austin, TX, USA","IEEE Transactions on Software Engineering","","1989","15","11","1382","1396","The author reviews Kit, a small multitasking operating system kernel written in the machine language of a uniprocessor von Neumann computer. The kernel is proved to implement on this shared computer a fixed number of conceptually distributed communicating processes. In addition to implementing processes, the kernel provides the following verified services: process scheduling, error handling, message passing, and an interface to asynchronous devices. As a by-product of the correctness proof, security-related results such as the protection of the kernel from tasks and the inability of tasks to enter supervisor mode are proved. The problem is stated in the Boyer-Moore logic, and the proof is mechanically checked with the Boyer-Moore theorem prover.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.41331","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=41331","","Operating systems;Kernel;Multitasking;Message passing;Processor scheduling;Protection;Military computing;Logic;Switches;Distributed computing","multiprogramming;operating systems (computers);program verification;theorem proving","verification;Kit;multitasking operating system kernel;machine language;uniprocessor von Neumann computer;conceptually distributed communicating processes;process scheduling;error handling;message passing;interface;asynchronous devices;correctness proof;security-related results;supervisor mode;Boyer-Moore logic;Boyer-Moore theorem prover","","29","","39","","","","","","IEEE","IEEE Journals & Magazines"
"A Paradigm for Developing Information Systems","B. I. Blum","Applied Physics Laboratory, The Johns Hopkins University","IEEE Transactions on Software Engineering","","1987","SE-13","4","432","439","This paper describes a paradigm for implementing software in which 1) a database is used to maintain virtually all recorded information about the application and 2) the executable product is generated directly from the formal specifications. A specific environment, TEDIUM, defined for a specific application class, the interactive information system, is presented as a proof of concept. The benefits of this paradigm are evaluated briefly, and the characteristics associated with its in productivity improvement are identified.","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1987.233180","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1702235","Information systems;integrated tool sets;life cycle environments productivity tools;program generation","Information systems;Databases;Application software;Productivity;Code standards;Software maintenance;Formal specifications;Hardware;Documentation;Testing","","Information systems;integrated tool sets;life cycle environments productivity tools;program generation","","2","","18","","","","","","IEEE","IEEE Journals & Magazines"
"Estimeetings: development estimates and a front-end process for a large project","L. M. Taff; J. W. Borchering; W. R. Hudgins","AT&T Bell Lab., West Long Branch, NJ, USA; NA; NA","IEEE Transactions on Software Engineering","","1991","17","8","839","849","A method for estimating software development effort in the early phases of a large software-intensive project and a front-end process incorporating this method are presented. The application of this methodology to the domestic US 5ESS Switch project (a large multiyear continuing effort, with new features incorporated into yearly releases) is described. For each feature to be estimated, a feature team generates a detailed feature definition with high-level functionality requirements and a high-level design proposal. These are used in a formal working meeting of estimators from affected parts of the project. The meeting produces a development estimate for use in deciding which features to include in the next release. The benefits of this methodology include well-defined milestones (high-level features requirements, high-level designs and estimates), and less tangible benefits like better working relationships between parts of the project, interorganizational synergy and increased confidence in the front-end process.<<ETX>>","0098-5589;1939-3520;2326-3881","","10.1109/32.83918","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=83918","","Switches;Phase estimation;Programming;Proposals;Software systems;Productivity;Application software;Project management;Software performance;Trademarks","DP management;human factors;personnel;project engineering;software engineering;telecommunications computing","estimeeting methodology;software development effort;large software-intensive project;front-end process;domestic US 5ESS Switch project;feature team;feature definition;high-level functionality requirements;high-level design proposal;formal working meeting;development estimate;well-defined milestones;high-level designs;working relationships;interorganizational synergy","","7","","11","","","","","","IEEE","IEEE Journals & Magazines"
"IEEE Finding Your Way","","","IEEE Transactions on Software Engineering","","1985","SE-11","12","1517","1517","","0098-5589;1939-3520;2326-3881","","10.1109/TSE.1985.232183","","https://ieeexplore-ieee-org.ezproxy.gsu.edu/stamp/stamp.jsp?arnumber=1701976","","","","","","","","","","","","","","IEEE","IEEE Journals & Magazines"
